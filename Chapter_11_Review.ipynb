{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing and Exploding gradients problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return(1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5,5,200)\n",
    "plt.figure(figsize=(13,8))\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "\n",
    "plt.plot(z,logit(z),\"b-\",linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\",size=18)\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\",size=18)\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\",size=18)\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier and He initlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape =(None,n_inputs),name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-da109dac52d3>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "he_init = tf.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                          kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.init_ops.VarianceScaling at 0x640df9940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/Relu:0' shape=(?, 300) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturing activation functions\n",
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha = 0.01):\n",
    "    return(np.maximum(alpha*z,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAFDCAYAAAByT6QaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9b3/8dcnCZCF9YrmIl4FodQFi0bkV1uupmorvWCxgooFK0oNLqj4UJS6QcWlraLFokW8EWUTAXcrPrRIxKXaolAVLrggaBEElARiEhKS7++P76AhJCEhc+bM8n4+HvPwZGaY856Tcd4569ecc4iIiEhw0sIOICIikuxUtiIiIgFT2YqIiARMZSsiIhIwla2IiEjAVLYiIiIBU9lKXDCzIjObGnaOZGBm+WbmzKxzDOa1zsyujcF8jjCzv5tZhZmtC3p+TcjjzGxo2DkkcahsZZ/M7BEzez7sHM0VKXAXuVWa2SdmdqeZtWnm64w0s9J9zGevPxT29e+ioYGyexPoAnwVxflMNLMP6nnoBOCBaM2nEbcBZcARkXnGRCOf/S7Ac7HKIYkvI+wAIgGbAdwAtMZ/Sc+I3P/b0BIFzDlXCWyK0by2xGI+QE/gGefcuhjNr1HOuZgsX0keWrOVFjOzDmY23cw2m9kOM3vVzPrWevwAM3vMzP5tZuVmttLMLtzHa55qZsVmNtrMTjKzKjP7zzrPud3M3ttHvDLn3Cbn3GfOuSeAl4Gf1XmdrmY2z8y2RW5/NbPvNXMx7Bcz+72ZrYksl3Vm9kczy6zznIFm9nbkOV+Z2XNmlmlmRcBhwF271+Ajz/92M3Lkd1NuZmfUec2fRZbpQfvKYWYjgQnA0bW2FIyMPLbHmrWZHWpmT0U+BzvM7EkzO6TW4xPN7AMzGxbZ0rDDzJ5ubJN35H31AW6JzHuimXWLTPet+9zdm3drPWeImb1sZmVmtsrMflrn3xxhZs+aWYmZlUY2Vx9jZhOBC4CBtd53ft35RH4+xsz+Fll+X0fWiDvUevwRM3vezK4ysw2Rz9kMM8tu6H1LclHZSouYmQF/BboCg4DjgKXAK2bWJfK0TODdyONHA1OAB83s1AZecwjwFFDgnHvQObcU+AT4da3npEV+LmxG1j7Aj4GqWvdlA0uACuBk4ERgI/C3GH0RfgNcBBwJXAYMA26slW8A8Az+j4TjgZ8Ar+L/3z0L+DdwK36zZhfqcM6VAM8Dw+s8NBx4yTm3uQk5HgcmA2tqzefxuvOKfBaeBnKBUyJZDwaejjy2WzfgXOCX+D98jgNub2D5EJnfmkiGLsDdjTy3PrcD9+EL+5/APDNrG8l8MPA64ICfAnnA/UB6ZD7zgb/Vet9v1vO+s4EXgVKgX+R9/Qh4uM5T/xvoDZzGd+//qma+F0lUzjnddGv0BjwCPN/AY6fgv2Sy6ty/AriukdecB/xvrZ+LgKlAAVAC/KzO868F/q/Wzz8HdgIHNDKPIqAykm8n/gu1GhhS6zkXAR8BVuu+dPz+znMiP48ESvcxn6n13N/ov2vgtS4BPq718xvAvEaevw64ts59+ZH32jny82D8/s52kZ+zgO3Aec3IMRH4oLH548uqGuhW6/HDgRrgtFqvUwF0qPWcG2vPq4E8HwATa/3cLfIe+9Z5ngOG1nnO6FqPd43c1z/y8+3AeqB1cz77deZzceQz266e30HPWq/zOZBR6zkPAX/bn/8ndUu8m9ZspaWOB7KBLZFNcKXmDwrqDfQAMLN0M7vRzN6LbAYtxa+VHVrntQbj1yoGOOdeqvPYo8DhZvajyM8XAU875/Z1ENDjwLH4Ndb5wEPOb06unb87sKNW9hKg0+78QTKzoWb2upltisz7XvZcLscBi1s4mxfwZfvLyM+/AAy/xtzUHE1xJPCFq7Vf1Tm3FvgCOKrW89Y7v8a92xfAQc2cV3PU3tXwReS/u+d3HPC68/u599eRwHvOuR217nsT/0dG7fe9yjm3q06WIN+3xBEdICUtlQZ8id9EVtf2yH+vBa7BbzJ7H7+meQd7f9G8h18bGGVmbznnvh2Syjm3xcyeBS4yszX4wjiDfStxzn0MYGYjgJVmNtI590it/Cvwm03r+roJrw/+fXao5/6O+OKul5n9EL+G/zvgaqAY/76au5m0Uc65KjNbgN90PDPy3yedc2VRzmH431+9MWpNV9XzWHP/8K+pNU8/Ydaqged+Oz/nnIts0d49P6v3XzRPLN+3JCiVrbTUu/h9dDWRtZj69Aeec87Ngm/37fXCf6nX9ilwBX6z7HQzK6hduPjNbguBtfiC/1tzgkZK5w7gTjObHymbd4HzgK3Oubp5mmoN8D9mZnXy5kUea8iPgQ3OuUm77zCzw+o8ZzlwKv6916cSv9l7X2YDr5rZUcAAYGAzczRlPquArmbWbffarZkdjt9vu6oJGZtj91HQtfdTH7sfr/MuMMLMWjewdtvU932RmbWrtXb7I3yR/t9+ZJIkpL+qpKnam9mxdW7d8IX3BvCMmf3czLqb2Ylm9jsz2722+yFwqpn1N7Mj8Ptmu9c3k0hh/wRfCNPrHFjzMn5f6gRghnOupp6X2Je5+DWKMZGf5+CL+xkzOzmS/yQzm2x7HpGcVs/77x157C/4fZN/NrM+ZvZ9M7saX+KNrR1+iC+n4WZ2uJldGvk3td0OnG1mt5nZUWZ2tJldXevgrXXAf5s/orrBI3qdc2/g903OBbYCrzQzxzrgMDPLM3+Uc33nKv8N+Bcwx8yON3+k8Bx8ob1Sz/P3m3OuHHgLuD6yTH7E/m0ReABoC8w3sxPMrKeZnWdmu4t7HdA78jvt3MDa8xz8AWYzzR+VfBLwIH7rwcf7kUmSkMpWmuq/8WtZtW93R9bk/gf/ZfoQfk1uPvB9vts/dhvwD2AR/kjlb/BfUPVyzn2CP8BkAP6oZYvc7/Dnybbiu/NlmyWy9jIVuC6yJlIGnIRfW14ArMbvH+4EbKv1T7Pqef9FkddcG3mN7wEvRd7rMOBs59wLjWR5DrgL+BN+E/pPgVvqPOcF/L7Wn0fm+Sr+j5Hdf2jcAvwX/mjtfZ3zOgd/RO5jzrnq5uQAnsDv+10cmU/dMt79+zkz8ngR/ijvTcCZddb4o+WiyH//iS+3m5r7As65DfjfXWt83uX4rSu7960+hF87XYZ/Xz+u5zXKgNOB9vjf/TPA32vlE/FHYIokCjP7C/4Iz5/u88kiInFC+2wlIZi/QMDx+HNrzwk5johIs6hsJVE8g79gQKFz7q9hhxERaQ5tRhYREQmYDpASEREJmMpWREQkYIHts+3cubPr1q1bUC8fdd988w05OTlhx0h6Ws7BWrNmDdXV1Rx11FH7frLsN32OY6Oh5VxeDv/3f+AcHHYYdG7wDPPYeuedd7Y65w6s77HAyrZbt24sW7YsqJePuqKiIvLz88OOkfS0nIOVn59PcXFxQv2/l4j0OY6N+pZzSQn07euL9sILobAQLBoX3YwCM1vf0GPajCwiIgnBORg5Ej7+GPr0gfvvj5+i3ReVrYiIJITJk+Hpp6FDB1i4ELKywk7UdCpbERGJe6++CuPH++lHH4WePcPN01wqWxERiWsbN8K550J1NVx/PQweHHai5lPZiohI3Kqq8kX75ZeQnw+33RZ2ov2jshURkbh1ww3w2mvQpQvMmwcZCXqR4WaVrZl9z8wqzGx2UIFEREQAli7tzN13Q3o6zJ8PublhJ9p/zV2zvR8/dqSIiEhgPvwQ/vCHIwC46y7o3z/kQC3U5LI1s2FAMX7waBERkUCUlcHQoVBWlsHQoTB2bNiJWq5JZWtm7YFbgWuCjSMiIqnMObjkEnj/ffiv/yqLqytEtURTdzVPwo8j+rk18q7NrAAoAMjNzaWoqKjFAWOltLQ0ofImKi3nYBUXF1NdXa1lHDB9joPz7LNdmDXr+2RmVnP99f/k3XeTYxjYfZatmR0LnAYct6/nOuemA9MB+vbt6xLp2qG61mlsaDkHq2PHjhQXF2sZB0yf42AsW+YvwQjwv/+bTteuLmmWc1PWbPOBbsBnkbXatkC6mR3lnMsLLpqIiKSKr77y+2krK+Gyy2D4cEimjQdNKdvpwLxaP1+LL99LgwgkIiKppaYGzj8f1q+Hfv3gnnvCThR9+yxb51wZULb7ZzMrBSqcc1uCDCYiIqnh9tth0SI44ABYsADatAk7UfQ1+1oczrmJAeQQEZEU9NJLMGGCP+J4zhw49NCwEwVDl2sUEZFQfPYZ/OpX/nSfCRPg9NPDThQcla2IiMTczp1w9tn+wKgBA+Dmm8NOFCyVrYiIxNw118A//uE3G8+eDWlJ3kZJ/vZERCTezJ3rz6dt3RoWLvQHRiU7la2IiMTMypVw8cV+esoUOOGEcPPEispWRERiYscOGDLEDzQwYgSMHh12othR2YqISOCcg1GjYM0a6N0bpk1LjgEGmkplKyIigZsyxV+wol07eOIJyMkJO1FsqWxFRCRQb7wB48b56RkzoFevcPOEQWUrIiKB+fJLOOcc2LXLn+4zZEjYicKhshURkUDs2gXnnQdffAH9+8Odd4adKDwqWxERCcQtt8CSJZCbC48/Dq1ahZ0oPCpbERGJumef9Wuy6em+aA8+OOxE4VLZiohIVK1dC7/+tZ++4w44+eRw88QDla2IiERNebk/CKqkBM4887ujkFOdylZERKJmzBhYsQJ69PCn+aTShSsao7IVEZGoKCyEhx+GzEx/4YqOHcNOFD9UtiIi0mLLl8Pll/vpadOgT59w88Qbla2IiLTItm0wdKgfEP7ii+GCC8JOFH9UtiIist9qany5rl0LeXlw331hJ4pPKlsREdlvf/gDPPccdOrkB4LPzAw7UXxS2YqIyH555RW46SY/PWsWdO8ebp54prIVEZFm27ABhg3zm5FvugkGDgw7UXxT2YqISLNUVfmRfLZsgdNOg4kTw04U/1S2IiLSLNddB2++CYccAnPn+usfS+NUtiIi0mTz58Of/uRH8FmwAA48MOxEiUFlKyIiTbJ6NYwa5acnT4Yf/jDcPIlEZSsiIvtUWuoHGCgt9QdGjRkTdqLEorIVEZFGOQcFBbBqFRx5JDz0kAYYaC6VrYiINOqBB+CxxyAnxw8w0LZt2IkSj8pWREQa9NZbcPXVfrqw0K/ZSvOpbEVEpF5btsDZZ/vzaq+8Es49N+xEiUtlKyIie6muhuHD4d//hhNPhLvuCjtRYlPZiojIXn73O3j5Zejc2Z9b27p12IkSm8pWRET28MILMGkSpKXBvHn+SlHSMipbERH51rp1MGKEn540CU49NdQ4SUNlKyIiAFRUwNChsG0bDBoE48eHnSh5qGxFRASAsWPhnXegWzeYOdNvRpbo0KIUERFmzoQHH4Q2bfyFKzp1CjtRclHZioikuPfeg0su8dNTp0JeXrh5kpHKVkQkhZWU+AEGysvhwgu/G9VHoktlKyKSopzzBfvxx9CnD9x/vwYYCIrKVkQkRU2eDE89BR06wMKFkJUVdqLkpbIVEUlBS5d+d2rPo49Cz57h5kl2KlsRkRSzcaMfVKC6Gq6/HgYPDjtR8lPZioikkKoqX7SbNkF+Ptx2W9iJUoPKVkQkhdxwA7z2GnTp4q97nJERdqLUoLIVEUkRTz4Jd98N6el+JJ/c3LATpY4mla2ZzTazjWa23cw+NLPfBB1MRESi56OP/Gk+4Mem7d8/3DyppqlrtncC3Zxz7YFfALeZ2fHBxRIRkWgpK/MXrti+3Q80MHZs2IlST5PK1jm30jm3c/ePkVuPwFKJiEhUOOcvxfj++9CrFxQW6sIVYWjyrnEzewAYCWQBy4EX6nlOAVAAkJubS1FRUVRCxkJpaWlC5U1UWs7BKi4uprq6Wss4YIn0OX722S7MmvV9MjOrGT/+Xd5995uwIzVZIi3nfTHnXNOfbJYOnAjkA39wzlU19Ny+ffu6ZcuWtThgrBQVFZGfnx92jKSn5Rys/Px8iouLWbFiRdhRklqifI6XLYMf/xgqK2H2bBg+POxEzZMoy3k3M3vHOde3vseadTSyc67aOfc6cAhwaTTCiYhI9H31ld8/W1kJl12WeEWbbPb31J8MtM9WRCQu1dTA+efD+vXQrx/cc0/YiWSfZWtmB5nZMDNra2bpZnY6cB7wSvDxRESkuW6/HRYtggMOgAUL/IDwEq6mHCDl8JuMp+HLeT0w1jn3TJDBRESk+V56CSZM8Eccz5kDhx4adiKBJpStc24LcHIMsoiISAt89hn86lf+dJ+JE+H008NOJLvpco0iIkmgshLOOccfGDVgANx8c9iJpDaVrYhIErjmGnj7bb/ZePZsSNO3e1zRr0NEJMHNnQtTp0Lr1rBwoT8wSuKLylZEJIGtXAkXX+ynp0yBE04IN4/UT2UrIpKgduzwAwyUlcGIETB6dNiJpCEqWxGRBOQcjBoFa9ZA794wbZoGGIhnKlsRkQQ0ZYq/YEW7dvDEE5CTE3YiaYzKVkQkwbzxBowb56dnzPBD50l8U9mKiCSQzZv9+bS7dvnTfYYMCTuRNIXKVkQkQezaBcOGwRdfQP/+cOedYSeSplLZiogkiFtugSVLIDcXHn8cWrUKO5E0lcpWRCQBPPusX5NNT/dFe/DBYSeS5lDZiojEubVr4de/9tN33AEna2iYhKOyFRGJY+Xl/iCokhI488zvjkKWxKKyFRGJY1dcAStWQI8e/jQfXbgiMalsRUTiVGGhv2Vm+gtXdOwYdiLZXypbEZE4tHw5XH65n542Dfr0CTePtIzKVkQkzmzbBkOHws6dfkSfCy4IO5G0lMpWRCSO1NT4cl27FvLy4L77wk4k0aCyFRGJI3/8Izz3HHTq5AeCz8wMO5FEg8pWRCROvPIK3Hijn541C7p3DzePRI/KVkQkDmzY4K97XFMDN90EAweGnUiiSWUrIhKyqio/ks+WLXDaaTBxYtiJJNpUtiIiIbvuOnjzTTjkEJg711//WJKLylZEJEQLFsCf/gQZGTB/Phx4YNiJJAgqWxGRkKxeDRdd5KfvuQdOPDHcPBIcla2ISAhKS/0AA6Wl/sCoMWPCTiRBUtmKiMSYc1BQAKtWwZFHwkMPaYCBZKeyFRGJsQcegMceg5wcP8BA27ZhJ5KgqWxFRGLorbfg6qv9dGGhX7OV5KeyFRGJkS1b4Oyz/Xm1V14J554bdiKJFZWtiEgMVFfD8OHw73/7o47vuivsRBJLKlsRkRi49VZ4+WXo3NmfT9u6ddiJJJZUtiIiAXvhBV+2aWkwb56/UpSkFpWtiEiA1q2DESP89KRJcOqpocaRkKhsRUQCUlEBQ4fCtm0waBCMHx92IgmLylZEJCBjx8I770C3bjBzpt+MLKlJv3oRkQDMnAkPPght2vgLV3TqFHYiCZPKVkQkyt57Dy65xE9PnQp5eeHmkfCpbEVEoqikxA8wUF4OF14Io0aFnUjigcpWRCRKnPMF+/HH0KcP3H+/BhgQT2UrIhIlkyfDU09Bhw6wcCFkZYWdSOKFylZEJAqWLv3u1J5HH4WePcPNI/FFZSsi0kIbN/pBBaqr4frrYfDgsBNJvFHZioi0wK5dMGwYbNoE+flw221hJ5J4pLIVEWmBG27wm5C7dPHXPc7ICDuRxCOVrYjIfnryST9UXnq6H8knNzfsRBKv9lm2ZtbGzArNbL2Z7TCz5Wb281iEExGJVx995E/zAV+4/fuHm0fiW1PWbDOAz4GTgQ7AzcB8M+sWXCwRkfhVUZHGkCGwfbsfaGDs2LATSbzb594F59w3wMRadz1vZp8CxwPrgoklIhKfnIN77+3F++9Dr15QWKgLV8i+NXufrZnlAr2AldGPIyIS3x56CF566T/JzvYDDLRvH3YiSQTNOm7OzFoBc4BHnXOr63m8ACgAyM3NpaioKBoZY6K0tDSh8iYqLedgFRcXU11drWUckDVr2nHFFccBaYwdu4qtWzejRR2cZPq+MOdc055olgbMBdoDg51zVY09v2/fvm7ZsmUtTxgjRUVF5Ofnhx0j6Wk5Bys/P5/i4mJWrFgRdpSk89VXcPzxsH49DB68gaef7hp2pKSXaN8XZvaOc65vfY81aTOymRlQCOQCQ/ZVtCIiyaSmBs4/3xdtv35w2WUfhx1JEkxT99n+BTgSOMM5Vx5gHhGRuHP77bBoERxwACxYAK1bN22LoMhuTTnP9jBgNHAssMnMSiO34YGnExEJ2csvw4QJ/ojjOXPg0EPDTiSJqCmn/qwHdGC7iKSczz6D887zp/tMnAinnx52IklUulyjiEg9KivhnHP8gVEDBsDNN4edSBKZylZEpB7XXANvv+03G8+eDWn6tpQW0MdHRKSOuXNh6lRo3RoWLvQHRom0hMpWRKSWlSvh4ov99JQpcMIJ4eaR5KCyFRGJ2LEDhgyBsjIYMQJGjw47kSQLla2ICP6I41GjYM0a6N0bpk3TAAMSPSpbERHgvvv8BSvatfMDDOTkhJ1IkonKVkRS3htvwLXX+ukZM/zQeSLRpLIVkZS2ebM/n3bXLn+6z5AhYSeSZKSyFZGUtWsXDBsGX3wB/fvDnXeGnUiSlcpWRFLWLbfAkiWQmwuPPw6tWoWdSJKVylZEUtJzz/k12bQ0mDcPDj447ESSzFS2IpJy1q7149OCL9wEGp9cEpTKVkRSSnm5PwiqpATOPBPGjQs7kaQCla2IpJQrroAVK6BHD3+ajy5cIbGgshWRlPHww1BYCJmZ/sIVHTuGnUhShcpWRFLC8uVw+eV+eto06NMn3DySWlS2IpL0tm2DoUOhosKP6HPBBWEnklSjshWRpFZT48t17VrIy/PXQBaJNZWtiCS1P/7Rn1PbqZMfCD4zM+xEkopUtiKStJYsgRtv9NOzZkH37uHmkdSlshWRpLRhg7/ucU0N3HQTDBwYdiJJZSpbEUk6VVV+JJ/Nm+G002DixLATSapT2YpI0rnuOnjzTTjkEJg7F9LTw04kqU5lKyJJZcEC+NOfICMD5s+HAw8MO5GIylZEksjq1XDRRX76nnvgxBPDzSOym8pWRJJCaakfYKC01B8YNWZM2IlEvqOyFZGE5xwUFMCqVXDkkfDQQxpgQOKLylZEEt4DD8Bjj0FOjh9goG3bsBOJ7EllKyIJ7e234eqr/XRhoV+zFYk3KlsRSVhbtvgBBqqq4Mor4dxzw04kUj+VrYgkpOpqGD4c/v1vf9TxXXeFnUikYSpbEUlIt94KL78MnTv782lbtw47kUjDVLYiknAWLfJlm5YG8+b5K0WJxDOVrYgklHXrYMQIPz1pEpx6aqhxRJpEZSsiCaOiwh8Q9fXXMGgQjB8fdiKRplHZikjCGDsW3nkHunWDmTP9ZmSRRKCPqogkhJkz4cEHoU0bf+GKTp3CTiTSdCpbEYl7778Pl1zip6dOhby8cPOINJfKVkTiWkmJH2CgvBwuvBBGjQo7kUjzqWxFJG455wv2o4+gTx+4/34NMCCJSWUrInFr8mR46ino0AEWLoSsrLATiewfla2IxKWlS787tefRR6Fnz3DziLSEylZE4s7GjX5QgepquP56GDw47EQiLaOyFZG4smsXDBsGmzZBfj7cdlvYiURaTmUrInHlhhv8JuQuXfx1jzMywk4k0nIqWxGJG0895YfKS0/3I/nk5oadSCQ6VLYiEhc++ghGjvTTd90F/fuHGkckqppUtmY2xsyWmdlOM3sk4EwikmLKyvyFK7Zv9wMNjB0bdiKR6Grq3pAvgNuA0wGd6SYiUeMcXHqpvyRjr15QWKgLV0jyaVLZOueeBDCzvoCGaRaRqHnoIT/IQHa2H2CgffuwE4lEn/bZikholi2DK67w09OnQ+/e4eYRCUpUD6o3swKgACA3N5eioqJovnygSktLEypvotJyDlZxcTHV1dUJsYy3b8+goKAvlZWZDB68ga5dPyIBYgP6HMdKMi3nqJatc246MB2gb9++Lj8/P5ovH6iioiISKW+i0nIOVseOHSkuLo77ZVxTA4MGwZdfQr9+8PjjXWnTpmvYsZpMn+PYSKblrM3IIhJzt98OixbBAQfAggV+QHiRZNakNVszy4g8Nx1IN7NMYJdzbleQ4UQk+bz8MkyY4I84njMHDj007EQiwWvqmu1NQDkwHhgRmb4pqFAikpw+/xzOO8+f7jNhApx+etiJRGKjqaf+TAQmBppERJJaZSWcfTZ89RUMGAA33xx2IpHY0T5bEYmJa66Bt9/2m41nz4Y0fftICtHHXUQCN3cuTJ0KrVvDwoX+wCiRVKKyFZFArVwJF1/sp6dMgRNOCDePSBhUtiISmB07/AADZWUwYgSMHh12IpFwqGxFJBDOwW9+A2vW+MswTpumAQYkdalsRSQQ993nB4Bv184PMJCTE3YikfCobEUk6t54A6691k/PmOGHzhNJZSpbEYmqzZvhnHNg1y5/us+QIWEnEgmfylZEoqa62l8h6osvoH9/uPPOsBOJxAeVrYhEzS23wCuvQG4uPP44tGoVdiKR+KCyFZGoeO45uOMOf2WoefPg4IPDTiQSP1S2ItJia9fC+ef76TvvhCQZglQkalS2cSI/P58xY8aEHUOk2crLYehQKCmBM8+EcePCTiQSf1S2TTRy5EgGDRoUdgyRuHPFFbB8OfTo4U/z0YUrRPamshWR/fbww1BYCJmZ/sIVHTuGnUgkPqlso6CkpISCggIOOugg2rVrx8knn8yyZcu+ffyrr77ivPPO45BDDiErK4ujjz6aGTNmNPqaixcvpmPHjjz44INBxxfZL8uXw+WX++lp06BPn3DziMQzlW0LOecYOHAgGzZs4Pnnn2f58uWcdNJJnHLKKWzcuBGAiooK8vLyeP7551m5ciVXXXUVo0ePZvHixfW+5hNPPMEvf/lLpk+fzmhduV3iUHGx309bUeFH9LnggrATicS3jLADJLolS5awYsUKtmzZQlZWFgCTJk3iueeeY9asWVx33XV07dqVcbWOGikoKOCVV17hscce49RTT93j9aZPn864ceNYuHAhP/vZz2L6XkSaoqYGfv1rfwRyXp6/BrKINE5l20LvvPMOZWVlHHjggXvcX1FRwSeffAJAdXU1v//973n88cfZsNzBXeMAAA4PSURBVGEDO3fupLKykvw650c888wzPPjggyxdupQTTzwxVm9BpFn++Ed/Tm2nTn4g+MzMsBOJxD+VbQvV1NSQm5vLa6+9ttdj7du3B+Duu+9m8uTJTJkyhWOOOYa2bdtyww03sHnz5j2e/4Mf/AAzo7CwkB/+8IeYDuuUOLNkCdx4o5+eNQu6dw83j0iiUNm2UF5eHl9++SVpaWkcfvjh9T7n9ddf54wzzuD8yFn/zjk+/PBDOtY5dLN79+78+c9/Jj8/n4KCAqZPn67ClbixYQMMG+Y3I990EwwcGHYikcShA6SaYfv27axYsWKPW8+ePfnxj3/M4MGDWbRoEZ9++il///vfmTBhwrdru7169WLx4sW8/vrrrF69mjFjxvDpp5/WO4/DDz+cJUuW8OKLL1JQUIBzLpZvUaReVVVw7rl+RJ/TToOJE8NOJJJYVLbN8Nprr3HcccftcRs3bhwvvPACp5xyChdffDHf//73Oeecc1izZg0HRy4Oe9NNN9GvXz9+/vOfc9JJJ5GTk8Pw4cMbnE+PHj0oKirixRdfZPTo0SpcCd311/sxag85BObOhfT0sBOJJBZtRm6iRx55hEceeaTBx6dMmcKUKVPqfaxTp048+eSTjb5+UVHRHj/36NGDzz//vLkxRaJuwQK4917IyID586HOsYAi0gRasxWRBq1eDRdd5KfvuQd0kLzI/lHZiki9SkthyBD/32HDQONkiOw/la2I7MU5GD0aVq2CI4+Ehx7SAAMiLaGyFZG9/OUv/kConBw/wEDbtmEnEklsKlsR2cPbb8PYsX66sNCv2YpIy6Rs2ZaUlHDWWWdx4+7L4YgIW7fC2Wf782qvvNKfWysiLZeSp/4sW7aMM844g23btvHiiy/Sv3//bwcREElV1dUwfDh8/rk/6viuu8JOJJI8UmrN1jnHPffcw0knncSmTZvYuXMn5eXlDBs2jK1bt4YdTyRUt94KL70EnTv782lbtw47kUjySJmy3bZtGwMGDODmm2+mvLx8j8e++eYb7rjjjpCSiYRv0SJftmlpMG+ev1KUiERPSmxGfuutt/jFL35BSUkJlZWVezxmZmRmZvKLX/wipHQi4Vq3DkaM8NOTJkGdIZZFJAqSes22pqaGO+64g1NOOYUtW7bsVbRZWVn06tWLFStW7DW2rEgq2LnTHxD19dcwaBCMHx92IpHklLRlu3XrVk455RRuv/32vTYbA2RnZzNixAj+9a9/0bNnzxASioRv7FhYtgy6dYOZM/1mZBGJvqTcjPzaa69x5plnsmPHDqqqqvZ4LC0tjezsbB599FHOOuuskBKKhG/mTJg2Ddq08Reu6NQp7EQiySup/o6tqalh4sSJnH766Xz99dd7FW12djZHHnkk77//vopWUtr778Mll/jpqVMhLy/cPCLJLmnWbL/88kvOOussVqxYUe9m46ysLC666CImT55Ma53TICmspMQPMFBeDhdeCKNGhZ1IJPklRdkuXryYoUOHUlpayq5du/Z4LD09nZycHGbPns0ZZ5wRUkKR+OCcHzLvo4+gTx+4/34NMCASCwm9Gbm6uprf/va3nHHGGRQXF+9VtNnZ2RxzzDF88MEHKloR/Ji0Tz4JHTrAwoWgC6eJxEbCrtl+8cUXDB48mFWrVjW42fjSSy/l97//PRkZCfs2RaJm6VK4/no//eijoIPwRWInIVto0aJFDBs2jLKysr3WZjMyMsjJyWHevHkMGDAgpIQi8WXjRj+oQHW1L9zBg8NOJJJaEmozclVVFVdffTVDhgxh+/bt9W42zsvLY9WqVSpakYhdu2DYMNi0CfLz4bbbwk4kknoSpmw/++wzTjjhBKZPn97gZuOxY8fy5ptvcvDBB4eQUCQ+3XCD34TcpYu/7rH2qojEXkL8b/fMM89w/vnnU1ZWRnV19R6PtWrVirZt2/LEE0/wk5/8JKSEIvHpqaf8UHnp6X4kn9zcsBOJpKa4XrOtrKzk8ssv51e/+hU7duzYq2izs7Pp168fq1evVtGK1PHRRzBypJ++6y7o3z/UOCIpLfSyvffee1mwYMFe969du5Zjjz2WGTNmUFZWttfjWVlZjB8/nqVLl3LQQQfFIqpIwigr8xeu2L4dhg7110AWkfA0aTOymf0HUAj8DNgK/NY5N7elM9+8eTM33ngjZsYxxxzDEUccAcCCBQu48MILKS8vp6amZo9/06pVK9q3b8/TTz9Nf/2pLlKvSy/1l2Ts1QsKC3XhCpGwNXXN9n6gEsgFhgN/MbOjWzrzSZMmUVNTQ3l5OQMHDqS4uJhRo0YxcuRIvvnmm72KNjs7m/79+7NmzRoVrUgDtmxpw8yZkJ3tBxho3z7sRCKyzzVbM8sBhgC9nXOlwOtm9ixwPrDfo19u2rSJwsJCdu7cCcDGjRvp2rUrzrkGjzaeMGEC48aNw/Rnusgeqqr8qT0rV8LWrf6yUNOnQ+/eIQcTEQDMOdf4E8yOA950zmXVuu9a4GTnXIPXQGzXrp07/vjjG3zdDz/8kE2bNtGE+ZORkUHv3r1pH+Cf6MXFxXTs2DGw1xcv1Zazc1BT42/V1cH99zsrAOjV61i6dAnlLaeEVPschyXRlvOrr776jnOub32PNWWfbVugpM59JUC7uk80swKgAPy+1eLi4npfsKqqqslF27ZtWw477DBqamoafL1oqK6uDvT1xYun5VxTY9TUgHMWKUT79r7a04097su0oX/jH4+VtDSHmaN162qysoqJk8WclOLpc5zMkmk5N6VsS4G6q5TtgR11n+icmw5MB+jbt69btmxZvS84evRoPv74YyorKxucaVZWFnfeeSdXXnllTDYbFxUVkZ+fH/h8Ut2+lrNzUFnpj6Zt6FZe3vjjTbnVs6ciMNnZ0btlZdV/f6tW/iCo/Px8iouLWbFiRezeYArS90VsJNpybqyrmlK2HwIZZvY959xHkfv6ACv3J8yGDRuYOXNmo0WbmZnJoEGDuOqqq/ZnFhKQXbtaVm5lZbB+/dHk5DT+3DrHxQUmM7N5hbY/tzZtdCSwiDShbJ1z35jZk8CtZvYb4FhgMPCj/ZnhhAkT9ro4RV0VFRX89a9/5YknnmDIkCH7M5uUUl39XZlFY62vobXIqqpopD1wn89o1Sp6a3yNPT8t9LPMRSRVNPVyjZcBDwObga+AS51zzV6z/fzzz5kzZw5VTfjWLisrY+TIkeTl5dG9e/fmziouOAcVFc0vtebeIgd0By4treVremvXfkC/fr0bLMesLF+2IiLJpEll65z7GjizpTNrylptWloabdu2pbq6msrKShYvXsxvfvObls56D875tbTahfXJJzlkZu7/Wl9Dt1gJenNo7f2CLVFUtJUE2gUjIhIVMRuIYP369Tz22GN7rNVmZ2eTkZFBWVkZnTt3pnfv3vy//3ciRxxxLD16/IADDzycioo0/vGP6G4eLS+ve7oEwAmBvO82bYLdHJqd7fc9ar+giEj8CqxsN22CW275ruBee20aFRUVpKfnkJX1fbKz+9GqVV/gB2RlHUV5eQ6vvgp/+1tQifaUng45Od8VlnOlHHhg26juK8zK8vMREZHUFljZbtgAkybVvmc8cCXV1f9JaalRWlr/vzPbswSD2CRa337BoqJlCXWIuYiIJI7AyjY3118M/buS6xC5NV6ErVtrk6iIiCSXwMr2kENgwoSgXl1ERCRx6ExDERGRgKlsRUREAqayFRERCZjKVkREJGAqWxERkYCpbEVERAKmshUREQmYylZERCRgKlsREZGAqWxFREQCprIVEREJmMpWREQkYCpbERGRgKlsRUREAqayFRERCZjKVkREJGAqWxERkYCpbEVERAJmzrlgXthsC7A+kBcPRmdga9ghUoCWc/C0jIOnZRwbibacD3POHVjfA4GVbaIxs2XOub5h50h2Ws7B0zIOnpZxbCTTctZmZBERkYCpbEVERAKmsv3O9LADpAgt5+BpGQdPyzg2kmY5a5+tiIhIwLRmKyIiEjCVrYiISMBUtg0ws++ZWYWZzQ47SzIxszZmVmhm681sh5ktN7Ofh50rGZjZf5jZU2b2TWT5/irsTMlEn93YSrbvYJVtw+4H/hl2iCSUAXwOnAx0AG4G5ptZtxAzJYv7gUogFxgO/MXMjg43UlLRZze2kuo7WGVbDzMbBhQDi8POkmycc9845yY659Y552qcc88DnwLHh50tkZlZDjAEuNk5V+qcex14Fjg/3GTJQ5/d2EnG72CVbR1m1h64Fbgm7CypwMxygV7AyrCzJLheQLVz7sNa9/0L0JptQPTZDUayfgerbPc2CSh0zn0edpBkZ2atgDnAo8651WHnSXBtgZI695UA7ULIkvT02Q1UUn4Hp1TZmlmRmbkGbq+b2bHAacC9YWdNVPtaxrWelwbMwu9jHBNa4ORRCrSvc197YEcIWZKaPrvBSebv4IywA8SScy6/scfNbCzQDfjMzMCvLaSb2VHOubzAAyaBfS1jAPMLtxB/IM//OOeqgs6VAj4EMszse865jyL39UGbOKNKn93A5ZOk38G6glQtZpbNnmsH1+J/8Zc657aEEioJmdk04FjgNOdcadh5koWZzQMc8Bv88n0B+JFzToUbJfrsBiuZv4NTas12X5xzZUDZ7p/NrBSoSPRfcjwxs8OA0cBOYFPkr1eA0c65OaEFSw6XAQ8Dm4Gv8F9QKtoo0Wc3eMn8Haw1WxERkYCl1AFSIiIiYVDZioiIBExlKyIiEjCVrYiISMBUtiIiIgFT2YqIiARMZSsiIhIwla2IiEjAVLYiIiIB+/9tDkS+O0rZlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(z, leaky_relu(z, 0.03), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing leak relu in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z,name=None):\n",
    "    return(tf.maximum(0.01*z,z,name=name))\n",
    "\n",
    "hidden1 = tf.layers.dense(X,n_hidden1,activation=leaky_relu,name='hidden1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/Maximum:0' shape=(?, 300) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train a neural network on MNIST using the leakyrelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None),name= \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'train/GradientDescent' type=NoOp>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load in the data and define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.datasets.mnist.load_data()[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.48 Validation accuracy: 0.4956\n",
      "5 Batch accuracy: 0.838 Validation accuracy: 0.8346\n",
      "10 Batch accuracy: 0.875 Validation accuracy: 0.8806\n",
      "15 Batch accuracy: 0.915 Validation accuracy: 0.8982\n",
      "20 Batch accuracy: 0.901 Validation accuracy: 0.9068\n",
      "25 Batch accuracy: 0.902 Validation accuracy: 0.9128\n",
      "30 Batch accuracy: 0.914 Validation accuracy: 0.9174\n",
      "35 Batch accuracy: 0.914 Validation accuracy: 0.9216\n",
      "40 Batch accuracy: 0.914 Validation accuracy: 0.926\n",
      "45 Batch accuracy: 0.932 Validation accuracy: 0.9282\n",
      "50 Batch accuracy: 0.914 Validation accuracy: 0.931\n",
      "55 Batch accuracy: 0.929 Validation accuracy: 0.9326\n",
      "60 Batch accuracy: 0.937 Validation accuracy: 0.935\n",
      "65 Batch accuracy: 0.932 Validation accuracy: 0.9364\n",
      "70 Batch accuracy: 0.935 Validation accuracy: 0.9376\n",
      "75 Batch accuracy: 0.935 Validation accuracy: 0.9388\n",
      "80 Batch accuracy: 0.923 Validation accuracy: 0.9398\n",
      "85 Batch accuracy: 0.939 Validation accuracy: 0.9414\n",
      "90 Batch accuracy: 0.947 Validation accuracy: 0.9426\n",
      "95 Batch accuracy: 0.941 Validation accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            file_writer.add_summary(summary_str, epoch)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z,alpha=1):\n",
    "    return(np.where(z<0,alpha*(np.exp(z)-1),z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(z,elu(z),\"b-\",linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/Elu:0' shape=(?, 300) dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'X:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELU, scaled exponential units\n",
    "* By Klambauer et al\n",
    "* During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize\n",
    "* the output of each layer will tend to preserver the mean and variance during training, which solves the vanishing/exploding gradient problem\n",
    "* outperforms other activation functions\n",
    "* the function is easily broken and difficult to implement regularization\n",
    "* it works quite well with sequential CNN's\n",
    "* if normlization is broken, SELU will not necessarily outperform other functions\n",
    "\n",
    "\\begin{align*}\n",
    "selu(x) = \\lambda\n",
    "\\begin{cases}\n",
    "x\n",
    "\\quad\n",
    "\\text{if}\n",
    "\\quad x > 0 \\\\\n",
    "\\alpha e^x\n",
    "\\quad\n",
    "\\text{if}\n",
    "\\quad\n",
    "x << 0\n",
    "\\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "#alphda and scale to sel normalize with mean and st dev 1\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6732632423543778"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0507009873554805"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.541725790028002e-08"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erfc(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z,scale=scale_0_1,alpha=alpha_0_1):\n",
    "    return(scale*elu(z,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all x less than 0, it has the shape e^x, but flipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SELU hyperparameters (scale and alpha) are tuned in such a way that the mean oupt of each nueron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1000 layers deep neural network preservers roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean 0.003619, std deviation 1.01\n",
      "Layer 50: mean -0.000275, std deviation 0.97\n",
      "Layer 100: mean -0.009258, std deviation 0.91\n",
      "Layer 150: mean -0.013290, std deviation 0.93\n",
      "Layer 200: mean -0.001869, std deviation 0.88\n",
      "Layer 250: mean 0.043744, std deviation 0.87\n",
      "Layer 300: mean 0.017311, std deviation 0.86\n",
      "Layer 350: mean 0.041500, std deviation 0.96\n",
      "Layer 400: mean -0.012337, std deviation 0.86\n",
      "Layer 450: mean 0.014573, std deviation 0.88\n",
      "Layer 500: mean 0.004564, std deviation 0.93\n",
      "Layer 550: mean -0.038700, std deviation 0.91\n",
      "Layer 600: mean 0.017596, std deviation 0.88\n",
      "Layer 650: mean 0.058942, std deviation 1.01\n",
      "Layer 700: mean -0.012028, std deviation 0.92\n",
      "Layer 750: mean -0.039358, std deviation 0.94\n",
      "Layer 800: mean 0.030063, std deviation 0.92\n",
      "Layer 850: mean -0.018686, std deviation 0.91\n",
      "Layer 900: mean 0.012818, std deviation 0.88\n",
      "Layer 950: mean -0.016715, std deviation 0.95\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(56784)\n",
    "Z = np.random.normal(size=(500,100))\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100,100),scale = np.sqrt(1/100)) #lecun initialzation over 100 nueron layer\n",
    "    Z = selu(np.dot(Z,W))\n",
    "    means = np.mean(Z,axis=0).mean()\n",
    "    stds = np.std(Z,axis=0).mean()\n",
    "    if layer % 50 == 0:\n",
    "        print('Layer {}: mean {:2f}, std deviation {:.2f}'.format(layer,means,stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selu(np.dot(Z,W)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z,scale=alpha_0_1,alpha=scale_0_1):\n",
    "    return(scale*tf.where(z>=0,z,alpha*tf.nn.elu(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the SELU activation function cannot be used along the regular Dropout (this would cancel the SELU activation function's self normalizing property). Fortunately, there is a drpout variant called alpha drpopout propes in the paper about SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets creatue a neurla network for MNSIT using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28\n",
    "n_hidden1 = 400\n",
    "n_hidden2 = 200\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name=\"X\")\n",
    "y = tf.placeholder(tf.int32,shape=(None),name='y')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 50\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train it, and don't forget to scale the inputs to mean 0 and standard deviation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.945 Validation accuracy: 0.91\n",
      "5 Batch accuracy: 0.945 Validation accuracy: 0.9526\n",
      "10 Batch accuracy: 0.975 Validation accuracy: 0.9602\n",
      "15 Batch accuracy: 0.975 Validation accuracy: 0.9624\n",
      "20 Batch accuracy: 0.995 Validation accuracy: 0.9658\n",
      "25 Batch accuracy: 0.995 Validation accuracy: 0.965\n",
      "30 Batch accuracy: 0.995 Validation accuracy: 0.9654\n",
      "35 Batch accuracy: 0.995 Validation accuracy: 0.9662\n",
      "40 Batch accuracy: 1.0 Validation accuracy: 0.9668\n",
      "45 Batch accuracy: 0.995 Validation accuracy: 0.9666\n"
     ]
    }
   ],
   "source": [
    "means = X_train.mean(axis =0, keepdims=True)\n",
    "stds = X_train.std(axis=0,keepdims=True) + 1e-10\n",
    "X_val_scaled = (X_valid - means) / stds\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch_scaled = (X_batch - means) / stds\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_val_scaled, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final_selu.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0,keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization\n",
    "\n",
    "Instead of using the batch_norm() function as a regulairze paramters to the fully_connected() function, we not use batch normizlation() and we explicitly create a disttinc layer. There parameters are a bit different in particular\n",
    "\n",
    "* decay is reanmed ot momentum\n",
    "* is training is renamed to trianing\n",
    "\n",
    "not that in order to run batch norm just before each hidden layers activation function, we apply the ELU activation function manually, right after the batch norm layer\n",
    "\n",
    "We compare notation using partial and not using partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-50-2f36d39a8af9>:15: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name= \"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(),name='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid repeating, we use python's partial function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.layers.normalization.batch_normalization(inputs, axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer=<tensorflow.python.ops.init_ops.Zeros object at 0x63e9dbe10>, gamma_initializer=<tensorflow.python.ops.init_ops.Ones object at 0x63e9dbe48>, moving_mean_initializer=<tensorflow.python.ops.init_ops.Zeros object at 0x63e9dbeb8>, moving_variance_initializer=<tensorflow.python.ops.init_ops.Ones object at 0x63e9dbf28>, beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None, training=False, trainable=True, name=None, reuse=None, renorm=False, renorm_clipping=None, renorm_momentum=0.99, fused=None, virtual_batch_size=None, adjustment=None)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.layers.batch_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try implementing a neural net for MNIST, using the activation ELU function and Batch Normalization at each layer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None, n_inputs),name=\"X\")\n",
    "y = tf.placeholder(tf.int32,shape=(None),name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(),name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "    \n",
    "    my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                                 training=training,\n",
    "                                 momentum=batch_norm_momentum)\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "    \n",
    "    hidden1 = my_dense_layer(X,n_hidden1,name='hidden1')\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1,n_hidden2,name='hidden2')\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2,n_outputs,name='outputs')\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we are sing batch.normalization instead of contrb, we need to explictly run the extra update opertiaons by batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "loss_summary = tf.summary.scalar('Loss', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8952\n",
      "1 Validation accuracy: 0.9202\n",
      "2 Validation accuracy: 0.9318\n",
      "3 Validation accuracy: 0.9422\n",
      "4 Validation accuracy: 0.9468\n",
      "5 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.962\n",
      "9 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.9662\n",
      "11 Validation accuracy: 0.9682\n",
      "12 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9696\n",
      "14 Validation accuracy: 0.9706\n",
      "15 Validation accuracy: 0.9704\n",
      "16 Validation accuracy: 0.9718\n",
      "17 Validation accuracy: 0.9726\n",
      "18 Validation accuracy: 0.9738\n",
      "19 Validation accuracy: 0.9742\n",
      "20 Validation accuracy: 0.9738\n",
      "21 Validation accuracy: 0.9746\n",
      "22 Validation accuracy: 0.9742\n",
      "23 Validation accuracy: 0.9758\n",
      "24 Validation accuracy: 0.9756\n",
      "25 Validation accuracy: 0.9752\n",
      "26 Validation accuracy: 0.9748\n",
      "27 Validation accuracy: 0.9758\n",
      "28 Validation accuracy: 0.976\n",
      "29 Validation accuracy: 0.9772\n",
      "30 Validation accuracy: 0.9768\n",
      "31 Validation accuracy: 0.9766\n",
      "32 Validation accuracy: 0.9758\n",
      "33 Validation accuracy: 0.976\n",
      "34 Validation accuracy: 0.9762\n",
      "35 Validation accuracy: 0.9758\n",
      "36 Validation accuracy: 0.9772\n",
      "37 Validation accuracy: 0.9778\n",
      "38 Validation accuracy: 0.979\n",
      "39 Validation accuracy: 0.977\n",
      "40 Validation accuracy: 0.9772\n",
      "41 Validation accuracy: 0.979\n",
      "42 Validation accuracy: 0.9782\n",
      "43 Validation accuracy: 0.9794\n",
      "44 Validation accuracy: 0.9784\n",
      "45 Validation accuracy: 0.9794\n",
      "46 Validation accuracy: 0.9784\n",
      "47 Validation accuracy: 0.9788\n",
      "48 Validation accuracy: 0.9792\n",
      "49 Validation accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            summary_str =loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            file_writer.add_summary(summary_str, epoch)\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this batch normilzation helped me out!\n",
    "\n",
    "Most of the time, batch norm and elu are most likely to have an effect in deeper networks.\n",
    "\n",
    "We could have alos implement the training operation this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, you would just have to evaluate the trainiing_op during training. tensorflow would automatically run the update operations as well:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the list of trainiable variables is hsorter than the list of all global variables. This is because the moving averages are non-trainable variables. if you want to re sue a pretraiend nueral network (see below) you must not forther these non-trainable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping\n",
    "\n",
    "Lets create a simple neural net for MNSIT and add gradient clipping. The first part is the same as earleir (except we added a few more layers to demonstrate reusing pretrained models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None, n_inputs),name=\"X\")\n",
    "y = tf.placeholder(tf.int32,shape=(None),name='y')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply gradient cliping. For this we need to get the gradients, use the clipp_by_value() then apply them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat the usual parts of the subgraph\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32),name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.2876\n",
      "1 Validation accuracy: 0.7944\n",
      "2 Validation accuracy: 0.8796\n",
      "3 Validation accuracy: 0.9058\n",
      "4 Validation accuracy: 0.9164\n",
      "5 Validation accuracy: 0.9218\n",
      "6 Validation accuracy: 0.9292\n",
      "7 Validation accuracy: 0.9356\n",
      "8 Validation accuracy: 0.9378\n",
      "9 Validation accuracy: 0.9416\n",
      "10 Validation accuracy: 0.9456\n",
      "11 Validation accuracy: 0.947\n",
      "12 Validation accuracy: 0.9476\n",
      "13 Validation accuracy: 0.9532\n",
      "14 Validation accuracy: 0.9564\n",
      "15 Validation accuracy: 0.9566\n",
      "16 Validation accuracy: 0.9576\n",
      "17 Validation accuracy: 0.959\n",
      "18 Validation accuracy: 0.9624\n",
      "19 Validation accuracy: 0.9614\n",
      "20 Validation accuracy: 0.9634\n",
      "21 Validation accuracy: 0.9646\n",
      "22 Validation accuracy: 0.9648\n",
      "23 Validation accuracy: 0.9646\n",
      "24 Validation accuracy: 0.9666\n",
      "25 Validation accuracy: 0.9672\n",
      "26 Validation accuracy: 0.9682\n",
      "27 Validation accuracy: 0.9664\n",
      "28 Validation accuracy: 0.966\n",
      "29 Validation accuracy: 0.9714\n",
      "30 Validation accuracy: 0.9672\n",
      "31 Validation accuracy: 0.9704\n",
      "32 Validation accuracy: 0.9712\n",
      "33 Validation accuracy: 0.9708\n",
      "34 Validation accuracy: 0.9692\n",
      "35 Validation accuracy: 0.9698\n",
      "36 Validation accuracy: 0.9712\n",
      "37 Validation accuracy: 0.9688\n",
      "38 Validation accuracy: 0.9726\n",
      "39 Validation accuracy: 0.9714\n",
      "40 Validation accuracy: 0.973\n",
      "41 Validation accuracy: 0.9724\n",
      "42 Validation accuracy: 0.9718\n",
      "43 Validation accuracy: 0.9738\n",
      "44 Validation accuracy: 0.9728\n",
      "45 Validation accuracy: 0.9742\n",
      "46 Validation accuracy: 0.9744\n",
      "47 Validation accuracy: 0.9734\n",
      "48 Validation accuracy: 0.975\n",
      "49 Validation accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing pretrained Layers\n",
    "### Reusing a TensforFlow Model\n",
    "\n",
    "First you need to load the graph's structue. The import_meta_graph() functions does just that, loading the graphs operations into the default graph, and returning a Saver that you can use to restore the model' state. Note that by default, a Saver saves the strucutre of the graph into a .meta file so thatss the file you shoud load!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "gradients/Shape\n",
      "gradients/grad_ys_0\n",
      "gradients/Fill\n",
      "gradients/loss/loss_grad/Reshape/shape\n",
      "gradients/loss/loss_grad/Reshape\n",
      "gradients/loss/loss_grad/Shape\n",
      "gradients/loss/loss_grad/Tile\n",
      "gradients/loss/loss_grad/Shape_1\n",
      "gradients/loss/loss_grad/Shape_2\n",
      "gradients/loss/loss_grad/Const\n",
      "gradients/loss/loss_grad/Prod\n",
      "gradients/loss/loss_grad/Const_1\n",
      "gradients/loss/loss_grad/Prod_1\n",
      "gradients/loss/loss_grad/Maximum/y\n",
      "gradients/loss/loss_grad/Maximum\n",
      "gradients/loss/loss_grad/floordiv\n",
      "gradients/loss/loss_grad/Cast\n",
      "gradients/loss/loss_grad/truediv\n",
      "gradients/zeros_like\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "clip_by_value/Minimum/y\n",
      "clip_by_value/Minimum\n",
      "clip_by_value/y\n",
      "clip_by_value\n",
      "clip_by_value_1/Minimum/y\n",
      "clip_by_value_1/Minimum\n",
      "clip_by_value_1/y\n",
      "clip_by_value_1\n",
      "clip_by_value_2/Minimum/y\n",
      "clip_by_value_2/Minimum\n",
      "clip_by_value_2/y\n",
      "clip_by_value_2\n",
      "clip_by_value_3/Minimum/y\n",
      "clip_by_value_3/Minimum\n",
      "clip_by_value_3/y\n",
      "clip_by_value_3\n",
      "clip_by_value_4/Minimum/y\n",
      "clip_by_value_4/Minimum\n",
      "clip_by_value_4/y\n",
      "clip_by_value_4\n",
      "clip_by_value_5/Minimum/y\n",
      "clip_by_value_5/Minimum\n",
      "clip_by_value_5/y\n",
      "clip_by_value_5\n",
      "clip_by_value_6/Minimum/y\n",
      "clip_by_value_6/Minimum\n",
      "clip_by_value_6/y\n",
      "clip_by_value_6\n",
      "clip_by_value_7/Minimum/y\n",
      "clip_by_value_7/Minimum\n",
      "clip_by_value_7/y\n",
      "clip_by_value_7\n",
      "clip_by_value_8/Minimum/y\n",
      "clip_by_value_8/Minimum\n",
      "clip_by_value_8/y\n",
      "clip_by_value_8\n",
      "clip_by_value_9/Minimum/y\n",
      "clip_by_value_9/Minimum\n",
      "clip_by_value_9/y\n",
      "clip_by_value_9\n",
      "clip_by_value_10/Minimum/y\n",
      "clip_by_value_10/Minimum\n",
      "clip_by_value_10/y\n",
      "clip_by_value_10\n",
      "clip_by_value_11/Minimum/y\n",
      "clip_by_value_11/Minimum\n",
      "clip_by_value_11/y\n",
      "clip_by_value_11\n",
      "GradientDescent/learning_rate\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/filename/input\n",
      "save/filename\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/Assign_3\n",
      "save/Assign_4\n",
      "save/Assign_5\n",
      "save/Assign_6\n",
      "save/Assign_7\n",
      "save/Assign_8\n",
      "save/Assign_9\n",
      "save/Assign_10\n",
      "save/Assign_11\n",
      "save/restore_all\n",
      "X_1\n",
      "y_1\n",
      "hidden1/kernel/Initializer/random_uniform/shape_1\n",
      "hidden1/kernel/Initializer/random_uniform/min_1\n",
      "hidden1/kernel/Initializer/random_uniform/max_1\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform_1\n",
      "hidden1/kernel/Initializer/random_uniform/sub_1\n",
      "hidden1/kernel/Initializer/random_uniform/mul_1\n",
      "hidden1/kernel/Initializer/random_uniform_1\n",
      "hidden1/kernel_1\n",
      "hidden1/kernel/Assign_1\n",
      "hidden1/kernel/read_1\n",
      "hidden1/bias/Initializer/zeros_1\n",
      "hidden1/bias_1\n",
      "hidden1/bias/Assign_1\n",
      "hidden1/bias/read_1\n",
      "dnn/hidden1/MatMul_1\n",
      "dnn/hidden1/BiasAdd_1\n",
      "dnn/hidden1/GreaterEqual/y\n",
      "dnn/hidden1/GreaterEqual\n",
      "dnn/hidden1/Elu\n",
      "dnn/hidden1/mul/x\n",
      "dnn/hidden1/mul\n",
      "dnn/hidden1/Select\n",
      "dnn/hidden1/mul_1/x\n",
      "dnn/hidden1/mul_1\n",
      "hidden2/kernel/Initializer/random_uniform/shape_1\n",
      "hidden2/kernel/Initializer/random_uniform/min_1\n",
      "hidden2/kernel/Initializer/random_uniform/max_1\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform_1\n",
      "hidden2/kernel/Initializer/random_uniform/sub_1\n",
      "hidden2/kernel/Initializer/random_uniform/mul_1\n",
      "hidden2/kernel/Initializer/random_uniform_1\n",
      "hidden2/kernel_1\n",
      "hidden2/kernel/Assign_1\n",
      "hidden2/kernel/read_1\n",
      "hidden2/bias/Initializer/zeros_1\n",
      "hidden2/bias_1\n",
      "hidden2/bias/Assign_1\n",
      "hidden2/bias/read_1\n",
      "dnn/hidden2/MatMul_1\n",
      "dnn/hidden2/BiasAdd_1\n",
      "dnn/hidden2/GreaterEqual/y\n",
      "dnn/hidden2/GreaterEqual\n",
      "dnn/hidden2/Elu\n",
      "dnn/hidden2/mul/x\n",
      "dnn/hidden2/mul\n",
      "dnn/hidden2/Select\n",
      "dnn/hidden2/mul_1/x\n",
      "dnn/hidden2/mul_1\n",
      "outputs/kernel/Initializer/random_uniform/shape_1\n",
      "outputs/kernel/Initializer/random_uniform/min_1\n",
      "outputs/kernel/Initializer/random_uniform/max_1\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform_1\n",
      "outputs/kernel/Initializer/random_uniform/sub_1\n",
      "outputs/kernel/Initializer/random_uniform/mul_1\n",
      "outputs/kernel/Initializer/random_uniform_1\n",
      "outputs/kernel_1\n",
      "outputs/kernel/Assign_1\n",
      "outputs/kernel/read_1\n",
      "outputs/bias/Initializer/zeros_1\n",
      "outputs/bias_1\n",
      "outputs/bias/Assign_1\n",
      "outputs/bias/read_1\n",
      "dnn/outputs/MatMul_1\n",
      "dnn/outputs/BiasAdd_1\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape_1\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_1\n",
      "loss/Const_1\n",
      "loss/loss_1\n",
      "train/gradients/Shape\n",
      "train/gradients/grad_ys_0\n",
      "train/gradients/Fill\n",
      "train/gradients/loss/loss_grad/Reshape/shape\n",
      "train/gradients/loss/loss_grad/Reshape\n",
      "train/gradients/loss/loss_grad/Shape\n",
      "train/gradients/loss/loss_grad/Tile\n",
      "train/gradients/loss/loss_grad/Shape_1\n",
      "train/gradients/loss/loss_grad/Shape_2\n",
      "train/gradients/loss/loss_grad/Const\n",
      "train/gradients/loss/loss_grad/Prod\n",
      "train/gradients/loss/loss_grad/Const_1\n",
      "train/gradients/loss/loss_grad/Prod_1\n",
      "train/gradients/loss/loss_grad/Maximum/y\n",
      "train/gradients/loss/loss_grad/Maximum\n",
      "train/gradients/loss/loss_grad/floordiv\n",
      "train/gradients/loss/loss_grad/Cast\n",
      "train/gradients/loss/loss_grad/truediv\n",
      "train/gradients/zeros_like\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "train/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "train/gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden2/mul_1_grad/Shape\n",
      "train/gradients/dnn/hidden2/mul_1_grad/Shape_1\n",
      "train/gradients/dnn/hidden2/mul_1_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/hidden2/mul_1_grad/Mul\n",
      "train/gradients/dnn/hidden2/mul_1_grad/Sum\n",
      "train/gradients/dnn/hidden2/mul_1_grad/Reshape\n",
      "train/gradients/dnn/hidden2/mul_1_grad/Mul_1\n",
      "train/gradients/dnn/hidden2/mul_1_grad/Sum_1\n",
      "train/gradients/dnn/hidden2/mul_1_grad/Reshape_1\n",
      "train/gradients/dnn/hidden2/mul_1_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden2/mul_1_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden2/mul_1_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden2/Select_grad/zeros_like\n",
      "train/gradients/dnn/hidden2/Select_grad/Select\n",
      "train/gradients/dnn/hidden2/Select_grad/Select_1\n",
      "train/gradients/dnn/hidden2/Select_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden2/Select_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden2/Select_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden2/mul_grad/Shape\n",
      "train/gradients/dnn/hidden2/mul_grad/Shape_1\n",
      "train/gradients/dnn/hidden2/mul_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/hidden2/mul_grad/Mul\n",
      "train/gradients/dnn/hidden2/mul_grad/Sum\n",
      "train/gradients/dnn/hidden2/mul_grad/Reshape\n",
      "train/gradients/dnn/hidden2/mul_grad/Mul_1\n",
      "train/gradients/dnn/hidden2/mul_grad/Sum_1\n",
      "train/gradients/dnn/hidden2/mul_grad/Reshape_1\n",
      "train/gradients/dnn/hidden2/mul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden2/mul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden2/mul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden2/Elu_grad/EluGrad\n",
      "train/gradients/AddN\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "train/gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden1/mul_1_grad/Shape\n",
      "train/gradients/dnn/hidden1/mul_1_grad/Shape_1\n",
      "train/gradients/dnn/hidden1/mul_1_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/hidden1/mul_1_grad/Mul\n",
      "train/gradients/dnn/hidden1/mul_1_grad/Sum\n",
      "train/gradients/dnn/hidden1/mul_1_grad/Reshape\n",
      "train/gradients/dnn/hidden1/mul_1_grad/Mul_1\n",
      "train/gradients/dnn/hidden1/mul_1_grad/Sum_1\n",
      "train/gradients/dnn/hidden1/mul_1_grad/Reshape_1\n",
      "train/gradients/dnn/hidden1/mul_1_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden1/mul_1_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden1/mul_1_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden1/Select_grad/zeros_like\n",
      "train/gradients/dnn/hidden1/Select_grad/Select\n",
      "train/gradients/dnn/hidden1/Select_grad/Select_1\n",
      "train/gradients/dnn/hidden1/Select_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden1/Select_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden1/Select_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden1/mul_grad/Shape\n",
      "train/gradients/dnn/hidden1/mul_grad/Shape_1\n",
      "train/gradients/dnn/hidden1/mul_grad/BroadcastGradientArgs\n",
      "train/gradients/dnn/hidden1/mul_grad/Mul\n",
      "train/gradients/dnn/hidden1/mul_grad/Sum\n",
      "train/gradients/dnn/hidden1/mul_grad/Reshape\n",
      "train/gradients/dnn/hidden1/mul_grad/Mul_1\n",
      "train/gradients/dnn/hidden1/mul_grad/Sum_1\n",
      "train/gradients/dnn/hidden1/mul_grad/Reshape_1\n",
      "train/gradients/dnn/hidden1/mul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden1/mul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden1/mul_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden1/Elu_grad/EluGrad\n",
      "train/gradients/AddN_1\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "train/gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "train/gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "train/gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "train/gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "train/GradientDescent/learning_rate\n",
      "train/GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "train/GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "train/GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "train/GradientDescent\n",
      "eval/in_top_k/InTopKV2/k_1\n",
      "eval/in_top_k/InTopKV2_1\n",
      "eval/Cast_1\n",
      "eval/Const_1\n",
      "eval/Mean\n",
      "init_1\n",
      "save/filename/input_1\n",
      "save/filename_1\n",
      "save/Const_1\n",
      "save/SaveV2/tensor_names_1\n",
      "save/SaveV2/shape_and_slices_1\n",
      "save/SaveV2_1\n",
      "save/control_dependency_1\n",
      "save/RestoreV2/tensor_names_1\n",
      "save/RestoreV2/shape_and_slices_1\n",
      "save/RestoreV2_1\n",
      "save/Assign_12\n",
      "save/Assign_1_1\n",
      "save/Assign_2_1\n",
      "save/Assign_3_1\n",
      "save/Assign_4_1\n",
      "save/Assign_5_1\n",
      "save/restore_all_1\n",
      "X_2\n",
      "y_2\n",
      "hidden1/kernel/Initializer/random_uniform/shape_2\n",
      "hidden1/kernel/Initializer/random_uniform/min_2\n",
      "hidden1/kernel/Initializer/random_uniform/max_2\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform_2\n",
      "hidden1/kernel/Initializer/random_uniform/sub_2\n",
      "hidden1/kernel/Initializer/random_uniform/mul_2\n",
      "hidden1/kernel/Initializer/random_uniform_2\n",
      "hidden1/kernel_2\n",
      "hidden1/kernel/Assign_2\n",
      "hidden1/kernel/read_2\n",
      "hidden1/bias/Initializer/zeros_2\n",
      "hidden1/bias_2\n",
      "hidden1/bias/Assign_2\n",
      "hidden1/bias/read_2\n",
      "dnn/hidden1/MatMul_2\n",
      "dnn/hidden1/BiasAdd_2\n",
      "dnn/hidden1/Relu_1\n",
      "hidden2/kernel/Initializer/random_uniform/shape_2\n",
      "hidden2/kernel/Initializer/random_uniform/min_2\n",
      "hidden2/kernel/Initializer/random_uniform/max_2\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform_2\n",
      "hidden2/kernel/Initializer/random_uniform/sub_2\n",
      "hidden2/kernel/Initializer/random_uniform/mul_2\n",
      "hidden2/kernel/Initializer/random_uniform_2\n",
      "hidden2/kernel_2\n",
      "hidden2/kernel/Assign_2\n",
      "hidden2/kernel/read_2\n",
      "hidden2/bias/Initializer/zeros_2\n",
      "hidden2/bias_2\n",
      "hidden2/bias/Assign_2\n",
      "hidden2/bias/read_2\n",
      "dnn/hidden2/MatMul_2\n",
      "dnn/hidden2/BiasAdd_2\n",
      "dnn/hidden2/Relu_1\n",
      "hidden3/kernel/Initializer/random_uniform/shape_1\n",
      "hidden3/kernel/Initializer/random_uniform/min_1\n",
      "hidden3/kernel/Initializer/random_uniform/max_1\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform_1\n",
      "hidden3/kernel/Initializer/random_uniform/sub_1\n",
      "hidden3/kernel/Initializer/random_uniform/mul_1\n",
      "hidden3/kernel/Initializer/random_uniform_1\n",
      "hidden3/kernel_1\n",
      "hidden3/kernel/Assign_1\n",
      "hidden3/kernel/read_1\n",
      "hidden3/bias/Initializer/zeros_1\n",
      "hidden3/bias_1\n",
      "hidden3/bias/Assign_1\n",
      "hidden3/bias/read_1\n",
      "dnn/hidden3/MatMul_1\n",
      "dnn/hidden3/BiasAdd_1\n",
      "dnn/hidden3/Relu_1\n",
      "hidden4/kernel/Initializer/random_uniform/shape_1\n",
      "hidden4/kernel/Initializer/random_uniform/min_1\n",
      "hidden4/kernel/Initializer/random_uniform/max_1\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform_1\n",
      "hidden4/kernel/Initializer/random_uniform/sub_1\n",
      "hidden4/kernel/Initializer/random_uniform/mul_1\n",
      "hidden4/kernel/Initializer/random_uniform_1\n",
      "hidden4/kernel_1\n",
      "hidden4/kernel/Assign_1\n",
      "hidden4/kernel/read_1\n",
      "hidden4/bias/Initializer/zeros_1\n",
      "hidden4/bias_1\n",
      "hidden4/bias/Assign_1\n",
      "hidden4/bias/read_1\n",
      "dnn/hidden4/MatMul_1\n",
      "dnn/hidden4/BiasAdd_1\n",
      "dnn/hidden4/Relu_1\n",
      "hidden5/kernel/Initializer/random_uniform/shape_1\n",
      "hidden5/kernel/Initializer/random_uniform/min_1\n",
      "hidden5/kernel/Initializer/random_uniform/max_1\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform_1\n",
      "hidden5/kernel/Initializer/random_uniform/sub_1\n",
      "hidden5/kernel/Initializer/random_uniform/mul_1\n",
      "hidden5/kernel/Initializer/random_uniform_1\n",
      "hidden5/kernel_1\n",
      "hidden5/kernel/Assign_1\n",
      "hidden5/kernel/read_1\n",
      "hidden5/bias/Initializer/zeros_1\n",
      "hidden5/bias_1\n",
      "hidden5/bias/Assign_1\n",
      "hidden5/bias/read_1\n",
      "dnn/hidden5/MatMul_1\n",
      "dnn/hidden5/BiasAdd_1\n",
      "dnn/hidden5/Relu_1\n",
      "outputs/kernel/Initializer/random_uniform/shape_2\n",
      "outputs/kernel/Initializer/random_uniform/min_2\n",
      "outputs/kernel/Initializer/random_uniform/max_2\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform_2\n",
      "outputs/kernel/Initializer/random_uniform/sub_2\n",
      "outputs/kernel/Initializer/random_uniform/mul_2\n",
      "outputs/kernel/Initializer/random_uniform_2\n",
      "outputs/kernel_2\n",
      "outputs/kernel/Assign_2\n",
      "outputs/kernel/read_2\n",
      "outputs/bias/Initializer/zeros_2\n",
      "outputs/bias_2\n",
      "outputs/bias/Assign_2\n",
      "outputs/bias/read_2\n",
      "dnn/outputs/MatMul_2\n",
      "dnn/outputs/BiasAdd_2\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape_2\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_2\n",
      "loss/Const_2\n",
      "loss/loss_2\n",
      "gradients/Shape_1\n",
      "gradients/grad_ys_0_1\n",
      "gradients/Fill_1\n",
      "gradients/loss/loss_grad/Reshape/shape_1\n",
      "gradients/loss/loss_grad/Reshape_1\n",
      "gradients/loss/loss_grad/Shape_3\n",
      "gradients/loss/loss_grad/Tile_1\n",
      "gradients/loss/loss_grad/Shape_1_1\n",
      "gradients/loss/loss_grad/Shape_2_1\n",
      "gradients/loss/loss_grad/Const_2\n",
      "gradients/loss/loss_grad/Prod_2\n",
      "gradients/loss/loss_grad/Const_1_1\n",
      "gradients/loss/loss_grad/Prod_1_1\n",
      "gradients/loss/loss_grad/Maximum/y_1\n",
      "gradients/loss/loss_grad/Maximum_1\n",
      "gradients/loss/loss_grad/floordiv_1\n",
      "gradients/loss/loss_grad/Cast_1\n",
      "gradients/loss/loss_grad/truediv_1\n",
      "gradients/zeros_like_1\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient_1\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim_1\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims_1\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul_1\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad_1\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps_1\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_2\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_2\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_2\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad_1\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad_1\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_2\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad_1\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad_1\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_2\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad_1\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad_1\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_2\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad_1\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad_1\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_2\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad_1\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad_1\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_2\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_2\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1_1\n",
      "clip_by_value/Minimum/y_1\n",
      "clip_by_value/Minimum_1\n",
      "clip_by_value/y_1\n",
      "clip_by_value_12\n",
      "clip_by_value_1/Minimum/y_1\n",
      "clip_by_value_1/Minimum_1\n",
      "clip_by_value_1/y_1\n",
      "clip_by_value_1_1\n",
      "clip_by_value_2/Minimum/y_1\n",
      "clip_by_value_2/Minimum_1\n",
      "clip_by_value_2/y_1\n",
      "clip_by_value_2_1\n",
      "clip_by_value_3/Minimum/y_1\n",
      "clip_by_value_3/Minimum_1\n",
      "clip_by_value_3/y_1\n",
      "clip_by_value_3_1\n",
      "clip_by_value_4/Minimum/y_1\n",
      "clip_by_value_4/Minimum_1\n",
      "clip_by_value_4/y_1\n",
      "clip_by_value_4_1\n",
      "clip_by_value_5/Minimum/y_1\n",
      "clip_by_value_5/Minimum_1\n",
      "clip_by_value_5/y_1\n",
      "clip_by_value_5_1\n",
      "clip_by_value_6/Minimum/y_1\n",
      "clip_by_value_6/Minimum_1\n",
      "clip_by_value_6/y_1\n",
      "clip_by_value_6_1\n",
      "clip_by_value_7/Minimum/y_1\n",
      "clip_by_value_7/Minimum_1\n",
      "clip_by_value_7/y_1\n",
      "clip_by_value_7_1\n",
      "clip_by_value_8/Minimum/y_1\n",
      "clip_by_value_8/Minimum_1\n",
      "clip_by_value_8/y_1\n",
      "clip_by_value_8_1\n",
      "clip_by_value_9/Minimum/y_1\n",
      "clip_by_value_9/Minimum_1\n",
      "clip_by_value_9/y_1\n",
      "clip_by_value_9_1\n",
      "clip_by_value_10/Minimum/y_1\n",
      "clip_by_value_10/Minimum_1\n",
      "clip_by_value_10/y_1\n",
      "clip_by_value_10_1\n",
      "clip_by_value_11/Minimum/y_1\n",
      "clip_by_value_11/Minimum_1\n",
      "clip_by_value_11/y_1\n",
      "clip_by_value_11_1\n",
      "GradientDescent/learning_rate_1\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent_1\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent_1\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent_1\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent_1\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent_1\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent_1\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent_1\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent_1\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent_1\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent_1\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent_1\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent_1\n",
      "GradientDescent_1\n",
      "eval/in_top_k/InTopKV2/k_2\n",
      "eval/in_top_k/InTopKV2_2\n",
      "eval/Cast_2\n",
      "eval/Const_2\n",
      "eval/accuracy_1\n",
      "init_2\n",
      "save/filename/input_2\n",
      "save/filename_2\n",
      "save/Const_2\n",
      "save/SaveV2/tensor_names_2\n",
      "save/SaveV2/shape_and_slices_2\n",
      "save/SaveV2_2\n",
      "save/control_dependency_2\n",
      "save/RestoreV2/tensor_names_2\n",
      "save/RestoreV2/shape_and_slices_2\n",
      "save/RestoreV2_2\n",
      "save/Assign_13\n",
      "save/Assign_1_2\n",
      "save/Assign_2_2\n",
      "save/Assign_3_2\n",
      "save/Assign_4_2\n",
      "save/Assign_5_2\n",
      "save/Assign_6_1\n",
      "save/Assign_7_1\n",
      "save/Assign_8_1\n",
      "save/Assign_9_1\n",
      "save/Assign_10_1\n",
      "save/Assign_11_1\n",
      "save/restore_all_2\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# This module defines the show_graph() function to visualize a TensorFlow graph within Jupyter.\n",
    "\n",
    "# As far as I can tell, this code was originally written by Alex Mordvintsev at:\n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb\n",
    "\n",
    "# The original code only worked on Chrome (because of the use of <link rel=\"import\"...>, but the version below\n",
    "# uses Polyfill (copied from this StackOverflow answer: https://stackoverflow.com/a/41463991/38626)\n",
    "# so that it can work on other browsers as well.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.03681556486084481&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.07439795136451721\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.13093073666095734\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.13093073666095734\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 22\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 39\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;hidden3/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden3/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;hidden3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden3/MatMul&quot;\\n  input: &quot;hidden3/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden3/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 56\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;hidden4/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden4/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  input: &quot;hidden4/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden4/MatMul&quot;\\n  input: &quot;hidden4/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden4/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.24494896829128265\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 73\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;hidden5/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden5/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  input: &quot;hidden5/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden5/MatMul&quot;\\n  input: &quot;hidden5/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden5/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.3162277638912201\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.3162277638912201\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 90\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2&quot;\\n  op: &quot;InTopKV2&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  input: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/in_top_k/InTopKV2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/accuracy&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden5/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden4/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value/Minimum&quot;\\n  input: &quot;clip_by_value/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_1/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_1/Minimum&quot;\\n  input: &quot;clip_by_value_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_2/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_2/Minimum&quot;\\n  input: &quot;clip_by_value_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_3/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_3/Minimum&quot;\\n  input: &quot;clip_by_value_3/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_4/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_4/Minimum&quot;\\n  input: &quot;clip_by_value_4/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_5/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_5/Minimum&quot;\\n  input: &quot;clip_by_value_5/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_6/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_6/Minimum&quot;\\n  input: &quot;clip_by_value_6/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_7/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_7/Minimum&quot;\\n  input: &quot;clip_by_value_7/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_8/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_8/Minimum&quot;\\n  input: &quot;clip_by_value_8/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_9/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_9/Minimum&quot;\\n  input: &quot;clip_by_value_9/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_10/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_10/Minimum&quot;\\n  input: &quot;clip_by_value_10/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_11/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_11/Minimum&quot;\\n  input: &quot;clip_by_value_11/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden3/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden3/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden4/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden4/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden5/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden5/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden3/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden3/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden4/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden4/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden5/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden5/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;save/filename/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/filename&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename/input&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;hidden3/bias&quot;\\n        string_val: &quot;hidden3/kernel&quot;\\n        string_val: &quot;hidden4/bias&quot;\\n        string_val: &quot;hidden4/kernel&quot;\\n        string_val: &quot;hidden5/bias&quot;\\n        string_val: &quot;hidden5/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;hidden3/bias&quot;\\n        string_val: &quot;hidden3/kernel&quot;\\n        string_val: &quot;hidden4/bias&quot;\\n        string_val: &quot;hidden4/kernel&quot;\\n        string_val: &quot;hidden5/bias&quot;\\n        string_val: &quot;hidden5/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;save/RestoreV2:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;save/RestoreV2:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;save/RestoreV2:5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_6&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;save/RestoreV2:6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_7&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;save/RestoreV2:7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_8&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;save/RestoreV2:8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_9&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;save/RestoreV2:9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_10&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;save/RestoreV2:10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_11&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;save/RestoreV2:11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_10&quot;\\n  input: &quot;^save/Assign_11&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n  input: &quot;^save/Assign_6&quot;\\n  input: &quot;^save/Assign_7&quot;\\n  input: &quot;^save/Assign_8&quot;\\n  input: &quot;^save/Assign_9&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.03681556486084481&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"my_important_ops\", op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    # continue training the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9758\n",
      "1 Validation accuracy: 0.9744\n",
      "2 Validation accuracy: 0.974\n",
      "3 Validation accuracy: 0.9764\n",
      "4 Validation accuracy: 0.9732\n",
      "5 Validation accuracy: 0.976\n",
      "6 Validation accuracy: 0.975\n",
      "7 Validation accuracy: 0.9764\n",
      "8 Validation accuracy: 0.9764\n",
      "9 Validation accuracy: 0.9758\n",
      "10 Validation accuracy: 0.9748\n",
      "11 Validation accuracy: 0.9774\n",
      "12 Validation accuracy: 0.9732\n",
      "13 Validation accuracy: 0.9742\n",
      "14 Validation accuracy: 0.9762\n",
      "15 Validation accuracy: 0.976\n",
      "16 Validation accuracy: 0.9756\n",
      "17 Validation accuracy: 0.9762\n",
      "18 Validation accuracy: 0.976\n",
      "19 Validation accuracy: 0.9772\n",
      "20 Validation accuracy: 0.9756\n",
      "21 Validation accuracy: 0.976\n",
      "22 Validation accuracy: 0.977\n",
      "23 Validation accuracy: 0.9756\n",
      "24 Validation accuracy: 0.9754\n",
      "25 Validation accuracy: 0.9766\n",
      "26 Validation accuracy: 0.9756\n",
      "27 Validation accuracy: 0.977\n",
      "28 Validation accuracy: 0.9734\n",
      "29 Validation accuracy: 0.9768\n",
      "30 Validation accuracy: 0.9762\n",
      "31 Validation accuracy: 0.9758\n",
      "32 Validation accuracy: 0.9762\n",
      "33 Validation accuracy: 0.9772\n",
      "34 Validation accuracy: 0.9762\n",
      "35 Validation accuracy: 0.9752\n",
      "36 Validation accuracy: 0.976\n",
      "37 Validation accuracy: 0.9746\n",
      "38 Validation accuracy: 0.977\n",
      "39 Validation accuracy: 0.9754\n",
      "40 Validation accuracy: 0.977\n",
      "41 Validation accuracy: 0.9758\n",
      "42 Validation accuracy: 0.977\n",
      "43 Validation accuracy: 0.9772\n",
      "44 Validation accuracy: 0.976\n",
      "45 Validation accuracy: 0.9762\n",
      "46 Validation accuracy: 0.9756\n",
      "47 Validation accuracy: 0.9768\n",
      "48 Validation accuracy: 0.977\n",
      "49 Validation accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the validation accuracy started off from the last part .9758 and didn't go up that much\n",
    "\n",
    "Alternatively, if you have access to the Python code that build the original graph, you can use it instead of import_meta_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9766\n",
      "1 Validation accuracy: 0.974\n",
      "2 Validation accuracy: 0.9742\n",
      "3 Validation accuracy: 0.976\n",
      "4 Validation accuracy: 0.973\n",
      "5 Validation accuracy: 0.976\n",
      "6 Validation accuracy: 0.975\n",
      "7 Validation accuracy: 0.9764\n",
      "8 Validation accuracy: 0.9764\n",
      "9 Validation accuracy: 0.9756\n",
      "10 Validation accuracy: 0.9748\n",
      "11 Validation accuracy: 0.9774\n",
      "12 Validation accuracy: 0.9732\n",
      "13 Validation accuracy: 0.9742\n",
      "14 Validation accuracy: 0.976\n",
      "15 Validation accuracy: 0.976\n",
      "16 Validation accuracy: 0.9756\n",
      "17 Validation accuracy: 0.9758\n",
      "18 Validation accuracy: 0.9758\n",
      "19 Validation accuracy: 0.9774\n",
      "20 Validation accuracy: 0.9756\n",
      "21 Validation accuracy: 0.9764\n",
      "22 Validation accuracy: 0.9766\n",
      "23 Validation accuracy: 0.9758\n",
      "24 Validation accuracy: 0.9754\n",
      "25 Validation accuracy: 0.9766\n",
      "26 Validation accuracy: 0.9756\n",
      "27 Validation accuracy: 0.9768\n",
      "28 Validation accuracy: 0.9736\n",
      "29 Validation accuracy: 0.9766\n",
      "30 Validation accuracy: 0.9762\n",
      "31 Validation accuracy: 0.9754\n",
      "32 Validation accuracy: 0.9762\n",
      "33 Validation accuracy: 0.9774\n",
      "34 Validation accuracy: 0.9764\n",
      "35 Validation accuracy: 0.9754\n",
      "36 Validation accuracy: 0.9758\n",
      "37 Validation accuracy: 0.9748\n",
      "38 Validation accuracy: 0.9772\n",
      "39 Validation accuracy: 0.9754\n",
      "40 Validation accuracy: 0.9768\n",
      "41 Validation accuracy: 0.9756\n",
      "42 Validation accuracy: 0.9768\n",
      "43 Validation accuracy: 0.9772\n",
      "44 Validation accuracy: 0.976\n",
      "45 Validation accuracy: 0.976\n",
      "46 Validation accuracy: 0.9756\n",
      "47 Validation accuracy: 0.977\n",
      "48 Validation accuracy: 0.977\n",
      "49 Validation accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes: in general you will want to resue only the lower layers. If you are using import_meta_graph() it will load the whole graph, but you can simply ignore the parts you do not need. In this examples, we add a new 4th hidden layer on top of the pretrained 3rd layer (igornoing the 4th hidden layer) We also build a new output layer, the loss for this new output, and a new optimizer to minimuze it. We also neeed another saver to save the whole graph (contain both the entire old grpah and plus the new operations) and an initlization operattion ot initialize all the new vairables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 30\n",
    "n_outputs = 10\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden3/Relu:0\")\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3,n_hidden4,activation=tf.nn.relu,name='new_hidden4')\n",
    "new_logits = tf.layers.dense(new_hidden4,n_outputs,name='new_outputs')\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9422\n",
      "1 Validation accuracy: 0.954\n",
      "2 Validation accuracy: 0.9588\n",
      "3 Validation accuracy: 0.9634\n",
      "4 Validation accuracy: 0.9642\n",
      "5 Validation accuracy: 0.9666\n",
      "6 Validation accuracy: 0.9676\n",
      "7 Validation accuracy: 0.9706\n",
      "8 Validation accuracy: 0.97\n",
      "9 Validation accuracy: 0.9712\n",
      "10 Validation accuracy: 0.9718\n",
      "11 Validation accuracy: 0.973\n",
      "12 Validation accuracy: 0.9704\n",
      "13 Validation accuracy: 0.9722\n",
      "14 Validation accuracy: 0.9744\n",
      "15 Validation accuracy: 0.9746\n",
      "16 Validation accuracy: 0.9748\n",
      "17 Validation accuracy: 0.9736\n",
      "18 Validation accuracy: 0.974\n",
      "19 Validation accuracy: 0.9738\n",
      "20 Validation accuracy: 0.974\n",
      "21 Validation accuracy: 0.9744\n",
      "22 Validation accuracy: 0.9748\n",
      "23 Validation accuracy: 0.976\n",
      "24 Validation accuracy: 0.9754\n",
      "25 Validation accuracy: 0.9758\n",
      "26 Validation accuracy: 0.9748\n",
      "27 Validation accuracy: 0.9744\n",
      "28 Validation accuracy: 0.974\n",
      "29 Validation accuracy: 0.9762\n",
      "30 Validation accuracy: 0.9758\n",
      "31 Validation accuracy: 0.9758\n",
      "32 Validation accuracy: 0.9756\n",
      "33 Validation accuracy: 0.9744\n",
      "34 Validation accuracy: 0.9748\n",
      "35 Validation accuracy: 0.9746\n",
      "36 Validation accuracy: 0.9748\n",
      "37 Validation accuracy: 0.9746\n",
      "38 Validation accuracy: 0.9762\n",
      "39 Validation accuracy: 0.9736\n",
      "40 Validation accuracy: 0.9762\n",
      "41 Validation accuracy: 0.9744\n",
      "42 Validation accuracy: 0.9772\n",
      "43 Validation accuracy: 0.9766\n",
      "44 Validation accuracy: 0.9762\n",
      "45 Validation accuracy: 0.9764\n",
      "46 Validation accuracy: 0.9764\n",
      "47 Validation accuracy: 0.9752\n",
      "48 Validation accuracy: 0.9752\n",
      "49 Validation accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    #creating a new model reusing old layers buyt adding new ones\n",
    "    save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have access to the python code that built the original grpah, you can just resue the parts you need and drop the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None),name='y')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you must create one Saver to restore the pretrained model (giving) it the list of variables to restore, ot else it will complain that the grpahs dont mathc) and another Saver to save the new model once it is trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 validation accuracy: 0.9094\n",
      "1 validation accuracy: 0.943\n",
      "2 validation accuracy: 0.9524\n",
      "3 validation accuracy: 0.9568\n",
      "4 validation accuracy: 0.9606\n",
      "5 validation accuracy: 0.9632\n",
      "6 validation accuracy: 0.9664\n",
      "7 validation accuracy: 0.9676\n",
      "8 validation accuracy: 0.9692\n",
      "9 validation accuracy: 0.97\n",
      "10 validation accuracy: 0.972\n",
      "11 validation accuracy: 0.9728\n",
      "12 validation accuracy: 0.9712\n",
      "13 validation accuracy: 0.9722\n",
      "14 validation accuracy: 0.9728\n",
      "15 validation accuracy: 0.974\n",
      "16 validation accuracy: 0.9738\n",
      "17 validation accuracy: 0.974\n",
      "18 validation accuracy: 0.9742\n",
      "19 validation accuracy: 0.9748\n",
      "20 validation accuracy: 0.9744\n",
      "21 validation accuracy: 0.9754\n",
      "22 validation accuracy: 0.9758\n",
      "23 validation accuracy: 0.977\n",
      "24 validation accuracy: 0.9754\n",
      "25 validation accuracy: 0.9764\n",
      "26 validation accuracy: 0.9758\n",
      "27 validation accuracy: 0.9762\n",
      "28 validation accuracy: 0.9746\n",
      "29 validation accuracy: 0.9766\n",
      "30 validation accuracy: 0.9764\n",
      "31 validation accuracy: 0.9762\n",
      "32 validation accuracy: 0.9762\n",
      "33 validation accuracy: 0.9752\n",
      "34 validation accuracy: 0.9756\n",
      "35 validation accuracy: 0.975\n",
      "36 validation accuracy: 0.9768\n",
      "37 validation accuracy: 0.975\n",
      "38 validation accuracy: 0.9768\n",
      "39 validation accuracy: 0.9756\n",
      "40 validation accuracy: 0.9762\n",
      "41 validation accuracy: 0.9774\n",
      "42 validation accuracy: 0.9772\n",
      "43 validation accuracy: 0.9766\n",
      "44 validation accuracy: 0.9758\n",
      "45 validation accuracy: 0.9764\n",
      "46 validation accuracy: 0.9774\n",
      "47 validation accuracy: 0.977\n",
      "48 validation accuracy: 0.9774\n",
      "49 validation accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                              scope='hidden[123]') #regular expression\n",
    "\n",
    "restore_saver = tf.train.Saver(reuse_vars) #to restore the layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch,y_batch in shuffle_batch(X_train,y_train,batch_size):\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X:X_valid,y:y_valid})\n",
    "        print(epoch,\"validation accuracy:\", accuracy_val)\n",
    "    \n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Models from Other Frameworks\n",
    "\n",
    "In this example, for each variable we want to reuse, we find its initializer assignment operations, adn get its second input, which corresports to the initlization value. When we run the initliazer, we replace the initlization values with the ones we want, using a feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "original_w = [[1.,2.,3.],[4.,5.,6.]]\n",
    "original_b = [7.,8.,9]\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "hidden1 = tf.layers.dense(X,n_hidden1,activation=tf.nn.relu,name='hidden1')\n",
    "\n",
    "#we need to get handles on the asignment nodes for the hidden1 variables\n",
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name(\"hidden1/kernel/Assign\")\n",
    "assign_bias = graph.get_operation_by_name(\"hidden1/bias/Assign\")\n",
    "init_kernel = assign_kernel.inputs[1]\n",
    "init_bias = assign_bias.inputs[1]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, feed_dict = {init_kernel:original_w,init_bias:original_b})\n",
    "    print(hidden1.eval(feed_dict={X:[[10.0,11.0]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: the weights variable created by the tf.layers.dense() functino is called kernel instead of wieghts, but the bias still reamins the same\n",
    "\n",
    "another approach (initually used before) would be to create the dedicated assignment nodes and dedicated placeholders. This is more verbose and less effcient, but easier to intrepete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3\n",
    "\n",
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights from the other framework\n",
    "original_b = [7., 8., 9.]                 # Load the biases from the other framework\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] Build the rest of the model\n",
    "\n",
    "#get handles on the variables of the hidden1\n",
    "with tf.variable_scope(\"\",default_name=\"\",reuse=True): #root scope\n",
    "    hidden1_weights = tf.get_variable(\"hidden1/kernel\")\n",
    "    hidden1_biases = tf.get_variable(\"hidden1/bias\")\n",
    "    \n",
    "#create dedicated placeholders and assignment nodes\n",
    "original_weights = tf.placeholder(tf.float32,shape=(n_inputs,n_hidden1))\n",
    "original_biases = tf.placeholder(tf.float32,shape=n_hidden1)\n",
    "assign_hidden1_weights = tf.assign(hidden1_weights,original_weights)\n",
    "assign_hidden1_biases = tf.assign(hidden1_biases, original_biases)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(assign_hidden1_weights,feed_dict ={original_weights:original_w})\n",
    "    sess.run(assign_hidden1_biases,feed_dict={original_biases:original_b})\n",
    "    print(hidden1.eval(feed_dict={X:[[10.0,11.0]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could also get a handle on the variables using get_collection() and specify the scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'X' type=Placeholder>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'hidden1/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden1/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/bias/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/MatMul' type=MatMul>,\n",
       " <tf.Operation 'hidden1/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'hidden1/Relu' type=Relu>,\n",
       " <tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_1' type=Placeholder>,\n",
       " <tf.Operation 'Assign' type=Assign>,\n",
       " <tf.Operation 'Assign_1' type=Assign>,\n",
       " <tf.Operation 'init' type=NoOp>]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/bias:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing the lower layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'X' type=Placeholder>,\n",
       " <tf.Operation 'y' type=Placeholder>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'hidden1/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden1/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/hidden1/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/hidden1/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dnn/hidden1/Relu' type=Relu>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'hidden2/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden2/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden2/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/hidden2/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/hidden2/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dnn/hidden2/Relu' type=Relu>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'hidden3/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden3/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden3/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/hidden3/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/hidden3/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dnn/hidden3/Relu' type=Relu>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'hidden4/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'hidden4/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden4/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden4/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden4/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden4/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden4/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden4/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/hidden4/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/hidden4/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'dnn/hidden4/Relu' type=Relu>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'outputs/kernel/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'outputs/kernel' type=VariableV2>,\n",
       " <tf.Operation 'outputs/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'outputs/kernel/read' type=Identity>,\n",
       " <tf.Operation 'outputs/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'outputs/bias' type=VariableV2>,\n",
       " <tf.Operation 'outputs/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'outputs/bias/read' type=Identity>,\n",
       " <tf.Operation 'dnn/outputs/MatMul' type=MatMul>,\n",
       " <tf.Operation 'dnn/outputs/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'loss/SparseSoftmaxCrossEntropyWithLogits/Shape' type=Shape>,\n",
       " <tf.Operation 'loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' type=SparseSoftmaxCrossEntropyWithLogits>,\n",
       " <tf.Operation 'loss/Const' type=Const>,\n",
       " <tf.Operation 'loss/loss' type=Mean>,\n",
       " <tf.Operation 'eval/in_top_k/InTopKV2/k' type=Const>,\n",
       " <tf.Operation 'eval/in_top_k/InTopKV2' type=InTopKV2>,\n",
       " <tf.Operation 'eval/Cast' type=Cast>,\n",
       " <tf.Operation 'eval/Const' type=Const>,\n",
       " <tf.Operation 'eval/accuracy' type=Mean>]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assignet trains vars to only hidden34\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                  scope='hidden[34]|outputs')\n",
    "    training_op = optimizer.minimize(loss, var_list = train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x1cf0b66d30>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.911\n",
      "1 Validation accuracy: 0.9438\n",
      "2 Validation accuracy: 0.9526\n",
      "3 Validation accuracy: 0.9568\n",
      "4 Validation accuracy: 0.9616\n",
      "5 Validation accuracy: 0.9634\n",
      "6 Validation accuracy: 0.966\n",
      "7 Validation accuracy: 0.9678\n",
      "8 Validation accuracy: 0.969\n",
      "9 Validation accuracy: 0.9688\n",
      "10 Validation accuracy: 0.969\n",
      "11 Validation accuracy: 0.9704\n",
      "12 Validation accuracy: 0.971\n",
      "13 Validation accuracy: 0.971\n",
      "14 Validation accuracy: 0.9714\n",
      "15 Validation accuracy: 0.9714\n",
      "16 Validation accuracy: 0.9712\n",
      "17 Validation accuracy: 0.9708\n",
      "18 Validation accuracy: 0.9714\n",
      "19 Validation accuracy: 0.9724\n",
      "20 Validation accuracy: 0.9712\n",
      "21 Validation accuracy: 0.9726\n",
      "22 Validation accuracy: 0.9714\n",
      "23 Validation accuracy: 0.972\n",
      "24 Validation accuracy: 0.9724\n",
      "25 Validation accuracy: 0.9722\n",
      "26 Validation accuracy: 0.973\n",
      "27 Validation accuracy: 0.9734\n",
      "28 Validation accuracy: 0.9734\n",
      "29 Validation accuracy: 0.9734\n",
      "30 Validation accuracy: 0.9724\n",
      "31 Validation accuracy: 0.9738\n",
      "32 Validation accuracy: 0.973\n",
      "33 Validation accuracy: 0.973\n",
      "34 Validation accuracy: 0.973\n",
      "35 Validation accuracy: 0.973\n",
      "36 Validation accuracy: 0.9722\n",
      "37 Validation accuracy: 0.9726\n",
      "38 Validation accuracy: 0.9726\n",
      "39 Validation accuracy: 0.9724\n",
      "40 Validation accuracy: 0.9738\n",
      "41 Validation accuracy: 0.9738\n",
      "42 Validation accuracy: 0.9736\n",
      "43 Validation accuracy: 0.9738\n",
      "44 Validation accuracy: 0.9726\n",
      "45 Validation accuracy: 0.9734\n",
      "46 Validation accuracy: 0.9742\n",
      "47 Validation accuracy: 0.9734\n",
      "48 Validation accuracy: 0.9736\n",
      "49 Validation accuracy: 0.9736\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4,n_outputs,name='outputs') #new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='accuracy')\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9166\n",
      "1 Validation accuracy: 0.9478\n",
      "2 Validation accuracy: 0.9578\n",
      "3 Validation accuracy: 0.9618\n",
      "4 Validation accuracy: 0.9638\n",
      "5 Validation accuracy: 0.9654\n",
      "6 Validation accuracy: 0.9668\n",
      "7 Validation accuracy: 0.9678\n",
      "8 Validation accuracy: 0.969\n",
      "9 Validation accuracy: 0.9686\n",
      "10 Validation accuracy: 0.9702\n",
      "11 Validation accuracy: 0.9696\n",
      "12 Validation accuracy: 0.9708\n",
      "13 Validation accuracy: 0.9706\n",
      "14 Validation accuracy: 0.9712\n",
      "15 Validation accuracy: 0.972\n",
      "16 Validation accuracy: 0.9714\n",
      "17 Validation accuracy: 0.9716\n",
      "18 Validation accuracy: 0.9712\n",
      "19 Validation accuracy: 0.9712\n",
      "20 Validation accuracy: 0.9722\n",
      "21 Validation accuracy: 0.9726\n",
      "22 Validation accuracy: 0.9722\n",
      "23 Validation accuracy: 0.9722\n",
      "24 Validation accuracy: 0.9728\n",
      "25 Validation accuracy: 0.9722\n",
      "26 Validation accuracy: 0.9732\n",
      "27 Validation accuracy: 0.9728\n",
      "28 Validation accuracy: 0.9728\n",
      "29 Validation accuracy: 0.9738\n",
      "30 Validation accuracy: 0.9732\n",
      "31 Validation accuracy: 0.9732\n",
      "32 Validation accuracy: 0.9732\n",
      "33 Validation accuracy: 0.9724\n",
      "34 Validation accuracy: 0.9726\n",
      "35 Validation accuracy: 0.9732\n",
      "36 Validation accuracy: 0.9718\n",
      "37 Validation accuracy: 0.9726\n",
      "38 Validation accuracy: 0.9728\n",
      "39 Validation accuracy: 0.9724\n",
      "40 Validation accuracy: 0.973\n",
      "41 Validation accuracy: 0.973\n",
      "42 Validation accuracy: 0.9736\n",
      "43 Validation accuracy: 0.973\n",
      "44 Validation accuracy: 0.9728\n",
      "45 Validation accuracy: 0.9734\n",
      "46 Validation accuracy: 0.9738\n",
      "47 Validation accuracy: 0.9724\n",
      "48 Validation accuracy: 0.9728\n",
      "49 Validation accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "#resue layes with trained weights\n",
    "#using saver to bring them back\n",
    "#creating a new saver\n",
    "\n",
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cahing the Frozen layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen & cached\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope='hidden[123]') #regex\n",
    "\n",
    "restore_saver = tf.train.Saver(reuse_vars) #to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9152\n",
      "1 Validation accuracy: 0.953\n",
      "2 Validation accuracy: 0.9594\n",
      "3 Validation accuracy: 0.9612\n",
      "4 Validation accuracy: 0.9626\n",
      "5 Validation accuracy: 0.9648\n",
      "6 Validation accuracy: 0.967\n",
      "7 Validation accuracy: 0.9692\n",
      "8 Validation accuracy: 0.9676\n",
      "9 Validation accuracy: 0.9688\n",
      "10 Validation accuracy: 0.9696\n",
      "11 Validation accuracy: 0.9706\n",
      "12 Validation accuracy: 0.9706\n",
      "13 Validation accuracy: 0.9708\n",
      "14 Validation accuracy: 0.971\n",
      "15 Validation accuracy: 0.9714\n",
      "16 Validation accuracy: 0.9714\n",
      "17 Validation accuracy: 0.9712\n",
      "18 Validation accuracy: 0.9708\n",
      "19 Validation accuracy: 0.9714\n",
      "20 Validation accuracy: 0.9722\n",
      "21 Validation accuracy: 0.9722\n",
      "22 Validation accuracy: 0.972\n",
      "23 Validation accuracy: 0.9726\n",
      "24 Validation accuracy: 0.972\n",
      "25 Validation accuracy: 0.9726\n",
      "26 Validation accuracy: 0.9724\n",
      "27 Validation accuracy: 0.9726\n",
      "28 Validation accuracy: 0.9734\n",
      "29 Validation accuracy: 0.9728\n",
      "30 Validation accuracy: 0.9734\n",
      "31 Validation accuracy: 0.9732\n",
      "32 Validation accuracy: 0.9722\n",
      "33 Validation accuracy: 0.9726\n",
      "34 Validation accuracy: 0.9732\n",
      "35 Validation accuracy: 0.9716\n",
      "36 Validation accuracy: 0.9726\n",
      "37 Validation accuracy: 0.9734\n",
      "38 Validation accuracy: 0.9718\n",
      "39 Validation accuracy: 0.9732\n",
      "40 Validation accuracy: 0.9732\n",
      "41 Validation accuracy: 0.9734\n",
      "42 Validation accuracy: 0.9732\n",
      "43 Validation accuracy: 0.9726\n",
      "44 Validation accuracy: 0.9734\n",
      "45 Validation accuracy: 0.9734\n",
      "46 Validation accuracy: 0.9724\n",
      "47 Validation accuracy: 0.9732\n",
      "48 Validation accuracy: 0.9732\n",
      "49 Validation accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_bacthes = len(X_train) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    h2_cache = sess.run(hidden2,feed_dict ={X:X_train})\n",
    "    h2_cache_valid = sess.run(hidden2,feed_dict={X:X_valid})\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(len(X_train))\n",
    "        hidden2_batches = np.array_split(h2_cache[shuffled_idx],n_bacthes)\n",
    "        y_batches = np.array_split(y_train[shuffled_idx],n_bacthes)\n",
    "        for hidden2_batch,y_batch in zip(hidden2_batches,y_batches):\n",
    "            sess.run(training_op,feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "        \n",
    "        accuracy_val = accuracy.eval(feed_dict={hidden2: h2_cache_valid, # not shown\n",
    "                                                y: y_valid})             # not shown\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)               # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34191, 23679, 44684, ..., 38158,   860, 15795])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum\n",
    "\n",
    "\\begin{align*}\n",
    "m \\to \\beta m - \\eta \\nabla_\\theta J(\\theta) \\\\\n",
    "\\theta \\to \\theta + m\n",
    "\\end{align*}\n",
    "\n",
    "Takes into account previous gradients, and gradient is used an acceleration and not speed, the beta value is used to simulate friction so it doesnt go shooting past the minimum. If the gradient remains constant, is it no different than multiplying by 1/1-beta. Helps roll past plateus\n",
    "\n",
    "m is just a sum of the previous gradients, sorta of but think of it like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Accelerate gradient descent\n",
    "\n",
    "\\begin{align*}\n",
    "m \\leftarrow \\beta m - \\eta \\nabla_\\theta J(\\theta + \\beta m)\\\\\n",
    "\\theta \\leftarrow + m \\\\\n",
    "\\end{align*}\n",
    "\n",
    "measure gradient not just at the local position, but also slighlty ahead. generally the momentum vectors will be pointing ahead in the right direction but a bit further with $J (\\theta + \\beta m)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad\n",
    "\n",
    "\\begin{align*}\n",
    "s \\leftarrow s + \\nabla_\\theta J(\\theta) \\otimes \\nabla_\\theta J(\\theta) \\\\\n",
    "\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J (\\theta) \\oslash \\sqrt{s + \\epsilon} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "first step is to quare the gradietns wrt to each theta. the vecotrized form is equivalent to $s_i \\leftarrow s_i + (\\frac{\\partial J(\\theta)}{\\partial \\theta_i})^2$\n",
    "\n",
    "then it is scaled down by $\\sqrt{s + \\epsilon}$\n",
    "\n",
    "this decays the learning rate proportional to the squared gradients, also called adaptive learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp\n",
    "\n",
    "\\begin{align*}\n",
    "s \\leftarrow \\beta s + (1 - \\beta) \\nabla_\\theta J(\\theta) \\otimes \\nabla_\\theta J(\\theta) \\\\\n",
    "\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta) \\oslash \\sqrt{s + \\epsilon} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "exponential decay with adagrad, again typically sent  0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam optimization\n",
    "\n",
    "stands for adaptive moment estimatinos and cmobines momentum and RMS prop, just like mometums is keeps track of an exponentially deacaying average of past gradeitns, and like RMS prop keeps track of an exponenitally decarying averae of past squared gradients\n",
    "\n",
    "\\begin{align*}\n",
    "m \\leftarrow \\beta_1 m - (1 - \\beta_1) \\nabla_\\theta J(\\theta) \\\\\n",
    "s \\leftarrow \\beta_2 s + (1-\\beta_2) \\nabla_\\theta J(\\theta) \\otimes  \\nabla_\\theta J(\\theta) \\\\\n",
    "\\hat{m} \\leftarrow \\frac{m}{1-\\beta_1^t}\\\\\n",
    "\\hat{s} \\leftarrow \\frac{s}{1 -\\beta_2^t} \\\\\n",
    "\\theta \\leftarrow \\theta + \\eta \\hat{m} \\oslash \\sqrt{\\hat{s} + \\epsilon} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "beta1 initalizes is the momentum decay hyperpatmeter and beta2 os hte scaling decay hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None, n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0,trainable=False,name='global_step')\n",
    "    learning_rate - tf.train.exponential_decay(initial_learning_rate,global_step,\n",
    "                                              decay_steps,decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate,momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9338\n",
      "1 Validation accuracy: 0.9496\n",
      "2 Validation accuracy: 0.9572\n",
      "3 Validation accuracy: 0.9682\n",
      "4 Validation accuracy: 0.9688\n",
      "5 Validation accuracy: 0.972\n",
      "6 Validation accuracy: 0.9752\n",
      "7 Validation accuracy: 0.9778\n",
      "8 Validation accuracy: 0.9782\n",
      "9 Validation accuracy: 0.9786\n",
      "10 Validation accuracy: 0.9786\n",
      "11 Validation accuracy: 0.981\n",
      "12 Validation accuracy: 0.9792\n",
      "13 Validation accuracy: 0.9784\n",
      "14 Validation accuracy: 0.9804\n",
      "15 Validation accuracy: 0.9818\n",
      "16 Validation accuracy: 0.982\n",
      "17 Validation accuracy: 0.9826\n",
      "18 Validation accuracy: 0.9812\n",
      "19 Validation accuracy: 0.983\n",
      "20 Validation accuracy: 0.9818\n",
      "21 Validation accuracy: 0.9814\n",
      "22 Validation accuracy: 0.9824\n",
      "23 Validation accuracy: 0.982\n",
      "24 Validation accuracy: 0.982\n",
      "25 Validation accuracy: 0.9828\n",
      "26 Validation accuracy: 0.983\n",
      "27 Validation accuracy: 0.9832\n",
      "28 Validation accuracy: 0.983\n",
      "29 Validation accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding overfitting Through regularization\n",
    "\n",
    "### $\\mathscr{l}_1 and \\mathscr{l}_2$ regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets implement $\\mathscr{l}_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we get a hanle on the layer wieghts, and we compute the total loss, which is euqal to the sum of the usual cross entropy loss and the $\\matchscr{l}_1$ loss (or jus the absolute value of the weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\")\n",
    "\n",
    "scale = 0.001\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy,name='avg_xentropy')\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1) + tf.reduce_sum(tf.abs(W2)))\n",
    "    loss = tf.add(base_loss,scale*reg_losses,name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again with the usual approach\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='accuracy')\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "save = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8776\n",
      "1 Validation accuracy: 0.0148\n",
      "2 Validation accuracy: 0.868\n",
      "3 Validation accuracy: 0.0788\n",
      "4 Validation accuracy: 0.8694\n",
      "5 Validation accuracy: 0.2064\n",
      "6 Validation accuracy: 0.8668\n",
      "7 Validation accuracy: 0.1398\n",
      "8 Validation accuracy: 0.8276\n",
      "9 Validation accuracy: 0.2006\n",
      "10 Validation accuracy: 0.871\n",
      "11 Validation accuracy: 0.212\n",
      "12 Validation accuracy: 0.9016\n",
      "13 Validation accuracy: 0.2048\n",
      "14 Validation accuracy: 0.7806\n",
      "15 Validation accuracy: 0.2294\n",
      "16 Validation accuracy: 0.7672\n",
      "17 Validation accuracy: 0.2062\n",
      "18 Validation accuracy: 0.764\n",
      "19 Validation accuracy: 0.207\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can pass a regulaization function to the tf.layers.dense() function which will use it to create operations that will compute the regulazation loss, and it adds these operatinos to the collecitno of regulatzation losses. The beginning is the same as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use python's partial function to avoiad repating teh same arugments over and over again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = my_dense_layer(X,n_hidden1,name='hidden1')\n",
    "    hidden2 = my_dense_layer(hidden1,n_hidden2,name='hidden2')\n",
    "    logits = my_dense_layer(hidden2,n_outputs,activation=None,name='outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to add the l2 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name='avg_xentropy')\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses,name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8274\n",
      "1 Validation accuracy: 0.8766\n",
      "2 Validation accuracy: 0.8952\n",
      "3 Validation accuracy: 0.9016\n",
      "4 Validation accuracy: 0.9084\n",
      "5 Validation accuracy: 0.9096\n",
      "6 Validation accuracy: 0.9126\n",
      "7 Validation accuracy: 0.9154\n",
      "8 Validation accuracy: 0.9178\n",
      "9 Validation accuracy: 0.919\n",
      "10 Validation accuracy: 0.92\n",
      "11 Validation accuracy: 0.9224\n",
      "12 Validation accuracy: 0.9212\n",
      "13 Validation accuracy: 0.9228\n",
      "14 Validation accuracy: 0.9224\n",
      "15 Validation accuracy: 0.9218\n",
      "16 Validation accuracy: 0.9218\n",
      "17 Validation accuracy: 0.9228\n",
      "18 Validation accuracy: 0.9216\n",
      "19 Validation accuracy: 0.9214\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-272-d22fa50fdb2c>:4: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    }
   ],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(),name='training')\n",
    "\n",
    "dropout_rate = 0.5\n",
    "X_drop = tf.layers.dropout(X,dropout_rate,training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop,n_hidden1,activation=tf.nn.relu,name='hidden1')\n",
    "    hidden1_drop = tf.layers.dropout(hidden1,dropout_rate,training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop,n_hidden2,activation=tf.nn.relu,name='hidden2')\n",
    "    hidden2_drop = tf.layers.dropout(hidden2,dropout_rate,training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop,n_outputs,name='outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8766\n",
      "1 Validation accuracy: 0.9102\n",
      "2 Validation accuracy: 0.9224\n",
      "3 Validation accuracy: 0.9312\n",
      "4 Validation accuracy: 0.9376\n",
      "5 Validation accuracy: 0.943\n",
      "6 Validation accuracy: 0.9474\n",
      "7 Validation accuracy: 0.952\n",
      "8 Validation accuracy: 0.9538\n",
      "9 Validation accuracy: 0.9564\n",
      "10 Validation accuracy: 0.9596\n",
      "11 Validation accuracy: 0.961\n",
      "12 Validation accuracy: 0.9608\n",
      "13 Validation accuracy: 0.9612\n",
      "14 Validation accuracy: 0.9626\n",
      "15 Validation accuracy: 0.9622\n",
      "16 Validation accuracy: 0.9628\n",
      "17 Validation accuracy: 0.9648\n",
      "18 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.9652\n",
      "20 Validation accuracy: 0.9672\n",
      "21 Validation accuracy: 0.9668\n",
      "22 Validation accuracy: 0.969\n",
      "23 Validation accuracy: 0.9682\n",
      "24 Validation accuracy: 0.9686\n",
      "25 Validation accuracy: 0.9684\n",
      "26 Validation accuracy: 0.9686\n",
      "27 Validation accuracy: 0.9702\n",
      "28 Validation accuracy: 0.9712\n",
      "29 Validation accuracy: 0.9698\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Norm\n",
    "\n",
    "Lets go back to a plain and simple nueral net for the MNIST with just two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 10\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X,n_hidden1,activation=tf.nn.relu,name='hidden1')\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2,n_hidden3,activation=tf.nn.relu,name='hidden3')\n",
    "    logits = tf.layers.dense(hidden3, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss) \n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get hangdle on the first hidden layer's weight and create an operation that will compute the clipped weihts using the clip by norm funcion. Then create a assigment operations to assign the clipped wieghts to the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for the second and third layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)\n",
    "\n",
    "weights3 = tf.get_default_graph().get_tensor_by_name(\"hidden3/kernel:0\")\n",
    "clipped_weights3 = tf.clip_by_norm(weights3, clip_norm=threshold, axes=1)\n",
    "clip_weights3 = tf.assign(weights3, clipped_weights3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add an initalizer and a saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model. pretty much the same thing, except that after running the training_op, we run the clip_weights and clip_weights2 operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9396\n",
      "1 Validation accuracy: 0.9654\n",
      "2 Validation accuracy: 0.9618\n",
      "3 Validation accuracy: 0.9714\n",
      "4 Validation accuracy: 0.9738\n",
      "5 Validation accuracy: 0.9728\n",
      "6 Validation accuracy: 0.9808\n",
      "7 Validation accuracy: 0.9806\n",
      "8 Validation accuracy: 0.9792\n",
      "9 Validation accuracy: 0.9796\n",
      "10 Validation accuracy: 0.9786\n",
      "11 Validation accuracy: 0.9822\n",
      "12 Validation accuracy: 0.9818\n",
      "13 Validation accuracy: 0.9834\n",
      "14 Validation accuracy: 0.983\n",
      "15 Validation accuracy: 0.9834\n",
      "16 Validation accuracy: 0.9836\n",
      "17 Validation accuracy: 0.983\n",
      "18 Validation accuracy: 0.9838\n",
      "19 Validation accuracy: 0.9838\n",
      "20 Validation accuracy: 0.984\n",
      "21 Validation accuracy: 0.9842\n",
      "22 Validation accuracy: 0.9842\n",
      "23 Validation accuracy: 0.9838\n",
      "24 Validation accuracy: 0.9842\n",
      "25 Validation accuracy: 0.9846\n",
      "26 Validation accuracy: 0.9844\n",
      "27 Validation accuracy: 0.9844\n",
      "28 Validation accuracy: 0.984\n",
      "29 Validation accuracy: 0.9834\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                              # not shown in the book\n",
    "    init.run()                                                          # not shown\n",
    "    for epoch in range(n_epochs):                                       # not shown\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): # not shown\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()\n",
    "            clip_weights2.eval() \n",
    "            clip_weights3.eval()# not shown\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})   # not shown\n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)                 # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets' define a function instead to make the code look cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_norm_regularizer(threshold,axes=1,name='max_norm',collection='max_norm'):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights,clip_norm=threshold,axes=axes)\n",
    "        clip_weights = tf.assign(weights,clipped,name=name)\n",
    "        tf.add_to_collection(collection,clip_weights)\n",
    "        return(None) #no reg loss term\n",
    "    return(max_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call this function to get a maxnorm regularize (with the threshold you want). When you create a hidden layer, you can pass this regularizer to the kernel_regualizer argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9558\n",
      "1 Validation accuracy: 0.9706\n",
      "2 Validation accuracy: 0.9732\n",
      "3 Validation accuracy: 0.9756\n",
      "4 Validation accuracy: 0.9762\n",
      "5 Validation accuracy: 0.9778\n",
      "6 Validation accuracy: 0.98\n",
      "7 Validation accuracy: 0.9804\n",
      "8 Validation accuracy: 0.981\n",
      "9 Validation accuracy: 0.9806\n",
      "10 Validation accuracy: 0.9816\n",
      "11 Validation accuracy: 0.9804\n",
      "12 Validation accuracy: 0.98\n",
      "13 Validation accuracy: 0.982\n",
      "14 Validation accuracy: 0.9816\n",
      "15 Validation accuracy: 0.9812\n",
      "16 Validation accuracy: 0.9818\n",
      "17 Validation accuracy: 0.9834\n",
      "18 Validation accuracy: 0.9822\n",
      "19 Validation accuracy: 0.9818\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) # not shown\n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)               # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "\n",
    "Build a DNN with fiver hiden layers of 100 nuerons each using He intilization, and ELU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers=5, n_neurons=100, name=None,\n",
    "        activation=tf.nn.elu, initializer=he_init):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n",
    "                                     kernel_initializer=initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "        return(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "n_outputs = 5\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs,n_outputs,kernel_initializer=he_init,name='logits')\n",
    "Y_proba = tf.nn.softmax(logits,name='Y_proba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Using Adam optimization and early stopping, try training it on MNIST but only on digits 0 to 4, as we will use transfer learning for digits 5 to 9 in the next exercise. You will need a softmax output layer with five neurons, and as always make sure to save checkpoints at regular intervals and save the final model so you can reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss = tf.reduce_mean(xentropy,name='loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss,name='training_op')\n",
    "\n",
    "correct = tf.nn.in_top_k(logits,y,1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='accuracy')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training data\n",
    "X_train1 = X_train[y_train < 5]\n",
    "y_train1 = y_train[y_train < 5]\n",
    "X_valid1 = X_valid[y_valid < 5]\n",
    "y_valid1 = y_valid[y_valid < 5]\n",
    "X_test1 = X_test[y_test < 5]\n",
    "y_test1 = y_test[y_test < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.118546\tBest loss: 0.118546\tAccuracy: 97.19%\n",
      "1\tValidation loss: 0.301569\tBest loss: 0.118546\tAccuracy: 93.71%\n",
      "2\tValidation loss: 0.088212\tBest loss: 0.088212\tAccuracy: 97.58%\n",
      "3\tValidation loss: 0.129962\tBest loss: 0.088212\tAccuracy: 97.34%\n",
      "4\tValidation loss: 0.095969\tBest loss: 0.088212\tAccuracy: 97.89%\n",
      "5\tValidation loss: 0.114553\tBest loss: 0.088212\tAccuracy: 97.46%\n",
      "6\tValidation loss: 0.066793\tBest loss: 0.066793\tAccuracy: 98.28%\n",
      "7\tValidation loss: 0.098616\tBest loss: 0.066793\tAccuracy: 98.16%\n",
      "8\tValidation loss: 0.149317\tBest loss: 0.066793\tAccuracy: 97.07%\n",
      "9\tValidation loss: 0.633880\tBest loss: 0.066793\tAccuracy: 77.13%\n",
      "10\tValidation loss: 0.121953\tBest loss: 0.066793\tAccuracy: 98.48%\n",
      "11\tValidation loss: 0.108103\tBest loss: 0.066793\tAccuracy: 97.85%\n",
      "12\tValidation loss: 0.104843\tBest loss: 0.066793\tAccuracy: 98.05%\n",
      "13\tValidation loss: 0.124018\tBest loss: 0.066793\tAccuracy: 98.44%\n",
      "14\tValidation loss: 0.148071\tBest loss: 0.066793\tAccuracy: 96.76%\n",
      "15\tValidation loss: 0.215179\tBest loss: 0.066793\tAccuracy: 95.31%\n",
      "16\tValidation loss: 0.225586\tBest loss: 0.066793\tAccuracy: 97.97%\n",
      "17\tValidation loss: 0.268801\tBest loss: 0.066793\tAccuracy: 93.67%\n",
      "18\tValidation loss: 0.231483\tBest loss: 0.066793\tAccuracy: 97.65%\n",
      "19\tValidation loss: 0.156306\tBest loss: 0.066793\tAccuracy: 97.58%\n",
      "20\tValidation loss: 0.371843\tBest loss: 0.066793\tAccuracy: 90.93%\n",
      "21\tValidation loss: 0.196588\tBest loss: 0.066793\tAccuracy: 97.19%\n",
      "22\tValidation loss: 5.230506\tBest loss: 0.066793\tAccuracy: 87.14%\n",
      "23\tValidation loss: 1.478813\tBest loss: 0.066793\tAccuracy: 89.87%\n",
      "24\tValidation loss: 0.251248\tBest loss: 0.066793\tAccuracy: 94.10%\n",
      "25\tValidation loss: 0.169567\tBest loss: 0.066793\tAccuracy: 97.62%\n",
      "26\tValidation loss: 0.152952\tBest loss: 0.066793\tAccuracy: 98.01%\n",
      "27\tValidation loss: 0.274072\tBest loss: 0.066793\tAccuracy: 98.12%\n",
      "EARLY STOPPING!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4.ckpt\n",
      "Final test accuracy: 98.70%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 30\n",
    "\n",
    "max_checks_without_progress = 21\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train1) // batch_size):\n",
    "            X_batch,y_batch = X_train1[rnd_indices],y_train1[rnd_indices]\n",
    "            sess.run(training_op,feed_dict={X:X_batch, y:y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid1, y: y_valid1})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess,\"./my_mnist_model_0_to_4.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress +=1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print('EARLY STOPPING!')\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercsie 8.3\n",
    "\n",
    "Tune the hyperparmaters using corss valdiation and see what prceision you can acheive\n",
    "\n",
    "first ets create a a DNN classifier class, that it is comptaible with skleanrs randomized cv class to perform hyperparemters tuning. THe key points of this implementaion include:\n",
    "\n",
    "* the __init__ method contruct doest nothing more thanc reate the instance variabels for each of the hyperparamters\n",
    "* the fit method creates the grpah and starts the session and trains the model:\n",
    "* it class the -builgrpah method. once called it saves all the imporant operations and instance variable for easy access by other methods\n",
    "* the _dnn() method bulds the hiddne layers, just like the dnn function avove, bt also wut support for batch norm and drop out\n",
    "* the fit() mehtod vies a vldiatoin set then implements early stoppping, it same the model to memory\n",
    "* afer the fit() method has finisehd training the model, it keeps the session open so that predicitons can be made quickly without having to save a model to disk and restor it for every pediciton, you can clos the ssion by calling the close_sesion method\n",
    "* the predict_proba method uses the traind model to prdict class proablitles\n",
    "* the predict method call the predict proba dnr eturns the class with the highest probablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=5, n_neurons=100, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=20, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, random_state=None):\n",
    "        \"\"\"Initialize the DNNClassifier by simply storing all the hyperparameters.\"\"\"\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        \"\"\"Build the hidden layers, with support for batch normalization and dropout.\"\"\"\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training=self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
    "                                     kernel_initializer=self.initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "\n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        \"\"\"Build the same model as earlier\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        dnn_outputs = self._dnn(X)\n",
    "\n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                  logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Make the important operations available easily through instance variables\n",
    "        self._X, self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Get all variable values (used for early stopping, faster than saving to disk)\"\"\"\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_params(self, model_params):\n",
    "        \"\"\"Set all variables to the given values (for early stopping, faster than loading from disk)\"\"\"\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        \"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        \n",
    "        # Translate the labels vector to a vector of sorted class indices, containing\n",
    "        # integers from 0 to n_outputs - 1.\n",
    "        # For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "        # labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "        # will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "        self.class_to_index_ = {label: index\n",
    "                                for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label]\n",
    "                      for label in y], dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "            # extra ops for batch normalization\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # needed in case of early stopping\n",
    "        max_checks_without_progress = 20\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "        \n",
    "        # Now train the model!\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                                 feed_dict={self._X: X_valid,\n",
    "                                                            self._y: y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                    print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                                     feed_dict={self._X: X_batch,\n",
    "                                                                self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_train, acc_train * 100))\n",
    "            # If we used early stopping then rollback to the best model found\n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._Y_proba.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_indices = np.argmax(self.predict_proba(X), axis=1)\n",
    "        return np.array([[self.classes_[class_index]]\n",
    "                         for class_index in class_indices], np.int32)\n",
    "\n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)\n",
    "        \n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.153689\tBest loss: 0.153689\tAccuracy: 96.56%\n",
      "1\tValidation loss: 1.676136\tBest loss: 0.153689\tAccuracy: 18.73%\n",
      "2\tValidation loss: 1.672754\tBest loss: 0.153689\tAccuracy: 20.91%\n",
      "3\tValidation loss: 1.795883\tBest loss: 0.153689\tAccuracy: 19.08%\n",
      "4\tValidation loss: 1.664711\tBest loss: 0.153689\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.652809\tBest loss: 0.153689\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.680399\tBest loss: 0.153689\tAccuracy: 18.73%\n",
      "7\tValidation loss: 1.778669\tBest loss: 0.153689\tAccuracy: 22.01%\n",
      "8\tValidation loss: 1.699487\tBest loss: 0.153689\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.767758\tBest loss: 0.153689\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.629352\tBest loss: 0.153689\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.812643\tBest loss: 0.153689\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.675938\tBest loss: 0.153689\tAccuracy: 18.73%\n",
      "13\tValidation loss: 1.633259\tBest loss: 0.153689\tAccuracy: 20.91%\n",
      "14\tValidation loss: 1.652904\tBest loss: 0.153689\tAccuracy: 20.91%\n",
      "15\tValidation loss: 1.635943\tBest loss: 0.153689\tAccuracy: 20.91%\n",
      "16\tValidation loss: 1.718915\tBest loss: 0.153689\tAccuracy: 19.08%\n",
      "17\tValidation loss: 1.682456\tBest loss: 0.153689\tAccuracy: 19.27%\n",
      "18\tValidation loss: 1.675366\tBest loss: 0.153689\tAccuracy: 18.73%\n",
      "19\tValidation loss: 1.645805\tBest loss: 0.153689\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.722336\tBest loss: 0.153689\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.656422\tBest loss: 0.153689\tAccuracy: 22.01%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x11591cd08>,\n",
       "              batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "              initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x1cfb2366a0>,\n",
       "              learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "              optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf = DNNClassifier(random_state=42)\n",
    "dnn_clf.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9706168515275345"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets try a randomized search for better hyperparmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.132177\tBest loss: 0.132177\tAccuracy: 97.15%\n",
      "1\tValidation loss: 0.119321\tBest loss: 0.119321\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.267502\tBest loss: 0.119321\tAccuracy: 95.62%\n",
      "3\tValidation loss: 0.111229\tBest loss: 0.111229\tAccuracy: 97.03%\n",
      "4\tValidation loss: 0.184809\tBest loss: 0.111229\tAccuracy: 96.87%\n",
      "5\tValidation loss: 0.300557\tBest loss: 0.111229\tAccuracy: 93.55%\n",
      "6\tValidation loss: 0.114679\tBest loss: 0.111229\tAccuracy: 97.19%\n",
      "7\tValidation loss: 0.390475\tBest loss: 0.111229\tAccuracy: 95.93%\n",
      "8\tValidation loss: 0.236895\tBest loss: 0.111229\tAccuracy: 95.19%\n",
      "9\tValidation loss: 0.097102\tBest loss: 0.097102\tAccuracy: 97.85%\n",
      "10\tValidation loss: 0.153292\tBest loss: 0.097102\tAccuracy: 96.64%\n",
      "11\tValidation loss: 1.473375\tBest loss: 0.097102\tAccuracy: 97.62%\n",
      "12\tValidation loss: 0.203095\tBest loss: 0.097102\tAccuracy: 97.46%\n",
      "13\tValidation loss: 0.248834\tBest loss: 0.097102\tAccuracy: 95.74%\n",
      "14\tValidation loss: 3.091063\tBest loss: 0.097102\tAccuracy: 97.07%\n",
      "15\tValidation loss: 0.252449\tBest loss: 0.097102\tAccuracy: 96.99%\n",
      "16\tValidation loss: 3.219923\tBest loss: 0.097102\tAccuracy: 91.99%\n",
      "17\tValidation loss: 2.558029\tBest loss: 0.097102\tAccuracy: 96.05%\n",
      "18\tValidation loss: 7.730983\tBest loss: 0.097102\tAccuracy: 97.38%\n",
      "19\tValidation loss: 0.717536\tBest loss: 0.097102\tAccuracy: 96.52%\n",
      "20\tValidation loss: 0.434851\tBest loss: 0.097102\tAccuracy: 96.05%\n",
      "21\tValidation loss: 0.542043\tBest loss: 0.097102\tAccuracy: 98.01%\n",
      "22\tValidation loss: 0.334916\tBest loss: 0.097102\tAccuracy: 94.49%\n",
      "23\tValidation loss: 0.283144\tBest loss: 0.097102\tAccuracy: 96.56%\n",
      "24\tValidation loss: 0.354250\tBest loss: 0.097102\tAccuracy: 96.44%\n",
      "25\tValidation loss: 0.271363\tBest loss: 0.097102\tAccuracy: 97.77%\n",
      "26\tValidation loss: 0.321312\tBest loss: 0.097102\tAccuracy: 97.30%\n",
      "27\tValidation loss: 0.335840\tBest loss: 0.097102\tAccuracy: 95.93%\n",
      "28\tValidation loss: 0.267543\tBest loss: 0.097102\tAccuracy: 97.42%\n",
      "29\tValidation loss: 1.155723\tBest loss: 0.097102\tAccuracy: 95.97%\n",
      "30\tValidation loss: 0.404090\tBest loss: 0.097102\tAccuracy: 97.38%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 3.6min\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.176181\tBest loss: 0.176181\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.157487\tBest loss: 0.157487\tAccuracy: 97.38%\n",
      "2\tValidation loss: 0.113619\tBest loss: 0.113619\tAccuracy: 97.22%\n",
      "3\tValidation loss: 0.268458\tBest loss: 0.113619\tAccuracy: 97.65%\n",
      "4\tValidation loss: 0.113712\tBest loss: 0.113619\tAccuracy: 97.34%\n",
      "5\tValidation loss: 0.094208\tBest loss: 0.094208\tAccuracy: 97.73%\n",
      "6\tValidation loss: 0.128818\tBest loss: 0.094208\tAccuracy: 97.58%\n",
      "7\tValidation loss: 0.146188\tBest loss: 0.094208\tAccuracy: 97.54%\n",
      "8\tValidation loss: 0.117907\tBest loss: 0.094208\tAccuracy: 98.05%\n",
      "9\tValidation loss: 0.100208\tBest loss: 0.094208\tAccuracy: 97.77%\n",
      "10\tValidation loss: 0.170968\tBest loss: 0.094208\tAccuracy: 95.66%\n",
      "11\tValidation loss: 0.110283\tBest loss: 0.094208\tAccuracy: 97.30%\n",
      "12\tValidation loss: 0.099022\tBest loss: 0.094208\tAccuracy: 97.62%\n",
      "13\tValidation loss: 0.443737\tBest loss: 0.094208\tAccuracy: 95.43%\n",
      "14\tValidation loss: 0.127646\tBest loss: 0.094208\tAccuracy: 97.19%\n",
      "15\tValidation loss: 0.113706\tBest loss: 0.094208\tAccuracy: 97.85%\n",
      "16\tValidation loss: 0.145156\tBest loss: 0.094208\tAccuracy: 96.64%\n",
      "17\tValidation loss: 0.115278\tBest loss: 0.094208\tAccuracy: 98.05%\n",
      "18\tValidation loss: 0.114734\tBest loss: 0.094208\tAccuracy: 97.85%\n",
      "19\tValidation loss: 0.154730\tBest loss: 0.094208\tAccuracy: 96.91%\n",
      "20\tValidation loss: 0.121355\tBest loss: 0.094208\tAccuracy: 97.73%\n",
      "21\tValidation loss: 0.146891\tBest loss: 0.094208\tAccuracy: 97.77%\n",
      "22\tValidation loss: 26.433136\tBest loss: 0.094208\tAccuracy: 91.99%\n",
      "23\tValidation loss: 0.225896\tBest loss: 0.094208\tAccuracy: 96.79%\n",
      "24\tValidation loss: 0.175232\tBest loss: 0.094208\tAccuracy: 98.05%\n",
      "25\tValidation loss: 0.137665\tBest loss: 0.094208\tAccuracy: 98.24%\n",
      "26\tValidation loss: 0.663363\tBest loss: 0.094208\tAccuracy: 91.20%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 3.3min\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.178839\tBest loss: 0.178839\tAccuracy: 95.58%\n",
      "1\tValidation loss: 0.125036\tBest loss: 0.125036\tAccuracy: 96.99%\n",
      "2\tValidation loss: 0.210554\tBest loss: 0.125036\tAccuracy: 95.82%\n",
      "3\tValidation loss: 0.243920\tBest loss: 0.125036\tAccuracy: 96.72%\n",
      "4\tValidation loss: 0.098237\tBest loss: 0.098237\tAccuracy: 97.38%\n",
      "5\tValidation loss: 0.105448\tBest loss: 0.098237\tAccuracy: 97.07%\n",
      "6\tValidation loss: 0.435791\tBest loss: 0.098237\tAccuracy: 88.39%\n",
      "7\tValidation loss: 0.188648\tBest loss: 0.098237\tAccuracy: 96.76%\n",
      "8\tValidation loss: 0.375252\tBest loss: 0.098237\tAccuracy: 95.31%\n",
      "9\tValidation loss: 0.199084\tBest loss: 0.098237\tAccuracy: 97.85%\n",
      "10\tValidation loss: 1.847897\tBest loss: 0.098237\tAccuracy: 89.41%\n",
      "11\tValidation loss: 0.239334\tBest loss: 0.098237\tAccuracy: 95.04%\n",
      "12\tValidation loss: 1.013291\tBest loss: 0.098237\tAccuracy: 85.93%\n",
      "13\tValidation loss: 2.431084\tBest loss: 0.098237\tAccuracy: 96.29%\n",
      "14\tValidation loss: 0.344683\tBest loss: 0.098237\tAccuracy: 96.72%\n",
      "15\tValidation loss: 15.937680\tBest loss: 0.098237\tAccuracy: 97.69%\n",
      "16\tValidation loss: 1.555398\tBest loss: 0.098237\tAccuracy: 97.93%\n",
      "17\tValidation loss: 0.367588\tBest loss: 0.098237\tAccuracy: 95.19%\n",
      "18\tValidation loss: 0.204558\tBest loss: 0.098237\tAccuracy: 96.83%\n",
      "19\tValidation loss: 4.228860\tBest loss: 0.098237\tAccuracy: 97.03%\n",
      "20\tValidation loss: 0.428087\tBest loss: 0.098237\tAccuracy: 96.99%\n",
      "21\tValidation loss: 0.393353\tBest loss: 0.098237\tAccuracy: 97.15%\n",
      "22\tValidation loss: 0.693856\tBest loss: 0.098237\tAccuracy: 97.85%\n",
      "23\tValidation loss: 0.178572\tBest loss: 0.098237\tAccuracy: 97.58%\n",
      "24\tValidation loss: 0.138825\tBest loss: 0.098237\tAccuracy: 97.97%\n",
      "25\tValidation loss: 0.242782\tBest loss: 0.098237\tAccuracy: 96.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 3.3min\n",
      "[CV] n_neurons=120, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.312997\tBest loss: 0.312997\tAccuracy: 93.82%\n",
      "1\tValidation loss: 0.165857\tBest loss: 0.165857\tAccuracy: 95.23%\n",
      "2\tValidation loss: 0.178981\tBest loss: 0.165857\tAccuracy: 95.31%\n",
      "3\tValidation loss: 0.142084\tBest loss: 0.142084\tAccuracy: 95.97%\n",
      "4\tValidation loss: 0.121323\tBest loss: 0.121323\tAccuracy: 96.83%\n",
      "5\tValidation loss: 0.778917\tBest loss: 0.121323\tAccuracy: 66.18%\n",
      "6\tValidation loss: 0.563230\tBest loss: 0.121323\tAccuracy: 76.04%\n",
      "7\tValidation loss: 0.540250\tBest loss: 0.121323\tAccuracy: 77.37%\n",
      "8\tValidation loss: 3.521883\tBest loss: 0.121323\tAccuracy: 59.30%\n",
      "9\tValidation loss: 0.831405\tBest loss: 0.121323\tAccuracy: 59.34%\n",
      "10\tValidation loss: 0.891796\tBest loss: 0.121323\tAccuracy: 74.12%\n",
      "11\tValidation loss: 0.557035\tBest loss: 0.121323\tAccuracy: 78.34%\n",
      "12\tValidation loss: 0.520887\tBest loss: 0.121323\tAccuracy: 77.29%\n",
      "13\tValidation loss: 0.769517\tBest loss: 0.121323\tAccuracy: 71.11%\n",
      "14\tValidation loss: 0.665707\tBest loss: 0.121323\tAccuracy: 73.46%\n",
      "15\tValidation loss: 0.854508\tBest loss: 0.121323\tAccuracy: 56.22%\n",
      "16\tValidation loss: 1.481513\tBest loss: 0.121323\tAccuracy: 48.67%\n",
      "17\tValidation loss: 1.138220\tBest loss: 0.121323\tAccuracy: 36.51%\n",
      "18\tValidation loss: 1.173611\tBest loss: 0.121323\tAccuracy: 40.27%\n",
      "19\tValidation loss: 1.186531\tBest loss: 0.121323\tAccuracy: 40.62%\n",
      "20\tValidation loss: 1.143946\tBest loss: 0.121323\tAccuracy: 40.50%\n",
      "21\tValidation loss: 1.139709\tBest loss: 0.121323\tAccuracy: 37.65%\n",
      "22\tValidation loss: 1.139231\tBest loss: 0.121323\tAccuracy: 37.65%\n",
      "23\tValidation loss: 1.138202\tBest loss: 0.121323\tAccuracy: 40.66%\n",
      "24\tValidation loss: 1.144976\tBest loss: 0.121323\tAccuracy: 40.66%\n",
      "25\tValidation loss: 1.137923\tBest loss: 0.121323\tAccuracy: 40.50%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8>, total= 3.6min\n",
      "[CV] n_neurons=120, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.200542\tBest loss: 0.200542\tAccuracy: 95.78%\n",
      "1\tValidation loss: 0.889991\tBest loss: 0.200542\tAccuracy: 94.64%\n",
      "2\tValidation loss: 0.562090\tBest loss: 0.200542\tAccuracy: 72.75%\n",
      "3\tValidation loss: 0.556068\tBest loss: 0.200542\tAccuracy: 75.33%\n",
      "4\tValidation loss: 0.690020\tBest loss: 0.200542\tAccuracy: 81.27%\n",
      "5\tValidation loss: 4.320987\tBest loss: 0.200542\tAccuracy: 51.25%\n",
      "6\tValidation loss: 1.004925\tBest loss: 0.200542\tAccuracy: 49.80%\n",
      "7\tValidation loss: 0.884619\tBest loss: 0.200542\tAccuracy: 58.80%\n",
      "8\tValidation loss: 0.778114\tBest loss: 0.200542\tAccuracy: 58.25%\n",
      "9\tValidation loss: 0.829708\tBest loss: 0.200542\tAccuracy: 57.11%\n",
      "10\tValidation loss: 0.760774\tBest loss: 0.200542\tAccuracy: 60.20%\n",
      "11\tValidation loss: 1.258005\tBest loss: 0.200542\tAccuracy: 37.33%\n",
      "12\tValidation loss: 1.368949\tBest loss: 0.200542\tAccuracy: 32.84%\n",
      "13\tValidation loss: 1.157818\tBest loss: 0.200542\tAccuracy: 39.84%\n",
      "14\tValidation loss: 1.121729\tBest loss: 0.200542\tAccuracy: 40.54%\n",
      "15\tValidation loss: 1.135947\tBest loss: 0.200542\tAccuracy: 42.22%\n",
      "16\tValidation loss: 1.592038\tBest loss: 0.200542\tAccuracy: 24.59%\n",
      "17\tValidation loss: 1.147495\tBest loss: 0.200542\tAccuracy: 42.46%\n",
      "18\tValidation loss: 1.143311\tBest loss: 0.200542\tAccuracy: 40.50%\n",
      "19\tValidation loss: 1.139533\tBest loss: 0.200542\tAccuracy: 40.50%\n",
      "20\tValidation loss: 1.140034\tBest loss: 0.200542\tAccuracy: 42.61%\n",
      "21\tValidation loss: 1.151985\tBest loss: 0.200542\tAccuracy: 40.34%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8>, total= 3.1min\n",
      "[CV] n_neurons=120, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.185329\tBest loss: 0.185329\tAccuracy: 95.90%\n",
      "1\tValidation loss: 0.155540\tBest loss: 0.155540\tAccuracy: 95.39%\n",
      "2\tValidation loss: 0.302616\tBest loss: 0.155540\tAccuracy: 93.90%\n",
      "3\tValidation loss: 0.191098\tBest loss: 0.155540\tAccuracy: 96.25%\n",
      "4\tValidation loss: 0.174476\tBest loss: 0.155540\tAccuracy: 94.88%\n",
      "5\tValidation loss: 0.110899\tBest loss: 0.110899\tAccuracy: 97.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tValidation loss: 0.243330\tBest loss: 0.110899\tAccuracy: 95.39%\n",
      "7\tValidation loss: 0.133355\tBest loss: 0.110899\tAccuracy: 97.07%\n",
      "8\tValidation loss: 0.645726\tBest loss: 0.110899\tAccuracy: 87.02%\n",
      "9\tValidation loss: 0.658897\tBest loss: 0.110899\tAccuracy: 74.39%\n",
      "10\tValidation loss: 0.288728\tBest loss: 0.110899\tAccuracy: 93.00%\n",
      "11\tValidation loss: 0.315874\tBest loss: 0.110899\tAccuracy: 94.57%\n",
      "12\tValidation loss: 0.431255\tBest loss: 0.110899\tAccuracy: 89.76%\n",
      "13\tValidation loss: 0.636159\tBest loss: 0.110899\tAccuracy: 75.92%\n",
      "14\tValidation loss: 1.128094\tBest loss: 0.110899\tAccuracy: 65.60%\n",
      "15\tValidation loss: 1.397883\tBest loss: 0.110899\tAccuracy: 58.60%\n",
      "16\tValidation loss: 0.885635\tBest loss: 0.110899\tAccuracy: 57.58%\n",
      "17\tValidation loss: 1.204867\tBest loss: 0.110899\tAccuracy: 37.72%\n",
      "18\tValidation loss: 0.982548\tBest loss: 0.110899\tAccuracy: 49.65%\n",
      "19\tValidation loss: 0.874289\tBest loss: 0.110899\tAccuracy: 58.25%\n",
      "20\tValidation loss: 0.853678\tBest loss: 0.110899\tAccuracy: 59.54%\n",
      "21\tValidation loss: 0.919389\tBest loss: 0.110899\tAccuracy: 56.49%\n",
      "22\tValidation loss: 1.153954\tBest loss: 0.110899\tAccuracy: 42.73%\n",
      "23\tValidation loss: 0.882750\tBest loss: 0.110899\tAccuracy: 56.53%\n",
      "24\tValidation loss: 0.819895\tBest loss: 0.110899\tAccuracy: 59.73%\n",
      "25\tValidation loss: 0.974671\tBest loss: 0.110899\tAccuracy: 54.69%\n",
      "26\tValidation loss: 0.979391\tBest loss: 0.110899\tAccuracy: 53.64%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=5, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8>, total= 3.8min\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 1.637595\tBest loss: 1.637595\tAccuracy: 19.27%\n",
      "1\tValidation loss: 1.621895\tBest loss: 1.621895\tAccuracy: 19.27%\n",
      "2\tValidation loss: 1.619830\tBest loss: 1.619830\tAccuracy: 19.27%\n",
      "3\tValidation loss: 1.616520\tBest loss: 1.616520\tAccuracy: 19.27%\n",
      "4\tValidation loss: 1.654958\tBest loss: 1.616520\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.621479\tBest loss: 1.616520\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.632693\tBest loss: 1.616520\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.614858\tBest loss: 1.614858\tAccuracy: 19.27%\n",
      "8\tValidation loss: 1.642606\tBest loss: 1.614858\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.639819\tBest loss: 1.614858\tAccuracy: 19.27%\n",
      "10\tValidation loss: 1.615375\tBest loss: 1.614858\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.630571\tBest loss: 1.614858\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.636737\tBest loss: 1.614858\tAccuracy: 19.08%\n",
      "13\tValidation loss: 1.613103\tBest loss: 1.613103\tAccuracy: 19.27%\n",
      "14\tValidation loss: 1.629263\tBest loss: 1.613103\tAccuracy: 19.08%\n",
      "15\tValidation loss: 1.617149\tBest loss: 1.613103\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.626923\tBest loss: 1.613103\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.608595\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "18\tValidation loss: 1.624737\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "19\tValidation loss: 1.624035\tBest loss: 1.608595\tAccuracy: 20.91%\n",
      "20\tValidation loss: 1.615449\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "21\tValidation loss: 1.629650\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "22\tValidation loss: 1.619098\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "23\tValidation loss: 1.621080\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.633989\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "25\tValidation loss: 1.647182\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "26\tValidation loss: 1.614127\tBest loss: 1.608595\tAccuracy: 19.08%\n",
      "27\tValidation loss: 1.638548\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "28\tValidation loss: 1.656264\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "29\tValidation loss: 1.617747\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "30\tValidation loss: 1.641874\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "31\tValidation loss: 1.631482\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "32\tValidation loss: 1.641183\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "33\tValidation loss: 1.647446\tBest loss: 1.608595\tAccuracy: 19.08%\n",
      "34\tValidation loss: 1.610284\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "35\tValidation loss: 1.624692\tBest loss: 1.608595\tAccuracy: 19.08%\n",
      "36\tValidation loss: 1.630852\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "37\tValidation loss: 1.632281\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "38\tValidation loss: 1.631021\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8>, total= 3.3min\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 1.632150\tBest loss: 1.632150\tAccuracy: 22.01%\n",
      "1\tValidation loss: 1.644851\tBest loss: 1.632150\tAccuracy: 19.08%\n",
      "2\tValidation loss: 1.611660\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "3\tValidation loss: 1.614178\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "4\tValidation loss: 1.617810\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.624092\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.635104\tBest loss: 1.611660\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.630919\tBest loss: 1.611660\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.639868\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.611889\tBest loss: 1.611660\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.613289\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.614457\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.615519\tBest loss: 1.611660\tAccuracy: 20.91%\n",
      "13\tValidation loss: 1.609585\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "14\tValidation loss: 1.628127\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "15\tValidation loss: 1.613724\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "16\tValidation loss: 1.621641\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.612427\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.622173\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.611825\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.612151\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "21\tValidation loss: 1.657982\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.643388\tBest loss: 1.609585\tAccuracy: 19.27%\n",
      "23\tValidation loss: 1.647551\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.652206\tBest loss: 1.609585\tAccuracy: 18.73%\n",
      "25\tValidation loss: 1.610976\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "26\tValidation loss: 1.614099\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "27\tValidation loss: 1.614363\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "28\tValidation loss: 1.642987\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "29\tValidation loss: 1.614047\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "30\tValidation loss: 1.609289\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "31\tValidation loss: 1.634889\tBest loss: 1.609289\tAccuracy: 18.73%\n",
      "32\tValidation loss: 1.614010\tBest loss: 1.609289\tAccuracy: 19.08%\n",
      "33\tValidation loss: 1.619313\tBest loss: 1.609289\tAccuracy: 19.08%\n",
      "34\tValidation loss: 1.611677\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "35\tValidation loss: 1.638078\tBest loss: 1.609289\tAccuracy: 20.91%\n",
      "36\tValidation loss: 1.621398\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "37\tValidation loss: 1.617562\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "38\tValidation loss: 1.620767\tBest loss: 1.609289\tAccuracy: 20.91%\n",
      "39\tValidation loss: 1.627334\tBest loss: 1.609289\tAccuracy: 19.27%\n",
      "40\tValidation loss: 1.607883\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "41\tValidation loss: 1.634031\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "42\tValidation loss: 1.618327\tBest loss: 1.607883\tAccuracy: 20.91%\n",
      "43\tValidation loss: 1.618746\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "44\tValidation loss: 1.621665\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "45\tValidation loss: 1.629383\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "46\tValidation loss: 1.637658\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "47\tValidation loss: 1.609600\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "48\tValidation loss: 1.612162\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "49\tValidation loss: 1.643133\tBest loss: 1.607883\tAccuracy: 19.27%\n",
      "50\tValidation loss: 1.611987\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "51\tValidation loss: 1.619979\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "52\tValidation loss: 1.627026\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "53\tValidation loss: 1.618519\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "54\tValidation loss: 1.654812\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "55\tValidation loss: 1.645117\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "56\tValidation loss: 1.669471\tBest loss: 1.607883\tAccuracy: 19.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\tValidation loss: 1.619669\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "58\tValidation loss: 1.612549\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "59\tValidation loss: 1.619514\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "60\tValidation loss: 1.635963\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "61\tValidation loss: 1.627401\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8>, total= 5.4min\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 1.647299\tBest loss: 1.647299\tAccuracy: 19.27%\n",
      "1\tValidation loss: 1.624645\tBest loss: 1.624645\tAccuracy: 19.27%\n",
      "2\tValidation loss: 1.614170\tBest loss: 1.614170\tAccuracy: 19.27%\n",
      "3\tValidation loss: 1.616990\tBest loss: 1.614170\tAccuracy: 19.27%\n",
      "4\tValidation loss: 1.614501\tBest loss: 1.614170\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.627706\tBest loss: 1.614170\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.648677\tBest loss: 1.614170\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.627603\tBest loss: 1.614170\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.625684\tBest loss: 1.614170\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.615558\tBest loss: 1.614170\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.619129\tBest loss: 1.614170\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.639600\tBest loss: 1.614170\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.627613\tBest loss: 1.614170\tAccuracy: 19.08%\n",
      "13\tValidation loss: 1.615011\tBest loss: 1.614170\tAccuracy: 19.08%\n",
      "14\tValidation loss: 1.624331\tBest loss: 1.614170\tAccuracy: 19.08%\n",
      "15\tValidation loss: 1.612441\tBest loss: 1.612441\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.627839\tBest loss: 1.612441\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.613220\tBest loss: 1.612441\tAccuracy: 18.73%\n",
      "18\tValidation loss: 1.615752\tBest loss: 1.612441\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.619096\tBest loss: 1.612441\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.609111\tBest loss: 1.609111\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.689011\tBest loss: 1.609111\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.618893\tBest loss: 1.609111\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.638928\tBest loss: 1.609111\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.660613\tBest loss: 1.609111\tAccuracy: 20.91%\n",
      "25\tValidation loss: 1.619334\tBest loss: 1.609111\tAccuracy: 19.27%\n",
      "26\tValidation loss: 1.611323\tBest loss: 1.609111\tAccuracy: 22.01%\n",
      "27\tValidation loss: 1.614304\tBest loss: 1.609111\tAccuracy: 20.91%\n",
      "28\tValidation loss: 1.628118\tBest loss: 1.609111\tAccuracy: 19.08%\n",
      "29\tValidation loss: 1.610351\tBest loss: 1.609111\tAccuracy: 20.91%\n",
      "30\tValidation loss: 1.626932\tBest loss: 1.609111\tAccuracy: 20.91%\n",
      "31\tValidation loss: 1.633272\tBest loss: 1.609111\tAccuracy: 18.73%\n",
      "32\tValidation loss: 1.609066\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "33\tValidation loss: 1.610652\tBest loss: 1.609066\tAccuracy: 19.08%\n",
      "34\tValidation loss: 1.616979\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "35\tValidation loss: 1.627558\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "36\tValidation loss: 1.609165\tBest loss: 1.609066\tAccuracy: 20.91%\n",
      "37\tValidation loss: 1.626449\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "38\tValidation loss: 1.614497\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "39\tValidation loss: 1.617754\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "40\tValidation loss: 1.623131\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "41\tValidation loss: 1.615777\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "42\tValidation loss: 1.617475\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "43\tValidation loss: 1.617776\tBest loss: 1.609066\tAccuracy: 19.08%\n",
      "44\tValidation loss: 1.626853\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "45\tValidation loss: 1.613777\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "46\tValidation loss: 1.618687\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "47\tValidation loss: 1.610630\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "48\tValidation loss: 1.614395\tBest loss: 1.609066\tAccuracy: 18.73%\n",
      "49\tValidation loss: 1.612180\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "50\tValidation loss: 1.623879\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "51\tValidation loss: 1.616768\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "52\tValidation loss: 1.620598\tBest loss: 1.609066\tAccuracy: 18.73%\n",
      "53\tValidation loss: 1.617682\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8>, total= 4.6min\n",
      "[CV] n_neurons=30, n_hidden_layers=0, learning_rate=0.1, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 1.391273\tBest loss: 1.391273\tAccuracy: 94.53%\n",
      "1\tValidation loss: 1.531589\tBest loss: 1.391273\tAccuracy: 94.84%\n",
      "2\tValidation loss: 1.570406\tBest loss: 1.391273\tAccuracy: 95.62%\n",
      "3\tValidation loss: 1.835272\tBest loss: 1.391273\tAccuracy: 94.53%\n",
      "4\tValidation loss: 1.394739\tBest loss: 1.391273\tAccuracy: 95.86%\n",
      "5\tValidation loss: 1.520939\tBest loss: 1.391273\tAccuracy: 95.74%\n",
      "6\tValidation loss: 2.097101\tBest loss: 1.391273\tAccuracy: 93.78%\n",
      "7\tValidation loss: 1.418016\tBest loss: 1.391273\tAccuracy: 96.36%\n",
      "8\tValidation loss: 1.624774\tBest loss: 1.391273\tAccuracy: 95.04%\n",
      "9\tValidation loss: 1.541408\tBest loss: 1.391273\tAccuracy: 96.01%\n",
      "10\tValidation loss: 2.386902\tBest loss: 1.391273\tAccuracy: 92.89%\n",
      "11\tValidation loss: 2.021392\tBest loss: 1.391273\tAccuracy: 95.00%\n",
      "12\tValidation loss: 1.985960\tBest loss: 1.391273\tAccuracy: 95.15%\n",
      "13\tValidation loss: 2.872411\tBest loss: 1.391273\tAccuracy: 94.14%\n",
      "14\tValidation loss: 1.858669\tBest loss: 1.391273\tAccuracy: 95.78%\n",
      "15\tValidation loss: 2.153511\tBest loss: 1.391273\tAccuracy: 94.76%\n",
      "16\tValidation loss: 1.795453\tBest loss: 1.391273\tAccuracy: 95.74%\n",
      "17\tValidation loss: 2.077914\tBest loss: 1.391273\tAccuracy: 94.53%\n",
      "18\tValidation loss: 1.816879\tBest loss: 1.391273\tAccuracy: 96.29%\n",
      "19\tValidation loss: 2.062783\tBest loss: 1.391273\tAccuracy: 95.07%\n",
      "20\tValidation loss: 2.105585\tBest loss: 1.391273\tAccuracy: 95.93%\n",
      "21\tValidation loss: 2.222647\tBest loss: 1.391273\tAccuracy: 95.39%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=0, learning_rate=0.1, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  30.1s\n",
      "[CV] n_neurons=30, n_hidden_layers=0, learning_rate=0.1, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 1.032407\tBest loss: 1.032407\tAccuracy: 96.29%\n",
      "1\tValidation loss: 1.191551\tBest loss: 1.032407\tAccuracy: 96.05%\n",
      "2\tValidation loss: 1.597726\tBest loss: 1.032407\tAccuracy: 95.15%\n",
      "3\tValidation loss: 1.476515\tBest loss: 1.032407\tAccuracy: 95.27%\n",
      "4\tValidation loss: 1.529388\tBest loss: 1.032407\tAccuracy: 95.97%\n",
      "5\tValidation loss: 1.626857\tBest loss: 1.032407\tAccuracy: 96.05%\n",
      "6\tValidation loss: 2.133962\tBest loss: 1.032407\tAccuracy: 94.45%\n",
      "7\tValidation loss: 2.026961\tBest loss: 1.032407\tAccuracy: 95.35%\n",
      "8\tValidation loss: 1.509227\tBest loss: 1.032407\tAccuracy: 96.48%\n",
      "9\tValidation loss: 2.035630\tBest loss: 1.032407\tAccuracy: 95.35%\n",
      "10\tValidation loss: 2.398579\tBest loss: 1.032407\tAccuracy: 94.06%\n",
      "11\tValidation loss: 1.743073\tBest loss: 1.032407\tAccuracy: 95.86%\n",
      "12\tValidation loss: 2.011258\tBest loss: 1.032407\tAccuracy: 95.47%\n",
      "13\tValidation loss: 2.254169\tBest loss: 1.032407\tAccuracy: 94.80%\n",
      "14\tValidation loss: 2.090015\tBest loss: 1.032407\tAccuracy: 96.01%\n",
      "15\tValidation loss: 2.287691\tBest loss: 1.032407\tAccuracy: 95.47%\n",
      "16\tValidation loss: 1.996468\tBest loss: 1.032407\tAccuracy: 95.66%\n",
      "17\tValidation loss: 2.168505\tBest loss: 1.032407\tAccuracy: 96.01%\n",
      "18\tValidation loss: 2.490728\tBest loss: 1.032407\tAccuracy: 95.07%\n",
      "19\tValidation loss: 2.450042\tBest loss: 1.032407\tAccuracy: 95.43%\n",
      "20\tValidation loss: 2.436237\tBest loss: 1.032407\tAccuracy: 95.58%\n",
      "21\tValidation loss: 2.323077\tBest loss: 1.032407\tAccuracy: 95.70%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=0, learning_rate=0.1, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  26.2s\n",
      "[CV] n_neurons=30, n_hidden_layers=0, learning_rate=0.1, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.937740\tBest loss: 0.937740\tAccuracy: 95.86%\n",
      "1\tValidation loss: 1.120775\tBest loss: 0.937740\tAccuracy: 95.74%\n",
      "2\tValidation loss: 1.851945\tBest loss: 0.937740\tAccuracy: 94.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\tValidation loss: 1.337731\tBest loss: 0.937740\tAccuracy: 95.74%\n",
      "4\tValidation loss: 1.581765\tBest loss: 0.937740\tAccuracy: 94.80%\n",
      "5\tValidation loss: 2.017296\tBest loss: 0.937740\tAccuracy: 93.94%\n",
      "6\tValidation loss: 1.635753\tBest loss: 0.937740\tAccuracy: 95.35%\n",
      "7\tValidation loss: 1.743495\tBest loss: 0.937740\tAccuracy: 95.27%\n",
      "8\tValidation loss: 1.808916\tBest loss: 0.937740\tAccuracy: 95.70%\n",
      "9\tValidation loss: 1.558122\tBest loss: 0.937740\tAccuracy: 95.19%\n",
      "10\tValidation loss: 1.741377\tBest loss: 0.937740\tAccuracy: 95.62%\n",
      "11\tValidation loss: 1.792447\tBest loss: 0.937740\tAccuracy: 95.07%\n",
      "12\tValidation loss: 1.575729\tBest loss: 0.937740\tAccuracy: 95.66%\n",
      "13\tValidation loss: 1.976281\tBest loss: 0.937740\tAccuracy: 95.27%\n",
      "14\tValidation loss: 3.815934\tBest loss: 0.937740\tAccuracy: 91.20%\n",
      "15\tValidation loss: 1.717470\tBest loss: 0.937740\tAccuracy: 95.27%\n",
      "16\tValidation loss: 1.711769\tBest loss: 0.937740\tAccuracy: 95.82%\n",
      "17\tValidation loss: 1.923801\tBest loss: 0.937740\tAccuracy: 94.29%\n",
      "18\tValidation loss: 2.262670\tBest loss: 0.937740\tAccuracy: 95.54%\n",
      "19\tValidation loss: 2.470259\tBest loss: 0.937740\tAccuracy: 94.80%\n",
      "20\tValidation loss: 1.966315\tBest loss: 0.937740\tAccuracy: 96.01%\n",
      "21\tValidation loss: 2.014452\tBest loss: 0.937740\tAccuracy: 95.04%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=0, learning_rate=0.1, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  27.3s\n",
      "[CV] n_neurons=70, n_hidden_layers=2, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.101419\tBest loss: 0.101419\tAccuracy: 97.46%\n",
      "1\tValidation loss: 0.091693\tBest loss: 0.091693\tAccuracy: 97.65%\n",
      "2\tValidation loss: 0.078537\tBest loss: 0.078537\tAccuracy: 98.24%\n",
      "3\tValidation loss: 0.110230\tBest loss: 0.078537\tAccuracy: 96.76%\n",
      "4\tValidation loss: 0.122940\tBest loss: 0.078537\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.090750\tBest loss: 0.078537\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.203819\tBest loss: 0.078537\tAccuracy: 95.19%\n",
      "7\tValidation loss: 0.091984\tBest loss: 0.078537\tAccuracy: 98.24%\n",
      "8\tValidation loss: 0.092923\tBest loss: 0.078537\tAccuracy: 98.16%\n",
      "9\tValidation loss: 0.155039\tBest loss: 0.078537\tAccuracy: 98.36%\n",
      "10\tValidation loss: 0.111763\tBest loss: 0.078537\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.139167\tBest loss: 0.078537\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.136830\tBest loss: 0.078537\tAccuracy: 97.97%\n",
      "13\tValidation loss: 0.115576\tBest loss: 0.078537\tAccuracy: 98.36%\n",
      "14\tValidation loss: 0.155114\tBest loss: 0.078537\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.136567\tBest loss: 0.078537\tAccuracy: 98.67%\n",
      "16\tValidation loss: 0.216351\tBest loss: 0.078537\tAccuracy: 97.58%\n",
      "17\tValidation loss: 0.143110\tBest loss: 0.078537\tAccuracy: 98.48%\n",
      "18\tValidation loss: 0.245699\tBest loss: 0.078537\tAccuracy: 97.19%\n",
      "19\tValidation loss: 0.218529\tBest loss: 0.078537\tAccuracy: 98.44%\n",
      "20\tValidation loss: 0.205913\tBest loss: 0.078537\tAccuracy: 98.51%\n",
      "21\tValidation loss: 0.189678\tBest loss: 0.078537\tAccuracy: 98.01%\n",
      "22\tValidation loss: 0.169126\tBest loss: 0.078537\tAccuracy: 98.51%\n",
      "23\tValidation loss: 0.175821\tBest loss: 0.078537\tAccuracy: 98.28%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=2, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  31.0s\n",
      "[CV] n_neurons=70, n_hidden_layers=2, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.085563\tBest loss: 0.085563\tAccuracy: 97.15%\n",
      "1\tValidation loss: 0.066328\tBest loss: 0.066328\tAccuracy: 97.97%\n",
      "2\tValidation loss: 0.127813\tBest loss: 0.066328\tAccuracy: 97.19%\n",
      "3\tValidation loss: 0.076663\tBest loss: 0.066328\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.083124\tBest loss: 0.066328\tAccuracy: 97.73%\n",
      "5\tValidation loss: 0.071712\tBest loss: 0.066328\tAccuracy: 98.32%\n",
      "6\tValidation loss: 0.115313\tBest loss: 0.066328\tAccuracy: 97.62%\n",
      "7\tValidation loss: 0.108958\tBest loss: 0.066328\tAccuracy: 97.30%\n",
      "8\tValidation loss: 0.154077\tBest loss: 0.066328\tAccuracy: 96.99%\n",
      "9\tValidation loss: 0.086223\tBest loss: 0.066328\tAccuracy: 98.01%\n",
      "10\tValidation loss: 0.117848\tBest loss: 0.066328\tAccuracy: 97.89%\n",
      "11\tValidation loss: 0.096751\tBest loss: 0.066328\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.126526\tBest loss: 0.066328\tAccuracy: 97.42%\n",
      "13\tValidation loss: 0.096316\tBest loss: 0.066328\tAccuracy: 98.55%\n",
      "14\tValidation loss: 0.083957\tBest loss: 0.066328\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.092253\tBest loss: 0.066328\tAccuracy: 98.36%\n",
      "16\tValidation loss: 0.138551\tBest loss: 0.066328\tAccuracy: 98.28%\n",
      "17\tValidation loss: 0.104815\tBest loss: 0.066328\tAccuracy: 98.16%\n",
      "18\tValidation loss: 0.107849\tBest loss: 0.066328\tAccuracy: 98.36%\n",
      "19\tValidation loss: 0.168498\tBest loss: 0.066328\tAccuracy: 97.77%\n",
      "20\tValidation loss: 0.109621\tBest loss: 0.066328\tAccuracy: 97.93%\n",
      "21\tValidation loss: 0.083833\tBest loss: 0.066328\tAccuracy: 98.79%\n",
      "22\tValidation loss: 0.184171\tBest loss: 0.066328\tAccuracy: 98.44%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=2, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  33.1s\n",
      "[CV] n_neurons=70, n_hidden_layers=2, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.126715\tBest loss: 0.126715\tAccuracy: 96.64%\n",
      "1\tValidation loss: 0.061970\tBest loss: 0.061970\tAccuracy: 98.32%\n",
      "2\tValidation loss: 0.079703\tBest loss: 0.061970\tAccuracy: 98.01%\n",
      "3\tValidation loss: 0.121878\tBest loss: 0.061970\tAccuracy: 97.81%\n",
      "4\tValidation loss: 0.109519\tBest loss: 0.061970\tAccuracy: 97.46%\n",
      "5\tValidation loss: 0.084470\tBest loss: 0.061970\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.100731\tBest loss: 0.061970\tAccuracy: 98.20%\n",
      "7\tValidation loss: 0.068806\tBest loss: 0.061970\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.132055\tBest loss: 0.061970\tAccuracy: 98.16%\n",
      "9\tValidation loss: 0.118486\tBest loss: 0.061970\tAccuracy: 98.12%\n",
      "10\tValidation loss: 0.086580\tBest loss: 0.061970\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.080337\tBest loss: 0.061970\tAccuracy: 98.01%\n",
      "12\tValidation loss: 0.076433\tBest loss: 0.061970\tAccuracy: 98.48%\n",
      "13\tValidation loss: 0.115806\tBest loss: 0.061970\tAccuracy: 97.93%\n",
      "14\tValidation loss: 0.066536\tBest loss: 0.061970\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.118486\tBest loss: 0.061970\tAccuracy: 97.26%\n",
      "16\tValidation loss: 0.154308\tBest loss: 0.061970\tAccuracy: 97.93%\n",
      "17\tValidation loss: 0.132880\tBest loss: 0.061970\tAccuracy: 98.01%\n",
      "18\tValidation loss: 0.115566\tBest loss: 0.061970\tAccuracy: 97.81%\n",
      "19\tValidation loss: 0.085085\tBest loss: 0.061970\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.385799\tBest loss: 0.061970\tAccuracy: 95.93%\n",
      "21\tValidation loss: 0.241617\tBest loss: 0.061970\tAccuracy: 98.20%\n",
      "22\tValidation loss: 0.140907\tBest loss: 0.061970\tAccuracy: 98.20%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=2, learning_rate=0.02, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  31.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=1, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.093537\tBest loss: 0.093537\tAccuracy: 96.99%\n",
      "1\tValidation loss: 0.063568\tBest loss: 0.063568\tAccuracy: 98.05%\n",
      "2\tValidation loss: 0.056872\tBest loss: 0.056872\tAccuracy: 98.24%\n",
      "3\tValidation loss: 0.052188\tBest loss: 0.052188\tAccuracy: 98.20%\n",
      "4\tValidation loss: 0.053473\tBest loss: 0.052188\tAccuracy: 98.67%\n",
      "5\tValidation loss: 0.052518\tBest loss: 0.052188\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.052960\tBest loss: 0.052188\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.052792\tBest loss: 0.052188\tAccuracy: 98.51%\n",
      "8\tValidation loss: 0.049900\tBest loss: 0.049900\tAccuracy: 98.51%\n",
      "9\tValidation loss: 0.046232\tBest loss: 0.046232\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.051299\tBest loss: 0.046232\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.049454\tBest loss: 0.046232\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.053449\tBest loss: 0.046232\tAccuracy: 98.79%\n",
      "13\tValidation loss: 0.051566\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "14\tValidation loss: 0.052491\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "15\tValidation loss: 0.053406\tBest loss: 0.046232\tAccuracy: 98.83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\tValidation loss: 0.053069\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "17\tValidation loss: 0.053590\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "18\tValidation loss: 0.054052\tBest loss: 0.046232\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.054402\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "20\tValidation loss: 0.054183\tBest loss: 0.046232\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.054448\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "22\tValidation loss: 0.055005\tBest loss: 0.046232\tAccuracy: 98.79%\n",
      "23\tValidation loss: 0.055414\tBest loss: 0.046232\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.055776\tBest loss: 0.046232\tAccuracy: 98.79%\n",
      "25\tValidation loss: 0.056236\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.055818\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.056092\tBest loss: 0.046232\tAccuracy: 98.87%\n",
      "28\tValidation loss: 0.056575\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "29\tValidation loss: 0.057184\tBest loss: 0.046232\tAccuracy: 98.83%\n",
      "30\tValidation loss: 0.057138\tBest loss: 0.046232\tAccuracy: 98.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, n_hidden_layers=1, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=   7.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=1, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.090603\tBest loss: 0.090603\tAccuracy: 97.42%\n",
      "1\tValidation loss: 0.060523\tBest loss: 0.060523\tAccuracy: 98.28%\n",
      "2\tValidation loss: 0.050038\tBest loss: 0.050038\tAccuracy: 98.59%\n",
      "3\tValidation loss: 0.043781\tBest loss: 0.043781\tAccuracy: 98.71%\n",
      "4\tValidation loss: 0.051719\tBest loss: 0.043781\tAccuracy: 98.63%\n",
      "5\tValidation loss: 0.039004\tBest loss: 0.039004\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.041995\tBest loss: 0.039004\tAccuracy: 98.87%\n",
      "7\tValidation loss: 0.041860\tBest loss: 0.039004\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.041121\tBest loss: 0.039004\tAccuracy: 98.91%\n",
      "9\tValidation loss: 0.044620\tBest loss: 0.039004\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.036733\tBest loss: 0.036733\tAccuracy: 98.83%\n",
      "11\tValidation loss: 0.045758\tBest loss: 0.036733\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.043836\tBest loss: 0.036733\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.039576\tBest loss: 0.036733\tAccuracy: 99.02%\n",
      "14\tValidation loss: 0.036731\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "15\tValidation loss: 0.037747\tBest loss: 0.036731\tAccuracy: 99.06%\n",
      "16\tValidation loss: 0.038751\tBest loss: 0.036731\tAccuracy: 99.06%\n",
      "17\tValidation loss: 0.039119\tBest loss: 0.036731\tAccuracy: 99.06%\n",
      "18\tValidation loss: 0.039846\tBest loss: 0.036731\tAccuracy: 99.10%\n",
      "19\tValidation loss: 0.040259\tBest loss: 0.036731\tAccuracy: 99.06%\n",
      "20\tValidation loss: 0.040300\tBest loss: 0.036731\tAccuracy: 99.06%\n",
      "21\tValidation loss: 0.040741\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "22\tValidation loss: 0.040878\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "23\tValidation loss: 0.041090\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "24\tValidation loss: 0.041520\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "25\tValidation loss: 0.041525\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "26\tValidation loss: 0.041869\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "27\tValidation loss: 0.042369\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "28\tValidation loss: 0.042360\tBest loss: 0.036731\tAccuracy: 99.10%\n",
      "29\tValidation loss: 0.042655\tBest loss: 0.036731\tAccuracy: 99.06%\n",
      "30\tValidation loss: 0.042876\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "31\tValidation loss: 0.043147\tBest loss: 0.036731\tAccuracy: 99.06%\n",
      "32\tValidation loss: 0.043390\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "33\tValidation loss: 0.043498\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "34\tValidation loss: 0.043539\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "35\tValidation loss: 0.043795\tBest loss: 0.036731\tAccuracy: 99.14%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, n_hidden_layers=1, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=   8.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=1, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.082925\tBest loss: 0.082925\tAccuracy: 97.54%\n",
      "1\tValidation loss: 0.056179\tBest loss: 0.056179\tAccuracy: 98.40%\n",
      "2\tValidation loss: 0.045923\tBest loss: 0.045923\tAccuracy: 98.59%\n",
      "3\tValidation loss: 0.038387\tBest loss: 0.038387\tAccuracy: 98.67%\n",
      "4\tValidation loss: 0.038697\tBest loss: 0.038387\tAccuracy: 98.79%\n",
      "5\tValidation loss: 0.040805\tBest loss: 0.038387\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.041051\tBest loss: 0.038387\tAccuracy: 98.83%\n",
      "7\tValidation loss: 0.049028\tBest loss: 0.038387\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.040287\tBest loss: 0.038387\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.040879\tBest loss: 0.038387\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.042355\tBest loss: 0.038387\tAccuracy: 98.79%\n",
      "11\tValidation loss: 0.046589\tBest loss: 0.038387\tAccuracy: 98.91%\n",
      "12\tValidation loss: 0.054385\tBest loss: 0.038387\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.049513\tBest loss: 0.038387\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.055336\tBest loss: 0.038387\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.052209\tBest loss: 0.038387\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.051466\tBest loss: 0.038387\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.062342\tBest loss: 0.038387\tAccuracy: 98.94%\n",
      "18\tValidation loss: 0.052333\tBest loss: 0.038387\tAccuracy: 98.79%\n",
      "19\tValidation loss: 0.050002\tBest loss: 0.038387\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.050821\tBest loss: 0.038387\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.051560\tBest loss: 0.038387\tAccuracy: 98.91%\n",
      "22\tValidation loss: 0.051295\tBest loss: 0.038387\tAccuracy: 98.91%\n",
      "23\tValidation loss: 0.051593\tBest loss: 0.038387\tAccuracy: 98.91%\n",
      "24\tValidation loss: 0.051732\tBest loss: 0.038387\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, n_hidden_layers=1, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=   6.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 34.178009\tBest loss: 34.178009\tAccuracy: 74.00%\n",
      "1\tValidation loss: 5.749254\tBest loss: 5.749254\tAccuracy: 90.66%\n",
      "2\tValidation loss: 4.163741\tBest loss: 4.163741\tAccuracy: 88.23%\n",
      "3\tValidation loss: 1.228498\tBest loss: 1.228498\tAccuracy: 95.90%\n",
      "4\tValidation loss: 2.132432\tBest loss: 1.228498\tAccuracy: 93.28%\n",
      "5\tValidation loss: 1.349350\tBest loss: 1.228498\tAccuracy: 93.39%\n",
      "6\tValidation loss: 0.951356\tBest loss: 0.951356\tAccuracy: 95.23%\n",
      "7\tValidation loss: 211.799652\tBest loss: 0.951356\tAccuracy: 93.47%\n",
      "8\tValidation loss: 50.766598\tBest loss: 0.951356\tAccuracy: 94.53%\n",
      "9\tValidation loss: 40.481018\tBest loss: 0.951356\tAccuracy: 94.53%\n",
      "10\tValidation loss: 25.851416\tBest loss: 0.951356\tAccuracy: 96.17%\n",
      "11\tValidation loss: 26.221121\tBest loss: 0.951356\tAccuracy: 96.68%\n",
      "12\tValidation loss: 21.945715\tBest loss: 0.951356\tAccuracy: 96.76%\n",
      "13\tValidation loss: 69.630577\tBest loss: 0.951356\tAccuracy: 96.25%\n",
      "14\tValidation loss: 97.381340\tBest loss: 0.951356\tAccuracy: 93.67%\n",
      "15\tValidation loss: 32.182407\tBest loss: 0.951356\tAccuracy: 95.86%\n",
      "16\tValidation loss: 20.762493\tBest loss: 0.951356\tAccuracy: 96.72%\n",
      "17\tValidation loss: 17.512970\tBest loss: 0.951356\tAccuracy: 96.56%\n",
      "18\tValidation loss: 103.129303\tBest loss: 0.951356\tAccuracy: 95.31%\n",
      "19\tValidation loss: 46.107800\tBest loss: 0.951356\tAccuracy: 96.01%\n",
      "20\tValidation loss: 47.871269\tBest loss: 0.951356\tAccuracy: 95.43%\n",
      "21\tValidation loss: 35.432961\tBest loss: 0.951356\tAccuracy: 96.99%\n",
      "22\tValidation loss: 145.486786\tBest loss: 0.951356\tAccuracy: 95.93%\n",
      "23\tValidation loss: 49.093971\tBest loss: 0.951356\tAccuracy: 96.44%\n",
      "24\tValidation loss: 72.085159\tBest loss: 0.951356\tAccuracy: 95.50%\n",
      "25\tValidation loss: 46.545036\tBest loss: 0.951356\tAccuracy: 95.70%\n",
      "26\tValidation loss: 350.025330\tBest loss: 0.951356\tAccuracy: 93.12%\n",
      "27\tValidation loss: 119.961861\tBest loss: 0.951356\tAccuracy: 96.44%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  54.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 1.325303\tBest loss: 1.325303\tAccuracy: 88.43%\n",
      "1\tValidation loss: 0.305967\tBest loss: 0.305967\tAccuracy: 94.02%\n",
      "2\tValidation loss: 0.201494\tBest loss: 0.201494\tAccuracy: 96.25%\n",
      "3\tValidation loss: 692.053528\tBest loss: 0.201494\tAccuracy: 34.75%\n",
      "4\tValidation loss: 9.645768\tBest loss: 0.201494\tAccuracy: 94.25%\n",
      "5\tValidation loss: 46.839256\tBest loss: 0.201494\tAccuracy: 71.34%\n",
      "6\tValidation loss: 9.248214\tBest loss: 0.201494\tAccuracy: 94.68%\n",
      "7\tValidation loss: 763.348633\tBest loss: 0.201494\tAccuracy: 63.84%\n",
      "8\tValidation loss: 50.142960\tBest loss: 0.201494\tAccuracy: 92.06%\n",
      "9\tValidation loss: 32.669216\tBest loss: 0.201494\tAccuracy: 92.53%\n",
      "10\tValidation loss: 29.940969\tBest loss: 0.201494\tAccuracy: 94.88%\n",
      "11\tValidation loss: 25.176582\tBest loss: 0.201494\tAccuracy: 95.66%\n",
      "12\tValidation loss: 26.190208\tBest loss: 0.201494\tAccuracy: 94.92%\n",
      "13\tValidation loss: 31.541836\tBest loss: 0.201494\tAccuracy: 94.49%\n",
      "14\tValidation loss: 154.473618\tBest loss: 0.201494\tAccuracy: 89.87%\n",
      "15\tValidation loss: 119.099197\tBest loss: 0.201494\tAccuracy: 92.96%\n",
      "16\tValidation loss: 109.059113\tBest loss: 0.201494\tAccuracy: 92.65%\n",
      "17\tValidation loss: 159.158981\tBest loss: 0.201494\tAccuracy: 87.61%\n",
      "18\tValidation loss: 65.934937\tBest loss: 0.201494\tAccuracy: 95.54%\n",
      "19\tValidation loss: 51.054600\tBest loss: 0.201494\tAccuracy: 95.39%\n",
      "20\tValidation loss: 154.374908\tBest loss: 0.201494\tAccuracy: 96.64%\n",
      "21\tValidation loss: 124.182152\tBest loss: 0.201494\tAccuracy: 96.36%\n",
      "22\tValidation loss: 306.900696\tBest loss: 0.201494\tAccuracy: 96.87%\n",
      "23\tValidation loss: 89.071335\tBest loss: 0.201494\tAccuracy: 96.60%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  50.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.191696\tBest loss: 0.191696\tAccuracy: 95.39%\n",
      "1\tValidation loss: 1.649477\tBest loss: 0.191696\tAccuracy: 95.66%\n",
      "2\tValidation loss: 20.763098\tBest loss: 0.191696\tAccuracy: 91.13%\n",
      "3\tValidation loss: 12.590378\tBest loss: 0.191696\tAccuracy: 90.15%\n",
      "4\tValidation loss: 8.446079\tBest loss: 0.191696\tAccuracy: 94.92%\n",
      "5\tValidation loss: 8.772712\tBest loss: 0.191696\tAccuracy: 94.21%\n",
      "6\tValidation loss: 7.856430\tBest loss: 0.191696\tAccuracy: 93.90%\n",
      "7\tValidation loss: 6.402571\tBest loss: 0.191696\tAccuracy: 95.39%\n",
      "8\tValidation loss: 14.620889\tBest loss: 0.191696\tAccuracy: 94.64%\n",
      "9\tValidation loss: 11.739104\tBest loss: 0.191696\tAccuracy: 96.48%\n",
      "10\tValidation loss: 13.512414\tBest loss: 0.191696\tAccuracy: 95.43%\n",
      "11\tValidation loss: 3223.224854\tBest loss: 0.191696\tAccuracy: 66.30%\n",
      "12\tValidation loss: 108.240791\tBest loss: 0.191696\tAccuracy: 94.25%\n",
      "13\tValidation loss: 57.008076\tBest loss: 0.191696\tAccuracy: 96.13%\n",
      "14\tValidation loss: 38.967529\tBest loss: 0.191696\tAccuracy: 96.60%\n",
      "15\tValidation loss: 47.359032\tBest loss: 0.191696\tAccuracy: 96.29%\n",
      "16\tValidation loss: 103.917221\tBest loss: 0.191696\tAccuracy: 96.56%\n",
      "17\tValidation loss: 42.596130\tBest loss: 0.191696\tAccuracy: 96.01%\n",
      "18\tValidation loss: 47.083309\tBest loss: 0.191696\tAccuracy: 95.00%\n",
      "19\tValidation loss: 339.527252\tBest loss: 0.191696\tAccuracy: 92.06%\n",
      "20\tValidation loss: 96.216614\tBest loss: 0.191696\tAccuracy: 92.77%\n",
      "21\tValidation loss: 79.484779\tBest loss: 0.191696\tAccuracy: 94.96%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  37.7s\n",
      "[CV] n_neurons=160, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.084870\tBest loss: 0.084870\tAccuracy: 97.30%\n",
      "1\tValidation loss: 0.049354\tBest loss: 0.049354\tAccuracy: 98.63%\n",
      "2\tValidation loss: 0.057858\tBest loss: 0.049354\tAccuracy: 98.16%\n",
      "3\tValidation loss: 0.042429\tBest loss: 0.042429\tAccuracy: 98.48%\n",
      "4\tValidation loss: 0.059581\tBest loss: 0.042429\tAccuracy: 98.40%\n",
      "5\tValidation loss: 0.053566\tBest loss: 0.042429\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.063927\tBest loss: 0.042429\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.056459\tBest loss: 0.042429\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.052806\tBest loss: 0.042429\tAccuracy: 98.67%\n",
      "9\tValidation loss: 0.056058\tBest loss: 0.042429\tAccuracy: 98.67%\n",
      "10\tValidation loss: 0.050956\tBest loss: 0.042429\tAccuracy: 98.98%\n",
      "11\tValidation loss: 0.053121\tBest loss: 0.042429\tAccuracy: 99.06%\n",
      "12\tValidation loss: 0.055373\tBest loss: 0.042429\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.056666\tBest loss: 0.042429\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.056705\tBest loss: 0.042429\tAccuracy: 98.91%\n",
      "15\tValidation loss: 0.055662\tBest loss: 0.042429\tAccuracy: 98.98%\n",
      "16\tValidation loss: 0.074629\tBest loss: 0.042429\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.089966\tBest loss: 0.042429\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.057464\tBest loss: 0.042429\tAccuracy: 98.94%\n",
      "19\tValidation loss: 0.066140\tBest loss: 0.042429\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.066976\tBest loss: 0.042429\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.069457\tBest loss: 0.042429\tAccuracy: 99.06%\n",
      "22\tValidation loss: 0.066662\tBest loss: 0.042429\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.064249\tBest loss: 0.042429\tAccuracy: 99.22%\n",
      "24\tValidation loss: 0.064411\tBest loss: 0.042429\tAccuracy: 99.14%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  20.0s\n",
      "[CV] n_neurons=160, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.078707\tBest loss: 0.078707\tAccuracy: 97.50%\n",
      "1\tValidation loss: 0.056937\tBest loss: 0.056937\tAccuracy: 98.48%\n",
      "2\tValidation loss: 0.043208\tBest loss: 0.043208\tAccuracy: 98.59%\n",
      "3\tValidation loss: 0.049830\tBest loss: 0.043208\tAccuracy: 98.59%\n",
      "4\tValidation loss: 0.062712\tBest loss: 0.043208\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.049664\tBest loss: 0.043208\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.048207\tBest loss: 0.043208\tAccuracy: 98.75%\n",
      "7\tValidation loss: 0.059507\tBest loss: 0.043208\tAccuracy: 98.51%\n",
      "8\tValidation loss: 0.043522\tBest loss: 0.043208\tAccuracy: 98.71%\n",
      "9\tValidation loss: 0.038693\tBest loss: 0.038693\tAccuracy: 98.91%\n",
      "10\tValidation loss: 0.050262\tBest loss: 0.038693\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.049757\tBest loss: 0.038693\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.049608\tBest loss: 0.038693\tAccuracy: 98.79%\n",
      "13\tValidation loss: 0.048338\tBest loss: 0.038693\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.103901\tBest loss: 0.038693\tAccuracy: 97.93%\n",
      "15\tValidation loss: 0.044024\tBest loss: 0.038693\tAccuracy: 98.91%\n",
      "16\tValidation loss: 0.034250\tBest loss: 0.034250\tAccuracy: 99.06%\n",
      "17\tValidation loss: 0.047155\tBest loss: 0.034250\tAccuracy: 99.02%\n",
      "18\tValidation loss: 0.051872\tBest loss: 0.034250\tAccuracy: 98.98%\n",
      "19\tValidation loss: 0.052757\tBest loss: 0.034250\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.041620\tBest loss: 0.034250\tAccuracy: 99.22%\n",
      "21\tValidation loss: 0.061547\tBest loss: 0.034250\tAccuracy: 98.98%\n",
      "22\tValidation loss: 0.082481\tBest loss: 0.034250\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.076621\tBest loss: 0.034250\tAccuracy: 98.83%\n",
      "24\tValidation loss: 0.059971\tBest loss: 0.034250\tAccuracy: 99.06%\n",
      "25\tValidation loss: 0.053320\tBest loss: 0.034250\tAccuracy: 98.75%\n",
      "26\tValidation loss: 0.048458\tBest loss: 0.034250\tAccuracy: 99.06%\n",
      "27\tValidation loss: 0.054733\tBest loss: 0.034250\tAccuracy: 99.34%\n",
      "28\tValidation loss: 0.074515\tBest loss: 0.034250\tAccuracy: 98.71%\n",
      "29\tValidation loss: 0.066695\tBest loss: 0.034250\tAccuracy: 98.87%\n",
      "30\tValidation loss: 0.067439\tBest loss: 0.034250\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.064330\tBest loss: 0.034250\tAccuracy: 98.63%\n",
      "32\tValidation loss: 0.052120\tBest loss: 0.034250\tAccuracy: 99.06%\n",
      "33\tValidation loss: 0.053563\tBest loss: 0.034250\tAccuracy: 99.10%\n",
      "34\tValidation loss: 0.051935\tBest loss: 0.034250\tAccuracy: 99.06%\n",
      "35\tValidation loss: 0.049276\tBest loss: 0.034250\tAccuracy: 99.10%\n",
      "36\tValidation loss: 0.039544\tBest loss: 0.034250\tAccuracy: 99.02%\n",
      "37\tValidation loss: 0.044919\tBest loss: 0.034250\tAccuracy: 99.30%\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neurons=160, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  30.7s\n",
      "[CV] n_neurons=160, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.065474\tBest loss: 0.065474\tAccuracy: 97.85%\n",
      "1\tValidation loss: 0.052326\tBest loss: 0.052326\tAccuracy: 98.40%\n",
      "2\tValidation loss: 0.041225\tBest loss: 0.041225\tAccuracy: 98.59%\n",
      "3\tValidation loss: 0.038819\tBest loss: 0.038819\tAccuracy: 98.63%\n",
      "4\tValidation loss: 0.052046\tBest loss: 0.038819\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.046402\tBest loss: 0.038819\tAccuracy: 98.75%\n",
      "6\tValidation loss: 0.078855\tBest loss: 0.038819\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.047987\tBest loss: 0.038819\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.056990\tBest loss: 0.038819\tAccuracy: 98.71%\n",
      "9\tValidation loss: 0.050569\tBest loss: 0.038819\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.057993\tBest loss: 0.038819\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.067054\tBest loss: 0.038819\tAccuracy: 98.79%\n",
      "12\tValidation loss: 0.065709\tBest loss: 0.038819\tAccuracy: 98.44%\n",
      "13\tValidation loss: 0.054748\tBest loss: 0.038819\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.064393\tBest loss: 0.038819\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.041748\tBest loss: 0.038819\tAccuracy: 98.91%\n",
      "16\tValidation loss: 0.071325\tBest loss: 0.038819\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.045021\tBest loss: 0.038819\tAccuracy: 98.87%\n",
      "18\tValidation loss: 0.041865\tBest loss: 0.038819\tAccuracy: 98.87%\n",
      "19\tValidation loss: 0.046018\tBest loss: 0.038819\tAccuracy: 98.94%\n",
      "20\tValidation loss: 0.067689\tBest loss: 0.038819\tAccuracy: 98.87%\n",
      "21\tValidation loss: 0.059408\tBest loss: 0.038819\tAccuracy: 98.67%\n",
      "22\tValidation loss: 0.059199\tBest loss: 0.038819\tAccuracy: 98.79%\n",
      "23\tValidation loss: 0.055698\tBest loss: 0.038819\tAccuracy: 98.91%\n",
      "24\tValidation loss: 0.051259\tBest loss: 0.038819\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  20.2s\n",
      "[CV] n_neurons=10, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.146599\tBest loss: 0.146599\tAccuracy: 95.58%\n",
      "1\tValidation loss: 0.124036\tBest loss: 0.124036\tAccuracy: 96.91%\n",
      "2\tValidation loss: 0.132049\tBest loss: 0.124036\tAccuracy: 96.95%\n",
      "3\tValidation loss: 0.161828\tBest loss: 0.124036\tAccuracy: 96.25%\n",
      "4\tValidation loss: 0.150890\tBest loss: 0.124036\tAccuracy: 97.11%\n",
      "5\tValidation loss: 0.154737\tBest loss: 0.124036\tAccuracy: 97.38%\n",
      "6\tValidation loss: 0.195944\tBest loss: 0.124036\tAccuracy: 96.44%\n",
      "7\tValidation loss: 0.193626\tBest loss: 0.124036\tAccuracy: 96.95%\n",
      "8\tValidation loss: 0.127379\tBest loss: 0.124036\tAccuracy: 97.46%\n",
      "9\tValidation loss: 0.174218\tBest loss: 0.124036\tAccuracy: 97.34%\n",
      "10\tValidation loss: 0.221827\tBest loss: 0.124036\tAccuracy: 97.07%\n",
      "11\tValidation loss: 0.162326\tBest loss: 0.124036\tAccuracy: 97.22%\n",
      "12\tValidation loss: 0.189733\tBest loss: 0.124036\tAccuracy: 96.56%\n",
      "13\tValidation loss: 0.242603\tBest loss: 0.124036\tAccuracy: 96.52%\n",
      "14\tValidation loss: 0.196156\tBest loss: 0.124036\tAccuracy: 97.03%\n",
      "15\tValidation loss: 0.203329\tBest loss: 0.124036\tAccuracy: 97.26%\n",
      "16\tValidation loss: 0.242726\tBest loss: 0.124036\tAccuracy: 96.91%\n",
      "17\tValidation loss: 0.278281\tBest loss: 0.124036\tAccuracy: 96.33%\n",
      "18\tValidation loss: 0.280421\tBest loss: 0.124036\tAccuracy: 97.07%\n",
      "19\tValidation loss: 0.214650\tBest loss: 0.124036\tAccuracy: 95.93%\n",
      "20\tValidation loss: 0.314849\tBest loss: 0.124036\tAccuracy: 97.15%\n",
      "21\tValidation loss: 0.263388\tBest loss: 0.124036\tAccuracy: 97.30%\n",
      "22\tValidation loss: 0.378120\tBest loss: 0.124036\tAccuracy: 96.40%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08>, total=  32.4s\n",
      "[CV] n_neurons=10, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.161370\tBest loss: 0.161370\tAccuracy: 95.50%\n",
      "1\tValidation loss: 0.124935\tBest loss: 0.124935\tAccuracy: 96.99%\n",
      "2\tValidation loss: 0.132978\tBest loss: 0.124935\tAccuracy: 96.25%\n",
      "3\tValidation loss: 0.152567\tBest loss: 0.124935\tAccuracy: 96.68%\n",
      "4\tValidation loss: 0.205453\tBest loss: 0.124935\tAccuracy: 95.90%\n",
      "5\tValidation loss: 0.167640\tBest loss: 0.124935\tAccuracy: 95.62%\n",
      "6\tValidation loss: 0.146602\tBest loss: 0.124935\tAccuracy: 96.76%\n",
      "7\tValidation loss: 0.154054\tBest loss: 0.124935\tAccuracy: 96.52%\n",
      "8\tValidation loss: 0.245112\tBest loss: 0.124935\tAccuracy: 96.17%\n",
      "9\tValidation loss: 0.198184\tBest loss: 0.124935\tAccuracy: 96.52%\n",
      "10\tValidation loss: 0.168356\tBest loss: 0.124935\tAccuracy: 96.64%\n",
      "11\tValidation loss: 0.140910\tBest loss: 0.124935\tAccuracy: 97.07%\n",
      "12\tValidation loss: 0.192307\tBest loss: 0.124935\tAccuracy: 96.76%\n",
      "13\tValidation loss: 0.197811\tBest loss: 0.124935\tAccuracy: 96.25%\n",
      "14\tValidation loss: 0.196434\tBest loss: 0.124935\tAccuracy: 96.64%\n",
      "15\tValidation loss: 0.168214\tBest loss: 0.124935\tAccuracy: 96.40%\n",
      "16\tValidation loss: 0.189170\tBest loss: 0.124935\tAccuracy: 96.87%\n",
      "17\tValidation loss: 0.178450\tBest loss: 0.124935\tAccuracy: 96.40%\n",
      "18\tValidation loss: 0.174330\tBest loss: 0.124935\tAccuracy: 96.91%\n",
      "19\tValidation loss: 0.237664\tBest loss: 0.124935\tAccuracy: 96.52%\n",
      "20\tValidation loss: 0.258931\tBest loss: 0.124935\tAccuracy: 97.11%\n",
      "21\tValidation loss: 0.217563\tBest loss: 0.124935\tAccuracy: 96.68%\n",
      "22\tValidation loss: 0.221082\tBest loss: 0.124935\tAccuracy: 96.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08>, total=  31.2s\n",
      "[CV] n_neurons=10, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.161736\tBest loss: 0.161736\tAccuracy: 95.74%\n",
      "1\tValidation loss: 0.145941\tBest loss: 0.145941\tAccuracy: 95.43%\n",
      "2\tValidation loss: 0.138262\tBest loss: 0.138262\tAccuracy: 96.48%\n",
      "3\tValidation loss: 0.147437\tBest loss: 0.138262\tAccuracy: 96.09%\n",
      "4\tValidation loss: 0.129571\tBest loss: 0.129571\tAccuracy: 96.83%\n",
      "5\tValidation loss: 0.151917\tBest loss: 0.129571\tAccuracy: 95.93%\n",
      "6\tValidation loss: 0.159425\tBest loss: 0.129571\tAccuracy: 96.40%\n",
      "7\tValidation loss: 0.197365\tBest loss: 0.129571\tAccuracy: 96.01%\n",
      "8\tValidation loss: 0.262111\tBest loss: 0.129571\tAccuracy: 96.64%\n",
      "9\tValidation loss: 0.130799\tBest loss: 0.129571\tAccuracy: 96.95%\n",
      "10\tValidation loss: 0.188034\tBest loss: 0.129571\tAccuracy: 95.07%\n",
      "11\tValidation loss: 0.173349\tBest loss: 0.129571\tAccuracy: 97.34%\n",
      "12\tValidation loss: 0.162448\tBest loss: 0.129571\tAccuracy: 96.56%\n",
      "13\tValidation loss: 0.172026\tBest loss: 0.129571\tAccuracy: 96.95%\n",
      "14\tValidation loss: 0.170784\tBest loss: 0.129571\tAccuracy: 96.91%\n",
      "15\tValidation loss: 0.249389\tBest loss: 0.129571\tAccuracy: 96.79%\n",
      "16\tValidation loss: 0.208774\tBest loss: 0.129571\tAccuracy: 96.25%\n",
      "17\tValidation loss: 0.166070\tBest loss: 0.129571\tAccuracy: 96.91%\n",
      "18\tValidation loss: 0.199601\tBest loss: 0.129571\tAccuracy: 96.72%\n",
      "19\tValidation loss: 0.199900\tBest loss: 0.129571\tAccuracy: 96.83%\n",
      "20\tValidation loss: 0.212148\tBest loss: 0.129571\tAccuracy: 96.21%\n",
      "21\tValidation loss: 0.184001\tBest loss: 0.129571\tAccuracy: 96.09%\n",
      "22\tValidation loss: 0.230072\tBest loss: 0.129571\tAccuracy: 96.76%\n",
      "23\tValidation loss: 0.209919\tBest loss: 0.129571\tAccuracy: 96.99%\n",
      "24\tValidation loss: 0.244315\tBest loss: 0.129571\tAccuracy: 96.79%\n",
      "25\tValidation loss: 0.258571\tBest loss: 0.129571\tAccuracy: 96.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08>, total=  35.8s\n",
      "[CV] n_neurons=140, n_hidden_layers=3, learning_rate=0.05, batch_size=50, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.282315\tBest loss: 0.282315\tAccuracy: 93.71%\n",
      "1\tValidation loss: 0.273479\tBest loss: 0.273479\tAccuracy: 93.59%\n",
      "2\tValidation loss: 0.173360\tBest loss: 0.173360\tAccuracy: 96.05%\n",
      "3\tValidation loss: 0.781198\tBest loss: 0.173360\tAccuracy: 76.39%\n",
      "4\tValidation loss: 0.313544\tBest loss: 0.173360\tAccuracy: 89.84%\n",
      "5\tValidation loss: 0.390019\tBest loss: 0.173360\tAccuracy: 89.25%\n",
      "6\tValidation loss: 0.255866\tBest loss: 0.173360\tAccuracy: 92.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\tValidation loss: 0.276139\tBest loss: 0.173360\tAccuracy: 91.01%\n",
      "8\tValidation loss: 0.242586\tBest loss: 0.173360\tAccuracy: 93.75%\n",
      "9\tValidation loss: 1.215923\tBest loss: 0.173360\tAccuracy: 42.34%\n",
      "10\tValidation loss: 0.952082\tBest loss: 0.173360\tAccuracy: 55.39%\n",
      "11\tValidation loss: 0.918870\tBest loss: 0.173360\tAccuracy: 55.59%\n",
      "12\tValidation loss: 0.919256\tBest loss: 0.173360\tAccuracy: 55.94%\n",
      "13\tValidation loss: 0.913112\tBest loss: 0.173360\tAccuracy: 55.86%\n",
      "14\tValidation loss: 1.148086\tBest loss: 0.173360\tAccuracy: 47.77%\n",
      "15\tValidation loss: 0.952559\tBest loss: 0.173360\tAccuracy: 54.85%\n",
      "16\tValidation loss: 0.865229\tBest loss: 0.173360\tAccuracy: 57.08%\n",
      "17\tValidation loss: 0.960922\tBest loss: 0.173360\tAccuracy: 50.55%\n",
      "18\tValidation loss: 0.915999\tBest loss: 0.173360\tAccuracy: 57.04%\n",
      "19\tValidation loss: 0.933366\tBest loss: 0.173360\tAccuracy: 55.00%\n",
      "20\tValidation loss: 1.005690\tBest loss: 0.173360\tAccuracy: 52.11%\n",
      "21\tValidation loss: 0.925830\tBest loss: 0.173360\tAccuracy: 54.89%\n",
      "22\tValidation loss: 0.935628\tBest loss: 0.173360\tAccuracy: 52.54%\n",
      "23\tValidation loss: 1.005638\tBest loss: 0.173360\tAccuracy: 50.16%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=3, learning_rate=0.05, batch_size=50, activation=<function relu at 0x117f566a8>, total=  33.7s\n",
      "[CV] n_neurons=140, n_hidden_layers=3, learning_rate=0.05, batch_size=50, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.193010\tBest loss: 0.193010\tAccuracy: 94.45%\n",
      "1\tValidation loss: 0.258700\tBest loss: 0.193010\tAccuracy: 94.10%\n",
      "2\tValidation loss: 0.170260\tBest loss: 0.170260\tAccuracy: 95.43%\n",
      "3\tValidation loss: 0.151387\tBest loss: 0.151387\tAccuracy: 96.40%\n",
      "4\tValidation loss: 0.276867\tBest loss: 0.151387\tAccuracy: 94.21%\n",
      "5\tValidation loss: 0.185235\tBest loss: 0.151387\tAccuracy: 94.80%\n",
      "6\tValidation loss: 0.161737\tBest loss: 0.151387\tAccuracy: 96.44%\n",
      "7\tValidation loss: 0.194347\tBest loss: 0.151387\tAccuracy: 95.47%\n",
      "8\tValidation loss: 0.187914\tBest loss: 0.151387\tAccuracy: 94.96%\n",
      "9\tValidation loss: 0.166145\tBest loss: 0.151387\tAccuracy: 95.62%\n",
      "10\tValidation loss: 0.212180\tBest loss: 0.151387\tAccuracy: 95.74%\n",
      "11\tValidation loss: 0.215523\tBest loss: 0.151387\tAccuracy: 94.76%\n",
      "12\tValidation loss: 0.190214\tBest loss: 0.151387\tAccuracy: 93.35%\n",
      "13\tValidation loss: 0.160722\tBest loss: 0.151387\tAccuracy: 95.86%\n",
      "14\tValidation loss: 0.160870\tBest loss: 0.151387\tAccuracy: 96.40%\n",
      "15\tValidation loss: 0.157335\tBest loss: 0.151387\tAccuracy: 95.70%\n",
      "16\tValidation loss: 0.287137\tBest loss: 0.151387\tAccuracy: 93.94%\n",
      "17\tValidation loss: 0.258392\tBest loss: 0.151387\tAccuracy: 94.25%\n",
      "18\tValidation loss: 0.456044\tBest loss: 0.151387\tAccuracy: 89.09%\n",
      "19\tValidation loss: 0.246679\tBest loss: 0.151387\tAccuracy: 95.43%\n",
      "20\tValidation loss: 0.288439\tBest loss: 0.151387\tAccuracy: 94.21%\n",
      "21\tValidation loss: 0.258797\tBest loss: 0.151387\tAccuracy: 95.00%\n",
      "22\tValidation loss: 0.501116\tBest loss: 0.151387\tAccuracy: 74.98%\n",
      "23\tValidation loss: 0.552785\tBest loss: 0.151387\tAccuracy: 74.28%\n",
      "24\tValidation loss: 0.488268\tBest loss: 0.151387\tAccuracy: 77.56%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=3, learning_rate=0.05, batch_size=50, activation=<function relu at 0x117f566a8>, total=  36.0s\n",
      "[CV] n_neurons=140, n_hidden_layers=3, learning_rate=0.05, batch_size=50, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.151165\tBest loss: 0.151165\tAccuracy: 96.21%\n",
      "1\tValidation loss: 0.153111\tBest loss: 0.151165\tAccuracy: 96.17%\n",
      "2\tValidation loss: 0.611910\tBest loss: 0.151165\tAccuracy: 70.37%\n",
      "3\tValidation loss: 0.379540\tBest loss: 0.151165\tAccuracy: 86.90%\n",
      "4\tValidation loss: 0.263092\tBest loss: 0.151165\tAccuracy: 94.21%\n",
      "5\tValidation loss: 0.238217\tBest loss: 0.151165\tAccuracy: 94.84%\n",
      "6\tValidation loss: 0.214298\tBest loss: 0.151165\tAccuracy: 94.96%\n",
      "7\tValidation loss: 0.222481\tBest loss: 0.151165\tAccuracy: 95.07%\n",
      "8\tValidation loss: 0.183791\tBest loss: 0.151165\tAccuracy: 94.92%\n",
      "9\tValidation loss: 0.331512\tBest loss: 0.151165\tAccuracy: 90.70%\n",
      "10\tValidation loss: 0.199887\tBest loss: 0.151165\tAccuracy: 94.92%\n",
      "11\tValidation loss: 0.425692\tBest loss: 0.151165\tAccuracy: 93.35%\n",
      "12\tValidation loss: 0.352393\tBest loss: 0.151165\tAccuracy: 95.86%\n",
      "13\tValidation loss: 0.247516\tBest loss: 0.151165\tAccuracy: 94.53%\n",
      "14\tValidation loss: 0.319065\tBest loss: 0.151165\tAccuracy: 95.00%\n",
      "15\tValidation loss: 0.297130\tBest loss: 0.151165\tAccuracy: 93.78%\n",
      "16\tValidation loss: 0.280290\tBest loss: 0.151165\tAccuracy: 93.35%\n",
      "17\tValidation loss: 0.233533\tBest loss: 0.151165\tAccuracy: 94.72%\n",
      "18\tValidation loss: 0.323976\tBest loss: 0.151165\tAccuracy: 92.77%\n",
      "19\tValidation loss: 0.266035\tBest loss: 0.151165\tAccuracy: 94.68%\n",
      "20\tValidation loss: 0.270604\tBest loss: 0.151165\tAccuracy: 93.94%\n",
      "21\tValidation loss: 0.227687\tBest loss: 0.151165\tAccuracy: 93.39%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=3, learning_rate=0.05, batch_size=50, activation=<function relu at 0x117f566a8>, total=  32.7s\n",
      "[CV] n_neurons=70, n_hidden_layers=5, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 9.562088\tBest loss: 9.562088\tAccuracy: 88.35%\n",
      "1\tValidation loss: 2.767327\tBest loss: 2.767327\tAccuracy: 94.25%\n",
      "2\tValidation loss: 5.165180\tBest loss: 2.767327\tAccuracy: 89.13%\n",
      "3\tValidation loss: 20.041094\tBest loss: 2.767327\tAccuracy: 88.90%\n",
      "4\tValidation loss: 56749.855469\tBest loss: 2.767327\tAccuracy: 77.29%\n",
      "5\tValidation loss: 21414.822266\tBest loss: 2.767327\tAccuracy: 85.97%\n",
      "6\tValidation loss: 14551.274414\tBest loss: 2.767327\tAccuracy: 87.33%\n",
      "7\tValidation loss: 4767.412109\tBest loss: 2.767327\tAccuracy: 93.63%\n",
      "8\tValidation loss: 3218.228027\tBest loss: 2.767327\tAccuracy: 94.76%\n",
      "9\tValidation loss: 5032.540527\tBest loss: 2.767327\tAccuracy: 92.26%\n",
      "10\tValidation loss: 4158.174316\tBest loss: 2.767327\tAccuracy: 93.86%\n",
      "11\tValidation loss: 6087.701660\tBest loss: 2.767327\tAccuracy: 89.84%\n",
      "12\tValidation loss: 2593.087891\tBest loss: 2.767327\tAccuracy: 94.41%\n",
      "13\tValidation loss: 113203.140625\tBest loss: 2.767327\tAccuracy: 72.05%\n",
      "14\tValidation loss: 7533.217285\tBest loss: 2.767327\tAccuracy: 95.58%\n",
      "15\tValidation loss: 6565.705078\tBest loss: 2.767327\tAccuracy: 92.69%\n",
      "16\tValidation loss: 3025.119629\tBest loss: 2.767327\tAccuracy: 95.74%\n",
      "17\tValidation loss: 83177.789062\tBest loss: 2.767327\tAccuracy: 85.11%\n",
      "18\tValidation loss: 20897.603516\tBest loss: 2.767327\tAccuracy: 91.67%\n",
      "19\tValidation loss: 8273.666992\tBest loss: 2.767327\tAccuracy: 95.39%\n",
      "20\tValidation loss: 8793.994141\tBest loss: 2.767327\tAccuracy: 92.73%\n",
      "21\tValidation loss: 89845.492188\tBest loss: 2.767327\tAccuracy: 93.98%\n",
      "22\tValidation loss: 342011.125000\tBest loss: 2.767327\tAccuracy: 93.08%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=5, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  52.6s\n",
      "[CV] n_neurons=70, n_hidden_layers=5, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.485389\tBest loss: 0.485389\tAccuracy: 89.95%\n",
      "1\tValidation loss: 0.290829\tBest loss: 0.290829\tAccuracy: 94.80%\n",
      "2\tValidation loss: 0.194218\tBest loss: 0.194218\tAccuracy: 94.88%\n",
      "3\tValidation loss: 42947.781250\tBest loss: 0.194218\tAccuracy: 76.11%\n",
      "4\tValidation loss: 15823.149414\tBest loss: 0.194218\tAccuracy: 91.01%\n",
      "5\tValidation loss: 26448.994141\tBest loss: 0.194218\tAccuracy: 83.19%\n",
      "6\tValidation loss: 4559.967285\tBest loss: 0.194218\tAccuracy: 93.39%\n",
      "7\tValidation loss: 2887.453369\tBest loss: 0.194218\tAccuracy: 94.61%\n",
      "8\tValidation loss: 3447.912109\tBest loss: 0.194218\tAccuracy: 91.20%\n",
      "9\tValidation loss: 2606.623047\tBest loss: 0.194218\tAccuracy: 93.28%\n",
      "10\tValidation loss: 5674.372559\tBest loss: 0.194218\tAccuracy: 93.08%\n",
      "11\tValidation loss: 2730.921631\tBest loss: 0.194218\tAccuracy: 93.98%\n",
      "12\tValidation loss: 2050.393555\tBest loss: 0.194218\tAccuracy: 94.68%\n",
      "13\tValidation loss: 1633.637939\tBest loss: 0.194218\tAccuracy: 94.37%\n",
      "14\tValidation loss: 1512.987915\tBest loss: 0.194218\tAccuracy: 94.61%\n",
      "15\tValidation loss: 1169.696411\tBest loss: 0.194218\tAccuracy: 94.37%\n",
      "16\tValidation loss: 2503.536133\tBest loss: 0.194218\tAccuracy: 94.84%\n",
      "17\tValidation loss: 2045.639893\tBest loss: 0.194218\tAccuracy: 94.45%\n",
      "18\tValidation loss: 9234.328125\tBest loss: 0.194218\tAccuracy: 83.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\tValidation loss: 674.960815\tBest loss: 0.194218\tAccuracy: 95.66%\n",
      "20\tValidation loss: 563.236023\tBest loss: 0.194218\tAccuracy: 95.97%\n",
      "21\tValidation loss: 381.752930\tBest loss: 0.194218\tAccuracy: 95.58%\n",
      "22\tValidation loss: 1697.105957\tBest loss: 0.194218\tAccuracy: 94.06%\n",
      "23\tValidation loss: 528.894958\tBest loss: 0.194218\tAccuracy: 95.35%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=5, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  53.7s\n",
      "[CV] n_neurons=70, n_hidden_layers=5, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 2473.604736\tBest loss: 2473.604736\tAccuracy: 78.50%\n",
      "1\tValidation loss: 254.423477\tBest loss: 254.423477\tAccuracy: 86.28%\n",
      "2\tValidation loss: 401.888641\tBest loss: 254.423477\tAccuracy: 77.52%\n",
      "3\tValidation loss: 114.034966\tBest loss: 114.034966\tAccuracy: 92.77%\n",
      "4\tValidation loss: 155.330704\tBest loss: 114.034966\tAccuracy: 86.16%\n",
      "5\tValidation loss: 66.120483\tBest loss: 66.120483\tAccuracy: 93.00%\n",
      "6\tValidation loss: 96.645760\tBest loss: 66.120483\tAccuracy: 84.71%\n",
      "7\tValidation loss: 22.877575\tBest loss: 22.877575\tAccuracy: 93.67%\n",
      "8\tValidation loss: 315.931549\tBest loss: 22.877575\tAccuracy: 84.28%\n",
      "9\tValidation loss: 43.054371\tBest loss: 22.877575\tAccuracy: 95.82%\n",
      "10\tValidation loss: 412201.937500\tBest loss: 22.877575\tAccuracy: 84.09%\n",
      "11\tValidation loss: 83517.562500\tBest loss: 22.877575\tAccuracy: 91.01%\n",
      "12\tValidation loss: 61938.300781\tBest loss: 22.877575\tAccuracy: 91.83%\n",
      "13\tValidation loss: 40120.500000\tBest loss: 22.877575\tAccuracy: 95.00%\n",
      "14\tValidation loss: 27227.501953\tBest loss: 22.877575\tAccuracy: 95.74%\n",
      "15\tValidation loss: 27961.830078\tBest loss: 22.877575\tAccuracy: 94.21%\n",
      "16\tValidation loss: 87735.828125\tBest loss: 22.877575\tAccuracy: 82.68%\n",
      "17\tValidation loss: 21790.013672\tBest loss: 22.877575\tAccuracy: 95.97%\n",
      "18\tValidation loss: 51320.531250\tBest loss: 22.877575\tAccuracy: 95.15%\n",
      "19\tValidation loss: 30171.421875\tBest loss: 22.877575\tAccuracy: 94.88%\n",
      "20\tValidation loss: 17995.244141\tBest loss: 22.877575\tAccuracy: 96.09%\n",
      "21\tValidation loss: 39685.964844\tBest loss: 22.877575\tAccuracy: 93.35%\n",
      "22\tValidation loss: 20468.556641\tBest loss: 22.877575\tAccuracy: 97.07%\n",
      "23\tValidation loss: 137935.328125\tBest loss: 22.877575\tAccuracy: 96.17%\n",
      "24\tValidation loss: 36680.558594\tBest loss: 22.877575\tAccuracy: 96.40%\n",
      "25\tValidation loss: 26437.664062\tBest loss: 22.877575\tAccuracy: 96.99%\n",
      "26\tValidation loss: 7023.244629\tBest loss: 22.877575\tAccuracy: 96.40%\n",
      "27\tValidation loss: 17121.361328\tBest loss: 22.877575\tAccuracy: 97.15%\n",
      "28\tValidation loss: 10618.527344\tBest loss: 22.877575\tAccuracy: 96.13%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=5, learning_rate=0.1, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 1.1min\n",
      "[CV] n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=500, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.204435\tBest loss: 0.204435\tAccuracy: 94.80%\n",
      "1\tValidation loss: 0.117420\tBest loss: 0.117420\tAccuracy: 96.79%\n",
      "2\tValidation loss: 0.104834\tBest loss: 0.104834\tAccuracy: 97.19%\n",
      "3\tValidation loss: 0.112037\tBest loss: 0.104834\tAccuracy: 96.83%\n",
      "4\tValidation loss: 0.096466\tBest loss: 0.096466\tAccuracy: 97.38%\n",
      "5\tValidation loss: 0.093495\tBest loss: 0.093495\tAccuracy: 97.38%\n",
      "6\tValidation loss: 0.075702\tBest loss: 0.075702\tAccuracy: 97.97%\n",
      "7\tValidation loss: 0.087515\tBest loss: 0.075702\tAccuracy: 97.85%\n",
      "8\tValidation loss: 0.073600\tBest loss: 0.073600\tAccuracy: 98.12%\n",
      "9\tValidation loss: 0.075189\tBest loss: 0.073600\tAccuracy: 98.40%\n",
      "10\tValidation loss: 0.072549\tBest loss: 0.072549\tAccuracy: 98.55%\n",
      "11\tValidation loss: 0.081042\tBest loss: 0.072549\tAccuracy: 98.05%\n",
      "12\tValidation loss: 0.090344\tBest loss: 0.072549\tAccuracy: 98.36%\n",
      "13\tValidation loss: 0.149471\tBest loss: 0.072549\tAccuracy: 97.58%\n",
      "14\tValidation loss: 0.083323\tBest loss: 0.072549\tAccuracy: 97.85%\n",
      "15\tValidation loss: 0.093947\tBest loss: 0.072549\tAccuracy: 97.69%\n",
      "16\tValidation loss: 0.078808\tBest loss: 0.072549\tAccuracy: 98.55%\n",
      "17\tValidation loss: 0.091470\tBest loss: 0.072549\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.098750\tBest loss: 0.072549\tAccuracy: 98.48%\n",
      "19\tValidation loss: 0.127998\tBest loss: 0.072549\tAccuracy: 98.12%\n",
      "20\tValidation loss: 0.125378\tBest loss: 0.072549\tAccuracy: 98.28%\n",
      "21\tValidation loss: 0.073869\tBest loss: 0.072549\tAccuracy: 98.59%\n",
      "22\tValidation loss: 0.109356\tBest loss: 0.072549\tAccuracy: 98.40%\n",
      "23\tValidation loss: 0.081432\tBest loss: 0.072549\tAccuracy: 98.36%\n",
      "24\tValidation loss: 0.088499\tBest loss: 0.072549\tAccuracy: 98.51%\n",
      "25\tValidation loss: 0.104576\tBest loss: 0.072549\tAccuracy: 98.40%\n",
      "26\tValidation loss: 0.084786\tBest loss: 0.072549\tAccuracy: 98.36%\n",
      "27\tValidation loss: 0.088233\tBest loss: 0.072549\tAccuracy: 98.67%\n",
      "28\tValidation loss: 0.130832\tBest loss: 0.072549\tAccuracy: 98.16%\n",
      "29\tValidation loss: 0.155194\tBest loss: 0.072549\tAccuracy: 98.08%\n",
      "30\tValidation loss: 0.110208\tBest loss: 0.072549\tAccuracy: 98.40%\n",
      "31\tValidation loss: 0.116939\tBest loss: 0.072549\tAccuracy: 98.36%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=500, activation=<function elu at 0x11591cd08>, total=  15.8s\n",
      "[CV] n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=500, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.202602\tBest loss: 0.202602\tAccuracy: 94.37%\n",
      "1\tValidation loss: 0.114484\tBest loss: 0.114484\tAccuracy: 96.44%\n",
      "2\tValidation loss: 0.093341\tBest loss: 0.093341\tAccuracy: 96.83%\n",
      "3\tValidation loss: 0.088081\tBest loss: 0.088081\tAccuracy: 97.22%\n",
      "4\tValidation loss: 0.085273\tBest loss: 0.085273\tAccuracy: 97.34%\n",
      "5\tValidation loss: 0.069302\tBest loss: 0.069302\tAccuracy: 97.93%\n",
      "6\tValidation loss: 0.077648\tBest loss: 0.069302\tAccuracy: 97.89%\n",
      "7\tValidation loss: 0.081199\tBest loss: 0.069302\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.104124\tBest loss: 0.069302\tAccuracy: 97.54%\n",
      "9\tValidation loss: 0.066871\tBest loss: 0.066871\tAccuracy: 98.28%\n",
      "10\tValidation loss: 0.072504\tBest loss: 0.066871\tAccuracy: 98.12%\n",
      "11\tValidation loss: 0.070802\tBest loss: 0.066871\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.077661\tBest loss: 0.066871\tAccuracy: 98.28%\n",
      "13\tValidation loss: 0.086085\tBest loss: 0.066871\tAccuracy: 97.97%\n",
      "14\tValidation loss: 0.086966\tBest loss: 0.066871\tAccuracy: 97.93%\n",
      "15\tValidation loss: 0.067952\tBest loss: 0.066871\tAccuracy: 98.44%\n",
      "16\tValidation loss: 0.070127\tBest loss: 0.066871\tAccuracy: 98.44%\n",
      "17\tValidation loss: 0.087860\tBest loss: 0.066871\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.088256\tBest loss: 0.066871\tAccuracy: 98.59%\n",
      "19\tValidation loss: 0.097805\tBest loss: 0.066871\tAccuracy: 98.20%\n",
      "20\tValidation loss: 0.078418\tBest loss: 0.066871\tAccuracy: 98.55%\n",
      "21\tValidation loss: 0.072374\tBest loss: 0.066871\tAccuracy: 98.59%\n",
      "22\tValidation loss: 0.084285\tBest loss: 0.066871\tAccuracy: 98.63%\n",
      "23\tValidation loss: 0.093170\tBest loss: 0.066871\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.078897\tBest loss: 0.066871\tAccuracy: 98.48%\n",
      "25\tValidation loss: 0.067198\tBest loss: 0.066871\tAccuracy: 98.71%\n",
      "26\tValidation loss: 0.110437\tBest loss: 0.066871\tAccuracy: 98.36%\n",
      "27\tValidation loss: 0.078667\tBest loss: 0.066871\tAccuracy: 98.51%\n",
      "28\tValidation loss: 0.095338\tBest loss: 0.066871\tAccuracy: 98.32%\n",
      "29\tValidation loss: 0.076066\tBest loss: 0.066871\tAccuracy: 98.28%\n",
      "30\tValidation loss: 0.072892\tBest loss: 0.066871\tAccuracy: 98.48%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=500, activation=<function elu at 0x11591cd08>, total=  15.9s\n",
      "[CV] n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=500, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.201595\tBest loss: 0.201595\tAccuracy: 94.88%\n",
      "1\tValidation loss: 0.102907\tBest loss: 0.102907\tAccuracy: 97.15%\n",
      "2\tValidation loss: 0.094691\tBest loss: 0.094691\tAccuracy: 97.11%\n",
      "3\tValidation loss: 0.098699\tBest loss: 0.094691\tAccuracy: 97.30%\n",
      "4\tValidation loss: 0.084039\tBest loss: 0.084039\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.085712\tBest loss: 0.084039\tAccuracy: 97.69%\n",
      "6\tValidation loss: 0.095700\tBest loss: 0.084039\tAccuracy: 97.34%\n",
      "7\tValidation loss: 0.090682\tBest loss: 0.084039\tAccuracy: 97.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\tValidation loss: 0.099787\tBest loss: 0.084039\tAccuracy: 97.69%\n",
      "9\tValidation loss: 0.068799\tBest loss: 0.068799\tAccuracy: 98.24%\n",
      "10\tValidation loss: 0.093099\tBest loss: 0.068799\tAccuracy: 98.32%\n",
      "11\tValidation loss: 0.064607\tBest loss: 0.064607\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.074724\tBest loss: 0.064607\tAccuracy: 98.08%\n",
      "13\tValidation loss: 0.096429\tBest loss: 0.064607\tAccuracy: 98.05%\n",
      "14\tValidation loss: 0.112859\tBest loss: 0.064607\tAccuracy: 97.65%\n",
      "15\tValidation loss: 0.084624\tBest loss: 0.064607\tAccuracy: 98.12%\n",
      "16\tValidation loss: 0.104542\tBest loss: 0.064607\tAccuracy: 98.12%\n",
      "17\tValidation loss: 0.082545\tBest loss: 0.064607\tAccuracy: 98.32%\n",
      "18\tValidation loss: 0.114922\tBest loss: 0.064607\tAccuracy: 98.01%\n",
      "19\tValidation loss: 0.110772\tBest loss: 0.064607\tAccuracy: 98.05%\n",
      "20\tValidation loss: 0.108180\tBest loss: 0.064607\tAccuracy: 98.32%\n",
      "21\tValidation loss: 0.114697\tBest loss: 0.064607\tAccuracy: 97.58%\n",
      "22\tValidation loss: 0.109906\tBest loss: 0.064607\tAccuracy: 98.08%\n",
      "23\tValidation loss: 0.080177\tBest loss: 0.064607\tAccuracy: 98.36%\n",
      "24\tValidation loss: 0.085903\tBest loss: 0.064607\tAccuracy: 98.20%\n",
      "25\tValidation loss: 0.106272\tBest loss: 0.064607\tAccuracy: 97.73%\n",
      "26\tValidation loss: 0.103366\tBest loss: 0.064607\tAccuracy: 98.63%\n",
      "27\tValidation loss: 0.078763\tBest loss: 0.064607\tAccuracy: 98.44%\n",
      "28\tValidation loss: 0.067357\tBest loss: 0.064607\tAccuracy: 98.55%\n",
      "29\tValidation loss: 0.091360\tBest loss: 0.064607\tAccuracy: 98.44%\n",
      "30\tValidation loss: 0.099667\tBest loss: 0.064607\tAccuracy: 98.63%\n",
      "31\tValidation loss: 0.087112\tBest loss: 0.064607\tAccuracy: 98.48%\n",
      "32\tValidation loss: 0.093527\tBest loss: 0.064607\tAccuracy: 98.55%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=500, activation=<function elu at 0x11591cd08>, total=  16.3s\n",
      "[CV] n_neurons=10, n_hidden_layers=4, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.151459\tBest loss: 0.151459\tAccuracy: 95.78%\n",
      "1\tValidation loss: 0.156720\tBest loss: 0.151459\tAccuracy: 95.19%\n",
      "2\tValidation loss: 0.668860\tBest loss: 0.151459\tAccuracy: 72.32%\n",
      "3\tValidation loss: 0.360008\tBest loss: 0.151459\tAccuracy: 87.57%\n",
      "4\tValidation loss: 0.264041\tBest loss: 0.151459\tAccuracy: 91.83%\n",
      "5\tValidation loss: 0.338591\tBest loss: 0.151459\tAccuracy: 88.47%\n",
      "6\tValidation loss: 0.232372\tBest loss: 0.151459\tAccuracy: 92.53%\n",
      "7\tValidation loss: 0.180134\tBest loss: 0.151459\tAccuracy: 94.64%\n",
      "8\tValidation loss: 0.164481\tBest loss: 0.151459\tAccuracy: 95.50%\n",
      "9\tValidation loss: 0.164657\tBest loss: 0.151459\tAccuracy: 95.07%\n",
      "10\tValidation loss: 0.206495\tBest loss: 0.151459\tAccuracy: 95.23%\n",
      "11\tValidation loss: 0.201141\tBest loss: 0.151459\tAccuracy: 93.82%\n",
      "12\tValidation loss: 0.150063\tBest loss: 0.150063\tAccuracy: 95.70%\n",
      "13\tValidation loss: 0.219589\tBest loss: 0.150063\tAccuracy: 93.35%\n",
      "14\tValidation loss: 0.133344\tBest loss: 0.133344\tAccuracy: 96.44%\n",
      "15\tValidation loss: 39.930744\tBest loss: 0.133344\tAccuracy: 55.55%\n",
      "16\tValidation loss: 1.055972\tBest loss: 0.133344\tAccuracy: 64.31%\n",
      "17\tValidation loss: 0.739223\tBest loss: 0.133344\tAccuracy: 77.01%\n",
      "18\tValidation loss: 0.640755\tBest loss: 0.133344\tAccuracy: 78.66%\n",
      "19\tValidation loss: 0.604571\tBest loss: 0.133344\tAccuracy: 81.98%\n",
      "20\tValidation loss: 0.388753\tBest loss: 0.133344\tAccuracy: 88.78%\n",
      "21\tValidation loss: 0.356271\tBest loss: 0.133344\tAccuracy: 89.60%\n",
      "22\tValidation loss: 0.276223\tBest loss: 0.133344\tAccuracy: 92.65%\n",
      "23\tValidation loss: 0.283952\tBest loss: 0.133344\tAccuracy: 92.26%\n",
      "24\tValidation loss: 0.280519\tBest loss: 0.133344\tAccuracy: 93.08%\n",
      "25\tValidation loss: 0.269493\tBest loss: 0.133344\tAccuracy: 93.98%\n",
      "26\tValidation loss: 0.526275\tBest loss: 0.133344\tAccuracy: 92.96%\n",
      "27\tValidation loss: 0.240202\tBest loss: 0.133344\tAccuracy: 93.00%\n",
      "28\tValidation loss: 0.220305\tBest loss: 0.133344\tAccuracy: 94.68%\n",
      "29\tValidation loss: 0.234681\tBest loss: 0.133344\tAccuracy: 95.27%\n",
      "30\tValidation loss: 0.214748\tBest loss: 0.133344\tAccuracy: 94.68%\n",
      "31\tValidation loss: 0.311154\tBest loss: 0.133344\tAccuracy: 93.90%\n",
      "32\tValidation loss: 0.660787\tBest loss: 0.133344\tAccuracy: 95.90%\n",
      "33\tValidation loss: 0.327877\tBest loss: 0.133344\tAccuracy: 94.18%\n",
      "34\tValidation loss: 1066.536743\tBest loss: 0.133344\tAccuracy: 37.02%\n",
      "35\tValidation loss: 2.264699\tBest loss: 0.133344\tAccuracy: 70.56%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, n_hidden_layers=4, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  24.7s\n",
      "[CV] n_neurons=10, n_hidden_layers=4, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.354948\tBest loss: 0.354948\tAccuracy: 88.58%\n",
      "1\tValidation loss: 0.184010\tBest loss: 0.184010\tAccuracy: 94.68%\n",
      "2\tValidation loss: 0.147523\tBest loss: 0.147523\tAccuracy: 96.36%\n",
      "3\tValidation loss: 0.128221\tBest loss: 0.128221\tAccuracy: 96.09%\n",
      "4\tValidation loss: 0.124622\tBest loss: 0.124622\tAccuracy: 96.52%\n",
      "5\tValidation loss: 0.154946\tBest loss: 0.124622\tAccuracy: 95.70%\n",
      "6\tValidation loss: 0.264595\tBest loss: 0.124622\tAccuracy: 96.60%\n",
      "7\tValidation loss: 0.222355\tBest loss: 0.124622\tAccuracy: 94.21%\n",
      "8\tValidation loss: 0.396653\tBest loss: 0.124622\tAccuracy: 94.10%\n",
      "9\tValidation loss: 0.810459\tBest loss: 0.124622\tAccuracy: 87.29%\n",
      "10\tValidation loss: 0.450086\tBest loss: 0.124622\tAccuracy: 90.19%\n",
      "11\tValidation loss: 0.301636\tBest loss: 0.124622\tAccuracy: 93.16%\n",
      "12\tValidation loss: 0.345591\tBest loss: 0.124622\tAccuracy: 92.34%\n",
      "13\tValidation loss: 0.273808\tBest loss: 0.124622\tAccuracy: 93.67%\n",
      "14\tValidation loss: 0.306101\tBest loss: 0.124622\tAccuracy: 93.67%\n",
      "15\tValidation loss: 0.449677\tBest loss: 0.124622\tAccuracy: 89.64%\n",
      "16\tValidation loss: 0.246601\tBest loss: 0.124622\tAccuracy: 93.20%\n",
      "17\tValidation loss: 0.368109\tBest loss: 0.124622\tAccuracy: 90.34%\n",
      "18\tValidation loss: 0.325927\tBest loss: 0.124622\tAccuracy: 92.46%\n",
      "19\tValidation loss: 0.196431\tBest loss: 0.124622\tAccuracy: 95.43%\n",
      "20\tValidation loss: 0.255604\tBest loss: 0.124622\tAccuracy: 95.11%\n",
      "21\tValidation loss: 0.220565\tBest loss: 0.124622\tAccuracy: 95.62%\n",
      "22\tValidation loss: 0.195919\tBest loss: 0.124622\tAccuracy: 95.19%\n",
      "23\tValidation loss: 0.276627\tBest loss: 0.124622\tAccuracy: 93.32%\n",
      "24\tValidation loss: 0.221265\tBest loss: 0.124622\tAccuracy: 96.01%\n",
      "25\tValidation loss: 0.235132\tBest loss: 0.124622\tAccuracy: 95.47%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, n_hidden_layers=4, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  17.0s\n",
      "[CV] n_neurons=10, n_hidden_layers=4, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.150132\tBest loss: 0.150132\tAccuracy: 95.78%\n",
      "1\tValidation loss: 0.606064\tBest loss: 0.150132\tAccuracy: 88.04%\n",
      "2\tValidation loss: 0.404103\tBest loss: 0.150132\tAccuracy: 88.70%\n",
      "3\tValidation loss: 0.264957\tBest loss: 0.150132\tAccuracy: 93.04%\n",
      "4\tValidation loss: 0.218782\tBest loss: 0.150132\tAccuracy: 94.21%\n",
      "5\tValidation loss: 0.189072\tBest loss: 0.150132\tAccuracy: 95.31%\n",
      "6\tValidation loss: 0.277048\tBest loss: 0.150132\tAccuracy: 91.79%\n",
      "7\tValidation loss: 0.685460\tBest loss: 0.150132\tAccuracy: 89.68%\n",
      "8\tValidation loss: 0.641347\tBest loss: 0.150132\tAccuracy: 87.33%\n",
      "9\tValidation loss: 0.404717\tBest loss: 0.150132\tAccuracy: 91.63%\n",
      "10\tValidation loss: 0.415353\tBest loss: 0.150132\tAccuracy: 88.70%\n",
      "11\tValidation loss: 0.253458\tBest loss: 0.150132\tAccuracy: 93.98%\n",
      "12\tValidation loss: 0.241087\tBest loss: 0.150132\tAccuracy: 94.96%\n",
      "13\tValidation loss: 0.222697\tBest loss: 0.150132\tAccuracy: 94.84%\n",
      "14\tValidation loss: 0.242903\tBest loss: 0.150132\tAccuracy: 94.25%\n",
      "15\tValidation loss: 0.187088\tBest loss: 0.150132\tAccuracy: 95.11%\n",
      "16\tValidation loss: 0.142811\tBest loss: 0.142811\tAccuracy: 96.29%\n",
      "17\tValidation loss: 0.150548\tBest loss: 0.142811\tAccuracy: 96.01%\n",
      "18\tValidation loss: 0.131027\tBest loss: 0.131027\tAccuracy: 96.52%\n",
      "19\tValidation loss: 0.135192\tBest loss: 0.131027\tAccuracy: 96.29%\n",
      "20\tValidation loss: 0.118326\tBest loss: 0.118326\tAccuracy: 96.68%\n",
      "21\tValidation loss: 0.143021\tBest loss: 0.118326\tAccuracy: 95.74%\n",
      "22\tValidation loss: 0.129148\tBest loss: 0.118326\tAccuracy: 96.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\tValidation loss: 0.195709\tBest loss: 0.118326\tAccuracy: 96.56%\n",
      "24\tValidation loss: 0.347733\tBest loss: 0.118326\tAccuracy: 95.15%\n",
      "25\tValidation loss: 14.162280\tBest loss: 0.118326\tAccuracy: 46.48%\n",
      "26\tValidation loss: 6.380793\tBest loss: 0.118326\tAccuracy: 86.86%\n",
      "27\tValidation loss: 1.565093\tBest loss: 0.118326\tAccuracy: 86.36%\n",
      "28\tValidation loss: 0.888816\tBest loss: 0.118326\tAccuracy: 92.30%\n",
      "29\tValidation loss: 0.848016\tBest loss: 0.118326\tAccuracy: 89.44%\n",
      "30\tValidation loss: 0.800007\tBest loss: 0.118326\tAccuracy: 89.05%\n",
      "31\tValidation loss: 0.696926\tBest loss: 0.118326\tAccuracy: 90.46%\n",
      "32\tValidation loss: 0.648534\tBest loss: 0.118326\tAccuracy: 89.33%\n",
      "33\tValidation loss: 0.420269\tBest loss: 0.118326\tAccuracy: 93.94%\n",
      "34\tValidation loss: 0.465195\tBest loss: 0.118326\tAccuracy: 93.39%\n",
      "35\tValidation loss: 0.452265\tBest loss: 0.118326\tAccuracy: 93.43%\n",
      "36\tValidation loss: 0.581847\tBest loss: 0.118326\tAccuracy: 91.52%\n",
      "37\tValidation loss: 0.386876\tBest loss: 0.118326\tAccuracy: 93.75%\n",
      "38\tValidation loss: 0.265007\tBest loss: 0.118326\tAccuracy: 95.74%\n",
      "39\tValidation loss: 0.392128\tBest loss: 0.118326\tAccuracy: 94.53%\n",
      "40\tValidation loss: 0.331320\tBest loss: 0.118326\tAccuracy: 93.67%\n",
      "41\tValidation loss: 0.282766\tBest loss: 0.118326\tAccuracy: 95.70%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, n_hidden_layers=4, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  29.7s\n",
      "[CV] n_neurons=140, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.151203\tBest loss: 0.151203\tAccuracy: 96.72%\n",
      "1\tValidation loss: 0.217564\tBest loss: 0.151203\tAccuracy: 96.01%\n",
      "2\tValidation loss: 0.145377\tBest loss: 0.145377\tAccuracy: 96.99%\n",
      "3\tValidation loss: 0.171931\tBest loss: 0.145377\tAccuracy: 96.25%\n",
      "4\tValidation loss: 0.205656\tBest loss: 0.145377\tAccuracy: 96.33%\n",
      "5\tValidation loss: 0.250342\tBest loss: 0.145377\tAccuracy: 96.40%\n",
      "6\tValidation loss: 0.189021\tBest loss: 0.145377\tAccuracy: 97.22%\n",
      "7\tValidation loss: 0.198963\tBest loss: 0.145377\tAccuracy: 97.03%\n",
      "8\tValidation loss: 0.264410\tBest loss: 0.145377\tAccuracy: 97.54%\n",
      "9\tValidation loss: 0.278724\tBest loss: 0.145377\tAccuracy: 97.26%\n",
      "10\tValidation loss: 0.235483\tBest loss: 0.145377\tAccuracy: 96.83%\n",
      "11\tValidation loss: 0.236198\tBest loss: 0.145377\tAccuracy: 97.50%\n",
      "12\tValidation loss: 0.226236\tBest loss: 0.145377\tAccuracy: 97.38%\n",
      "13\tValidation loss: 0.260700\tBest loss: 0.145377\tAccuracy: 96.79%\n",
      "14\tValidation loss: 0.254282\tBest loss: 0.145377\tAccuracy: 97.22%\n",
      "15\tValidation loss: 0.326529\tBest loss: 0.145377\tAccuracy: 96.91%\n",
      "16\tValidation loss: 0.254162\tBest loss: 0.145377\tAccuracy: 96.95%\n",
      "17\tValidation loss: 0.432536\tBest loss: 0.145377\tAccuracy: 97.22%\n",
      "18\tValidation loss: 0.359831\tBest loss: 0.145377\tAccuracy: 97.26%\n",
      "19\tValidation loss: 0.446983\tBest loss: 0.145377\tAccuracy: 97.58%\n",
      "20\tValidation loss: 0.383226\tBest loss: 0.145377\tAccuracy: 97.07%\n",
      "21\tValidation loss: 0.396869\tBest loss: 0.145377\tAccuracy: 97.62%\n",
      "22\tValidation loss: 0.425163\tBest loss: 0.145377\tAccuracy: 97.77%\n",
      "23\tValidation loss: 0.384005\tBest loss: 0.145377\tAccuracy: 97.03%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function relu at 0x117f566a8>, total= 1.6min\n",
      "[CV] n_neurons=140, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.173310\tBest loss: 0.173310\tAccuracy: 96.09%\n",
      "1\tValidation loss: 0.149108\tBest loss: 0.149108\tAccuracy: 97.07%\n",
      "2\tValidation loss: 0.138328\tBest loss: 0.138328\tAccuracy: 97.54%\n",
      "3\tValidation loss: 0.273626\tBest loss: 0.138328\tAccuracy: 97.19%\n",
      "4\tValidation loss: 0.123625\tBest loss: 0.123625\tAccuracy: 98.20%\n",
      "5\tValidation loss: 0.183306\tBest loss: 0.123625\tAccuracy: 96.48%\n",
      "6\tValidation loss: 0.182192\tBest loss: 0.123625\tAccuracy: 97.46%\n",
      "7\tValidation loss: 0.147487\tBest loss: 0.123625\tAccuracy: 97.62%\n",
      "8\tValidation loss: 0.109269\tBest loss: 0.109269\tAccuracy: 98.12%\n",
      "9\tValidation loss: 0.297157\tBest loss: 0.109269\tAccuracy: 97.81%\n",
      "10\tValidation loss: 0.178126\tBest loss: 0.109269\tAccuracy: 97.62%\n",
      "11\tValidation loss: 0.281750\tBest loss: 0.109269\tAccuracy: 97.46%\n",
      "12\tValidation loss: 0.188946\tBest loss: 0.109269\tAccuracy: 97.26%\n",
      "13\tValidation loss: 0.305972\tBest loss: 0.109269\tAccuracy: 97.65%\n",
      "14\tValidation loss: 0.270346\tBest loss: 0.109269\tAccuracy: 97.26%\n",
      "15\tValidation loss: 0.208464\tBest loss: 0.109269\tAccuracy: 97.97%\n",
      "16\tValidation loss: 0.233785\tBest loss: 0.109269\tAccuracy: 97.73%\n",
      "17\tValidation loss: 0.337515\tBest loss: 0.109269\tAccuracy: 97.77%\n",
      "18\tValidation loss: 0.228232\tBest loss: 0.109269\tAccuracy: 97.73%\n",
      "19\tValidation loss: 0.270096\tBest loss: 0.109269\tAccuracy: 98.05%\n",
      "20\tValidation loss: 0.150528\tBest loss: 0.109269\tAccuracy: 97.81%\n",
      "21\tValidation loss: 0.141585\tBest loss: 0.109269\tAccuracy: 97.89%\n",
      "22\tValidation loss: 0.207048\tBest loss: 0.109269\tAccuracy: 97.85%\n",
      "23\tValidation loss: 0.282743\tBest loss: 0.109269\tAccuracy: 97.46%\n",
      "24\tValidation loss: 0.321675\tBest loss: 0.109269\tAccuracy: 98.16%\n",
      "25\tValidation loss: 0.268729\tBest loss: 0.109269\tAccuracy: 98.05%\n",
      "26\tValidation loss: 0.336416\tBest loss: 0.109269\tAccuracy: 98.16%\n",
      "27\tValidation loss: 0.234326\tBest loss: 0.109269\tAccuracy: 97.50%\n",
      "28\tValidation loss: 0.197671\tBest loss: 0.109269\tAccuracy: 98.01%\n",
      "29\tValidation loss: 0.271539\tBest loss: 0.109269\tAccuracy: 97.26%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function relu at 0x117f566a8>, total= 2.0min\n",
      "[CV] n_neurons=140, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.150042\tBest loss: 0.150042\tAccuracy: 95.58%\n",
      "1\tValidation loss: 0.126981\tBest loss: 0.126981\tAccuracy: 97.42%\n",
      "2\tValidation loss: 0.211668\tBest loss: 0.126981\tAccuracy: 96.52%\n",
      "3\tValidation loss: 0.158594\tBest loss: 0.126981\tAccuracy: 96.99%\n",
      "4\tValidation loss: 0.143819\tBest loss: 0.126981\tAccuracy: 96.95%\n",
      "5\tValidation loss: 0.313781\tBest loss: 0.126981\tAccuracy: 95.93%\n",
      "6\tValidation loss: 0.234783\tBest loss: 0.126981\tAccuracy: 96.68%\n",
      "7\tValidation loss: 0.162880\tBest loss: 0.126981\tAccuracy: 97.22%\n",
      "8\tValidation loss: 0.181880\tBest loss: 0.126981\tAccuracy: 97.15%\n",
      "9\tValidation loss: 0.200727\tBest loss: 0.126981\tAccuracy: 96.36%\n",
      "10\tValidation loss: 0.268666\tBest loss: 0.126981\tAccuracy: 96.29%\n",
      "11\tValidation loss: 0.243861\tBest loss: 0.126981\tAccuracy: 96.87%\n",
      "12\tValidation loss: 0.206568\tBest loss: 0.126981\tAccuracy: 96.52%\n",
      "13\tValidation loss: 0.259178\tBest loss: 0.126981\tAccuracy: 96.79%\n",
      "14\tValidation loss: 0.271022\tBest loss: 0.126981\tAccuracy: 96.95%\n",
      "15\tValidation loss: 0.276500\tBest loss: 0.126981\tAccuracy: 97.65%\n",
      "16\tValidation loss: 0.287189\tBest loss: 0.126981\tAccuracy: 97.34%\n",
      "17\tValidation loss: 0.227963\tBest loss: 0.126981\tAccuracy: 97.26%\n",
      "18\tValidation loss: 0.246505\tBest loss: 0.126981\tAccuracy: 97.85%\n",
      "19\tValidation loss: 0.326068\tBest loss: 0.126981\tAccuracy: 97.15%\n",
      "20\tValidation loss: 0.232738\tBest loss: 0.126981\tAccuracy: 97.50%\n",
      "21\tValidation loss: 0.282731\tBest loss: 0.126981\tAccuracy: 97.77%\n",
      "22\tValidation loss: 0.345728\tBest loss: 0.126981\tAccuracy: 97.03%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=1, learning_rate=0.02, batch_size=10, activation=<function relu at 0x117f566a8>, total= 1.5min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 1.352799\tBest loss: 1.352799\tAccuracy: 91.44%\n",
      "1\tValidation loss: 0.151287\tBest loss: 0.151287\tAccuracy: 96.83%\n",
      "2\tValidation loss: 0.319036\tBest loss: 0.151287\tAccuracy: 96.87%\n",
      "3\tValidation loss: 0.284196\tBest loss: 0.151287\tAccuracy: 95.43%\n",
      "4\tValidation loss: 0.415489\tBest loss: 0.151287\tAccuracy: 96.01%\n",
      "5\tValidation loss: 0.580648\tBest loss: 0.151287\tAccuracy: 97.11%\n",
      "6\tValidation loss: 1.304852\tBest loss: 0.151287\tAccuracy: 96.60%\n",
      "7\tValidation loss: 1.132948\tBest loss: 0.151287\tAccuracy: 94.21%\n",
      "8\tValidation loss: 1.272172\tBest loss: 0.151287\tAccuracy: 96.36%\n",
      "9\tValidation loss: 1.280880\tBest loss: 0.151287\tAccuracy: 96.99%\n",
      "10\tValidation loss: 1.222350\tBest loss: 0.151287\tAccuracy: 96.72%\n",
      "11\tValidation loss: 1.044093\tBest loss: 0.151287\tAccuracy: 97.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\tValidation loss: 1.422340\tBest loss: 0.151287\tAccuracy: 97.69%\n",
      "13\tValidation loss: 2.083337\tBest loss: 0.151287\tAccuracy: 96.17%\n",
      "14\tValidation loss: 1.951116\tBest loss: 0.151287\tAccuracy: 95.90%\n",
      "15\tValidation loss: 1.672124\tBest loss: 0.151287\tAccuracy: 97.19%\n",
      "16\tValidation loss: 2.569048\tBest loss: 0.151287\tAccuracy: 97.22%\n",
      "17\tValidation loss: 25.806154\tBest loss: 0.151287\tAccuracy: 94.45%\n",
      "18\tValidation loss: 4.951986\tBest loss: 0.151287\tAccuracy: 97.77%\n",
      "19\tValidation loss: 11.313670\tBest loss: 0.151287\tAccuracy: 97.34%\n",
      "20\tValidation loss: 6.913876\tBest loss: 0.151287\tAccuracy: 97.58%\n",
      "21\tValidation loss: 3.297506\tBest loss: 0.151287\tAccuracy: 97.54%\n",
      "22\tValidation loss: 2.735474\tBest loss: 0.151287\tAccuracy: 97.07%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.4min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.154965\tBest loss: 0.154965\tAccuracy: 95.90%\n",
      "1\tValidation loss: 0.280104\tBest loss: 0.154965\tAccuracy: 94.06%\n",
      "2\tValidation loss: 0.598995\tBest loss: 0.154965\tAccuracy: 93.12%\n",
      "3\tValidation loss: 0.204676\tBest loss: 0.154965\tAccuracy: 96.87%\n",
      "4\tValidation loss: 0.645694\tBest loss: 0.154965\tAccuracy: 96.52%\n",
      "5\tValidation loss: 0.550170\tBest loss: 0.154965\tAccuracy: 96.52%\n",
      "6\tValidation loss: 0.565979\tBest loss: 0.154965\tAccuracy: 95.39%\n",
      "7\tValidation loss: 0.942534\tBest loss: 0.154965\tAccuracy: 96.79%\n",
      "8\tValidation loss: 0.604789\tBest loss: 0.154965\tAccuracy: 96.13%\n",
      "9\tValidation loss: 0.511627\tBest loss: 0.154965\tAccuracy: 96.99%\n",
      "10\tValidation loss: 1.108449\tBest loss: 0.154965\tAccuracy: 96.44%\n",
      "11\tValidation loss: 1.824006\tBest loss: 0.154965\tAccuracy: 96.79%\n",
      "12\tValidation loss: 0.463144\tBest loss: 0.154965\tAccuracy: 97.77%\n",
      "13\tValidation loss: 0.739735\tBest loss: 0.154965\tAccuracy: 97.89%\n",
      "14\tValidation loss: 1.124860\tBest loss: 0.154965\tAccuracy: 96.60%\n",
      "15\tValidation loss: 1.481107\tBest loss: 0.154965\tAccuracy: 97.42%\n",
      "16\tValidation loss: 5.371510\tBest loss: 0.154965\tAccuracy: 97.69%\n",
      "17\tValidation loss: 1.311457\tBest loss: 0.154965\tAccuracy: 96.72%\n",
      "18\tValidation loss: 1.108182\tBest loss: 0.154965\tAccuracy: 97.54%\n",
      "19\tValidation loss: 3.439329\tBest loss: 0.154965\tAccuracy: 97.15%\n",
      "20\tValidation loss: 4.071588\tBest loss: 0.154965\tAccuracy: 97.93%\n",
      "21\tValidation loss: 3.724088\tBest loss: 0.154965\tAccuracy: 95.97%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.2min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.226186\tBest loss: 0.226186\tAccuracy: 94.57%\n",
      "1\tValidation loss: 0.211427\tBest loss: 0.211427\tAccuracy: 96.33%\n",
      "2\tValidation loss: 0.245168\tBest loss: 0.211427\tAccuracy: 96.60%\n",
      "3\tValidation loss: 0.302771\tBest loss: 0.211427\tAccuracy: 96.33%\n",
      "4\tValidation loss: 0.960721\tBest loss: 0.211427\tAccuracy: 96.29%\n",
      "5\tValidation loss: 0.570483\tBest loss: 0.211427\tAccuracy: 95.58%\n",
      "6\tValidation loss: 0.297922\tBest loss: 0.211427\tAccuracy: 96.91%\n",
      "7\tValidation loss: 0.760775\tBest loss: 0.211427\tAccuracy: 96.87%\n",
      "8\tValidation loss: 0.674609\tBest loss: 0.211427\tAccuracy: 96.60%\n",
      "9\tValidation loss: 1.026663\tBest loss: 0.211427\tAccuracy: 95.23%\n",
      "10\tValidation loss: 1.633429\tBest loss: 0.211427\tAccuracy: 95.00%\n",
      "11\tValidation loss: 1.022084\tBest loss: 0.211427\tAccuracy: 97.42%\n",
      "12\tValidation loss: 0.737625\tBest loss: 0.211427\tAccuracy: 96.95%\n",
      "13\tValidation loss: 1.615097\tBest loss: 0.211427\tAccuracy: 97.22%\n",
      "14\tValidation loss: 1.952236\tBest loss: 0.211427\tAccuracy: 97.15%\n",
      "15\tValidation loss: 1.247021\tBest loss: 0.211427\tAccuracy: 97.34%\n",
      "16\tValidation loss: 1.947144\tBest loss: 0.211427\tAccuracy: 97.81%\n",
      "17\tValidation loss: 1.786856\tBest loss: 0.211427\tAccuracy: 97.93%\n",
      "18\tValidation loss: 1.414423\tBest loss: 0.211427\tAccuracy: 98.55%\n",
      "19\tValidation loss: 2.828832\tBest loss: 0.211427\tAccuracy: 97.89%\n",
      "20\tValidation loss: 4.359519\tBest loss: 0.211427\tAccuracy: 97.50%\n",
      "21\tValidation loss: 2.382680\tBest loss: 0.211427\tAccuracy: 97.73%\n",
      "22\tValidation loss: 8.330420\tBest loss: 0.211427\tAccuracy: 97.19%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 3.9min\n",
      "[CV] n_neurons=70, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.090763\tBest loss: 0.090763\tAccuracy: 97.26%\n",
      "1\tValidation loss: 0.058981\tBest loss: 0.058981\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.060857\tBest loss: 0.058981\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.058357\tBest loss: 0.058357\tAccuracy: 98.24%\n",
      "4\tValidation loss: 0.056549\tBest loss: 0.056549\tAccuracy: 98.24%\n",
      "5\tValidation loss: 0.041899\tBest loss: 0.041899\tAccuracy: 98.87%\n",
      "6\tValidation loss: 0.053382\tBest loss: 0.041899\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.056660\tBest loss: 0.041899\tAccuracy: 98.59%\n",
      "8\tValidation loss: 0.059491\tBest loss: 0.041899\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.053430\tBest loss: 0.041899\tAccuracy: 99.10%\n",
      "10\tValidation loss: 0.069993\tBest loss: 0.041899\tAccuracy: 98.59%\n",
      "11\tValidation loss: 0.055404\tBest loss: 0.041899\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.055076\tBest loss: 0.041899\tAccuracy: 98.79%\n",
      "13\tValidation loss: 0.061732\tBest loss: 0.041899\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.065911\tBest loss: 0.041899\tAccuracy: 98.75%\n",
      "15\tValidation loss: 0.064828\tBest loss: 0.041899\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.057068\tBest loss: 0.041899\tAccuracy: 98.98%\n",
      "17\tValidation loss: 0.085590\tBest loss: 0.041899\tAccuracy: 98.63%\n",
      "18\tValidation loss: 0.059477\tBest loss: 0.041899\tAccuracy: 98.59%\n",
      "19\tValidation loss: 0.048006\tBest loss: 0.041899\tAccuracy: 98.83%\n",
      "20\tValidation loss: 0.069806\tBest loss: 0.041899\tAccuracy: 98.91%\n",
      "21\tValidation loss: 0.070443\tBest loss: 0.041899\tAccuracy: 98.94%\n",
      "22\tValidation loss: 0.073040\tBest loss: 0.041899\tAccuracy: 98.91%\n",
      "23\tValidation loss: 0.073524\tBest loss: 0.041899\tAccuracy: 98.98%\n",
      "24\tValidation loss: 0.074028\tBest loss: 0.041899\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.074508\tBest loss: 0.041899\tAccuracy: 99.02%\n",
      "26\tValidation loss: 0.075101\tBest loss: 0.041899\tAccuracy: 99.02%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function relu at 0x117f566a8>, total=   7.0s\n",
      "[CV] n_neurons=70, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.089672\tBest loss: 0.089672\tAccuracy: 97.15%\n",
      "1\tValidation loss: 0.057299\tBest loss: 0.057299\tAccuracy: 98.24%\n",
      "2\tValidation loss: 0.046966\tBest loss: 0.046966\tAccuracy: 98.36%\n",
      "3\tValidation loss: 0.044145\tBest loss: 0.044145\tAccuracy: 98.59%\n",
      "4\tValidation loss: 0.038722\tBest loss: 0.038722\tAccuracy: 98.91%\n",
      "5\tValidation loss: 0.050570\tBest loss: 0.038722\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.044595\tBest loss: 0.038722\tAccuracy: 98.71%\n",
      "7\tValidation loss: 0.037337\tBest loss: 0.037337\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.049642\tBest loss: 0.037337\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.052341\tBest loss: 0.037337\tAccuracy: 98.55%\n",
      "10\tValidation loss: 0.036582\tBest loss: 0.036582\tAccuracy: 98.91%\n",
      "11\tValidation loss: 0.038744\tBest loss: 0.036582\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.049440\tBest loss: 0.036582\tAccuracy: 98.91%\n",
      "13\tValidation loss: 0.043095\tBest loss: 0.036582\tAccuracy: 98.83%\n",
      "14\tValidation loss: 0.044550\tBest loss: 0.036582\tAccuracy: 99.14%\n",
      "15\tValidation loss: 0.058004\tBest loss: 0.036582\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.055491\tBest loss: 0.036582\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.072220\tBest loss: 0.036582\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.049401\tBest loss: 0.036582\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.050670\tBest loss: 0.036582\tAccuracy: 98.98%\n",
      "20\tValidation loss: 0.051084\tBest loss: 0.036582\tAccuracy: 99.06%\n",
      "21\tValidation loss: 0.042917\tBest loss: 0.036582\tAccuracy: 99.26%\n",
      "22\tValidation loss: 0.046093\tBest loss: 0.036582\tAccuracy: 99.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\tValidation loss: 0.046359\tBest loss: 0.036582\tAccuracy: 99.18%\n",
      "24\tValidation loss: 0.049359\tBest loss: 0.036582\tAccuracy: 99.22%\n",
      "25\tValidation loss: 0.049978\tBest loss: 0.036582\tAccuracy: 99.22%\n",
      "26\tValidation loss: 0.050567\tBest loss: 0.036582\tAccuracy: 99.26%\n",
      "27\tValidation loss: 0.051319\tBest loss: 0.036582\tAccuracy: 99.26%\n",
      "28\tValidation loss: 0.052052\tBest loss: 0.036582\tAccuracy: 99.26%\n",
      "29\tValidation loss: 0.052581\tBest loss: 0.036582\tAccuracy: 99.26%\n",
      "30\tValidation loss: 0.052855\tBest loss: 0.036582\tAccuracy: 99.26%\n",
      "31\tValidation loss: 0.053369\tBest loss: 0.036582\tAccuracy: 99.26%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function relu at 0x117f566a8>, total=   8.2s\n",
      "[CV] n_neurons=70, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.077457\tBest loss: 0.077457\tAccuracy: 97.81%\n",
      "1\tValidation loss: 0.051841\tBest loss: 0.051841\tAccuracy: 98.36%\n",
      "2\tValidation loss: 0.054147\tBest loss: 0.051841\tAccuracy: 98.36%\n",
      "3\tValidation loss: 0.046629\tBest loss: 0.046629\tAccuracy: 98.67%\n",
      "4\tValidation loss: 0.045076\tBest loss: 0.045076\tAccuracy: 98.71%\n",
      "5\tValidation loss: 0.039558\tBest loss: 0.039558\tAccuracy: 98.71%\n",
      "6\tValidation loss: 0.043256\tBest loss: 0.039558\tAccuracy: 98.79%\n",
      "7\tValidation loss: 0.066465\tBest loss: 0.039558\tAccuracy: 98.40%\n",
      "8\tValidation loss: 0.048646\tBest loss: 0.039558\tAccuracy: 98.87%\n",
      "9\tValidation loss: 0.058155\tBest loss: 0.039558\tAccuracy: 98.59%\n",
      "10\tValidation loss: 0.052170\tBest loss: 0.039558\tAccuracy: 98.67%\n",
      "11\tValidation loss: 0.054736\tBest loss: 0.039558\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.057334\tBest loss: 0.039558\tAccuracy: 98.83%\n",
      "13\tValidation loss: 0.061998\tBest loss: 0.039558\tAccuracy: 98.67%\n",
      "14\tValidation loss: 0.063605\tBest loss: 0.039558\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.045317\tBest loss: 0.039558\tAccuracy: 98.83%\n",
      "16\tValidation loss: 0.035532\tBest loss: 0.035532\tAccuracy: 98.98%\n",
      "17\tValidation loss: 0.049595\tBest loss: 0.035532\tAccuracy: 99.14%\n",
      "18\tValidation loss: 0.070149\tBest loss: 0.035532\tAccuracy: 98.67%\n",
      "19\tValidation loss: 0.109758\tBest loss: 0.035532\tAccuracy: 97.89%\n",
      "20\tValidation loss: 0.070968\tBest loss: 0.035532\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.073971\tBest loss: 0.035532\tAccuracy: 98.51%\n",
      "22\tValidation loss: 0.054996\tBest loss: 0.035532\tAccuracy: 98.94%\n",
      "23\tValidation loss: 0.060790\tBest loss: 0.035532\tAccuracy: 98.91%\n",
      "24\tValidation loss: 0.057510\tBest loss: 0.035532\tAccuracy: 98.75%\n",
      "25\tValidation loss: 0.060074\tBest loss: 0.035532\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.058745\tBest loss: 0.035532\tAccuracy: 99.14%\n",
      "27\tValidation loss: 0.060460\tBest loss: 0.035532\tAccuracy: 99.06%\n",
      "28\tValidation loss: 0.057071\tBest loss: 0.035532\tAccuracy: 99.22%\n",
      "29\tValidation loss: 0.056128\tBest loss: 0.035532\tAccuracy: 99.14%\n",
      "30\tValidation loss: 0.056933\tBest loss: 0.035532\tAccuracy: 99.18%\n",
      "31\tValidation loss: 0.057616\tBest loss: 0.035532\tAccuracy: 99.18%\n",
      "32\tValidation loss: 0.058287\tBest loss: 0.035532\tAccuracy: 99.18%\n",
      "33\tValidation loss: 0.058797\tBest loss: 0.035532\tAccuracy: 99.18%\n",
      "34\tValidation loss: 0.059340\tBest loss: 0.035532\tAccuracy: 99.18%\n",
      "35\tValidation loss: 0.059798\tBest loss: 0.035532\tAccuracy: 99.18%\n",
      "36\tValidation loss: 0.060267\tBest loss: 0.035532\tAccuracy: 99.18%\n",
      "37\tValidation loss: 0.060633\tBest loss: 0.035532\tAccuracy: 99.18%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function relu at 0x117f566a8>, total=   9.7s\n",
      "[CV] n_neurons=140, n_hidden_layers=1, learning_rate=0.1, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 1.554935\tBest loss: 1.554935\tAccuracy: 94.33%\n",
      "1\tValidation loss: 1.701708\tBest loss: 1.554935\tAccuracy: 94.92%\n",
      "2\tValidation loss: 2.316829\tBest loss: 1.554935\tAccuracy: 93.78%\n",
      "3\tValidation loss: 1.983243\tBest loss: 1.554935\tAccuracy: 93.28%\n",
      "4\tValidation loss: 1.442527\tBest loss: 1.442527\tAccuracy: 79.09%\n",
      "5\tValidation loss: 2.850562\tBest loss: 1.442527\tAccuracy: 94.25%\n",
      "6\tValidation loss: 2.888374\tBest loss: 1.442527\tAccuracy: 95.54%\n",
      "7\tValidation loss: 2.282539\tBest loss: 1.442527\tAccuracy: 94.76%\n",
      "8\tValidation loss: 2.689183\tBest loss: 1.442527\tAccuracy: 93.82%\n",
      "9\tValidation loss: 3.523838\tBest loss: 1.442527\tAccuracy: 95.97%\n",
      "10\tValidation loss: 2.404076\tBest loss: 1.442527\tAccuracy: 95.82%\n",
      "11\tValidation loss: 3.423790\tBest loss: 1.442527\tAccuracy: 95.58%\n",
      "12\tValidation loss: 4.736463\tBest loss: 1.442527\tAccuracy: 95.23%\n",
      "13\tValidation loss: 2.332280\tBest loss: 1.442527\tAccuracy: 95.15%\n",
      "14\tValidation loss: 3.353518\tBest loss: 1.442527\tAccuracy: 94.41%\n",
      "15\tValidation loss: 6.314873\tBest loss: 1.442527\tAccuracy: 78.77%\n",
      "16\tValidation loss: 4.393913\tBest loss: 1.442527\tAccuracy: 94.68%\n",
      "17\tValidation loss: 3.442975\tBest loss: 1.442527\tAccuracy: 95.15%\n",
      "18\tValidation loss: 4.960191\tBest loss: 1.442527\tAccuracy: 95.15%\n",
      "19\tValidation loss: 4.074256\tBest loss: 1.442527\tAccuracy: 95.47%\n",
      "20\tValidation loss: 3.609504\tBest loss: 1.442527\tAccuracy: 95.70%\n",
      "21\tValidation loss: 4.014105\tBest loss: 1.442527\tAccuracy: 94.96%\n",
      "22\tValidation loss: 3.860125\tBest loss: 1.442527\tAccuracy: 94.84%\n",
      "23\tValidation loss: 6.220671\tBest loss: 1.442527\tAccuracy: 95.15%\n",
      "24\tValidation loss: 4.128174\tBest loss: 1.442527\tAccuracy: 95.43%\n",
      "25\tValidation loss: 4.182242\tBest loss: 1.442527\tAccuracy: 95.39%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=1, learning_rate=0.1, batch_size=10, activation=<function elu at 0x11591cd08>, total= 1.6min\n",
      "[CV] n_neurons=140, n_hidden_layers=1, learning_rate=0.1, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 1.861292\tBest loss: 1.861292\tAccuracy: 87.49%\n",
      "1\tValidation loss: 1.355463\tBest loss: 1.355463\tAccuracy: 95.74%\n",
      "2\tValidation loss: 1.478809\tBest loss: 1.355463\tAccuracy: 83.35%\n",
      "3\tValidation loss: 3.212618\tBest loss: 1.355463\tAccuracy: 92.42%\n",
      "4\tValidation loss: 5.365822\tBest loss: 1.355463\tAccuracy: 92.92%\n",
      "5\tValidation loss: 3.681794\tBest loss: 1.355463\tAccuracy: 94.64%\n",
      "6\tValidation loss: 3.297095\tBest loss: 1.355463\tAccuracy: 96.05%\n",
      "7\tValidation loss: 2.462107\tBest loss: 1.355463\tAccuracy: 95.62%\n",
      "8\tValidation loss: 2.469051\tBest loss: 1.355463\tAccuracy: 96.48%\n",
      "9\tValidation loss: 3.781743\tBest loss: 1.355463\tAccuracy: 88.35%\n",
      "10\tValidation loss: 1.913409\tBest loss: 1.355463\tAccuracy: 95.04%\n",
      "11\tValidation loss: 4.800873\tBest loss: 1.355463\tAccuracy: 85.85%\n",
      "12\tValidation loss: 4.465870\tBest loss: 1.355463\tAccuracy: 96.36%\n",
      "13\tValidation loss: 3.794357\tBest loss: 1.355463\tAccuracy: 96.91%\n",
      "14\tValidation loss: 7.465009\tBest loss: 1.355463\tAccuracy: 89.13%\n",
      "15\tValidation loss: 4.095875\tBest loss: 1.355463\tAccuracy: 96.48%\n",
      "16\tValidation loss: 2.131670\tBest loss: 1.355463\tAccuracy: 87.14%\n",
      "17\tValidation loss: 5.265560\tBest loss: 1.355463\tAccuracy: 96.52%\n",
      "18\tValidation loss: 3.357685\tBest loss: 1.355463\tAccuracy: 96.44%\n",
      "19\tValidation loss: 4.512941\tBest loss: 1.355463\tAccuracy: 91.87%\n",
      "20\tValidation loss: 4.876236\tBest loss: 1.355463\tAccuracy: 89.33%\n",
      "21\tValidation loss: 5.728590\tBest loss: 1.355463\tAccuracy: 96.40%\n",
      "22\tValidation loss: 4.947500\tBest loss: 1.355463\tAccuracy: 97.26%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=1, learning_rate=0.1, batch_size=10, activation=<function elu at 0x11591cd08>, total= 1.5min\n",
      "[CV] n_neurons=140, n_hidden_layers=1, learning_rate=0.1, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 1.632714\tBest loss: 1.632714\tAccuracy: 93.55%\n",
      "1\tValidation loss: 1.462348\tBest loss: 1.462348\tAccuracy: 95.35%\n",
      "2\tValidation loss: 2.540099\tBest loss: 1.462348\tAccuracy: 95.23%\n",
      "3\tValidation loss: 1.906894\tBest loss: 1.462348\tAccuracy: 94.49%\n",
      "4\tValidation loss: 3.407293\tBest loss: 1.462348\tAccuracy: 94.80%\n",
      "5\tValidation loss: 2.222515\tBest loss: 1.462348\tAccuracy: 77.83%\n",
      "6\tValidation loss: 5.540812\tBest loss: 1.462348\tAccuracy: 95.11%\n",
      "7\tValidation loss: 3.645474\tBest loss: 1.462348\tAccuracy: 95.23%\n",
      "8\tValidation loss: 2.247555\tBest loss: 1.462348\tAccuracy: 95.35%\n",
      "9\tValidation loss: 2.454098\tBest loss: 1.462348\tAccuracy: 78.34%\n",
      "10\tValidation loss: 1.659444\tBest loss: 1.462348\tAccuracy: 94.96%\n",
      "11\tValidation loss: 2.361268\tBest loss: 1.462348\tAccuracy: 93.82%\n",
      "12\tValidation loss: 3.142729\tBest loss: 1.462348\tAccuracy: 95.82%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\tValidation loss: 4.167859\tBest loss: 1.462348\tAccuracy: 95.93%\n",
      "14\tValidation loss: 4.117615\tBest loss: 1.462348\tAccuracy: 95.00%\n",
      "15\tValidation loss: 2.861652\tBest loss: 1.462348\tAccuracy: 95.31%\n",
      "16\tValidation loss: 3.550066\tBest loss: 1.462348\tAccuracy: 76.54%\n",
      "17\tValidation loss: 2.801289\tBest loss: 1.462348\tAccuracy: 95.43%\n",
      "18\tValidation loss: 3.190454\tBest loss: 1.462348\tAccuracy: 79.44%\n",
      "19\tValidation loss: 4.257212\tBest loss: 1.462348\tAccuracy: 95.86%\n",
      "20\tValidation loss: 3.616263\tBest loss: 1.462348\tAccuracy: 79.44%\n",
      "21\tValidation loss: 7.131831\tBest loss: 1.462348\tAccuracy: 95.70%\n",
      "22\tValidation loss: 1.860288\tBest loss: 1.462348\tAccuracy: 95.11%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=1, learning_rate=0.1, batch_size=10, activation=<function elu at 0x11591cd08>, total= 1.6min\n",
      "[CV] n_neurons=30, n_hidden_layers=5, learning_rate=0.02, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.090917\tBest loss: 0.090917\tAccuracy: 97.07%\n",
      "1\tValidation loss: 0.082013\tBest loss: 0.082013\tAccuracy: 97.77%\n",
      "2\tValidation loss: 0.093401\tBest loss: 0.082013\tAccuracy: 97.54%\n",
      "3\tValidation loss: 0.107703\tBest loss: 0.082013\tAccuracy: 97.11%\n",
      "4\tValidation loss: 0.097109\tBest loss: 0.082013\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.090368\tBest loss: 0.082013\tAccuracy: 97.73%\n",
      "6\tValidation loss: 0.069419\tBest loss: 0.069419\tAccuracy: 98.01%\n",
      "7\tValidation loss: 0.086618\tBest loss: 0.069419\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.081836\tBest loss: 0.069419\tAccuracy: 97.97%\n",
      "9\tValidation loss: 0.060206\tBest loss: 0.060206\tAccuracy: 98.28%\n",
      "10\tValidation loss: 0.097240\tBest loss: 0.060206\tAccuracy: 97.73%\n",
      "11\tValidation loss: 0.098382\tBest loss: 0.060206\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.098408\tBest loss: 0.060206\tAccuracy: 97.46%\n",
      "13\tValidation loss: 0.148490\tBest loss: 0.060206\tAccuracy: 97.85%\n",
      "14\tValidation loss: 0.131041\tBest loss: 0.060206\tAccuracy: 98.05%\n",
      "15\tValidation loss: 0.536083\tBest loss: 0.060206\tAccuracy: 92.77%\n",
      "16\tValidation loss: 0.225725\tBest loss: 0.060206\tAccuracy: 91.83%\n",
      "17\tValidation loss: 0.150101\tBest loss: 0.060206\tAccuracy: 95.70%\n",
      "18\tValidation loss: 0.151543\tBest loss: 0.060206\tAccuracy: 95.62%\n",
      "19\tValidation loss: 0.129047\tBest loss: 0.060206\tAccuracy: 96.83%\n",
      "20\tValidation loss: 0.114907\tBest loss: 0.060206\tAccuracy: 96.68%\n",
      "21\tValidation loss: 0.119936\tBest loss: 0.060206\tAccuracy: 96.95%\n",
      "22\tValidation loss: 0.113225\tBest loss: 0.060206\tAccuracy: 97.30%\n",
      "23\tValidation loss: 0.137556\tBest loss: 0.060206\tAccuracy: 97.26%\n",
      "24\tValidation loss: 0.180393\tBest loss: 0.060206\tAccuracy: 97.77%\n",
      "25\tValidation loss: 0.133763\tBest loss: 0.060206\tAccuracy: 96.76%\n",
      "26\tValidation loss: 0.128906\tBest loss: 0.060206\tAccuracy: 97.58%\n",
      "27\tValidation loss: 0.144728\tBest loss: 0.060206\tAccuracy: 96.05%\n",
      "28\tValidation loss: 0.149448\tBest loss: 0.060206\tAccuracy: 97.42%\n",
      "29\tValidation loss: 0.117119\tBest loss: 0.060206\tAccuracy: 96.56%\n",
      "30\tValidation loss: 0.112377\tBest loss: 0.060206\tAccuracy: 97.03%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=5, learning_rate=0.02, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  30.9s\n",
      "[CV] n_neurons=30, n_hidden_layers=5, learning_rate=0.02, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.120600\tBest loss: 0.120600\tAccuracy: 96.33%\n",
      "1\tValidation loss: 0.087058\tBest loss: 0.087058\tAccuracy: 97.77%\n",
      "2\tValidation loss: 0.070494\tBest loss: 0.070494\tAccuracy: 97.89%\n",
      "3\tValidation loss: 0.165425\tBest loss: 0.070494\tAccuracy: 96.56%\n",
      "4\tValidation loss: 0.127119\tBest loss: 0.070494\tAccuracy: 96.87%\n",
      "5\tValidation loss: 0.104796\tBest loss: 0.070494\tAccuracy: 97.54%\n",
      "6\tValidation loss: 0.114886\tBest loss: 0.070494\tAccuracy: 97.11%\n",
      "7\tValidation loss: 0.111670\tBest loss: 0.070494\tAccuracy: 96.52%\n",
      "8\tValidation loss: 0.107952\tBest loss: 0.070494\tAccuracy: 97.85%\n",
      "9\tValidation loss: 0.148124\tBest loss: 0.070494\tAccuracy: 95.82%\n",
      "10\tValidation loss: 0.123058\tBest loss: 0.070494\tAccuracy: 97.93%\n",
      "11\tValidation loss: 0.116541\tBest loss: 0.070494\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.077679\tBest loss: 0.070494\tAccuracy: 98.24%\n",
      "13\tValidation loss: 0.068819\tBest loss: 0.068819\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.082093\tBest loss: 0.068819\tAccuracy: 97.85%\n",
      "15\tValidation loss: 0.079878\tBest loss: 0.068819\tAccuracy: 98.16%\n",
      "16\tValidation loss: 0.134284\tBest loss: 0.068819\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.125093\tBest loss: 0.068819\tAccuracy: 98.01%\n",
      "18\tValidation loss: 1.388247\tBest loss: 0.068819\tAccuracy: 71.58%\n",
      "19\tValidation loss: 0.225920\tBest loss: 0.068819\tAccuracy: 93.51%\n",
      "20\tValidation loss: 0.117184\tBest loss: 0.068819\tAccuracy: 97.34%\n",
      "21\tValidation loss: 0.104636\tBest loss: 0.068819\tAccuracy: 97.50%\n",
      "22\tValidation loss: 0.110545\tBest loss: 0.068819\tAccuracy: 97.65%\n",
      "23\tValidation loss: 0.199512\tBest loss: 0.068819\tAccuracy: 97.65%\n",
      "24\tValidation loss: 0.122894\tBest loss: 0.068819\tAccuracy: 97.58%\n",
      "25\tValidation loss: 0.132680\tBest loss: 0.068819\tAccuracy: 97.30%\n",
      "26\tValidation loss: 0.154488\tBest loss: 0.068819\tAccuracy: 97.30%\n",
      "27\tValidation loss: 0.149779\tBest loss: 0.068819\tAccuracy: 97.65%\n",
      "28\tValidation loss: 0.196529\tBest loss: 0.068819\tAccuracy: 97.15%\n",
      "29\tValidation loss: 0.178888\tBest loss: 0.068819\tAccuracy: 97.69%\n",
      "30\tValidation loss: 0.143406\tBest loss: 0.068819\tAccuracy: 97.77%\n",
      "31\tValidation loss: 0.132523\tBest loss: 0.068819\tAccuracy: 97.73%\n",
      "32\tValidation loss: 0.146448\tBest loss: 0.068819\tAccuracy: 98.05%\n",
      "33\tValidation loss: 0.131382\tBest loss: 0.068819\tAccuracy: 98.20%\n",
      "34\tValidation loss: 0.135460\tBest loss: 0.068819\tAccuracy: 97.81%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=5, learning_rate=0.02, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  34.6s\n",
      "[CV] n_neurons=30, n_hidden_layers=5, learning_rate=0.02, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.119797\tBest loss: 0.119797\tAccuracy: 96.68%\n",
      "1\tValidation loss: 0.082200\tBest loss: 0.082200\tAccuracy: 97.93%\n",
      "2\tValidation loss: 0.084148\tBest loss: 0.082200\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.075840\tBest loss: 0.075840\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.100593\tBest loss: 0.075840\tAccuracy: 97.73%\n",
      "5\tValidation loss: 0.074375\tBest loss: 0.074375\tAccuracy: 98.63%\n",
      "6\tValidation loss: 0.092952\tBest loss: 0.074375\tAccuracy: 97.46%\n",
      "7\tValidation loss: 0.066239\tBest loss: 0.066239\tAccuracy: 98.36%\n",
      "8\tValidation loss: 0.098774\tBest loss: 0.066239\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.073560\tBest loss: 0.066239\tAccuracy: 98.32%\n",
      "10\tValidation loss: 0.090471\tBest loss: 0.066239\tAccuracy: 98.67%\n",
      "11\tValidation loss: 1.341011\tBest loss: 0.066239\tAccuracy: 65.29%\n",
      "12\tValidation loss: 0.110075\tBest loss: 0.066239\tAccuracy: 96.72%\n",
      "13\tValidation loss: 0.099737\tBest loss: 0.066239\tAccuracy: 97.50%\n",
      "14\tValidation loss: 0.085648\tBest loss: 0.066239\tAccuracy: 98.24%\n",
      "15\tValidation loss: 0.611508\tBest loss: 0.066239\tAccuracy: 97.89%\n",
      "16\tValidation loss: 0.297916\tBest loss: 0.066239\tAccuracy: 98.44%\n",
      "17\tValidation loss: 0.117953\tBest loss: 0.066239\tAccuracy: 97.97%\n",
      "18\tValidation loss: 0.214954\tBest loss: 0.066239\tAccuracy: 97.03%\n",
      "19\tValidation loss: 0.120773\tBest loss: 0.066239\tAccuracy: 96.99%\n",
      "20\tValidation loss: 0.074070\tBest loss: 0.066239\tAccuracy: 98.16%\n",
      "21\tValidation loss: 0.076182\tBest loss: 0.066239\tAccuracy: 98.51%\n",
      "22\tValidation loss: 0.086019\tBest loss: 0.066239\tAccuracy: 98.28%\n",
      "23\tValidation loss: 0.098069\tBest loss: 0.066239\tAccuracy: 97.89%\n",
      "24\tValidation loss: 0.167927\tBest loss: 0.066239\tAccuracy: 95.43%\n",
      "25\tValidation loss: 0.112025\tBest loss: 0.066239\tAccuracy: 97.19%\n",
      "26\tValidation loss: 0.499172\tBest loss: 0.066239\tAccuracy: 90.93%\n",
      "27\tValidation loss: 0.126033\tBest loss: 0.066239\tAccuracy: 97.54%\n",
      "28\tValidation loss: 0.103943\tBest loss: 0.066239\tAccuracy: 97.30%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=5, learning_rate=0.02, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  28.4s\n",
      "[CV] n_neurons=90, n_hidden_layers=5, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 1.617723\tBest loss: 1.617723\tAccuracy: 22.01%\n",
      "1\tValidation loss: 1.632911\tBest loss: 1.617723\tAccuracy: 22.01%\n",
      "2\tValidation loss: 1.629249\tBest loss: 1.617723\tAccuracy: 18.73%\n",
      "3\tValidation loss: 1.670466\tBest loss: 1.617723\tAccuracy: 19.08%\n",
      "4\tValidation loss: 1.701460\tBest loss: 1.617723\tAccuracy: 19.27%\n",
      "5\tValidation loss: 1.634358\tBest loss: 1.617723\tAccuracy: 18.73%\n",
      "6\tValidation loss: 1.661117\tBest loss: 1.617723\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.636438\tBest loss: 1.617723\tAccuracy: 19.08%\n",
      "8\tValidation loss: 1.712350\tBest loss: 1.617723\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.842654\tBest loss: 1.617723\tAccuracy: 19.08%\n",
      "10\tValidation loss: 1.684767\tBest loss: 1.617723\tAccuracy: 19.08%\n",
      "11\tValidation loss: 1.688392\tBest loss: 1.617723\tAccuracy: 18.73%\n",
      "12\tValidation loss: 1.694640\tBest loss: 1.617723\tAccuracy: 19.08%\n",
      "13\tValidation loss: 1.676945\tBest loss: 1.617723\tAccuracy: 22.01%\n",
      "14\tValidation loss: 1.731991\tBest loss: 1.617723\tAccuracy: 19.08%\n",
      "15\tValidation loss: 1.647903\tBest loss: 1.617723\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.696204\tBest loss: 1.617723\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.704797\tBest loss: 1.617723\tAccuracy: 18.73%\n",
      "18\tValidation loss: 1.754046\tBest loss: 1.617723\tAccuracy: 20.91%\n",
      "19\tValidation loss: 1.813527\tBest loss: 1.617723\tAccuracy: 20.91%\n",
      "20\tValidation loss: 1.622714\tBest loss: 1.617723\tAccuracy: 19.08%\n",
      "21\tValidation loss: 1.690328\tBest loss: 1.617723\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=5, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08>, total=  36.7s\n",
      "[CV] n_neurons=90, n_hidden_layers=5, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.386357\tBest loss: 0.386357\tAccuracy: 89.01%\n",
      "1\tValidation loss: 0.207140\tBest loss: 0.207140\tAccuracy: 94.92%\n",
      "2\tValidation loss: 0.179083\tBest loss: 0.179083\tAccuracy: 95.58%\n",
      "3\tValidation loss: 16.721212\tBest loss: 0.179083\tAccuracy: 20.91%\n",
      "4\tValidation loss: 1.617745\tBest loss: 0.179083\tAccuracy: 19.08%\n",
      "5\tValidation loss: 1.668670\tBest loss: 0.179083\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.641309\tBest loss: 0.179083\tAccuracy: 19.08%\n",
      "7\tValidation loss: 1.623434\tBest loss: 0.179083\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.621030\tBest loss: 0.179083\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.680731\tBest loss: 0.179083\tAccuracy: 22.01%\n",
      "10\tValidation loss: 1.627806\tBest loss: 0.179083\tAccuracy: 19.27%\n",
      "11\tValidation loss: 1.635338\tBest loss: 0.179083\tAccuracy: 19.27%\n",
      "12\tValidation loss: 1.628813\tBest loss: 0.179083\tAccuracy: 20.91%\n",
      "13\tValidation loss: 1.633628\tBest loss: 0.179083\tAccuracy: 22.01%\n",
      "14\tValidation loss: 1.731845\tBest loss: 0.179083\tAccuracy: 22.01%\n",
      "15\tValidation loss: 1.705526\tBest loss: 0.179083\tAccuracy: 18.73%\n",
      "16\tValidation loss: 1.645483\tBest loss: 0.179083\tAccuracy: 19.27%\n",
      "17\tValidation loss: 1.674466\tBest loss: 0.179083\tAccuracy: 20.91%\n",
      "18\tValidation loss: 1.716356\tBest loss: 0.179083\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.666893\tBest loss: 0.179083\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.810196\tBest loss: 0.179083\tAccuracy: 19.27%\n",
      "21\tValidation loss: 1.838524\tBest loss: 0.179083\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.715574\tBest loss: 0.179083\tAccuracy: 19.27%\n",
      "23\tValidation loss: 1.704712\tBest loss: 0.179083\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=5, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08>, total=  43.1s\n",
      "[CV] n_neurons=90, n_hidden_layers=5, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.761970\tBest loss: 0.761970\tAccuracy: 66.18%\n",
      "1\tValidation loss: 0.297700\tBest loss: 0.297700\tAccuracy: 91.05%\n",
      "2\tValidation loss: 0.218007\tBest loss: 0.218007\tAccuracy: 94.45%\n",
      "3\tValidation loss: 0.189696\tBest loss: 0.189696\tAccuracy: 94.92%\n",
      "4\tValidation loss: 0.159339\tBest loss: 0.159339\tAccuracy: 95.74%\n",
      "5\tValidation loss: 0.191753\tBest loss: 0.159339\tAccuracy: 94.64%\n",
      "6\tValidation loss: 0.155898\tBest loss: 0.155898\tAccuracy: 96.01%\n",
      "7\tValidation loss: 0.136903\tBest loss: 0.136903\tAccuracy: 96.68%\n",
      "8\tValidation loss: 0.179943\tBest loss: 0.136903\tAccuracy: 95.62%\n",
      "9\tValidation loss: 0.363323\tBest loss: 0.136903\tAccuracy: 89.56%\n",
      "10\tValidation loss: 0.128087\tBest loss: 0.128087\tAccuracy: 96.95%\n",
      "11\tValidation loss: 0.140648\tBest loss: 0.128087\tAccuracy: 97.07%\n",
      "12\tValidation loss: 0.144148\tBest loss: 0.128087\tAccuracy: 97.15%\n",
      "13\tValidation loss: 0.128568\tBest loss: 0.128087\tAccuracy: 96.72%\n",
      "14\tValidation loss: 0.166473\tBest loss: 0.128087\tAccuracy: 96.25%\n",
      "15\tValidation loss: 0.302021\tBest loss: 0.128087\tAccuracy: 93.12%\n",
      "16\tValidation loss: 1.721658\tBest loss: 0.128087\tAccuracy: 19.27%\n",
      "17\tValidation loss: 1.617163\tBest loss: 0.128087\tAccuracy: 22.01%\n",
      "18\tValidation loss: 1.631557\tBest loss: 0.128087\tAccuracy: 18.73%\n",
      "19\tValidation loss: 1.707559\tBest loss: 0.128087\tAccuracy: 18.73%\n",
      "20\tValidation loss: 1.658999\tBest loss: 0.128087\tAccuracy: 19.08%\n",
      "21\tValidation loss: 1.940728\tBest loss: 0.128087\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.733727\tBest loss: 0.128087\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.693387\tBest loss: 0.128087\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.621321\tBest loss: 0.128087\tAccuracy: 18.73%\n",
      "25\tValidation loss: 1.811207\tBest loss: 0.128087\tAccuracy: 22.01%\n",
      "26\tValidation loss: 1.757600\tBest loss: 0.128087\tAccuracy: 20.91%\n",
      "27\tValidation loss: 1.764703\tBest loss: 0.128087\tAccuracy: 20.91%\n",
      "28\tValidation loss: 1.718997\tBest loss: 0.128087\tAccuracy: 22.01%\n",
      "29\tValidation loss: 1.810100\tBest loss: 0.128087\tAccuracy: 19.08%\n",
      "30\tValidation loss: 1.977449\tBest loss: 0.128087\tAccuracy: 20.91%\n",
      "31\tValidation loss: 1.831398\tBest loss: 0.128087\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=5, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08>, total=  52.5s\n",
      "[CV] n_neurons=30, n_hidden_layers=2, learning_rate=0.1, batch_size=50, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.270295\tBest loss: 0.270295\tAccuracy: 93.20%\n",
      "1\tValidation loss: 0.831729\tBest loss: 0.270295\tAccuracy: 90.66%\n",
      "2\tValidation loss: 0.796213\tBest loss: 0.270295\tAccuracy: 70.91%\n",
      "3\tValidation loss: 0.864130\tBest loss: 0.270295\tAccuracy: 59.34%\n",
      "4\tValidation loss: 0.582596\tBest loss: 0.270295\tAccuracy: 85.50%\n",
      "5\tValidation loss: 0.673328\tBest loss: 0.270295\tAccuracy: 91.24%\n",
      "6\tValidation loss: 1.160416\tBest loss: 0.270295\tAccuracy: 55.55%\n",
      "7\tValidation loss: 0.725883\tBest loss: 0.270295\tAccuracy: 87.96%\n",
      "8\tValidation loss: 1.582613\tBest loss: 0.270295\tAccuracy: 88.43%\n",
      "9\tValidation loss: 3.263273\tBest loss: 0.270295\tAccuracy: 42.42%\n",
      "10\tValidation loss: 4.166241\tBest loss: 0.270295\tAccuracy: 54.93%\n",
      "11\tValidation loss: 0.970768\tBest loss: 0.270295\tAccuracy: 57.94%\n",
      "12\tValidation loss: 3.153479\tBest loss: 0.270295\tAccuracy: 70.76%\n",
      "13\tValidation loss: 0.991399\tBest loss: 0.270295\tAccuracy: 68.26%\n",
      "14\tValidation loss: 0.772109\tBest loss: 0.270295\tAccuracy: 68.06%\n",
      "15\tValidation loss: 0.822050\tBest loss: 0.270295\tAccuracy: 69.12%\n",
      "16\tValidation loss: 1.570761\tBest loss: 0.270295\tAccuracy: 66.26%\n",
      "17\tValidation loss: 0.925089\tBest loss: 0.270295\tAccuracy: 67.24%\n",
      "18\tValidation loss: 1.491236\tBest loss: 0.270295\tAccuracy: 64.62%\n",
      "19\tValidation loss: 2.542321\tBest loss: 0.270295\tAccuracy: 72.71%\n",
      "20\tValidation loss: 2.036032\tBest loss: 0.270295\tAccuracy: 71.15%\n",
      "21\tValidation loss: 1.374851\tBest loss: 0.270295\tAccuracy: 71.89%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=2, learning_rate=0.1, batch_size=50, activation=<function elu at 0x11591cd08>, total=  18.2s\n",
      "[CV] n_neurons=30, n_hidden_layers=2, learning_rate=0.1, batch_size=50, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.259291\tBest loss: 0.259291\tAccuracy: 93.75%\n",
      "1\tValidation loss: 0.603778\tBest loss: 0.259291\tAccuracy: 90.85%\n",
      "2\tValidation loss: 0.640563\tBest loss: 0.259291\tAccuracy: 74.98%\n",
      "3\tValidation loss: 0.749748\tBest loss: 0.259291\tAccuracy: 82.21%\n",
      "4\tValidation loss: 0.559692\tBest loss: 0.259291\tAccuracy: 89.48%\n",
      "5\tValidation loss: 1.097767\tBest loss: 0.259291\tAccuracy: 74.39%\n",
      "6\tValidation loss: 1.381879\tBest loss: 0.259291\tAccuracy: 76.15%\n",
      "7\tValidation loss: 1.231720\tBest loss: 0.259291\tAccuracy: 49.22%\n",
      "8\tValidation loss: 1.375983\tBest loss: 0.259291\tAccuracy: 87.72%\n",
      "9\tValidation loss: 0.944146\tBest loss: 0.259291\tAccuracy: 73.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\tValidation loss: 0.995608\tBest loss: 0.259291\tAccuracy: 70.91%\n",
      "11\tValidation loss: 0.808038\tBest loss: 0.259291\tAccuracy: 66.61%\n",
      "12\tValidation loss: 0.932507\tBest loss: 0.259291\tAccuracy: 70.29%\n",
      "13\tValidation loss: 1.086659\tBest loss: 0.259291\tAccuracy: 76.04%\n",
      "14\tValidation loss: 1.032581\tBest loss: 0.259291\tAccuracy: 53.60%\n",
      "15\tValidation loss: 1.094724\tBest loss: 0.259291\tAccuracy: 50.98%\n",
      "16\tValidation loss: 0.859258\tBest loss: 0.259291\tAccuracy: 67.87%\n",
      "17\tValidation loss: 3.950998\tBest loss: 0.259291\tAccuracy: 71.03%\n",
      "18\tValidation loss: 1.395199\tBest loss: 0.259291\tAccuracy: 51.13%\n",
      "19\tValidation loss: 1.056119\tBest loss: 0.259291\tAccuracy: 55.51%\n",
      "20\tValidation loss: 1.085557\tBest loss: 0.259291\tAccuracy: 72.44%\n",
      "21\tValidation loss: 2.522842\tBest loss: 0.259291\tAccuracy: 76.82%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=2, learning_rate=0.1, batch_size=50, activation=<function elu at 0x11591cd08>, total=  18.0s\n",
      "[CV] n_neurons=30, n_hidden_layers=2, learning_rate=0.1, batch_size=50, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.166946\tBest loss: 0.166946\tAccuracy: 95.23%\n",
      "1\tValidation loss: 1.044733\tBest loss: 0.166946\tAccuracy: 74.94%\n",
      "2\tValidation loss: 0.789565\tBest loss: 0.166946\tAccuracy: 72.40%\n",
      "3\tValidation loss: 0.826801\tBest loss: 0.166946\tAccuracy: 72.71%\n",
      "4\tValidation loss: 0.814633\tBest loss: 0.166946\tAccuracy: 66.97%\n",
      "5\tValidation loss: 0.792159\tBest loss: 0.166946\tAccuracy: 67.67%\n",
      "6\tValidation loss: 2.241968\tBest loss: 0.166946\tAccuracy: 76.82%\n",
      "7\tValidation loss: 1.034508\tBest loss: 0.166946\tAccuracy: 75.96%\n",
      "8\tValidation loss: 1.293882\tBest loss: 0.166946\tAccuracy: 73.77%\n",
      "9\tValidation loss: 1.007827\tBest loss: 0.166946\tAccuracy: 73.81%\n",
      "10\tValidation loss: 1.059526\tBest loss: 0.166946\tAccuracy: 57.54%\n",
      "11\tValidation loss: 1.009339\tBest loss: 0.166946\tAccuracy: 72.91%\n",
      "12\tValidation loss: 1.343207\tBest loss: 0.166946\tAccuracy: 71.81%\n",
      "13\tValidation loss: 1.871841\tBest loss: 0.166946\tAccuracy: 64.62%\n",
      "14\tValidation loss: 1.547708\tBest loss: 0.166946\tAccuracy: 75.57%\n",
      "15\tValidation loss: 1.404140\tBest loss: 0.166946\tAccuracy: 74.16%\n",
      "16\tValidation loss: 1.575823\tBest loss: 0.166946\tAccuracy: 73.38%\n",
      "17\tValidation loss: 1.961458\tBest loss: 0.166946\tAccuracy: 71.89%\n",
      "18\tValidation loss: 1.329197\tBest loss: 0.166946\tAccuracy: 75.25%\n",
      "19\tValidation loss: 3.012209\tBest loss: 0.166946\tAccuracy: 75.02%\n",
      "20\tValidation loss: 1.217674\tBest loss: 0.166946\tAccuracy: 72.17%\n",
      "21\tValidation loss: 4.236769\tBest loss: 0.166946\tAccuracy: 62.63%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=2, learning_rate=0.1, batch_size=50, activation=<function elu at 0x11591cd08>, total=  18.4s\n",
      "[CV] n_neurons=160, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.737963\tBest loss: 0.737963\tAccuracy: 69.86%\n",
      "1\tValidation loss: 1.786210\tBest loss: 0.737963\tAccuracy: 50.70%\n",
      "2\tValidation loss: 1.320381\tBest loss: 0.737963\tAccuracy: 36.20%\n",
      "3\tValidation loss: 1.502824\tBest loss: 0.737963\tAccuracy: 27.33%\n",
      "4\tValidation loss: 1.502444\tBest loss: 0.737963\tAccuracy: 29.09%\n",
      "5\tValidation loss: 1.596991\tBest loss: 0.737963\tAccuracy: 20.17%\n",
      "6\tValidation loss: 1.549011\tBest loss: 0.737963\tAccuracy: 33.46%\n",
      "7\tValidation loss: 1.640962\tBest loss: 0.737963\tAccuracy: 27.48%\n",
      "8\tValidation loss: 1.763124\tBest loss: 0.737963\tAccuracy: 31.67%\n",
      "9\tValidation loss: 2.110629\tBest loss: 0.737963\tAccuracy: 40.73%\n",
      "10\tValidation loss: 1.822986\tBest loss: 0.737963\tAccuracy: 30.81%\n",
      "11\tValidation loss: 1.670489\tBest loss: 0.737963\tAccuracy: 37.76%\n",
      "12\tValidation loss: 2.273552\tBest loss: 0.737963\tAccuracy: 49.53%\n",
      "13\tValidation loss: 1.216058\tBest loss: 0.737963\tAccuracy: 40.38%\n",
      "14\tValidation loss: 1.674262\tBest loss: 0.737963\tAccuracy: 51.95%\n",
      "15\tValidation loss: 1.304280\tBest loss: 0.737963\tAccuracy: 51.06%\n",
      "16\tValidation loss: 1.314774\tBest loss: 0.737963\tAccuracy: 35.89%\n",
      "17\tValidation loss: 1.230169\tBest loss: 0.737963\tAccuracy: 49.73%\n",
      "18\tValidation loss: 1.123747\tBest loss: 0.737963\tAccuracy: 51.80%\n",
      "19\tValidation loss: 1.433149\tBest loss: 0.737963\tAccuracy: 47.07%\n",
      "20\tValidation loss: 1.153524\tBest loss: 0.737963\tAccuracy: 48.40%\n",
      "21\tValidation loss: 1.308799\tBest loss: 0.737963\tAccuracy: 48.48%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function relu at 0x117f566a8>, total= 1.9min\n",
      "[CV] n_neurons=160, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.424085\tBest loss: 0.424085\tAccuracy: 90.54%\n",
      "1\tValidation loss: 0.850668\tBest loss: 0.424085\tAccuracy: 57.27%\n",
      "2\tValidation loss: 0.557061\tBest loss: 0.424085\tAccuracy: 78.15%\n",
      "3\tValidation loss: 0.525535\tBest loss: 0.424085\tAccuracy: 77.99%\n",
      "4\tValidation loss: 0.465536\tBest loss: 0.424085\tAccuracy: 78.07%\n",
      "5\tValidation loss: 3.233208\tBest loss: 0.424085\tAccuracy: 77.52%\n",
      "6\tValidation loss: 0.948260\tBest loss: 0.424085\tAccuracy: 57.58%\n",
      "7\tValidation loss: 0.761352\tBest loss: 0.424085\tAccuracy: 57.86%\n",
      "8\tValidation loss: 0.760715\tBest loss: 0.424085\tAccuracy: 58.13%\n",
      "9\tValidation loss: 0.751432\tBest loss: 0.424085\tAccuracy: 59.66%\n",
      "10\tValidation loss: 0.784049\tBest loss: 0.424085\tAccuracy: 59.93%\n",
      "11\tValidation loss: 0.758233\tBest loss: 0.424085\tAccuracy: 56.06%\n",
      "12\tValidation loss: 0.697915\tBest loss: 0.424085\tAccuracy: 59.66%\n",
      "13\tValidation loss: 0.694006\tBest loss: 0.424085\tAccuracy: 57.27%\n",
      "14\tValidation loss: 0.744418\tBest loss: 0.424085\tAccuracy: 56.72%\n",
      "15\tValidation loss: 0.694534\tBest loss: 0.424085\tAccuracy: 59.42%\n",
      "16\tValidation loss: 0.725153\tBest loss: 0.424085\tAccuracy: 56.92%\n",
      "17\tValidation loss: 0.702929\tBest loss: 0.424085\tAccuracy: 60.52%\n",
      "18\tValidation loss: 0.793244\tBest loss: 0.424085\tAccuracy: 60.63%\n",
      "19\tValidation loss: 0.740020\tBest loss: 0.424085\tAccuracy: 58.21%\n",
      "20\tValidation loss: 0.742125\tBest loss: 0.424085\tAccuracy: 59.07%\n",
      "21\tValidation loss: 0.732311\tBest loss: 0.424085\tAccuracy: 58.09%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function relu at 0x117f566a8>, total= 1.9min\n",
      "[CV] n_neurons=160, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.616209\tBest loss: 0.616209\tAccuracy: 75.22%\n",
      "1\tValidation loss: 0.321856\tBest loss: 0.321856\tAccuracy: 91.71%\n",
      "2\tValidation loss: 0.274150\tBest loss: 0.274150\tAccuracy: 91.79%\n",
      "3\tValidation loss: 0.413540\tBest loss: 0.274150\tAccuracy: 92.81%\n",
      "4\tValidation loss: 0.311080\tBest loss: 0.274150\tAccuracy: 93.35%\n",
      "5\tValidation loss: 0.235937\tBest loss: 0.235937\tAccuracy: 94.06%\n",
      "6\tValidation loss: 0.335727\tBest loss: 0.235937\tAccuracy: 92.06%\n",
      "7\tValidation loss: 0.305831\tBest loss: 0.235937\tAccuracy: 91.09%\n",
      "8\tValidation loss: 0.369252\tBest loss: 0.235937\tAccuracy: 92.18%\n",
      "9\tValidation loss: 0.285115\tBest loss: 0.235937\tAccuracy: 94.21%\n",
      "10\tValidation loss: 0.304515\tBest loss: 0.235937\tAccuracy: 90.97%\n",
      "11\tValidation loss: 0.577865\tBest loss: 0.235937\tAccuracy: 73.46%\n",
      "12\tValidation loss: 1.034067\tBest loss: 0.235937\tAccuracy: 46.48%\n",
      "13\tValidation loss: 1.084616\tBest loss: 0.235937\tAccuracy: 51.41%\n",
      "14\tValidation loss: 0.664367\tBest loss: 0.235937\tAccuracy: 71.11%\n",
      "15\tValidation loss: 0.854503\tBest loss: 0.235937\tAccuracy: 58.80%\n",
      "16\tValidation loss: 0.636034\tBest loss: 0.235937\tAccuracy: 74.08%\n",
      "17\tValidation loss: 0.870940\tBest loss: 0.235937\tAccuracy: 60.24%\n",
      "18\tValidation loss: 0.809012\tBest loss: 0.235937\tAccuracy: 59.66%\n",
      "19\tValidation loss: 0.766936\tBest loss: 0.235937\tAccuracy: 57.90%\n",
      "20\tValidation loss: 0.797704\tBest loss: 0.235937\tAccuracy: 58.01%\n",
      "21\tValidation loss: 0.851253\tBest loss: 0.235937\tAccuracy: 57.35%\n",
      "22\tValidation loss: 0.866932\tBest loss: 0.235937\tAccuracy: 59.73%\n",
      "23\tValidation loss: 0.799009\tBest loss: 0.235937\tAccuracy: 58.33%\n",
      "24\tValidation loss: 0.740912\tBest loss: 0.235937\tAccuracy: 71.54%\n",
      "25\tValidation loss: 0.851676\tBest loss: 0.235937\tAccuracy: 57.43%\n",
      "26\tValidation loss: 0.850393\tBest loss: 0.235937\tAccuracy: 60.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function relu at 0x117f566a8>, total= 2.4min\n",
      "[CV] n_neurons=90, n_hidden_layers=4, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.114646\tBest loss: 0.114646\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.073446\tBest loss: 0.073446\tAccuracy: 97.65%\n",
      "2\tValidation loss: 0.082619\tBest loss: 0.073446\tAccuracy: 97.34%\n",
      "3\tValidation loss: 0.065193\tBest loss: 0.065193\tAccuracy: 97.89%\n",
      "4\tValidation loss: 0.076188\tBest loss: 0.065193\tAccuracy: 97.77%\n",
      "5\tValidation loss: 0.064466\tBest loss: 0.064466\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.065387\tBest loss: 0.064466\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.069329\tBest loss: 0.064466\tAccuracy: 98.08%\n",
      "8\tValidation loss: 0.069026\tBest loss: 0.064466\tAccuracy: 98.01%\n",
      "9\tValidation loss: 0.057306\tBest loss: 0.057306\tAccuracy: 98.48%\n",
      "10\tValidation loss: 0.048234\tBest loss: 0.048234\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.064756\tBest loss: 0.048234\tAccuracy: 97.97%\n",
      "12\tValidation loss: 0.060405\tBest loss: 0.048234\tAccuracy: 98.44%\n",
      "13\tValidation loss: 0.059582\tBest loss: 0.048234\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.078491\tBest loss: 0.048234\tAccuracy: 98.05%\n",
      "15\tValidation loss: 0.060526\tBest loss: 0.048234\tAccuracy: 98.32%\n",
      "16\tValidation loss: 0.068785\tBest loss: 0.048234\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.107825\tBest loss: 0.048234\tAccuracy: 97.97%\n",
      "18\tValidation loss: 0.097115\tBest loss: 0.048234\tAccuracy: 97.89%\n",
      "19\tValidation loss: 0.052953\tBest loss: 0.048234\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.059386\tBest loss: 0.048234\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.094818\tBest loss: 0.048234\tAccuracy: 97.62%\n",
      "22\tValidation loss: 0.097884\tBest loss: 0.048234\tAccuracy: 98.36%\n",
      "23\tValidation loss: 0.065588\tBest loss: 0.048234\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.064644\tBest loss: 0.048234\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.072104\tBest loss: 0.048234\tAccuracy: 98.91%\n",
      "26\tValidation loss: 0.060898\tBest loss: 0.048234\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.100572\tBest loss: 0.048234\tAccuracy: 98.36%\n",
      "28\tValidation loss: 0.077133\tBest loss: 0.048234\tAccuracy: 98.40%\n",
      "29\tValidation loss: 0.087544\tBest loss: 0.048234\tAccuracy: 98.55%\n",
      "30\tValidation loss: 0.095812\tBest loss: 0.048234\tAccuracy: 98.83%\n",
      "31\tValidation loss: 0.116057\tBest loss: 0.048234\tAccuracy: 98.55%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=4, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  22.3s\n",
      "[CV] n_neurons=90, n_hidden_layers=4, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.100693\tBest loss: 0.100693\tAccuracy: 96.68%\n",
      "1\tValidation loss: 0.071498\tBest loss: 0.071498\tAccuracy: 98.05%\n",
      "2\tValidation loss: 0.070097\tBest loss: 0.070097\tAccuracy: 97.77%\n",
      "3\tValidation loss: 0.054110\tBest loss: 0.054110\tAccuracy: 98.24%\n",
      "4\tValidation loss: 0.057548\tBest loss: 0.054110\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.073354\tBest loss: 0.054110\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.067660\tBest loss: 0.054110\tAccuracy: 98.36%\n",
      "7\tValidation loss: 0.060483\tBest loss: 0.054110\tAccuracy: 98.48%\n",
      "8\tValidation loss: 0.051200\tBest loss: 0.051200\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.057102\tBest loss: 0.051200\tAccuracy: 98.87%\n",
      "10\tValidation loss: 0.058476\tBest loss: 0.051200\tAccuracy: 98.55%\n",
      "11\tValidation loss: 0.089505\tBest loss: 0.051200\tAccuracy: 97.97%\n",
      "12\tValidation loss: 0.083930\tBest loss: 0.051200\tAccuracy: 98.08%\n",
      "13\tValidation loss: 0.066063\tBest loss: 0.051200\tAccuracy: 98.24%\n",
      "14\tValidation loss: 0.075579\tBest loss: 0.051200\tAccuracy: 98.08%\n",
      "15\tValidation loss: 0.082986\tBest loss: 0.051200\tAccuracy: 98.59%\n",
      "16\tValidation loss: 0.080511\tBest loss: 0.051200\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.073564\tBest loss: 0.051200\tAccuracy: 98.55%\n",
      "18\tValidation loss: 0.061813\tBest loss: 0.051200\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.084638\tBest loss: 0.051200\tAccuracy: 97.97%\n",
      "20\tValidation loss: 0.101612\tBest loss: 0.051200\tAccuracy: 98.59%\n",
      "21\tValidation loss: 0.121208\tBest loss: 0.051200\tAccuracy: 98.01%\n",
      "22\tValidation loss: 70.534241\tBest loss: 0.051200\tAccuracy: 78.54%\n",
      "23\tValidation loss: 4.598977\tBest loss: 0.051200\tAccuracy: 96.29%\n",
      "24\tValidation loss: 1.748574\tBest loss: 0.051200\tAccuracy: 97.19%\n",
      "25\tValidation loss: 1.868116\tBest loss: 0.051200\tAccuracy: 96.64%\n",
      "26\tValidation loss: 1.614128\tBest loss: 0.051200\tAccuracy: 97.03%\n",
      "27\tValidation loss: 2.552659\tBest loss: 0.051200\tAccuracy: 96.48%\n",
      "28\tValidation loss: 1.575864\tBest loss: 0.051200\tAccuracy: 96.99%\n",
      "29\tValidation loss: 1.239419\tBest loss: 0.051200\tAccuracy: 96.83%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=4, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  19.6s\n",
      "[CV] n_neurons=90, n_hidden_layers=4, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.106342\tBest loss: 0.106342\tAccuracy: 96.91%\n",
      "1\tValidation loss: 0.078522\tBest loss: 0.078522\tAccuracy: 97.81%\n",
      "2\tValidation loss: 0.058829\tBest loss: 0.058829\tAccuracy: 98.08%\n",
      "3\tValidation loss: 0.054734\tBest loss: 0.054734\tAccuracy: 98.40%\n",
      "4\tValidation loss: 0.056354\tBest loss: 0.054734\tAccuracy: 98.28%\n",
      "5\tValidation loss: 0.058052\tBest loss: 0.054734\tAccuracy: 98.40%\n",
      "6\tValidation loss: 0.043507\tBest loss: 0.043507\tAccuracy: 98.75%\n",
      "7\tValidation loss: 0.051940\tBest loss: 0.043507\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.061578\tBest loss: 0.043507\tAccuracy: 98.44%\n",
      "9\tValidation loss: 0.079365\tBest loss: 0.043507\tAccuracy: 98.24%\n",
      "10\tValidation loss: 0.072921\tBest loss: 0.043507\tAccuracy: 98.32%\n",
      "11\tValidation loss: 0.075793\tBest loss: 0.043507\tAccuracy: 97.97%\n",
      "12\tValidation loss: 0.113000\tBest loss: 0.043507\tAccuracy: 97.77%\n",
      "13\tValidation loss: 0.068567\tBest loss: 0.043507\tAccuracy: 98.44%\n",
      "14\tValidation loss: 0.087974\tBest loss: 0.043507\tAccuracy: 98.48%\n",
      "15\tValidation loss: 0.073243\tBest loss: 0.043507\tAccuracy: 98.63%\n",
      "16\tValidation loss: 0.122634\tBest loss: 0.043507\tAccuracy: 98.20%\n",
      "17\tValidation loss: 0.062458\tBest loss: 0.043507\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.072894\tBest loss: 0.043507\tAccuracy: 98.67%\n",
      "19\tValidation loss: 0.066703\tBest loss: 0.043507\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.076473\tBest loss: 0.043507\tAccuracy: 98.63%\n",
      "21\tValidation loss: 0.081394\tBest loss: 0.043507\tAccuracy: 98.63%\n",
      "22\tValidation loss: 0.085126\tBest loss: 0.043507\tAccuracy: 98.51%\n",
      "23\tValidation loss: 0.075038\tBest loss: 0.043507\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.061043\tBest loss: 0.043507\tAccuracy: 98.91%\n",
      "25\tValidation loss: 0.090851\tBest loss: 0.043507\tAccuracy: 98.63%\n",
      "26\tValidation loss: 0.250367\tBest loss: 0.043507\tAccuracy: 97.26%\n",
      "27\tValidation loss: 11.561208\tBest loss: 0.043507\tAccuracy: 88.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=4, learning_rate=0.02, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  18.4s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 1.637596\tBest loss: 1.637596\tAccuracy: 19.27%\n",
      "1\tValidation loss: 1.621899\tBest loss: 1.621899\tAccuracy: 19.27%\n",
      "2\tValidation loss: 1.619830\tBest loss: 1.619830\tAccuracy: 19.27%\n",
      "3\tValidation loss: 1.616520\tBest loss: 1.616520\tAccuracy: 19.27%\n",
      "4\tValidation loss: 1.654958\tBest loss: 1.616520\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.621479\tBest loss: 1.616520\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.632693\tBest loss: 1.616520\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.614858\tBest loss: 1.614858\tAccuracy: 19.27%\n",
      "8\tValidation loss: 1.642606\tBest loss: 1.614858\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.639819\tBest loss: 1.614858\tAccuracy: 19.27%\n",
      "10\tValidation loss: 1.615375\tBest loss: 1.614858\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.630571\tBest loss: 1.614858\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.636737\tBest loss: 1.614858\tAccuracy: 19.08%\n",
      "13\tValidation loss: 1.613103\tBest loss: 1.613103\tAccuracy: 19.27%\n",
      "14\tValidation loss: 1.629263\tBest loss: 1.613103\tAccuracy: 19.08%\n",
      "15\tValidation loss: 1.617149\tBest loss: 1.613103\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.626923\tBest loss: 1.613103\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.608595\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "18\tValidation loss: 1.624737\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "19\tValidation loss: 1.624035\tBest loss: 1.608595\tAccuracy: 20.91%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\tValidation loss: 1.615449\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "21\tValidation loss: 1.629650\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "22\tValidation loss: 1.619098\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "23\tValidation loss: 1.621080\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.633989\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "25\tValidation loss: 1.647182\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "26\tValidation loss: 1.614127\tBest loss: 1.608595\tAccuracy: 19.08%\n",
      "27\tValidation loss: 1.638548\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "28\tValidation loss: 1.656264\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "29\tValidation loss: 1.617747\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "30\tValidation loss: 1.641874\tBest loss: 1.608595\tAccuracy: 19.27%\n",
      "31\tValidation loss: 1.631482\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "32\tValidation loss: 1.641183\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "33\tValidation loss: 1.647446\tBest loss: 1.608595\tAccuracy: 19.08%\n",
      "34\tValidation loss: 1.610284\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "35\tValidation loss: 1.624692\tBest loss: 1.608595\tAccuracy: 19.08%\n",
      "36\tValidation loss: 1.630852\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "37\tValidation loss: 1.632281\tBest loss: 1.608595\tAccuracy: 18.73%\n",
      "38\tValidation loss: 1.631021\tBest loss: 1.608595\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8>, total= 3.3min\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 1.631924\tBest loss: 1.631924\tAccuracy: 22.01%\n",
      "1\tValidation loss: 1.644789\tBest loss: 1.631924\tAccuracy: 19.08%\n",
      "2\tValidation loss: 1.611664\tBest loss: 1.611664\tAccuracy: 22.01%\n",
      "3\tValidation loss: 1.614178\tBest loss: 1.611664\tAccuracy: 22.01%\n",
      "4\tValidation loss: 1.617810\tBest loss: 1.611664\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.624092\tBest loss: 1.611664\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.635104\tBest loss: 1.611664\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.630919\tBest loss: 1.611664\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.639868\tBest loss: 1.611664\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.611889\tBest loss: 1.611664\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.613289\tBest loss: 1.611664\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.614457\tBest loss: 1.611664\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.615519\tBest loss: 1.611664\tAccuracy: 20.91%\n",
      "13\tValidation loss: 1.609585\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "14\tValidation loss: 1.628127\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "15\tValidation loss: 1.613724\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "16\tValidation loss: 1.621641\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.612427\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.622173\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.611825\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.612151\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "21\tValidation loss: 1.657982\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.643388\tBest loss: 1.609585\tAccuracy: 19.27%\n",
      "23\tValidation loss: 1.647551\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.652206\tBest loss: 1.609585\tAccuracy: 18.73%\n",
      "25\tValidation loss: 1.610976\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "26\tValidation loss: 1.614099\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "27\tValidation loss: 1.614363\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "28\tValidation loss: 1.642987\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "29\tValidation loss: 1.614047\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "30\tValidation loss: 1.609289\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "31\tValidation loss: 1.634889\tBest loss: 1.609289\tAccuracy: 18.73%\n",
      "32\tValidation loss: 1.614009\tBest loss: 1.609289\tAccuracy: 19.08%\n",
      "33\tValidation loss: 1.619313\tBest loss: 1.609289\tAccuracy: 19.08%\n",
      "34\tValidation loss: 1.611677\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "35\tValidation loss: 1.638078\tBest loss: 1.609289\tAccuracy: 20.91%\n",
      "36\tValidation loss: 1.621398\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "37\tValidation loss: 1.617562\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "38\tValidation loss: 1.620767\tBest loss: 1.609289\tAccuracy: 20.91%\n",
      "39\tValidation loss: 1.627335\tBest loss: 1.609289\tAccuracy: 19.27%\n",
      "40\tValidation loss: 1.607883\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "41\tValidation loss: 1.634031\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "42\tValidation loss: 1.618327\tBest loss: 1.607883\tAccuracy: 20.91%\n",
      "43\tValidation loss: 1.618746\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "44\tValidation loss: 1.621665\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "45\tValidation loss: 1.629383\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "46\tValidation loss: 1.637658\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "47\tValidation loss: 1.609600\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "48\tValidation loss: 1.612162\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "49\tValidation loss: 1.643133\tBest loss: 1.607883\tAccuracy: 19.27%\n",
      "50\tValidation loss: 1.611987\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "51\tValidation loss: 1.619979\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "52\tValidation loss: 1.627026\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "53\tValidation loss: 1.618519\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "54\tValidation loss: 1.654812\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "55\tValidation loss: 1.645117\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "56\tValidation loss: 1.669471\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "57\tValidation loss: 1.619669\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "58\tValidation loss: 1.612549\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "59\tValidation loss: 1.619514\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "60\tValidation loss: 1.635963\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "61\tValidation loss: 1.627401\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8>, total= 6.9min\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 1.642225\tBest loss: 1.642225\tAccuracy: 19.27%\n",
      "1\tValidation loss: 1.624815\tBest loss: 1.624815\tAccuracy: 19.27%\n",
      "2\tValidation loss: 1.614195\tBest loss: 1.614195\tAccuracy: 19.27%\n",
      "3\tValidation loss: 1.616993\tBest loss: 1.614195\tAccuracy: 19.27%\n",
      "4\tValidation loss: 1.614502\tBest loss: 1.614195\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.627706\tBest loss: 1.614195\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.648677\tBest loss: 1.614195\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.627603\tBest loss: 1.614195\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.625684\tBest loss: 1.614195\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.615558\tBest loss: 1.614195\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.619129\tBest loss: 1.614195\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.639600\tBest loss: 1.614195\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.627613\tBest loss: 1.614195\tAccuracy: 19.08%\n",
      "13\tValidation loss: 1.615011\tBest loss: 1.614195\tAccuracy: 19.08%\n",
      "14\tValidation loss: 1.624331\tBest loss: 1.614195\tAccuracy: 19.08%\n",
      "15\tValidation loss: 1.612441\tBest loss: 1.612441\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.627839\tBest loss: 1.612441\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.613220\tBest loss: 1.612441\tAccuracy: 18.73%\n",
      "18\tValidation loss: 1.615752\tBest loss: 1.612441\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.619096\tBest loss: 1.612441\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.609111\tBest loss: 1.609111\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.689011\tBest loss: 1.609111\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.618893\tBest loss: 1.609111\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.638928\tBest loss: 1.609111\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.660613\tBest loss: 1.609111\tAccuracy: 20.91%\n",
      "25\tValidation loss: 1.619334\tBest loss: 1.609111\tAccuracy: 19.27%\n",
      "26\tValidation loss: 1.611323\tBest loss: 1.609111\tAccuracy: 22.01%\n",
      "27\tValidation loss: 1.614304\tBest loss: 1.609111\tAccuracy: 20.91%\n",
      "28\tValidation loss: 1.628118\tBest loss: 1.609111\tAccuracy: 19.08%\n",
      "29\tValidation loss: 1.610351\tBest loss: 1.609111\tAccuracy: 20.91%\n",
      "30\tValidation loss: 1.626932\tBest loss: 1.609111\tAccuracy: 20.91%\n",
      "31\tValidation loss: 1.633272\tBest loss: 1.609111\tAccuracy: 18.73%\n",
      "32\tValidation loss: 1.609066\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "33\tValidation loss: 1.610652\tBest loss: 1.609066\tAccuracy: 19.08%\n",
      "34\tValidation loss: 1.616979\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "35\tValidation loss: 1.627558\tBest loss: 1.609066\tAccuracy: 19.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\tValidation loss: 1.609165\tBest loss: 1.609066\tAccuracy: 20.91%\n",
      "37\tValidation loss: 1.626449\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "38\tValidation loss: 1.614496\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "39\tValidation loss: 1.617754\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "40\tValidation loss: 1.623131\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "41\tValidation loss: 1.615777\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "42\tValidation loss: 1.617475\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "43\tValidation loss: 1.617776\tBest loss: 1.609066\tAccuracy: 19.08%\n",
      "44\tValidation loss: 1.626853\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "45\tValidation loss: 1.613777\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "46\tValidation loss: 1.618688\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "47\tValidation loss: 1.610630\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "48\tValidation loss: 1.614395\tBest loss: 1.609066\tAccuracy: 18.73%\n",
      "49\tValidation loss: 1.612180\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "50\tValidation loss: 1.623879\tBest loss: 1.609066\tAccuracy: 19.27%\n",
      "51\tValidation loss: 1.616768\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "52\tValidation loss: 1.620598\tBest loss: 1.609066\tAccuracy: 18.73%\n",
      "53\tValidation loss: 1.617682\tBest loss: 1.609066\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8>, total= 4.3min\n",
      "[CV] n_neurons=120, n_hidden_layers=5, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 1.842638\tBest loss: 1.842638\tAccuracy: 19.27%\n",
      "1\tValidation loss: 1.629474\tBest loss: 1.629474\tAccuracy: 22.01%\n",
      "2\tValidation loss: 1.752402\tBest loss: 1.629474\tAccuracy: 18.73%\n",
      "3\tValidation loss: 1.632305\tBest loss: 1.629474\tAccuracy: 22.01%\n",
      "4\tValidation loss: 1.939066\tBest loss: 1.629474\tAccuracy: 19.27%\n",
      "5\tValidation loss: 2.026619\tBest loss: 1.629474\tAccuracy: 19.08%\n",
      "6\tValidation loss: 1.877789\tBest loss: 1.629474\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.808834\tBest loss: 1.629474\tAccuracy: 19.08%\n",
      "8\tValidation loss: 1.808720\tBest loss: 1.629474\tAccuracy: 20.91%\n",
      "9\tValidation loss: 1.735294\tBest loss: 1.629474\tAccuracy: 22.01%\n",
      "10\tValidation loss: 2.043398\tBest loss: 1.629474\tAccuracy: 19.08%\n",
      "11\tValidation loss: 1.787563\tBest loss: 1.629474\tAccuracy: 18.73%\n",
      "12\tValidation loss: 1.787478\tBest loss: 1.629474\tAccuracy: 18.73%\n",
      "13\tValidation loss: 2.026939\tBest loss: 1.629474\tAccuracy: 19.27%\n",
      "14\tValidation loss: 2.119593\tBest loss: 1.629474\tAccuracy: 18.73%\n",
      "15\tValidation loss: 2.111103\tBest loss: 1.629474\tAccuracy: 22.01%\n",
      "16\tValidation loss: 2.164248\tBest loss: 1.629474\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.756706\tBest loss: 1.629474\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.954802\tBest loss: 1.629474\tAccuracy: 19.08%\n",
      "19\tValidation loss: 2.223609\tBest loss: 1.629474\tAccuracy: 20.91%\n",
      "20\tValidation loss: 1.664297\tBest loss: 1.629474\tAccuracy: 18.73%\n",
      "21\tValidation loss: 1.741097\tBest loss: 1.629474\tAccuracy: 20.91%\n",
      "22\tValidation loss: 1.813512\tBest loss: 1.629474\tAccuracy: 20.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=5, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08>, total= 3.1min\n",
      "[CV] n_neurons=120, n_hidden_layers=5, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 1.629091\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "1\tValidation loss: 1.635360\tBest loss: 1.629091\tAccuracy: 19.27%\n",
      "2\tValidation loss: 1.793682\tBest loss: 1.629091\tAccuracy: 18.73%\n",
      "3\tValidation loss: 1.759707\tBest loss: 1.629091\tAccuracy: 19.27%\n",
      "4\tValidation loss: 1.921652\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "5\tValidation loss: 1.683079\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "6\tValidation loss: 1.915557\tBest loss: 1.629091\tAccuracy: 20.91%\n",
      "7\tValidation loss: 1.906128\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "8\tValidation loss: 1.819193\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "9\tValidation loss: 1.664906\tBest loss: 1.629091\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.863216\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "11\tValidation loss: 1.799126\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "12\tValidation loss: 1.914413\tBest loss: 1.629091\tAccuracy: 20.91%\n",
      "13\tValidation loss: 1.870670\tBest loss: 1.629091\tAccuracy: 22.01%\n",
      "14\tValidation loss: 1.705371\tBest loss: 1.629091\tAccuracy: 19.27%\n",
      "15\tValidation loss: 2.203127\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "16\tValidation loss: 1.818025\tBest loss: 1.629091\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.934456\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.886799\tBest loss: 1.629091\tAccuracy: 19.08%\n",
      "19\tValidation loss: 1.767183\tBest loss: 1.629091\tAccuracy: 20.91%\n",
      "20\tValidation loss: 1.952155\tBest loss: 1.629091\tAccuracy: 18.73%\n",
      "21\tValidation loss: 1.822314\tBest loss: 1.629091\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=5, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08>, total= 3.6min\n",
      "[CV] n_neurons=120, n_hidden_layers=5, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 1.677368\tBest loss: 1.677368\tAccuracy: 20.91%\n",
      "1\tValidation loss: 1.735613\tBest loss: 1.677368\tAccuracy: 19.08%\n",
      "2\tValidation loss: 1.967966\tBest loss: 1.677368\tAccuracy: 18.73%\n",
      "3\tValidation loss: 1.955316\tBest loss: 1.677368\tAccuracy: 22.01%\n",
      "4\tValidation loss: 2.721774\tBest loss: 1.677368\tAccuracy: 19.08%\n",
      "5\tValidation loss: 2.007839\tBest loss: 1.677368\tAccuracy: 19.27%\n",
      "6\tValidation loss: 1.699454\tBest loss: 1.677368\tAccuracy: 22.01%\n",
      "7\tValidation loss: 2.340198\tBest loss: 1.677368\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.804791\tBest loss: 1.677368\tAccuracy: 19.27%\n",
      "9\tValidation loss: 2.051867\tBest loss: 1.677368\tAccuracy: 19.27%\n",
      "10\tValidation loss: 2.095576\tBest loss: 1.677368\tAccuracy: 18.73%\n",
      "11\tValidation loss: 1.759784\tBest loss: 1.677368\tAccuracy: 19.27%\n",
      "12\tValidation loss: 2.036220\tBest loss: 1.677368\tAccuracy: 20.91%\n",
      "13\tValidation loss: 2.325144\tBest loss: 1.677368\tAccuracy: 19.08%\n",
      "14\tValidation loss: 1.806804\tBest loss: 1.677368\tAccuracy: 22.01%\n",
      "15\tValidation loss: 2.011077\tBest loss: 1.677368\tAccuracy: 20.91%\n",
      "16\tValidation loss: 2.077839\tBest loss: 1.677368\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.987821\tBest loss: 1.677368\tAccuracy: 20.91%\n",
      "18\tValidation loss: 2.003823\tBest loss: 1.677368\tAccuracy: 19.08%\n",
      "19\tValidation loss: 1.687011\tBest loss: 1.677368\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.776847\tBest loss: 1.677368\tAccuracy: 19.27%\n",
      "21\tValidation loss: 1.729060\tBest loss: 1.677368\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=5, learning_rate=0.02, batch_size=10, activation=<function elu at 0x11591cd08>, total= 3.7min\n",
      "[CV] n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.090541\tBest loss: 0.090541\tAccuracy: 97.26%\n",
      "1\tValidation loss: 0.097129\tBest loss: 0.090541\tAccuracy: 97.73%\n",
      "2\tValidation loss: 0.081756\tBest loss: 0.081756\tAccuracy: 98.20%\n",
      "3\tValidation loss: 8.120781\tBest loss: 0.081756\tAccuracy: 82.13%\n",
      "4\tValidation loss: 0.330175\tBest loss: 0.081756\tAccuracy: 97.73%\n",
      "5\tValidation loss: 0.383031\tBest loss: 0.081756\tAccuracy: 96.13%\n",
      "6\tValidation loss: 0.233774\tBest loss: 0.081756\tAccuracy: 96.91%\n",
      "7\tValidation loss: 0.196217\tBest loss: 0.081756\tAccuracy: 97.11%\n",
      "8\tValidation loss: 0.164796\tBest loss: 0.081756\tAccuracy: 98.05%\n",
      "9\tValidation loss: 0.154864\tBest loss: 0.081756\tAccuracy: 97.65%\n",
      "10\tValidation loss: 0.172256\tBest loss: 0.081756\tAccuracy: 97.81%\n",
      "11\tValidation loss: 0.137902\tBest loss: 0.081756\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.208470\tBest loss: 0.081756\tAccuracy: 97.62%\n",
      "13\tValidation loss: 0.177292\tBest loss: 0.081756\tAccuracy: 97.38%\n",
      "14\tValidation loss: 0.301687\tBest loss: 0.081756\tAccuracy: 97.73%\n",
      "15\tValidation loss: 0.371870\tBest loss: 0.081756\tAccuracy: 97.69%\n",
      "16\tValidation loss: 0.167693\tBest loss: 0.081756\tAccuracy: 98.16%\n",
      "17\tValidation loss: 0.226409\tBest loss: 0.081756\tAccuracy: 98.12%\n",
      "18\tValidation loss: 1.939425\tBest loss: 0.081756\tAccuracy: 94.61%\n",
      "19\tValidation loss: 8.684072\tBest loss: 0.081756\tAccuracy: 96.40%\n",
      "20\tValidation loss: 3.200727\tBest loss: 0.081756\tAccuracy: 97.50%\n",
      "21\tValidation loss: 3.157850\tBest loss: 0.081756\tAccuracy: 97.34%\n",
      "22\tValidation loss: 2.682683\tBest loss: 0.081756\tAccuracy: 97.69%\n",
      "23\tValidation loss: 2.723001\tBest loss: 0.081756\tAccuracy: 97.50%\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  57.0s\n",
      "[CV] n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.098780\tBest loss: 0.098780\tAccuracy: 97.26%\n",
      "1\tValidation loss: 0.081865\tBest loss: 0.081865\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.097573\tBest loss: 0.081865\tAccuracy: 98.32%\n",
      "3\tValidation loss: 17.634907\tBest loss: 0.081865\tAccuracy: 88.31%\n",
      "4\tValidation loss: 0.426507\tBest loss: 0.081865\tAccuracy: 96.95%\n",
      "5\tValidation loss: 0.230147\tBest loss: 0.081865\tAccuracy: 97.46%\n",
      "6\tValidation loss: 0.156465\tBest loss: 0.081865\tAccuracy: 97.62%\n",
      "7\tValidation loss: 0.155484\tBest loss: 0.081865\tAccuracy: 97.54%\n",
      "8\tValidation loss: 0.269267\tBest loss: 0.081865\tAccuracy: 95.43%\n",
      "9\tValidation loss: 0.158181\tBest loss: 0.081865\tAccuracy: 97.97%\n",
      "10\tValidation loss: 0.153919\tBest loss: 0.081865\tAccuracy: 97.62%\n",
      "11\tValidation loss: 0.107206\tBest loss: 0.081865\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.144366\tBest loss: 0.081865\tAccuracy: 97.97%\n",
      "13\tValidation loss: 0.134454\tBest loss: 0.081865\tAccuracy: 97.85%\n",
      "14\tValidation loss: 0.157127\tBest loss: 0.081865\tAccuracy: 97.69%\n",
      "15\tValidation loss: 0.139807\tBest loss: 0.081865\tAccuracy: 98.28%\n",
      "16\tValidation loss: 0.140986\tBest loss: 0.081865\tAccuracy: 98.16%\n",
      "17\tValidation loss: 0.180737\tBest loss: 0.081865\tAccuracy: 97.97%\n",
      "18\tValidation loss: 0.208740\tBest loss: 0.081865\tAccuracy: 96.52%\n",
      "19\tValidation loss: 81.585281\tBest loss: 0.081865\tAccuracy: 93.75%\n",
      "20\tValidation loss: 6.935806\tBest loss: 0.081865\tAccuracy: 96.56%\n",
      "21\tValidation loss: 4.387330\tBest loss: 0.081865\tAccuracy: 97.34%\n",
      "22\tValidation loss: 1.778743\tBest loss: 0.081865\tAccuracy: 97.19%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  56.4s\n",
      "[CV] n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.095856\tBest loss: 0.095856\tAccuracy: 97.89%\n",
      "1\tValidation loss: 0.081220\tBest loss: 0.081220\tAccuracy: 98.12%\n",
      "2\tValidation loss: 0.080329\tBest loss: 0.080329\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.071916\tBest loss: 0.071916\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.081591\tBest loss: 0.071916\tAccuracy: 97.97%\n",
      "5\tValidation loss: 70.383385\tBest loss: 0.071916\tAccuracy: 92.73%\n",
      "6\tValidation loss: 11.137596\tBest loss: 0.071916\tAccuracy: 97.15%\n",
      "7\tValidation loss: 4.360224\tBest loss: 0.071916\tAccuracy: 97.77%\n",
      "8\tValidation loss: 6.676235\tBest loss: 0.071916\tAccuracy: 96.56%\n",
      "9\tValidation loss: 2.533269\tBest loss: 0.071916\tAccuracy: 98.01%\n",
      "10\tValidation loss: 2.137318\tBest loss: 0.071916\tAccuracy: 97.73%\n",
      "11\tValidation loss: 2.168264\tBest loss: 0.071916\tAccuracy: 98.24%\n",
      "12\tValidation loss: 1.952018\tBest loss: 0.071916\tAccuracy: 98.20%\n",
      "13\tValidation loss: 1.925826\tBest loss: 0.071916\tAccuracy: 98.01%\n",
      "14\tValidation loss: 2.036454\tBest loss: 0.071916\tAccuracy: 98.16%\n",
      "15\tValidation loss: 2.147228\tBest loss: 0.071916\tAccuracy: 97.85%\n",
      "16\tValidation loss: 1.892310\tBest loss: 0.071916\tAccuracy: 98.28%\n",
      "17\tValidation loss: 1.723966\tBest loss: 0.071916\tAccuracy: 98.08%\n",
      "18\tValidation loss: 1.679471\tBest loss: 0.071916\tAccuracy: 98.44%\n",
      "19\tValidation loss: 1.473582\tBest loss: 0.071916\tAccuracy: 98.71%\n",
      "20\tValidation loss: 2.177151\tBest loss: 0.071916\tAccuracy: 97.46%\n",
      "21\tValidation loss: 1.946258\tBest loss: 0.071916\tAccuracy: 97.77%\n",
      "22\tValidation loss: 1.598609\tBest loss: 0.071916\tAccuracy: 98.36%\n",
      "23\tValidation loss: 2.408249\tBest loss: 0.071916\tAccuracy: 97.69%\n",
      "24\tValidation loss: 1.984408\tBest loss: 0.071916\tAccuracy: 98.44%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 1.0min\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.195935\tBest loss: 0.195935\tAccuracy: 95.70%\n",
      "1\tValidation loss: 0.146546\tBest loss: 0.146546\tAccuracy: 96.40%\n",
      "2\tValidation loss: 0.149569\tBest loss: 0.146546\tAccuracy: 97.38%\n",
      "3\tValidation loss: 0.101450\tBest loss: 0.101450\tAccuracy: 97.69%\n",
      "4\tValidation loss: 0.096369\tBest loss: 0.096369\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.112210\tBest loss: 0.096369\tAccuracy: 97.54%\n",
      "6\tValidation loss: 0.191014\tBest loss: 0.096369\tAccuracy: 97.07%\n",
      "7\tValidation loss: 0.203934\tBest loss: 0.096369\tAccuracy: 97.89%\n",
      "8\tValidation loss: 0.110976\tBest loss: 0.096369\tAccuracy: 98.24%\n",
      "9\tValidation loss: 0.334340\tBest loss: 0.096369\tAccuracy: 96.01%\n",
      "10\tValidation loss: 0.204176\tBest loss: 0.096369\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.195635\tBest loss: 0.096369\tAccuracy: 96.09%\n",
      "12\tValidation loss: 0.226887\tBest loss: 0.096369\tAccuracy: 98.20%\n",
      "13\tValidation loss: 0.147312\tBest loss: 0.096369\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.362964\tBest loss: 0.096369\tAccuracy: 97.19%\n",
      "15\tValidation loss: 0.326185\tBest loss: 0.096369\tAccuracy: 97.89%\n",
      "16\tValidation loss: 0.208378\tBest loss: 0.096369\tAccuracy: 96.68%\n",
      "17\tValidation loss: 0.485656\tBest loss: 0.096369\tAccuracy: 97.69%\n",
      "18\tValidation loss: 0.642399\tBest loss: 0.096369\tAccuracy: 97.77%\n",
      "19\tValidation loss: 0.311121\tBest loss: 0.096369\tAccuracy: 97.97%\n",
      "20\tValidation loss: 0.203424\tBest loss: 0.096369\tAccuracy: 98.12%\n",
      "21\tValidation loss: 0.876767\tBest loss: 0.096369\tAccuracy: 97.85%\n",
      "22\tValidation loss: 0.560447\tBest loss: 0.096369\tAccuracy: 97.93%\n",
      "23\tValidation loss: 0.307548\tBest loss: 0.096369\tAccuracy: 97.97%\n",
      "24\tValidation loss: 0.461085\tBest loss: 0.096369\tAccuracy: 97.58%\n",
      "25\tValidation loss: 0.256642\tBest loss: 0.096369\tAccuracy: 97.42%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8>, total= 2.2min\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.131451\tBest loss: 0.131451\tAccuracy: 96.72%\n",
      "1\tValidation loss: 0.120505\tBest loss: 0.120505\tAccuracy: 97.69%\n",
      "2\tValidation loss: 0.132209\tBest loss: 0.120505\tAccuracy: 97.03%\n",
      "3\tValidation loss: 0.297163\tBest loss: 0.120505\tAccuracy: 88.74%\n",
      "4\tValidation loss: 0.207208\tBest loss: 0.120505\tAccuracy: 95.58%\n",
      "5\tValidation loss: 0.229773\tBest loss: 0.120505\tAccuracy: 93.32%\n",
      "6\tValidation loss: 0.138758\tBest loss: 0.120505\tAccuracy: 96.95%\n",
      "7\tValidation loss: 0.108200\tBest loss: 0.108200\tAccuracy: 97.69%\n",
      "8\tValidation loss: 0.181001\tBest loss: 0.108200\tAccuracy: 97.11%\n",
      "9\tValidation loss: 0.226261\tBest loss: 0.108200\tAccuracy: 97.62%\n",
      "10\tValidation loss: 0.148331\tBest loss: 0.108200\tAccuracy: 97.89%\n",
      "11\tValidation loss: 0.199790\tBest loss: 0.108200\tAccuracy: 97.89%\n",
      "12\tValidation loss: 0.111899\tBest loss: 0.108200\tAccuracy: 98.16%\n",
      "13\tValidation loss: 0.152536\tBest loss: 0.108200\tAccuracy: 97.81%\n",
      "14\tValidation loss: 0.203412\tBest loss: 0.108200\tAccuracy: 98.08%\n",
      "15\tValidation loss: 0.273628\tBest loss: 0.108200\tAccuracy: 98.01%\n",
      "16\tValidation loss: 0.258768\tBest loss: 0.108200\tAccuracy: 97.22%\n",
      "17\tValidation loss: 0.176494\tBest loss: 0.108200\tAccuracy: 97.42%\n",
      "18\tValidation loss: 0.257005\tBest loss: 0.108200\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.246690\tBest loss: 0.108200\tAccuracy: 96.44%\n",
      "20\tValidation loss: 0.169028\tBest loss: 0.108200\tAccuracy: 96.01%\n",
      "21\tValidation loss: 0.141938\tBest loss: 0.108200\tAccuracy: 97.58%\n",
      "22\tValidation loss: 0.275754\tBest loss: 0.108200\tAccuracy: 95.66%\n",
      "23\tValidation loss: 0.687893\tBest loss: 0.108200\tAccuracy: 97.34%\n",
      "24\tValidation loss: 0.267646\tBest loss: 0.108200\tAccuracy: 98.12%\n",
      "25\tValidation loss: 0.083862\tBest loss: 0.083862\tAccuracy: 98.40%\n",
      "26\tValidation loss: 0.216180\tBest loss: 0.083862\tAccuracy: 98.08%\n",
      "27\tValidation loss: 0.686983\tBest loss: 0.083862\tAccuracy: 97.69%\n",
      "28\tValidation loss: 0.147539\tBest loss: 0.083862\tAccuracy: 98.36%\n",
      "29\tValidation loss: 0.183186\tBest loss: 0.083862\tAccuracy: 95.86%\n",
      "30\tValidation loss: 0.209288\tBest loss: 0.083862\tAccuracy: 98.12%\n",
      "31\tValidation loss: 0.799316\tBest loss: 0.083862\tAccuracy: 98.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\tValidation loss: 0.341011\tBest loss: 0.083862\tAccuracy: 97.73%\n",
      "33\tValidation loss: 0.393197\tBest loss: 0.083862\tAccuracy: 97.07%\n",
      "34\tValidation loss: 0.207288\tBest loss: 0.083862\tAccuracy: 97.19%\n",
      "35\tValidation loss: 0.303756\tBest loss: 0.083862\tAccuracy: 98.12%\n",
      "36\tValidation loss: 0.438636\tBest loss: 0.083862\tAccuracy: 98.48%\n",
      "37\tValidation loss: 0.483459\tBest loss: 0.083862\tAccuracy: 98.20%\n",
      "38\tValidation loss: 0.564102\tBest loss: 0.083862\tAccuracy: 98.12%\n",
      "39\tValidation loss: 0.237789\tBest loss: 0.083862\tAccuracy: 97.77%\n",
      "40\tValidation loss: 0.399648\tBest loss: 0.083862\tAccuracy: 98.12%\n",
      "41\tValidation loss: 0.501371\tBest loss: 0.083862\tAccuracy: 97.54%\n",
      "42\tValidation loss: 0.357431\tBest loss: 0.083862\tAccuracy: 96.76%\n",
      "43\tValidation loss: 0.313046\tBest loss: 0.083862\tAccuracy: 97.46%\n",
      "44\tValidation loss: 0.629774\tBest loss: 0.083862\tAccuracy: 98.55%\n",
      "45\tValidation loss: 0.233671\tBest loss: 0.083862\tAccuracy: 97.34%\n",
      "46\tValidation loss: 0.433719\tBest loss: 0.083862\tAccuracy: 98.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8>, total= 3.7min\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.095696\tBest loss: 0.095696\tAccuracy: 97.26%\n",
      "1\tValidation loss: 0.097564\tBest loss: 0.095696\tAccuracy: 97.03%\n",
      "2\tValidation loss: 0.094672\tBest loss: 0.094672\tAccuracy: 97.50%\n",
      "3\tValidation loss: 0.104557\tBest loss: 0.094672\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.173508\tBest loss: 0.094672\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.176573\tBest loss: 0.094672\tAccuracy: 96.33%\n",
      "6\tValidation loss: 0.116207\tBest loss: 0.094672\tAccuracy: 97.46%\n",
      "7\tValidation loss: 0.103128\tBest loss: 0.094672\tAccuracy: 97.89%\n",
      "8\tValidation loss: 0.130436\tBest loss: 0.094672\tAccuracy: 97.30%\n",
      "9\tValidation loss: 0.187473\tBest loss: 0.094672\tAccuracy: 97.58%\n",
      "10\tValidation loss: 0.237850\tBest loss: 0.094672\tAccuracy: 97.77%\n",
      "11\tValidation loss: 0.158905\tBest loss: 0.094672\tAccuracy: 98.16%\n",
      "12\tValidation loss: 0.152648\tBest loss: 0.094672\tAccuracy: 97.65%\n",
      "13\tValidation loss: 0.248881\tBest loss: 0.094672\tAccuracy: 97.89%\n",
      "14\tValidation loss: 0.206708\tBest loss: 0.094672\tAccuracy: 97.30%\n",
      "15\tValidation loss: 0.080260\tBest loss: 0.080260\tAccuracy: 98.36%\n",
      "16\tValidation loss: 0.154000\tBest loss: 0.080260\tAccuracy: 97.62%\n",
      "17\tValidation loss: 0.119175\tBest loss: 0.080260\tAccuracy: 97.62%\n",
      "18\tValidation loss: 0.125418\tBest loss: 0.080260\tAccuracy: 98.05%\n",
      "19\tValidation loss: 0.100105\tBest loss: 0.080260\tAccuracy: 98.16%\n",
      "20\tValidation loss: 0.487738\tBest loss: 0.080260\tAccuracy: 97.62%\n",
      "21\tValidation loss: 0.622334\tBest loss: 0.080260\tAccuracy: 96.83%\n",
      "22\tValidation loss: 0.191735\tBest loss: 0.080260\tAccuracy: 98.05%\n",
      "23\tValidation loss: 0.446481\tBest loss: 0.080260\tAccuracy: 97.81%\n",
      "24\tValidation loss: 0.487672\tBest loss: 0.080260\tAccuracy: 97.54%\n",
      "25\tValidation loss: 0.174875\tBest loss: 0.080260\tAccuracy: 97.97%\n",
      "26\tValidation loss: 0.153089\tBest loss: 0.080260\tAccuracy: 98.08%\n",
      "27\tValidation loss: 0.131494\tBest loss: 0.080260\tAccuracy: 97.89%\n",
      "28\tValidation loss: 0.294765\tBest loss: 0.080260\tAccuracy: 98.44%\n",
      "29\tValidation loss: 0.210587\tBest loss: 0.080260\tAccuracy: 98.16%\n",
      "30\tValidation loss: 0.231833\tBest loss: 0.080260\tAccuracy: 98.08%\n",
      "31\tValidation loss: 0.347523\tBest loss: 0.080260\tAccuracy: 97.50%\n",
      "32\tValidation loss: 0.284078\tBest loss: 0.080260\tAccuracy: 98.05%\n",
      "33\tValidation loss: 0.388389\tBest loss: 0.080260\tAccuracy: 98.24%\n",
      "34\tValidation loss: 0.240549\tBest loss: 0.080260\tAccuracy: 97.97%\n",
      "35\tValidation loss: 0.250172\tBest loss: 0.080260\tAccuracy: 98.28%\n",
      "36\tValidation loss: 0.242114\tBest loss: 0.080260\tAccuracy: 97.85%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, batch_size=10, activation=<function relu at 0x117f566a8>, total= 2.9min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=500, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.129634\tBest loss: 0.129634\tAccuracy: 95.86%\n",
      "1\tValidation loss: 0.104189\tBest loss: 0.104189\tAccuracy: 96.64%\n",
      "2\tValidation loss: 0.105799\tBest loss: 0.104189\tAccuracy: 96.99%\n",
      "3\tValidation loss: 0.092929\tBest loss: 0.092929\tAccuracy: 97.11%\n",
      "4\tValidation loss: 0.080605\tBest loss: 0.080605\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.096063\tBest loss: 0.080605\tAccuracy: 97.15%\n",
      "6\tValidation loss: 0.094771\tBest loss: 0.080605\tAccuracy: 97.77%\n",
      "7\tValidation loss: 0.102469\tBest loss: 0.080605\tAccuracy: 97.38%\n",
      "8\tValidation loss: 0.083479\tBest loss: 0.080605\tAccuracy: 97.54%\n",
      "9\tValidation loss: 0.081137\tBest loss: 0.080605\tAccuracy: 97.54%\n",
      "10\tValidation loss: 0.105392\tBest loss: 0.080605\tAccuracy: 97.77%\n",
      "11\tValidation loss: 0.090207\tBest loss: 0.080605\tAccuracy: 97.73%\n",
      "12\tValidation loss: 0.084140\tBest loss: 0.080605\tAccuracy: 98.16%\n",
      "13\tValidation loss: 0.092068\tBest loss: 0.080605\tAccuracy: 98.08%\n",
      "14\tValidation loss: 0.102483\tBest loss: 0.080605\tAccuracy: 97.89%\n",
      "15\tValidation loss: 0.093191\tBest loss: 0.080605\tAccuracy: 97.73%\n",
      "16\tValidation loss: 0.107741\tBest loss: 0.080605\tAccuracy: 97.81%\n",
      "17\tValidation loss: 0.117051\tBest loss: 0.080605\tAccuracy: 98.05%\n",
      "18\tValidation loss: 0.112847\tBest loss: 0.080605\tAccuracy: 97.93%\n",
      "19\tValidation loss: 0.093412\tBest loss: 0.080605\tAccuracy: 97.93%\n",
      "20\tValidation loss: 0.124244\tBest loss: 0.080605\tAccuracy: 97.73%\n",
      "21\tValidation loss: 0.126024\tBest loss: 0.080605\tAccuracy: 97.81%\n",
      "22\tValidation loss: 0.123332\tBest loss: 0.080605\tAccuracy: 97.73%\n",
      "23\tValidation loss: 0.157359\tBest loss: 0.080605\tAccuracy: 97.54%\n",
      "24\tValidation loss: 0.120107\tBest loss: 0.080605\tAccuracy: 97.54%\n",
      "25\tValidation loss: 0.137945\tBest loss: 0.080605\tAccuracy: 97.69%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=500, activation=<function relu at 0x117f566a8>, total=   9.8s\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=500, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.176501\tBest loss: 0.176501\tAccuracy: 94.96%\n",
      "1\tValidation loss: 0.107525\tBest loss: 0.107525\tAccuracy: 96.68%\n",
      "2\tValidation loss: 0.104191\tBest loss: 0.104191\tAccuracy: 96.91%\n",
      "3\tValidation loss: 0.098992\tBest loss: 0.098992\tAccuracy: 97.34%\n",
      "4\tValidation loss: 0.095592\tBest loss: 0.095592\tAccuracy: 96.79%\n",
      "5\tValidation loss: 0.091897\tBest loss: 0.091897\tAccuracy: 97.34%\n",
      "6\tValidation loss: 0.092397\tBest loss: 0.091897\tAccuracy: 97.30%\n",
      "7\tValidation loss: 0.087813\tBest loss: 0.087813\tAccuracy: 97.19%\n",
      "8\tValidation loss: 0.096526\tBest loss: 0.087813\tAccuracy: 97.19%\n",
      "9\tValidation loss: 0.084770\tBest loss: 0.084770\tAccuracy: 97.15%\n",
      "10\tValidation loss: 0.116815\tBest loss: 0.084770\tAccuracy: 96.52%\n",
      "11\tValidation loss: 0.108338\tBest loss: 0.084770\tAccuracy: 97.38%\n",
      "12\tValidation loss: 0.095869\tBest loss: 0.084770\tAccuracy: 96.99%\n",
      "13\tValidation loss: 0.100601\tBest loss: 0.084770\tAccuracy: 97.22%\n",
      "14\tValidation loss: 0.085178\tBest loss: 0.084770\tAccuracy: 97.69%\n",
      "15\tValidation loss: 0.083681\tBest loss: 0.083681\tAccuracy: 97.46%\n",
      "16\tValidation loss: 0.095444\tBest loss: 0.083681\tAccuracy: 97.38%\n",
      "17\tValidation loss: 0.110116\tBest loss: 0.083681\tAccuracy: 97.54%\n",
      "18\tValidation loss: 0.109822\tBest loss: 0.083681\tAccuracy: 97.85%\n",
      "19\tValidation loss: 0.104633\tBest loss: 0.083681\tAccuracy: 97.62%\n",
      "20\tValidation loss: 0.104651\tBest loss: 0.083681\tAccuracy: 97.58%\n",
      "21\tValidation loss: 0.093110\tBest loss: 0.083681\tAccuracy: 97.46%\n",
      "22\tValidation loss: 0.093136\tBest loss: 0.083681\tAccuracy: 97.73%\n",
      "23\tValidation loss: 0.118540\tBest loss: 0.083681\tAccuracy: 97.38%\n",
      "24\tValidation loss: 0.112223\tBest loss: 0.083681\tAccuracy: 97.62%\n",
      "25\tValidation loss: 0.117503\tBest loss: 0.083681\tAccuracy: 97.58%\n",
      "26\tValidation loss: 0.113277\tBest loss: 0.083681\tAccuracy: 97.26%\n",
      "27\tValidation loss: 0.115358\tBest loss: 0.083681\tAccuracy: 97.15%\n",
      "28\tValidation loss: 0.100300\tBest loss: 0.083681\tAccuracy: 97.46%\n",
      "29\tValidation loss: 0.109383\tBest loss: 0.083681\tAccuracy: 97.42%\n",
      "30\tValidation loss: 0.120684\tBest loss: 0.083681\tAccuracy: 97.42%\n",
      "31\tValidation loss: 0.116767\tBest loss: 0.083681\tAccuracy: 97.65%\n",
      "32\tValidation loss: 0.111976\tBest loss: 0.083681\tAccuracy: 97.85%\n",
      "33\tValidation loss: 0.117906\tBest loss: 0.083681\tAccuracy: 97.93%\n",
      "34\tValidation loss: 0.098518\tBest loss: 0.083681\tAccuracy: 98.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\tValidation loss: 0.116521\tBest loss: 0.083681\tAccuracy: 97.42%\n",
      "36\tValidation loss: 0.115597\tBest loss: 0.083681\tAccuracy: 97.69%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=500, activation=<function relu at 0x117f566a8>, total=  14.3s\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=500, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.146588\tBest loss: 0.146588\tAccuracy: 95.74%\n",
      "1\tValidation loss: 0.114416\tBest loss: 0.114416\tAccuracy: 96.64%\n",
      "2\tValidation loss: 0.100971\tBest loss: 0.100971\tAccuracy: 96.87%\n",
      "3\tValidation loss: 0.092147\tBest loss: 0.092147\tAccuracy: 97.34%\n",
      "4\tValidation loss: 0.087230\tBest loss: 0.087230\tAccuracy: 97.54%\n",
      "5\tValidation loss: 0.094787\tBest loss: 0.087230\tAccuracy: 96.99%\n",
      "6\tValidation loss: 0.094449\tBest loss: 0.087230\tAccuracy: 97.46%\n",
      "7\tValidation loss: 0.102550\tBest loss: 0.087230\tAccuracy: 97.15%\n",
      "8\tValidation loss: 0.093523\tBest loss: 0.087230\tAccuracy: 97.46%\n",
      "9\tValidation loss: 0.089347\tBest loss: 0.087230\tAccuracy: 97.50%\n",
      "10\tValidation loss: 0.092073\tBest loss: 0.087230\tAccuracy: 97.19%\n",
      "11\tValidation loss: 0.082613\tBest loss: 0.082613\tAccuracy: 98.05%\n",
      "12\tValidation loss: 0.093263\tBest loss: 0.082613\tAccuracy: 97.58%\n",
      "13\tValidation loss: 0.101457\tBest loss: 0.082613\tAccuracy: 97.19%\n",
      "14\tValidation loss: 0.094235\tBest loss: 0.082613\tAccuracy: 97.54%\n",
      "15\tValidation loss: 0.092707\tBest loss: 0.082613\tAccuracy: 97.62%\n",
      "16\tValidation loss: 0.100127\tBest loss: 0.082613\tAccuracy: 97.54%\n",
      "17\tValidation loss: 0.094830\tBest loss: 0.082613\tAccuracy: 97.89%\n",
      "18\tValidation loss: 0.104065\tBest loss: 0.082613\tAccuracy: 97.46%\n",
      "19\tValidation loss: 0.101202\tBest loss: 0.082613\tAccuracy: 97.26%\n",
      "20\tValidation loss: 0.100132\tBest loss: 0.082613\tAccuracy: 97.85%\n",
      "21\tValidation loss: 0.106471\tBest loss: 0.082613\tAccuracy: 97.65%\n",
      "22\tValidation loss: 0.096585\tBest loss: 0.082613\tAccuracy: 97.54%\n",
      "23\tValidation loss: 0.090624\tBest loss: 0.082613\tAccuracy: 97.58%\n",
      "24\tValidation loss: 0.093375\tBest loss: 0.082613\tAccuracy: 97.62%\n",
      "25\tValidation loss: 0.096345\tBest loss: 0.082613\tAccuracy: 97.42%\n",
      "26\tValidation loss: 0.099443\tBest loss: 0.082613\tAccuracy: 97.58%\n",
      "27\tValidation loss: 0.117378\tBest loss: 0.082613\tAccuracy: 97.07%\n",
      "28\tValidation loss: 0.099706\tBest loss: 0.082613\tAccuracy: 97.77%\n",
      "29\tValidation loss: 0.120791\tBest loss: 0.082613\tAccuracy: 97.54%\n",
      "30\tValidation loss: 0.100425\tBest loss: 0.082613\tAccuracy: 97.30%\n",
      "31\tValidation loss: 0.108817\tBest loss: 0.082613\tAccuracy: 97.30%\n",
      "32\tValidation loss: 0.115543\tBest loss: 0.082613\tAccuracy: 97.65%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=500, activation=<function relu at 0x117f566a8>, total=  14.1s\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 1.017622\tBest loss: 1.017622\tAccuracy: 93.71%\n",
      "1\tValidation loss: 2.620664\tBest loss: 1.017622\tAccuracy: 94.57%\n",
      "2\tValidation loss: 6.974045\tBest loss: 1.017622\tAccuracy: 95.19%\n",
      "3\tValidation loss: 6.436133\tBest loss: 1.017622\tAccuracy: 93.75%\n",
      "4\tValidation loss: 6.893331\tBest loss: 1.017622\tAccuracy: 96.01%\n",
      "5\tValidation loss: 5.147964\tBest loss: 1.017622\tAccuracy: 95.90%\n",
      "6\tValidation loss: 12.185301\tBest loss: 1.017622\tAccuracy: 96.40%\n",
      "7\tValidation loss: 21.889059\tBest loss: 1.017622\tAccuracy: 97.03%\n",
      "8\tValidation loss: 7.253792\tBest loss: 1.017622\tAccuracy: 95.74%\n",
      "9\tValidation loss: 13.210875\tBest loss: 1.017622\tAccuracy: 96.36%\n",
      "10\tValidation loss: 14.608676\tBest loss: 1.017622\tAccuracy: 96.68%\n",
      "11\tValidation loss: 13.051893\tBest loss: 1.017622\tAccuracy: 95.97%\n",
      "12\tValidation loss: 11.934371\tBest loss: 1.017622\tAccuracy: 96.76%\n",
      "13\tValidation loss: 12.165814\tBest loss: 1.017622\tAccuracy: 96.99%\n",
      "14\tValidation loss: 14.661254\tBest loss: 1.017622\tAccuracy: 96.64%\n",
      "15\tValidation loss: 45.002949\tBest loss: 1.017622\tAccuracy: 96.05%\n",
      "16\tValidation loss: 17.327803\tBest loss: 1.017622\tAccuracy: 96.09%\n",
      "17\tValidation loss: 16.851612\tBest loss: 1.017622\tAccuracy: 96.99%\n",
      "18\tValidation loss: 15.795158\tBest loss: 1.017622\tAccuracy: 97.50%\n",
      "19\tValidation loss: 21.361074\tBest loss: 1.017622\tAccuracy: 97.11%\n",
      "20\tValidation loss: 35.461403\tBest loss: 1.017622\tAccuracy: 96.95%\n",
      "21\tValidation loss: 41.159622\tBest loss: 1.017622\tAccuracy: 97.50%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.3min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 5.252276\tBest loss: 5.252276\tAccuracy: 90.30%\n",
      "1\tValidation loss: 8.727468\tBest loss: 5.252276\tAccuracy: 94.57%\n",
      "2\tValidation loss: 1.972043\tBest loss: 1.972043\tAccuracy: 95.43%\n",
      "3\tValidation loss: 2.739010\tBest loss: 1.972043\tAccuracy: 93.55%\n",
      "4\tValidation loss: 7.375019\tBest loss: 1.972043\tAccuracy: 96.01%\n",
      "5\tValidation loss: 3.531422\tBest loss: 1.972043\tAccuracy: 95.43%\n",
      "6\tValidation loss: 5.106793\tBest loss: 1.972043\tAccuracy: 94.80%\n",
      "7\tValidation loss: 5.715584\tBest loss: 1.972043\tAccuracy: 96.13%\n",
      "8\tValidation loss: 8.478835\tBest loss: 1.972043\tAccuracy: 95.54%\n",
      "9\tValidation loss: 11.234115\tBest loss: 1.972043\tAccuracy: 93.55%\n",
      "10\tValidation loss: 16.146883\tBest loss: 1.972043\tAccuracy: 96.48%\n",
      "11\tValidation loss: 11.130293\tBest loss: 1.972043\tAccuracy: 96.64%\n",
      "12\tValidation loss: 14.256248\tBest loss: 1.972043\tAccuracy: 96.40%\n",
      "13\tValidation loss: 52.340740\tBest loss: 1.972043\tAccuracy: 94.53%\n",
      "14\tValidation loss: 44.304504\tBest loss: 1.972043\tAccuracy: 96.21%\n",
      "15\tValidation loss: 35.186493\tBest loss: 1.972043\tAccuracy: 95.97%\n",
      "16\tValidation loss: 46.910271\tBest loss: 1.972043\tAccuracy: 91.52%\n",
      "17\tValidation loss: 21.364069\tBest loss: 1.972043\tAccuracy: 95.82%\n",
      "18\tValidation loss: 16.753551\tBest loss: 1.972043\tAccuracy: 96.83%\n",
      "19\tValidation loss: 18.577251\tBest loss: 1.972043\tAccuracy: 95.62%\n",
      "20\tValidation loss: 40.304668\tBest loss: 1.972043\tAccuracy: 96.44%\n",
      "21\tValidation loss: 31.869534\tBest loss: 1.972043\tAccuracy: 96.44%\n",
      "22\tValidation loss: 35.320259\tBest loss: 1.972043\tAccuracy: 96.21%\n",
      "23\tValidation loss: 49.999054\tBest loss: 1.972043\tAccuracy: 95.90%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.6min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 1.542837\tBest loss: 1.542837\tAccuracy: 93.32%\n",
      "1\tValidation loss: 2.119156\tBest loss: 1.542837\tAccuracy: 95.31%\n",
      "2\tValidation loss: 8.546778\tBest loss: 1.542837\tAccuracy: 93.86%\n",
      "3\tValidation loss: 3.218143\tBest loss: 1.542837\tAccuracy: 95.31%\n",
      "4\tValidation loss: 8.902883\tBest loss: 1.542837\tAccuracy: 94.84%\n",
      "5\tValidation loss: 6.357061\tBest loss: 1.542837\tAccuracy: 95.90%\n",
      "6\tValidation loss: 17.750319\tBest loss: 1.542837\tAccuracy: 92.14%\n",
      "7\tValidation loss: 7.671145\tBest loss: 1.542837\tAccuracy: 96.29%\n",
      "8\tValidation loss: 42.468960\tBest loss: 1.542837\tAccuracy: 92.42%\n",
      "9\tValidation loss: 12.883394\tBest loss: 1.542837\tAccuracy: 96.48%\n",
      "10\tValidation loss: 12.682743\tBest loss: 1.542837\tAccuracy: 96.21%\n",
      "11\tValidation loss: 17.856636\tBest loss: 1.542837\tAccuracy: 97.07%\n",
      "12\tValidation loss: 14.069089\tBest loss: 1.542837\tAccuracy: 97.03%\n",
      "13\tValidation loss: 18.025455\tBest loss: 1.542837\tAccuracy: 94.57%\n",
      "14\tValidation loss: 36.457199\tBest loss: 1.542837\tAccuracy: 96.48%\n",
      "15\tValidation loss: 139.493942\tBest loss: 1.542837\tAccuracy: 97.22%\n",
      "16\tValidation loss: 41.830532\tBest loss: 1.542837\tAccuracy: 96.29%\n",
      "17\tValidation loss: 92.589752\tBest loss: 1.542837\tAccuracy: 97.26%\n",
      "18\tValidation loss: 49.678177\tBest loss: 1.542837\tAccuracy: 97.38%\n",
      "19\tValidation loss: 35.380035\tBest loss: 1.542837\tAccuracy: 96.01%\n",
      "20\tValidation loss: 54.574165\tBest loss: 1.542837\tAccuracy: 97.62%\n",
      "21\tValidation loss: 82.248329\tBest loss: 1.542837\tAccuracy: 96.40%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.5min\n",
      "[CV] n_neurons=30, n_hidden_layers=3, learning_rate=0.02, batch_size=50, activation=<function relu at 0x117f566a8> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.108517\tBest loss: 0.108517\tAccuracy: 96.56%\n",
      "1\tValidation loss: 0.075926\tBest loss: 0.075926\tAccuracy: 97.81%\n",
      "2\tValidation loss: 0.081819\tBest loss: 0.075926\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.132833\tBest loss: 0.075926\tAccuracy: 97.15%\n",
      "4\tValidation loss: 0.076688\tBest loss: 0.075926\tAccuracy: 98.01%\n",
      "5\tValidation loss: 0.087899\tBest loss: 0.075926\tAccuracy: 97.97%\n",
      "6\tValidation loss: 0.092248\tBest loss: 0.075926\tAccuracy: 97.50%\n",
      "7\tValidation loss: 0.161413\tBest loss: 0.075926\tAccuracy: 95.70%\n",
      "8\tValidation loss: 0.130514\tBest loss: 0.075926\tAccuracy: 98.16%\n",
      "9\tValidation loss: 0.091831\tBest loss: 0.075926\tAccuracy: 98.01%\n",
      "10\tValidation loss: 0.089991\tBest loss: 0.075926\tAccuracy: 98.01%\n",
      "11\tValidation loss: 0.091557\tBest loss: 0.075926\tAccuracy: 98.01%\n",
      "12\tValidation loss: 0.101924\tBest loss: 0.075926\tAccuracy: 97.69%\n",
      "13\tValidation loss: 0.108203\tBest loss: 0.075926\tAccuracy: 97.50%\n",
      "14\tValidation loss: 0.100804\tBest loss: 0.075926\tAccuracy: 98.12%\n",
      "15\tValidation loss: 0.100767\tBest loss: 0.075926\tAccuracy: 98.16%\n",
      "16\tValidation loss: 0.096154\tBest loss: 0.075926\tAccuracy: 97.85%\n",
      "17\tValidation loss: 0.097143\tBest loss: 0.075926\tAccuracy: 98.08%\n",
      "18\tValidation loss: 0.105604\tBest loss: 0.075926\tAccuracy: 98.08%\n",
      "19\tValidation loss: 0.089704\tBest loss: 0.075926\tAccuracy: 98.08%\n",
      "20\tValidation loss: 0.100029\tBest loss: 0.075926\tAccuracy: 98.20%\n",
      "21\tValidation loss: 0.106772\tBest loss: 0.075926\tAccuracy: 98.32%\n",
      "22\tValidation loss: 0.113528\tBest loss: 0.075926\tAccuracy: 98.40%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=3, learning_rate=0.02, batch_size=50, activation=<function relu at 0x117f566a8>, total=  21.5s\n",
      "[CV] n_neurons=30, n_hidden_layers=3, learning_rate=0.02, batch_size=50, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.109511\tBest loss: 0.109511\tAccuracy: 97.19%\n",
      "1\tValidation loss: 0.085053\tBest loss: 0.085053\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.087587\tBest loss: 0.085053\tAccuracy: 97.46%\n",
      "3\tValidation loss: 0.093281\tBest loss: 0.085053\tAccuracy: 97.38%\n",
      "4\tValidation loss: 0.106094\tBest loss: 0.085053\tAccuracy: 96.76%\n",
      "5\tValidation loss: 0.131710\tBest loss: 0.085053\tAccuracy: 97.30%\n",
      "6\tValidation loss: 0.087573\tBest loss: 0.085053\tAccuracy: 97.50%\n",
      "7\tValidation loss: 0.080211\tBest loss: 0.080211\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.124222\tBest loss: 0.080211\tAccuracy: 97.65%\n",
      "9\tValidation loss: 0.131580\tBest loss: 0.080211\tAccuracy: 97.65%\n",
      "10\tValidation loss: 0.141116\tBest loss: 0.080211\tAccuracy: 97.15%\n",
      "11\tValidation loss: 0.173023\tBest loss: 0.080211\tAccuracy: 97.97%\n",
      "12\tValidation loss: 0.092818\tBest loss: 0.080211\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.131002\tBest loss: 0.080211\tAccuracy: 96.21%\n",
      "14\tValidation loss: 0.103248\tBest loss: 0.080211\tAccuracy: 98.08%\n",
      "15\tValidation loss: 0.073059\tBest loss: 0.073059\tAccuracy: 97.89%\n",
      "16\tValidation loss: 0.111896\tBest loss: 0.073059\tAccuracy: 98.08%\n",
      "17\tValidation loss: 0.094757\tBest loss: 0.073059\tAccuracy: 97.73%\n",
      "18\tValidation loss: 0.107817\tBest loss: 0.073059\tAccuracy: 97.73%\n",
      "19\tValidation loss: 0.082575\tBest loss: 0.073059\tAccuracy: 98.01%\n",
      "20\tValidation loss: 0.104023\tBest loss: 0.073059\tAccuracy: 98.05%\n",
      "21\tValidation loss: 0.124933\tBest loss: 0.073059\tAccuracy: 98.20%\n",
      "22\tValidation loss: 0.166776\tBest loss: 0.073059\tAccuracy: 98.24%\n",
      "23\tValidation loss: 0.090568\tBest loss: 0.073059\tAccuracy: 97.77%\n",
      "24\tValidation loss: 0.106706\tBest loss: 0.073059\tAccuracy: 98.28%\n",
      "25\tValidation loss: 0.189752\tBest loss: 0.073059\tAccuracy: 97.54%\n",
      "26\tValidation loss: 0.142434\tBest loss: 0.073059\tAccuracy: 98.28%\n",
      "27\tValidation loss: 0.110736\tBest loss: 0.073059\tAccuracy: 97.50%\n",
      "28\tValidation loss: 0.185126\tBest loss: 0.073059\tAccuracy: 97.50%\n",
      "29\tValidation loss: 0.220437\tBest loss: 0.073059\tAccuracy: 97.77%\n",
      "30\tValidation loss: 0.115172\tBest loss: 0.073059\tAccuracy: 98.12%\n",
      "31\tValidation loss: 0.075615\tBest loss: 0.073059\tAccuracy: 98.12%\n",
      "32\tValidation loss: 0.112494\tBest loss: 0.073059\tAccuracy: 97.77%\n",
      "33\tValidation loss: 0.116771\tBest loss: 0.073059\tAccuracy: 97.89%\n",
      "34\tValidation loss: 0.153326\tBest loss: 0.073059\tAccuracy: 96.40%\n",
      "35\tValidation loss: 0.144887\tBest loss: 0.073059\tAccuracy: 97.97%\n",
      "36\tValidation loss: 0.125693\tBest loss: 0.073059\tAccuracy: 97.85%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=3, learning_rate=0.02, batch_size=50, activation=<function relu at 0x117f566a8>, total=  31.1s\n",
      "[CV] n_neurons=30, n_hidden_layers=3, learning_rate=0.02, batch_size=50, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.086599\tBest loss: 0.086599\tAccuracy: 97.69%\n",
      "1\tValidation loss: 0.093580\tBest loss: 0.086599\tAccuracy: 97.65%\n",
      "2\tValidation loss: 0.120617\tBest loss: 0.086599\tAccuracy: 96.76%\n",
      "3\tValidation loss: 0.107766\tBest loss: 0.086599\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.090294\tBest loss: 0.086599\tAccuracy: 97.89%\n",
      "5\tValidation loss: 0.099787\tBest loss: 0.086599\tAccuracy: 98.05%\n",
      "6\tValidation loss: 0.101744\tBest loss: 0.086599\tAccuracy: 97.97%\n",
      "7\tValidation loss: 0.104643\tBest loss: 0.086599\tAccuracy: 97.34%\n",
      "8\tValidation loss: 0.103582\tBest loss: 0.086599\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.096830\tBest loss: 0.086599\tAccuracy: 98.20%\n",
      "10\tValidation loss: 0.093828\tBest loss: 0.086599\tAccuracy: 98.12%\n",
      "11\tValidation loss: 0.130470\tBest loss: 0.086599\tAccuracy: 97.69%\n",
      "12\tValidation loss: 0.062687\tBest loss: 0.062687\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.104614\tBest loss: 0.062687\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.117554\tBest loss: 0.062687\tAccuracy: 98.48%\n",
      "15\tValidation loss: 0.125365\tBest loss: 0.062687\tAccuracy: 97.65%\n",
      "16\tValidation loss: 0.155959\tBest loss: 0.062687\tAccuracy: 97.26%\n",
      "17\tValidation loss: 0.138930\tBest loss: 0.062687\tAccuracy: 97.69%\n",
      "18\tValidation loss: 0.124603\tBest loss: 0.062687\tAccuracy: 97.15%\n",
      "19\tValidation loss: 0.094339\tBest loss: 0.062687\tAccuracy: 98.24%\n",
      "20\tValidation loss: 0.092617\tBest loss: 0.062687\tAccuracy: 98.36%\n",
      "21\tValidation loss: 0.093278\tBest loss: 0.062687\tAccuracy: 98.24%\n",
      "22\tValidation loss: 0.107235\tBest loss: 0.062687\tAccuracy: 98.20%\n",
      "23\tValidation loss: 0.155851\tBest loss: 0.062687\tAccuracy: 97.89%\n",
      "24\tValidation loss: 0.099788\tBest loss: 0.062687\tAccuracy: 98.05%\n",
      "25\tValidation loss: 0.082434\tBest loss: 0.062687\tAccuracy: 98.55%\n",
      "26\tValidation loss: 0.109992\tBest loss: 0.062687\tAccuracy: 97.81%\n",
      "27\tValidation loss: 0.103589\tBest loss: 0.062687\tAccuracy: 98.08%\n",
      "28\tValidation loss: 0.094197\tBest loss: 0.062687\tAccuracy: 98.24%\n",
      "29\tValidation loss: 0.118869\tBest loss: 0.062687\tAccuracy: 98.08%\n",
      "30\tValidation loss: 0.111189\tBest loss: 0.062687\tAccuracy: 98.32%\n",
      "31\tValidation loss: 0.189179\tBest loss: 0.062687\tAccuracy: 98.05%\n",
      "32\tValidation loss: 0.123977\tBest loss: 0.062687\tAccuracy: 97.77%\n",
      "33\tValidation loss: 0.129427\tBest loss: 0.062687\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, n_hidden_layers=3, learning_rate=0.02, batch_size=50, activation=<function relu at 0x117f566a8>, total=  28.9s\n",
      "[CV] n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.920480\tBest loss: 0.920480\tAccuracy: 52.58%\n",
      "1\tValidation loss: 1.221328\tBest loss: 0.920480\tAccuracy: 36.24%\n",
      "2\tValidation loss: 1.075658\tBest loss: 0.920480\tAccuracy: 36.90%\n",
      "3\tValidation loss: 1.185681\tBest loss: 0.920480\tAccuracy: 33.82%\n",
      "4\tValidation loss: 1.155157\tBest loss: 0.920480\tAccuracy: 39.48%\n",
      "5\tValidation loss: 1.139235\tBest loss: 0.920480\tAccuracy: 38.31%\n",
      "6\tValidation loss: 1.165815\tBest loss: 0.920480\tAccuracy: 34.60%\n",
      "7\tValidation loss: 1.081444\tBest loss: 0.920480\tAccuracy: 36.75%\n",
      "8\tValidation loss: 1.144574\tBest loss: 0.920480\tAccuracy: 36.86%\n",
      "9\tValidation loss: 1.213381\tBest loss: 0.920480\tAccuracy: 38.86%\n",
      "10\tValidation loss: 1.156394\tBest loss: 0.920480\tAccuracy: 40.93%\n",
      "11\tValidation loss: 1.172951\tBest loss: 0.920480\tAccuracy: 34.71%\n",
      "12\tValidation loss: 1.232025\tBest loss: 0.920480\tAccuracy: 34.79%\n",
      "13\tValidation loss: 1.126404\tBest loss: 0.920480\tAccuracy: 38.66%\n",
      "14\tValidation loss: 1.174476\tBest loss: 0.920480\tAccuracy: 40.50%\n",
      "15\tValidation loss: 1.123658\tBest loss: 0.920480\tAccuracy: 40.50%\n",
      "16\tValidation loss: 1.173663\tBest loss: 0.920480\tAccuracy: 40.38%\n",
      "17\tValidation loss: 1.154646\tBest loss: 0.920480\tAccuracy: 42.57%\n",
      "18\tValidation loss: 1.178797\tBest loss: 0.920480\tAccuracy: 42.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\tValidation loss: 1.213799\tBest loss: 0.920480\tAccuracy: 42.10%\n",
      "20\tValidation loss: 1.302080\tBest loss: 0.920480\tAccuracy: 38.31%\n",
      "21\tValidation loss: 1.236419\tBest loss: 0.920480\tAccuracy: 39.21%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8>, total= 1.4min\n",
      "[CV] n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 1.631829\tBest loss: 1.631829\tAccuracy: 22.01%\n",
      "1\tValidation loss: 1.644821\tBest loss: 1.631829\tAccuracy: 19.08%\n",
      "2\tValidation loss: 1.611660\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "3\tValidation loss: 1.614179\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "4\tValidation loss: 1.617810\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.624092\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.635104\tBest loss: 1.611660\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.630919\tBest loss: 1.611660\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.639868\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.611889\tBest loss: 1.611660\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.613289\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.614457\tBest loss: 1.611660\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.615519\tBest loss: 1.611660\tAccuracy: 20.91%\n",
      "13\tValidation loss: 1.609585\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "14\tValidation loss: 1.628127\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "15\tValidation loss: 1.613724\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "16\tValidation loss: 1.621641\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.612427\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.622173\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.611825\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.612151\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "21\tValidation loss: 1.657982\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.643388\tBest loss: 1.609585\tAccuracy: 19.27%\n",
      "23\tValidation loss: 1.647551\tBest loss: 1.609585\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.652206\tBest loss: 1.609585\tAccuracy: 18.73%\n",
      "25\tValidation loss: 1.610976\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "26\tValidation loss: 1.614099\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "27\tValidation loss: 1.614363\tBest loss: 1.609585\tAccuracy: 20.91%\n",
      "28\tValidation loss: 1.642987\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "29\tValidation loss: 1.614047\tBest loss: 1.609585\tAccuracy: 19.08%\n",
      "30\tValidation loss: 1.609289\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "31\tValidation loss: 1.634889\tBest loss: 1.609289\tAccuracy: 18.73%\n",
      "32\tValidation loss: 1.614010\tBest loss: 1.609289\tAccuracy: 19.08%\n",
      "33\tValidation loss: 1.619313\tBest loss: 1.609289\tAccuracy: 19.08%\n",
      "34\tValidation loss: 1.611677\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "35\tValidation loss: 1.638078\tBest loss: 1.609289\tAccuracy: 20.91%\n",
      "36\tValidation loss: 1.621398\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "37\tValidation loss: 1.617562\tBest loss: 1.609289\tAccuracy: 22.01%\n",
      "38\tValidation loss: 1.620767\tBest loss: 1.609289\tAccuracy: 20.91%\n",
      "39\tValidation loss: 1.627334\tBest loss: 1.609289\tAccuracy: 19.27%\n",
      "40\tValidation loss: 1.607883\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "41\tValidation loss: 1.634031\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "42\tValidation loss: 1.618327\tBest loss: 1.607883\tAccuracy: 20.91%\n",
      "43\tValidation loss: 1.618746\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "44\tValidation loss: 1.621665\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "45\tValidation loss: 1.629383\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "46\tValidation loss: 1.637658\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "47\tValidation loss: 1.609600\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "48\tValidation loss: 1.612162\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "49\tValidation loss: 1.643133\tBest loss: 1.607883\tAccuracy: 19.27%\n",
      "50\tValidation loss: 1.611987\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "51\tValidation loss: 1.619979\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "52\tValidation loss: 1.627026\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "53\tValidation loss: 1.618519\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "54\tValidation loss: 1.654812\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "55\tValidation loss: 1.645117\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "56\tValidation loss: 1.669471\tBest loss: 1.607883\tAccuracy: 19.08%\n",
      "57\tValidation loss: 1.619669\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "58\tValidation loss: 1.612549\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "59\tValidation loss: 1.619514\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "60\tValidation loss: 1.635963\tBest loss: 1.607883\tAccuracy: 18.73%\n",
      "61\tValidation loss: 1.627401\tBest loss: 1.607883\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8>, total= 3.9min\n",
      "[CV] n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.969493\tBest loss: 0.969493\tAccuracy: 60.36%\n",
      "1\tValidation loss: 1.350172\tBest loss: 0.969493\tAccuracy: 38.78%\n",
      "2\tValidation loss: 1.196436\tBest loss: 0.969493\tAccuracy: 40.93%\n",
      "3\tValidation loss: 1.189349\tBest loss: 0.969493\tAccuracy: 39.41%\n",
      "4\tValidation loss: 1.213466\tBest loss: 0.969493\tAccuracy: 39.41%\n",
      "5\tValidation loss: 1.251713\tBest loss: 0.969493\tAccuracy: 41.05%\n",
      "6\tValidation loss: 1.231191\tBest loss: 0.969493\tAccuracy: 39.41%\n",
      "7\tValidation loss: 1.213851\tBest loss: 0.969493\tAccuracy: 38.90%\n",
      "8\tValidation loss: 1.221809\tBest loss: 0.969493\tAccuracy: 38.51%\n",
      "9\tValidation loss: 1.285546\tBest loss: 0.969493\tAccuracy: 41.95%\n",
      "10\tValidation loss: 1.178024\tBest loss: 0.969493\tAccuracy: 39.80%\n",
      "11\tValidation loss: 1.210223\tBest loss: 0.969493\tAccuracy: 39.72%\n",
      "12\tValidation loss: 1.205502\tBest loss: 0.969493\tAccuracy: 39.87%\n",
      "13\tValidation loss: 1.183676\tBest loss: 0.969493\tAccuracy: 39.87%\n",
      "14\tValidation loss: 1.181250\tBest loss: 0.969493\tAccuracy: 39.87%\n",
      "15\tValidation loss: 1.169324\tBest loss: 0.969493\tAccuracy: 40.19%\n",
      "16\tValidation loss: 1.195027\tBest loss: 0.969493\tAccuracy: 39.72%\n",
      "17\tValidation loss: 1.162413\tBest loss: 0.969493\tAccuracy: 40.19%\n",
      "18\tValidation loss: 1.172472\tBest loss: 0.969493\tAccuracy: 39.72%\n",
      "19\tValidation loss: 1.180833\tBest loss: 0.969493\tAccuracy: 39.72%\n",
      "20\tValidation loss: 1.156200\tBest loss: 0.969493\tAccuracy: 41.83%\n",
      "21\tValidation loss: 1.208110\tBest loss: 0.969493\tAccuracy: 39.72%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=10, activation=<function relu at 0x117f566a8>, total= 1.4min\n",
      "[CV] n_neurons=90, n_hidden_layers=3, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 10.280422\tBest loss: 10.280422\tAccuracy: 77.29%\n",
      "1\tValidation loss: 3.593293\tBest loss: 3.593293\tAccuracy: 81.27%\n",
      "2\tValidation loss: 15.071418\tBest loss: 3.593293\tAccuracy: 82.33%\n",
      "3\tValidation loss: 42.850559\tBest loss: 3.593293\tAccuracy: 90.38%\n",
      "4\tValidation loss: 32.261036\tBest loss: 3.593293\tAccuracy: 76.66%\n",
      "5\tValidation loss: 11.758821\tBest loss: 3.593293\tAccuracy: 90.42%\n",
      "6\tValidation loss: 6.706314\tBest loss: 3.593293\tAccuracy: 92.73%\n",
      "7\tValidation loss: 6.763640\tBest loss: 3.593293\tAccuracy: 90.89%\n",
      "8\tValidation loss: 247.241577\tBest loss: 3.593293\tAccuracy: 95.58%\n",
      "9\tValidation loss: 26.424927\tBest loss: 3.593293\tAccuracy: 88.58%\n",
      "10\tValidation loss: 11.815883\tBest loss: 3.593293\tAccuracy: 95.58%\n",
      "11\tValidation loss: 6.471841\tBest loss: 3.593293\tAccuracy: 96.40%\n",
      "12\tValidation loss: 47.035873\tBest loss: 3.593293\tAccuracy: 93.71%\n",
      "13\tValidation loss: 606.059021\tBest loss: 3.593293\tAccuracy: 93.35%\n",
      "14\tValidation loss: 25.290688\tBest loss: 3.593293\tAccuracy: 93.98%\n",
      "15\tValidation loss: 383.256104\tBest loss: 3.593293\tAccuracy: 96.76%\n",
      "16\tValidation loss: 1075.602783\tBest loss: 3.593293\tAccuracy: 94.76%\n",
      "17\tValidation loss: 563.197571\tBest loss: 3.593293\tAccuracy: 91.91%\n",
      "18\tValidation loss: 495.700653\tBest loss: 3.593293\tAccuracy: 93.28%\n",
      "19\tValidation loss: 54.778427\tBest loss: 3.593293\tAccuracy: 95.15%\n",
      "20\tValidation loss: 27.783642\tBest loss: 3.593293\tAccuracy: 94.88%\n",
      "21\tValidation loss: 33.170147\tBest loss: 3.593293\tAccuracy: 94.72%\n",
      "22\tValidation loss: 32.951088\tBest loss: 3.593293\tAccuracy: 94.88%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=3, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.3min\n",
      "[CV] n_neurons=90, n_hidden_layers=3, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 2.540606\tBest loss: 2.540606\tAccuracy: 81.55%\n",
      "1\tValidation loss: 10.280129\tBest loss: 2.540606\tAccuracy: 83.50%\n",
      "2\tValidation loss: 11.020812\tBest loss: 2.540606\tAccuracy: 84.25%\n",
      "3\tValidation loss: 17.098921\tBest loss: 2.540606\tAccuracy: 92.57%\n",
      "4\tValidation loss: 6.046637\tBest loss: 2.540606\tAccuracy: 94.37%\n",
      "5\tValidation loss: 14.135324\tBest loss: 2.540606\tAccuracy: 69.86%\n",
      "6\tValidation loss: 63.807522\tBest loss: 2.540606\tAccuracy: 84.13%\n",
      "7\tValidation loss: 9.681630\tBest loss: 2.540606\tAccuracy: 93.43%\n",
      "8\tValidation loss: 29.873222\tBest loss: 2.540606\tAccuracy: 89.84%\n",
      "9\tValidation loss: 36.661026\tBest loss: 2.540606\tAccuracy: 96.01%\n",
      "10\tValidation loss: 31.855150\tBest loss: 2.540606\tAccuracy: 94.37%\n",
      "11\tValidation loss: 18.657475\tBest loss: 2.540606\tAccuracy: 95.47%\n",
      "12\tValidation loss: 11.625096\tBest loss: 2.540606\tAccuracy: 94.84%\n",
      "13\tValidation loss: 41.218285\tBest loss: 2.540606\tAccuracy: 76.70%\n",
      "14\tValidation loss: 12.777139\tBest loss: 2.540606\tAccuracy: 93.63%\n",
      "15\tValidation loss: 10.419136\tBest loss: 2.540606\tAccuracy: 95.04%\n",
      "16\tValidation loss: 32.479469\tBest loss: 2.540606\tAccuracy: 85.73%\n",
      "17\tValidation loss: 15.522323\tBest loss: 2.540606\tAccuracy: 95.27%\n",
      "18\tValidation loss: 16.312971\tBest loss: 2.540606\tAccuracy: 96.40%\n",
      "19\tValidation loss: 375.412292\tBest loss: 2.540606\tAccuracy: 66.50%\n",
      "20\tValidation loss: 20.639025\tBest loss: 2.540606\tAccuracy: 92.10%\n",
      "21\tValidation loss: 14.995791\tBest loss: 2.540606\tAccuracy: 95.54%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=3, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.2min\n",
      "[CV] n_neurons=90, n_hidden_layers=3, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.699411\tBest loss: 0.699411\tAccuracy: 92.96%\n",
      "1\tValidation loss: 32.530552\tBest loss: 0.699411\tAccuracy: 88.00%\n",
      "2\tValidation loss: 5.578635\tBest loss: 0.699411\tAccuracy: 95.43%\n",
      "3\tValidation loss: 25.604713\tBest loss: 0.699411\tAccuracy: 85.89%\n",
      "4\tValidation loss: 5.386969\tBest loss: 0.699411\tAccuracy: 93.82%\n",
      "5\tValidation loss: 99.712212\tBest loss: 0.699411\tAccuracy: 95.50%\n",
      "6\tValidation loss: 17.954664\tBest loss: 0.699411\tAccuracy: 96.44%\n",
      "7\tValidation loss: 6.559061\tBest loss: 0.699411\tAccuracy: 96.52%\n",
      "8\tValidation loss: 25.683838\tBest loss: 0.699411\tAccuracy: 93.67%\n",
      "9\tValidation loss: 26.289457\tBest loss: 0.699411\tAccuracy: 94.25%\n",
      "10\tValidation loss: 13.228728\tBest loss: 0.699411\tAccuracy: 96.13%\n",
      "11\tValidation loss: 45.997692\tBest loss: 0.699411\tAccuracy: 95.07%\n",
      "12\tValidation loss: 26.936083\tBest loss: 0.699411\tAccuracy: 96.91%\n",
      "13\tValidation loss: 20.226345\tBest loss: 0.699411\tAccuracy: 91.71%\n",
      "14\tValidation loss: 20.556324\tBest loss: 0.699411\tAccuracy: 95.23%\n",
      "15\tValidation loss: 105.639572\tBest loss: 0.699411\tAccuracy: 93.24%\n",
      "16\tValidation loss: 443.601288\tBest loss: 0.699411\tAccuracy: 96.91%\n",
      "17\tValidation loss: 130.477646\tBest loss: 0.699411\tAccuracy: 94.76%\n",
      "18\tValidation loss: 448.866730\tBest loss: 0.699411\tAccuracy: 88.90%\n",
      "19\tValidation loss: 59.655754\tBest loss: 0.699411\tAccuracy: 95.97%\n",
      "20\tValidation loss: 164.382782\tBest loss: 0.699411\tAccuracy: 95.47%\n",
      "21\tValidation loss: 415.259735\tBest loss: 0.699411\tAccuracy: 95.66%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=3, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.2min\n",
      "[CV] n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.134906\tBest loss: 0.134906\tAccuracy: 96.79%\n",
      "1\tValidation loss: 0.075356\tBest loss: 0.075356\tAccuracy: 98.08%\n",
      "2\tValidation loss: 8.004476\tBest loss: 0.075356\tAccuracy: 93.67%\n",
      "3\tValidation loss: 0.257542\tBest loss: 0.075356\tAccuracy: 95.78%\n",
      "4\tValidation loss: 0.208354\tBest loss: 0.075356\tAccuracy: 97.62%\n",
      "5\tValidation loss: 0.150336\tBest loss: 0.075356\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.131803\tBest loss: 0.075356\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.162478\tBest loss: 0.075356\tAccuracy: 98.01%\n",
      "8\tValidation loss: 0.155195\tBest loss: 0.075356\tAccuracy: 98.16%\n",
      "9\tValidation loss: 0.153410\tBest loss: 0.075356\tAccuracy: 97.77%\n",
      "10\tValidation loss: 0.233725\tBest loss: 0.075356\tAccuracy: 96.99%\n",
      "11\tValidation loss: 5.864634\tBest loss: 0.075356\tAccuracy: 96.48%\n",
      "12\tValidation loss: 0.269695\tBest loss: 0.075356\tAccuracy: 97.50%\n",
      "13\tValidation loss: 0.670618\tBest loss: 0.075356\tAccuracy: 96.36%\n",
      "14\tValidation loss: 0.217886\tBest loss: 0.075356\tAccuracy: 98.24%\n",
      "15\tValidation loss: 0.270682\tBest loss: 0.075356\tAccuracy: 97.93%\n",
      "16\tValidation loss: 0.372109\tBest loss: 0.075356\tAccuracy: 96.56%\n",
      "17\tValidation loss: 0.376727\tBest loss: 0.075356\tAccuracy: 98.59%\n",
      "18\tValidation loss: 2.458449\tBest loss: 0.075356\tAccuracy: 90.30%\n",
      "19\tValidation loss: 3.586823\tBest loss: 0.075356\tAccuracy: 96.83%\n",
      "20\tValidation loss: 1.623338\tBest loss: 0.075356\tAccuracy: 97.65%\n",
      "21\tValidation loss: 1.108813\tBest loss: 0.075356\tAccuracy: 97.69%\n",
      "22\tValidation loss: 1.409972\tBest loss: 0.075356\tAccuracy: 97.93%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  51.6s\n",
      "[CV] n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.100051\tBest loss: 0.100051\tAccuracy: 97.07%\n",
      "1\tValidation loss: 0.210126\tBest loss: 0.100051\tAccuracy: 96.29%\n",
      "2\tValidation loss: 0.252447\tBest loss: 0.100051\tAccuracy: 96.64%\n",
      "3\tValidation loss: 0.192591\tBest loss: 0.100051\tAccuracy: 97.38%\n",
      "4\tValidation loss: 0.094213\tBest loss: 0.094213\tAccuracy: 98.08%\n",
      "5\tValidation loss: 0.103472\tBest loss: 0.094213\tAccuracy: 98.24%\n",
      "6\tValidation loss: 0.116614\tBest loss: 0.094213\tAccuracy: 98.12%\n",
      "7\tValidation loss: 0.127156\tBest loss: 0.094213\tAccuracy: 98.24%\n",
      "8\tValidation loss: 3.786069\tBest loss: 0.094213\tAccuracy: 96.40%\n",
      "9\tValidation loss: 1.314759\tBest loss: 0.094213\tAccuracy: 97.69%\n",
      "10\tValidation loss: 0.932434\tBest loss: 0.094213\tAccuracy: 98.24%\n",
      "11\tValidation loss: 0.629883\tBest loss: 0.094213\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.620713\tBest loss: 0.094213\tAccuracy: 98.48%\n",
      "13\tValidation loss: 0.494851\tBest loss: 0.094213\tAccuracy: 98.67%\n",
      "14\tValidation loss: 0.578676\tBest loss: 0.094213\tAccuracy: 98.40%\n",
      "15\tValidation loss: 0.881697\tBest loss: 0.094213\tAccuracy: 97.07%\n",
      "16\tValidation loss: 0.526407\tBest loss: 0.094213\tAccuracy: 98.24%\n",
      "17\tValidation loss: 0.346658\tBest loss: 0.094213\tAccuracy: 98.79%\n",
      "18\tValidation loss: 0.451352\tBest loss: 0.094213\tAccuracy: 98.67%\n",
      "19\tValidation loss: 2.757215\tBest loss: 0.094213\tAccuracy: 96.40%\n",
      "20\tValidation loss: 1.256388\tBest loss: 0.094213\tAccuracy: 97.03%\n",
      "21\tValidation loss: 1.855293\tBest loss: 0.094213\tAccuracy: 98.01%\n",
      "22\tValidation loss: 4.437262\tBest loss: 0.094213\tAccuracy: 98.16%\n",
      "23\tValidation loss: 1.593420\tBest loss: 0.094213\tAccuracy: 98.28%\n",
      "24\tValidation loss: 7.294721\tBest loss: 0.094213\tAccuracy: 98.20%\n",
      "25\tValidation loss: 17.450724\tBest loss: 0.094213\tAccuracy: 94.61%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 1.0min\n",
      "[CV] n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.120025\tBest loss: 0.120025\tAccuracy: 96.76%\n",
      "1\tValidation loss: 0.118760\tBest loss: 0.118760\tAccuracy: 97.19%\n",
      "2\tValidation loss: 0.083787\tBest loss: 0.083787\tAccuracy: 97.77%\n",
      "3\tValidation loss: 0.082507\tBest loss: 0.082507\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.086637\tBest loss: 0.082507\tAccuracy: 98.20%\n",
      "5\tValidation loss: 0.086676\tBest loss: 0.082507\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.575812\tBest loss: 0.082507\tAccuracy: 96.95%\n",
      "7\tValidation loss: 0.150970\tBest loss: 0.082507\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.131651\tBest loss: 0.082507\tAccuracy: 97.81%\n",
      "9\tValidation loss: 0.117441\tBest loss: 0.082507\tAccuracy: 97.81%\n",
      "10\tValidation loss: 0.113224\tBest loss: 0.082507\tAccuracy: 98.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\tValidation loss: 0.107416\tBest loss: 0.082507\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.134400\tBest loss: 0.082507\tAccuracy: 98.16%\n",
      "13\tValidation loss: 0.185604\tBest loss: 0.082507\tAccuracy: 98.05%\n",
      "14\tValidation loss: 0.190683\tBest loss: 0.082507\tAccuracy: 98.05%\n",
      "15\tValidation loss: 103.065224\tBest loss: 0.082507\tAccuracy: 93.32%\n",
      "16\tValidation loss: 1.916109\tBest loss: 0.082507\tAccuracy: 98.01%\n",
      "17\tValidation loss: 1.556220\tBest loss: 0.082507\tAccuracy: 97.97%\n",
      "18\tValidation loss: 1.340443\tBest loss: 0.082507\tAccuracy: 97.58%\n",
      "19\tValidation loss: 1.000810\tBest loss: 0.082507\tAccuracy: 98.32%\n",
      "20\tValidation loss: 1.262149\tBest loss: 0.082507\tAccuracy: 97.97%\n",
      "21\tValidation loss: 1.037944\tBest loss: 0.082507\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.709063\tBest loss: 0.082507\tAccuracy: 98.32%\n",
      "23\tValidation loss: 1.015409\tBest loss: 0.082507\tAccuracy: 98.24%\n",
      "24\tValidation loss: 1.302261\tBest loss: 0.082507\tAccuracy: 98.40%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  56.5s\n",
      "[CV] n_neurons=120, n_hidden_layers=1, learning_rate=0.1, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.229680\tBest loss: 0.229680\tAccuracy: 96.87%\n",
      "1\tValidation loss: 0.159507\tBest loss: 0.159507\tAccuracy: 96.72%\n",
      "2\tValidation loss: 0.126597\tBest loss: 0.126597\tAccuracy: 96.99%\n",
      "3\tValidation loss: 0.132987\tBest loss: 0.126597\tAccuracy: 97.11%\n",
      "4\tValidation loss: 0.126425\tBest loss: 0.126425\tAccuracy: 97.85%\n",
      "5\tValidation loss: 0.178934\tBest loss: 0.126425\tAccuracy: 97.07%\n",
      "6\tValidation loss: 0.180611\tBest loss: 0.126425\tAccuracy: 97.22%\n",
      "7\tValidation loss: 0.168865\tBest loss: 0.126425\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.151370\tBest loss: 0.126425\tAccuracy: 97.85%\n",
      "9\tValidation loss: 0.178509\tBest loss: 0.126425\tAccuracy: 97.93%\n",
      "10\tValidation loss: 0.179652\tBest loss: 0.126425\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.311256\tBest loss: 0.126425\tAccuracy: 97.81%\n",
      "12\tValidation loss: 0.249391\tBest loss: 0.126425\tAccuracy: 98.05%\n",
      "13\tValidation loss: 0.254166\tBest loss: 0.126425\tAccuracy: 97.65%\n",
      "14\tValidation loss: 0.269834\tBest loss: 0.126425\tAccuracy: 97.89%\n",
      "15\tValidation loss: 0.298753\tBest loss: 0.126425\tAccuracy: 97.93%\n",
      "16\tValidation loss: 0.278936\tBest loss: 0.126425\tAccuracy: 98.36%\n",
      "17\tValidation loss: 0.354082\tBest loss: 0.126425\tAccuracy: 97.65%\n",
      "18\tValidation loss: 0.358594\tBest loss: 0.126425\tAccuracy: 98.20%\n",
      "19\tValidation loss: 0.356936\tBest loss: 0.126425\tAccuracy: 98.01%\n",
      "20\tValidation loss: 0.276174\tBest loss: 0.126425\tAccuracy: 98.79%\n",
      "21\tValidation loss: 0.306779\tBest loss: 0.126425\tAccuracy: 98.48%\n",
      "22\tValidation loss: 0.407450\tBest loss: 0.126425\tAccuracy: 98.05%\n",
      "23\tValidation loss: 0.287051\tBest loss: 0.126425\tAccuracy: 98.44%\n",
      "24\tValidation loss: 0.535089\tBest loss: 0.126425\tAccuracy: 97.97%\n",
      "25\tValidation loss: 0.601901\tBest loss: 0.126425\tAccuracy: 97.62%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=1, learning_rate=0.1, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=   8.3s\n",
      "[CV] n_neurons=120, n_hidden_layers=1, learning_rate=0.1, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.307541\tBest loss: 0.307541\tAccuracy: 95.50%\n",
      "1\tValidation loss: 0.167038\tBest loss: 0.167038\tAccuracy: 97.19%\n",
      "2\tValidation loss: 0.205933\tBest loss: 0.167038\tAccuracy: 95.39%\n",
      "3\tValidation loss: 0.097701\tBest loss: 0.097701\tAccuracy: 97.77%\n",
      "4\tValidation loss: 0.109305\tBest loss: 0.097701\tAccuracy: 97.62%\n",
      "5\tValidation loss: 0.124128\tBest loss: 0.097701\tAccuracy: 97.62%\n",
      "6\tValidation loss: 0.132794\tBest loss: 0.097701\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.293631\tBest loss: 0.097701\tAccuracy: 96.48%\n",
      "8\tValidation loss: 0.154789\tBest loss: 0.097701\tAccuracy: 97.50%\n",
      "9\tValidation loss: 0.123504\tBest loss: 0.097701\tAccuracy: 97.81%\n",
      "10\tValidation loss: 0.150188\tBest loss: 0.097701\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.159643\tBest loss: 0.097701\tAccuracy: 97.73%\n",
      "12\tValidation loss: 0.335707\tBest loss: 0.097701\tAccuracy: 97.46%\n",
      "13\tValidation loss: 0.180859\tBest loss: 0.097701\tAccuracy: 98.05%\n",
      "14\tValidation loss: 0.246664\tBest loss: 0.097701\tAccuracy: 97.30%\n",
      "15\tValidation loss: 0.228751\tBest loss: 0.097701\tAccuracy: 97.73%\n",
      "16\tValidation loss: 0.172666\tBest loss: 0.097701\tAccuracy: 98.05%\n",
      "17\tValidation loss: 0.175312\tBest loss: 0.097701\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.255666\tBest loss: 0.097701\tAccuracy: 97.73%\n",
      "19\tValidation loss: 0.460422\tBest loss: 0.097701\tAccuracy: 97.03%\n",
      "20\tValidation loss: 0.353967\tBest loss: 0.097701\tAccuracy: 97.81%\n",
      "21\tValidation loss: 0.380974\tBest loss: 0.097701\tAccuracy: 98.16%\n",
      "22\tValidation loss: 0.337655\tBest loss: 0.097701\tAccuracy: 98.20%\n",
      "23\tValidation loss: 0.472543\tBest loss: 0.097701\tAccuracy: 98.05%\n",
      "24\tValidation loss: 0.493519\tBest loss: 0.097701\tAccuracy: 98.16%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=1, learning_rate=0.1, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=   7.9s\n",
      "[CV] n_neurons=120, n_hidden_layers=1, learning_rate=0.1, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.260437\tBest loss: 0.260437\tAccuracy: 96.33%\n",
      "1\tValidation loss: 0.154718\tBest loss: 0.154718\tAccuracy: 97.15%\n",
      "2\tValidation loss: 0.208668\tBest loss: 0.154718\tAccuracy: 96.48%\n",
      "3\tValidation loss: 0.110015\tBest loss: 0.110015\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.110141\tBest loss: 0.110015\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.115643\tBest loss: 0.110015\tAccuracy: 97.89%\n",
      "6\tValidation loss: 0.093374\tBest loss: 0.093374\tAccuracy: 98.12%\n",
      "7\tValidation loss: 0.106480\tBest loss: 0.093374\tAccuracy: 98.08%\n",
      "8\tValidation loss: 0.146478\tBest loss: 0.093374\tAccuracy: 97.93%\n",
      "9\tValidation loss: 0.184759\tBest loss: 0.093374\tAccuracy: 97.93%\n",
      "10\tValidation loss: 0.156978\tBest loss: 0.093374\tAccuracy: 98.24%\n",
      "11\tValidation loss: 0.128210\tBest loss: 0.093374\tAccuracy: 98.44%\n",
      "12\tValidation loss: 0.157398\tBest loss: 0.093374\tAccuracy: 98.08%\n",
      "13\tValidation loss: 0.204999\tBest loss: 0.093374\tAccuracy: 98.05%\n",
      "14\tValidation loss: 0.251153\tBest loss: 0.093374\tAccuracy: 98.20%\n",
      "15\tValidation loss: 0.258697\tBest loss: 0.093374\tAccuracy: 98.36%\n",
      "16\tValidation loss: 0.376661\tBest loss: 0.093374\tAccuracy: 98.01%\n",
      "17\tValidation loss: 0.292270\tBest loss: 0.093374\tAccuracy: 98.32%\n",
      "18\tValidation loss: 0.252075\tBest loss: 0.093374\tAccuracy: 97.81%\n",
      "19\tValidation loss: 0.194121\tBest loss: 0.093374\tAccuracy: 98.75%\n",
      "20\tValidation loss: 0.288619\tBest loss: 0.093374\tAccuracy: 98.63%\n",
      "21\tValidation loss: 0.401131\tBest loss: 0.093374\tAccuracy: 98.08%\n",
      "22\tValidation loss: 0.366232\tBest loss: 0.093374\tAccuracy: 98.44%\n",
      "23\tValidation loss: 0.375712\tBest loss: 0.093374\tAccuracy: 98.24%\n",
      "24\tValidation loss: 0.435735\tBest loss: 0.093374\tAccuracy: 98.28%\n",
      "25\tValidation loss: 0.650725\tBest loss: 0.093374\tAccuracy: 97.50%\n",
      "26\tValidation loss: 0.532296\tBest loss: 0.093374\tAccuracy: 98.28%\n",
      "27\tValidation loss: 0.633277\tBest loss: 0.093374\tAccuracy: 97.89%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=1, learning_rate=0.1, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=   9.0s\n",
      "[CV] n_neurons=160, n_hidden_layers=1, learning_rate=0.05, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.135922\tBest loss: 0.135922\tAccuracy: 96.95%\n",
      "1\tValidation loss: 0.156319\tBest loss: 0.135922\tAccuracy: 97.93%\n",
      "2\tValidation loss: 0.333873\tBest loss: 0.135922\tAccuracy: 96.76%\n",
      "3\tValidation loss: 0.194543\tBest loss: 0.135922\tAccuracy: 97.15%\n",
      "4\tValidation loss: 0.191699\tBest loss: 0.135922\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.563503\tBest loss: 0.135922\tAccuracy: 97.26%\n",
      "6\tValidation loss: 0.239153\tBest loss: 0.135922\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.353359\tBest loss: 0.135922\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.270299\tBest loss: 0.135922\tAccuracy: 98.12%\n",
      "9\tValidation loss: 0.329136\tBest loss: 0.135922\tAccuracy: 97.58%\n",
      "10\tValidation loss: 0.641654\tBest loss: 0.135922\tAccuracy: 97.77%\n",
      "11\tValidation loss: 0.577914\tBest loss: 0.135922\tAccuracy: 97.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\tValidation loss: 0.647129\tBest loss: 0.135922\tAccuracy: 97.93%\n",
      "13\tValidation loss: 0.537147\tBest loss: 0.135922\tAccuracy: 97.97%\n",
      "14\tValidation loss: 0.579876\tBest loss: 0.135922\tAccuracy: 97.77%\n",
      "15\tValidation loss: 0.567983\tBest loss: 0.135922\tAccuracy: 98.24%\n",
      "16\tValidation loss: 0.852193\tBest loss: 0.135922\tAccuracy: 98.16%\n",
      "17\tValidation loss: 0.563198\tBest loss: 0.135922\tAccuracy: 98.55%\n",
      "18\tValidation loss: 0.650193\tBest loss: 0.135922\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.972271\tBest loss: 0.135922\tAccuracy: 98.51%\n",
      "20\tValidation loss: 0.949890\tBest loss: 0.135922\tAccuracy: 98.16%\n",
      "21\tValidation loss: 0.551321\tBest loss: 0.135922\tAccuracy: 98.83%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=1, learning_rate=0.05, batch_size=100, activation=<function elu at 0x11591cd08>, total=  15.7s\n",
      "[CV] n_neurons=160, n_hidden_layers=1, learning_rate=0.05, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.099587\tBest loss: 0.099587\tAccuracy: 97.19%\n",
      "1\tValidation loss: 0.138159\tBest loss: 0.099587\tAccuracy: 97.46%\n",
      "2\tValidation loss: 0.350826\tBest loss: 0.099587\tAccuracy: 95.97%\n",
      "3\tValidation loss: 0.254080\tBest loss: 0.099587\tAccuracy: 97.46%\n",
      "4\tValidation loss: 0.179016\tBest loss: 0.099587\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.170484\tBest loss: 0.099587\tAccuracy: 98.67%\n",
      "6\tValidation loss: 0.650498\tBest loss: 0.099587\tAccuracy: 96.36%\n",
      "7\tValidation loss: 0.291936\tBest loss: 0.099587\tAccuracy: 97.50%\n",
      "8\tValidation loss: 0.620826\tBest loss: 0.099587\tAccuracy: 97.38%\n",
      "9\tValidation loss: 0.330416\tBest loss: 0.099587\tAccuracy: 98.12%\n",
      "10\tValidation loss: 0.729933\tBest loss: 0.099587\tAccuracy: 97.85%\n",
      "11\tValidation loss: 0.505960\tBest loss: 0.099587\tAccuracy: 98.01%\n",
      "12\tValidation loss: 0.701658\tBest loss: 0.099587\tAccuracy: 97.69%\n",
      "13\tValidation loss: 0.414389\tBest loss: 0.099587\tAccuracy: 98.36%\n",
      "14\tValidation loss: 0.585925\tBest loss: 0.099587\tAccuracy: 98.40%\n",
      "15\tValidation loss: 0.535003\tBest loss: 0.099587\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.401935\tBest loss: 0.099587\tAccuracy: 98.05%\n",
      "17\tValidation loss: 0.444564\tBest loss: 0.099587\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.684060\tBest loss: 0.099587\tAccuracy: 97.03%\n",
      "19\tValidation loss: 0.604062\tBest loss: 0.099587\tAccuracy: 98.12%\n",
      "20\tValidation loss: 0.839541\tBest loss: 0.099587\tAccuracy: 98.16%\n",
      "21\tValidation loss: 0.681818\tBest loss: 0.099587\tAccuracy: 97.30%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=1, learning_rate=0.05, batch_size=100, activation=<function elu at 0x11591cd08>, total=  15.7s\n",
      "[CV] n_neurons=160, n_hidden_layers=1, learning_rate=0.05, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.141978\tBest loss: 0.141978\tAccuracy: 96.72%\n",
      "1\tValidation loss: 0.194267\tBest loss: 0.141978\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.242060\tBest loss: 0.141978\tAccuracy: 97.26%\n",
      "3\tValidation loss: 0.212855\tBest loss: 0.141978\tAccuracy: 97.50%\n",
      "4\tValidation loss: 0.164309\tBest loss: 0.141978\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.315405\tBest loss: 0.141978\tAccuracy: 97.46%\n",
      "6\tValidation loss: 0.684922\tBest loss: 0.141978\tAccuracy: 95.50%\n",
      "7\tValidation loss: 0.274218\tBest loss: 0.141978\tAccuracy: 97.85%\n",
      "8\tValidation loss: 0.334179\tBest loss: 0.141978\tAccuracy: 98.01%\n",
      "9\tValidation loss: 0.307998\tBest loss: 0.141978\tAccuracy: 98.05%\n",
      "10\tValidation loss: 0.293088\tBest loss: 0.141978\tAccuracy: 97.54%\n",
      "11\tValidation loss: 0.307783\tBest loss: 0.141978\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.324854\tBest loss: 0.141978\tAccuracy: 98.05%\n",
      "13\tValidation loss: 0.312384\tBest loss: 0.141978\tAccuracy: 98.44%\n",
      "14\tValidation loss: 0.440767\tBest loss: 0.141978\tAccuracy: 95.70%\n",
      "15\tValidation loss: 0.518325\tBest loss: 0.141978\tAccuracy: 98.05%\n",
      "16\tValidation loss: 0.348393\tBest loss: 0.141978\tAccuracy: 98.36%\n",
      "17\tValidation loss: 0.461906\tBest loss: 0.141978\tAccuracy: 98.05%\n",
      "18\tValidation loss: 0.434165\tBest loss: 0.141978\tAccuracy: 98.24%\n",
      "19\tValidation loss: 0.385952\tBest loss: 0.141978\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.712864\tBest loss: 0.141978\tAccuracy: 96.64%\n",
      "21\tValidation loss: 0.519518\tBest loss: 0.141978\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=1, learning_rate=0.05, batch_size=100, activation=<function elu at 0x11591cd08>, total=  15.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.184484\tBest loss: 0.184484\tAccuracy: 95.35%\n",
      "1\tValidation loss: 0.306595\tBest loss: 0.184484\tAccuracy: 94.29%\n",
      "2\tValidation loss: 1.690922\tBest loss: 0.184484\tAccuracy: 18.73%\n",
      "3\tValidation loss: 1.660609\tBest loss: 0.184484\tAccuracy: 18.73%\n",
      "4\tValidation loss: 1.797518\tBest loss: 0.184484\tAccuracy: 18.73%\n",
      "5\tValidation loss: 1.724852\tBest loss: 0.184484\tAccuracy: 18.73%\n",
      "6\tValidation loss: 1.728181\tBest loss: 0.184484\tAccuracy: 22.01%\n",
      "7\tValidation loss: 1.672060\tBest loss: 0.184484\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.762317\tBest loss: 0.184484\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.680190\tBest loss: 0.184484\tAccuracy: 19.08%\n",
      "10\tValidation loss: 1.630278\tBest loss: 0.184484\tAccuracy: 19.08%\n",
      "11\tValidation loss: 1.761902\tBest loss: 0.184484\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.694066\tBest loss: 0.184484\tAccuracy: 18.73%\n",
      "13\tValidation loss: 1.900412\tBest loss: 0.184484\tAccuracy: 19.27%\n",
      "14\tValidation loss: 1.819685\tBest loss: 0.184484\tAccuracy: 19.08%\n",
      "15\tValidation loss: 1.650046\tBest loss: 0.184484\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.764809\tBest loss: 0.184484\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.782692\tBest loss: 0.184484\tAccuracy: 22.01%\n",
      "18\tValidation loss: 1.752953\tBest loss: 0.184484\tAccuracy: 19.27%\n",
      "19\tValidation loss: 1.855329\tBest loss: 0.184484\tAccuracy: 20.91%\n",
      "20\tValidation loss: 1.641765\tBest loss: 0.184484\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.741715\tBest loss: 0.184484\tAccuracy: 19.27%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08>, total=  17.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.198367\tBest loss: 0.198367\tAccuracy: 95.19%\n",
      "1\tValidation loss: 0.165506\tBest loss: 0.165506\tAccuracy: 96.76%\n",
      "2\tValidation loss: 0.165785\tBest loss: 0.165506\tAccuracy: 95.54%\n",
      "3\tValidation loss: 0.155506\tBest loss: 0.155506\tAccuracy: 96.95%\n",
      "4\tValidation loss: 0.129501\tBest loss: 0.129501\tAccuracy: 96.79%\n",
      "5\tValidation loss: 1.687190\tBest loss: 0.129501\tAccuracy: 18.73%\n",
      "6\tValidation loss: 1.704381\tBest loss: 0.129501\tAccuracy: 22.01%\n",
      "7\tValidation loss: 1.648111\tBest loss: 0.129501\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.742404\tBest loss: 0.129501\tAccuracy: 18.73%\n",
      "9\tValidation loss: 1.654308\tBest loss: 0.129501\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.689952\tBest loss: 0.129501\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.710360\tBest loss: 0.129501\tAccuracy: 18.73%\n",
      "12\tValidation loss: 1.722977\tBest loss: 0.129501\tAccuracy: 19.27%\n",
      "13\tValidation loss: 1.664674\tBest loss: 0.129501\tAccuracy: 19.08%\n",
      "14\tValidation loss: 1.785452\tBest loss: 0.129501\tAccuracy: 18.73%\n",
      "15\tValidation loss: 1.648576\tBest loss: 0.129501\tAccuracy: 18.73%\n",
      "16\tValidation loss: 1.699832\tBest loss: 0.129501\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.754199\tBest loss: 0.129501\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.769000\tBest loss: 0.129501\tAccuracy: 22.01%\n",
      "19\tValidation loss: 1.661196\tBest loss: 0.129501\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.781069\tBest loss: 0.129501\tAccuracy: 20.91%\n",
      "21\tValidation loss: 1.862150\tBest loss: 0.129501\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.783809\tBest loss: 0.129501\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.766721\tBest loss: 0.129501\tAccuracy: 22.01%\n",
      "24\tValidation loss: 1.922701\tBest loss: 0.129501\tAccuracy: 18.73%\n",
      "25\tValidation loss: 1.706513\tBest loss: 0.129501\tAccuracy: 20.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08>, total=  21.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.133516\tBest loss: 0.133516\tAccuracy: 96.83%\n",
      "1\tValidation loss: 0.135349\tBest loss: 0.133516\tAccuracy: 96.56%\n",
      "2\tValidation loss: 0.145202\tBest loss: 0.133516\tAccuracy: 95.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\tValidation loss: 0.159769\tBest loss: 0.133516\tAccuracy: 96.87%\n",
      "4\tValidation loss: 0.144007\tBest loss: 0.133516\tAccuracy: 96.72%\n",
      "5\tValidation loss: 0.169823\tBest loss: 0.133516\tAccuracy: 95.58%\n",
      "6\tValidation loss: 1.630095\tBest loss: 0.133516\tAccuracy: 19.27%\n",
      "7\tValidation loss: 1.701934\tBest loss: 0.133516\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.641772\tBest loss: 0.133516\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.758981\tBest loss: 0.133516\tAccuracy: 19.27%\n",
      "10\tValidation loss: 1.624188\tBest loss: 0.133516\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.718683\tBest loss: 0.133516\tAccuracy: 18.73%\n",
      "12\tValidation loss: 1.695165\tBest loss: 0.133516\tAccuracy: 19.08%\n",
      "13\tValidation loss: 1.794336\tBest loss: 0.133516\tAccuracy: 19.08%\n",
      "14\tValidation loss: 1.713031\tBest loss: 0.133516\tAccuracy: 22.01%\n",
      "15\tValidation loss: 1.680268\tBest loss: 0.133516\tAccuracy: 19.27%\n",
      "16\tValidation loss: 1.728526\tBest loss: 0.133516\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.780126\tBest loss: 0.133516\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.656789\tBest loss: 0.133516\tAccuracy: 19.27%\n",
      "19\tValidation loss: 1.674110\tBest loss: 0.133516\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.619319\tBest loss: 0.133516\tAccuracy: 22.01%\n",
      "21\tValidation loss: 2.277025\tBest loss: 0.133516\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.1, batch_size=100, activation=<function elu at 0x11591cd08>, total=  18.3s\n",
      "[CV] n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.193336\tBest loss: 0.193336\tAccuracy: 95.39%\n",
      "1\tValidation loss: 0.281908\tBest loss: 0.193336\tAccuracy: 93.94%\n",
      "2\tValidation loss: 0.128857\tBest loss: 0.128857\tAccuracy: 97.26%\n",
      "3\tValidation loss: 6.825543\tBest loss: 0.128857\tAccuracy: 81.51%\n",
      "4\tValidation loss: 5.265888\tBest loss: 0.128857\tAccuracy: 96.68%\n",
      "5\tValidation loss: 5.819910\tBest loss: 0.128857\tAccuracy: 96.44%\n",
      "6\tValidation loss: 4.844565\tBest loss: 0.128857\tAccuracy: 96.56%\n",
      "7\tValidation loss: 5.810616\tBest loss: 0.128857\tAccuracy: 96.40%\n",
      "8\tValidation loss: 2.933967\tBest loss: 0.128857\tAccuracy: 97.03%\n",
      "9\tValidation loss: 6.185387\tBest loss: 0.128857\tAccuracy: 95.62%\n",
      "10\tValidation loss: 4.660215\tBest loss: 0.128857\tAccuracy: 96.44%\n",
      "11\tValidation loss: 5.105992\tBest loss: 0.128857\tAccuracy: 96.13%\n",
      "12\tValidation loss: 10.528371\tBest loss: 0.128857\tAccuracy: 95.86%\n",
      "13\tValidation loss: 29.396868\tBest loss: 0.128857\tAccuracy: 92.14%\n",
      "14\tValidation loss: 14.347390\tBest loss: 0.128857\tAccuracy: 97.73%\n",
      "15\tValidation loss: 31.155523\tBest loss: 0.128857\tAccuracy: 96.13%\n",
      "16\tValidation loss: 16.444742\tBest loss: 0.128857\tAccuracy: 97.30%\n",
      "17\tValidation loss: 38.907772\tBest loss: 0.128857\tAccuracy: 96.91%\n",
      "18\tValidation loss: 21.211042\tBest loss: 0.128857\tAccuracy: 97.50%\n",
      "19\tValidation loss: 24.872019\tBest loss: 0.128857\tAccuracy: 97.93%\n",
      "20\tValidation loss: 47.133862\tBest loss: 0.128857\tAccuracy: 96.99%\n",
      "21\tValidation loss: 30.933365\tBest loss: 0.128857\tAccuracy: 97.93%\n",
      "22\tValidation loss: 26.386095\tBest loss: 0.128857\tAccuracy: 97.73%\n",
      "23\tValidation loss: 33.422558\tBest loss: 0.128857\tAccuracy: 98.12%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  17.8s\n",
      "[CV] n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.546391\tBest loss: 0.546391\tAccuracy: 92.65%\n",
      "1\tValidation loss: 0.282691\tBest loss: 0.282691\tAccuracy: 94.18%\n",
      "2\tValidation loss: 0.254299\tBest loss: 0.254299\tAccuracy: 96.21%\n",
      "3\tValidation loss: 9.875636\tBest loss: 0.254299\tAccuracy: 96.76%\n",
      "4\tValidation loss: 7.478296\tBest loss: 0.254299\tAccuracy: 96.56%\n",
      "5\tValidation loss: 4.746306\tBest loss: 0.254299\tAccuracy: 95.00%\n",
      "6\tValidation loss: 4.790523\tBest loss: 0.254299\tAccuracy: 96.95%\n",
      "7\tValidation loss: 2.436973\tBest loss: 0.254299\tAccuracy: 96.72%\n",
      "8\tValidation loss: 2.037205\tBest loss: 0.254299\tAccuracy: 97.26%\n",
      "9\tValidation loss: 3.226943\tBest loss: 0.254299\tAccuracy: 96.76%\n",
      "10\tValidation loss: 4.100308\tBest loss: 0.254299\tAccuracy: 96.44%\n",
      "11\tValidation loss: 4.341909\tBest loss: 0.254299\tAccuracy: 96.83%\n",
      "12\tValidation loss: 5.396663\tBest loss: 0.254299\tAccuracy: 96.87%\n",
      "13\tValidation loss: 6.273142\tBest loss: 0.254299\tAccuracy: 96.40%\n",
      "14\tValidation loss: 12.136604\tBest loss: 0.254299\tAccuracy: 94.80%\n",
      "15\tValidation loss: 62.117733\tBest loss: 0.254299\tAccuracy: 95.47%\n",
      "16\tValidation loss: 43.303665\tBest loss: 0.254299\tAccuracy: 96.79%\n",
      "17\tValidation loss: 18.254677\tBest loss: 0.254299\tAccuracy: 97.26%\n",
      "18\tValidation loss: 12.696078\tBest loss: 0.254299\tAccuracy: 97.42%\n",
      "19\tValidation loss: 16.871243\tBest loss: 0.254299\tAccuracy: 97.73%\n",
      "20\tValidation loss: 10.987875\tBest loss: 0.254299\tAccuracy: 98.20%\n",
      "21\tValidation loss: 18.494093\tBest loss: 0.254299\tAccuracy: 97.34%\n",
      "22\tValidation loss: 20.340317\tBest loss: 0.254299\tAccuracy: 97.22%\n",
      "23\tValidation loss: 35.704994\tBest loss: 0.254299\tAccuracy: 97.34%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  18.3s\n",
      "[CV] n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.113076\tBest loss: 0.113076\tAccuracy: 96.91%\n",
      "1\tValidation loss: 0.124768\tBest loss: 0.113076\tAccuracy: 96.44%\n",
      "2\tValidation loss: 0.326754\tBest loss: 0.113076\tAccuracy: 94.84%\n",
      "3\tValidation loss: 0.645273\tBest loss: 0.113076\tAccuracy: 93.35%\n",
      "4\tValidation loss: 14.162915\tBest loss: 0.113076\tAccuracy: 96.25%\n",
      "5\tValidation loss: 9.061103\tBest loss: 0.113076\tAccuracy: 94.61%\n",
      "6\tValidation loss: 4.587387\tBest loss: 0.113076\tAccuracy: 97.54%\n",
      "7\tValidation loss: 3.986295\tBest loss: 0.113076\tAccuracy: 97.26%\n",
      "8\tValidation loss: 3.157483\tBest loss: 0.113076\tAccuracy: 96.29%\n",
      "9\tValidation loss: 3.312661\tBest loss: 0.113076\tAccuracy: 97.15%\n",
      "10\tValidation loss: 2.279160\tBest loss: 0.113076\tAccuracy: 97.77%\n",
      "11\tValidation loss: 3.858750\tBest loss: 0.113076\tAccuracy: 97.11%\n",
      "12\tValidation loss: 4.588251\tBest loss: 0.113076\tAccuracy: 96.79%\n",
      "13\tValidation loss: 5.464884\tBest loss: 0.113076\tAccuracy: 96.79%\n",
      "14\tValidation loss: 15.984944\tBest loss: 0.113076\tAccuracy: 94.88%\n",
      "15\tValidation loss: 35.310722\tBest loss: 0.113076\tAccuracy: 95.90%\n",
      "16\tValidation loss: 10.861382\tBest loss: 0.113076\tAccuracy: 97.26%\n",
      "17\tValidation loss: 16.818701\tBest loss: 0.113076\tAccuracy: 96.21%\n",
      "18\tValidation loss: 11.868601\tBest loss: 0.113076\tAccuracy: 97.58%\n",
      "19\tValidation loss: 11.866504\tBest loss: 0.113076\tAccuracy: 97.07%\n",
      "20\tValidation loss: 8.450540\tBest loss: 0.113076\tAccuracy: 98.20%\n",
      "21\tValidation loss: 28.105145\tBest loss: 0.113076\tAccuracy: 96.56%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=2, learning_rate=0.1, batch_size=100, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  16.4s\n",
      "[CV] n_neurons=140, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.102634\tBest loss: 0.102634\tAccuracy: 96.64%\n",
      "1\tValidation loss: 0.071574\tBest loss: 0.071574\tAccuracy: 98.01%\n",
      "2\tValidation loss: 0.064260\tBest loss: 0.064260\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.054076\tBest loss: 0.054076\tAccuracy: 98.16%\n",
      "4\tValidation loss: 0.056409\tBest loss: 0.054076\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.059866\tBest loss: 0.054076\tAccuracy: 98.20%\n",
      "6\tValidation loss: 0.052101\tBest loss: 0.052101\tAccuracy: 98.59%\n",
      "7\tValidation loss: 0.053001\tBest loss: 0.052101\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.046510\tBest loss: 0.046510\tAccuracy: 98.94%\n",
      "9\tValidation loss: 0.053397\tBest loss: 0.046510\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.073744\tBest loss: 0.046510\tAccuracy: 98.40%\n",
      "11\tValidation loss: 0.058650\tBest loss: 0.046510\tAccuracy: 98.71%\n",
      "12\tValidation loss: 0.067608\tBest loss: 0.046510\tAccuracy: 98.83%\n",
      "13\tValidation loss: 0.099237\tBest loss: 0.046510\tAccuracy: 98.40%\n",
      "14\tValidation loss: 0.076196\tBest loss: 0.046510\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.077248\tBest loss: 0.046510\tAccuracy: 98.63%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\tValidation loss: 0.075855\tBest loss: 0.046510\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.070888\tBest loss: 0.046510\tAccuracy: 98.94%\n",
      "18\tValidation loss: 0.083190\tBest loss: 0.046510\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.076650\tBest loss: 0.046510\tAccuracy: 98.79%\n",
      "20\tValidation loss: 0.087988\tBest loss: 0.046510\tAccuracy: 98.36%\n",
      "21\tValidation loss: 0.077288\tBest loss: 0.046510\tAccuracy: 98.48%\n",
      "22\tValidation loss: 0.077805\tBest loss: 0.046510\tAccuracy: 98.32%\n",
      "23\tValidation loss: 0.108691\tBest loss: 0.046510\tAccuracy: 98.20%\n",
      "24\tValidation loss: 0.076149\tBest loss: 0.046510\tAccuracy: 98.48%\n",
      "25\tValidation loss: 0.060622\tBest loss: 0.046510\tAccuracy: 98.79%\n",
      "26\tValidation loss: 0.077019\tBest loss: 0.046510\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.096670\tBest loss: 0.046510\tAccuracy: 98.44%\n",
      "28\tValidation loss: 0.066196\tBest loss: 0.046510\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.084260\tBest loss: 0.046510\tAccuracy: 98.67%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function elu at 0x11591cd08>, total=  15.6s\n",
      "[CV] n_neurons=140, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.101471\tBest loss: 0.101471\tAccuracy: 96.64%\n",
      "1\tValidation loss: 0.065014\tBest loss: 0.065014\tAccuracy: 97.85%\n",
      "2\tValidation loss: 0.054181\tBest loss: 0.054181\tAccuracy: 98.16%\n",
      "3\tValidation loss: 0.052021\tBest loss: 0.052021\tAccuracy: 98.36%\n",
      "4\tValidation loss: 0.057642\tBest loss: 0.052021\tAccuracy: 98.24%\n",
      "5\tValidation loss: 0.047600\tBest loss: 0.047600\tAccuracy: 98.48%\n",
      "6\tValidation loss: 0.049659\tBest loss: 0.047600\tAccuracy: 98.71%\n",
      "7\tValidation loss: 0.052357\tBest loss: 0.047600\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.048218\tBest loss: 0.047600\tAccuracy: 98.36%\n",
      "9\tValidation loss: 0.066609\tBest loss: 0.047600\tAccuracy: 98.79%\n",
      "10\tValidation loss: 0.043630\tBest loss: 0.043630\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.079312\tBest loss: 0.043630\tAccuracy: 98.44%\n",
      "12\tValidation loss: 0.033469\tBest loss: 0.033469\tAccuracy: 99.06%\n",
      "13\tValidation loss: 0.040780\tBest loss: 0.033469\tAccuracy: 98.94%\n",
      "14\tValidation loss: 0.059562\tBest loss: 0.033469\tAccuracy: 98.75%\n",
      "15\tValidation loss: 0.048462\tBest loss: 0.033469\tAccuracy: 98.98%\n",
      "16\tValidation loss: 0.069632\tBest loss: 0.033469\tAccuracy: 98.63%\n",
      "17\tValidation loss: 0.074621\tBest loss: 0.033469\tAccuracy: 98.40%\n",
      "18\tValidation loss: 0.067623\tBest loss: 0.033469\tAccuracy: 98.59%\n",
      "19\tValidation loss: 0.041986\tBest loss: 0.033469\tAccuracy: 99.02%\n",
      "20\tValidation loss: 0.057137\tBest loss: 0.033469\tAccuracy: 99.10%\n",
      "21\tValidation loss: 0.066677\tBest loss: 0.033469\tAccuracy: 98.67%\n",
      "22\tValidation loss: 0.081944\tBest loss: 0.033469\tAccuracy: 98.36%\n",
      "23\tValidation loss: 0.077250\tBest loss: 0.033469\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.058221\tBest loss: 0.033469\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.041658\tBest loss: 0.033469\tAccuracy: 99.10%\n",
      "26\tValidation loss: 0.058611\tBest loss: 0.033469\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.079557\tBest loss: 0.033469\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.084434\tBest loss: 0.033469\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.084221\tBest loss: 0.033469\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.064680\tBest loss: 0.033469\tAccuracy: 98.98%\n",
      "31\tValidation loss: 0.088291\tBest loss: 0.033469\tAccuracy: 98.67%\n",
      "32\tValidation loss: 0.061489\tBest loss: 0.033469\tAccuracy: 99.14%\n",
      "33\tValidation loss: 0.116855\tBest loss: 0.033469\tAccuracy: 98.55%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function elu at 0x11591cd08>, total=  17.8s\n",
      "[CV] n_neurons=140, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.099426\tBest loss: 0.099426\tAccuracy: 96.83%\n",
      "1\tValidation loss: 0.061937\tBest loss: 0.061937\tAccuracy: 98.12%\n",
      "2\tValidation loss: 0.061499\tBest loss: 0.061499\tAccuracy: 98.24%\n",
      "3\tValidation loss: 0.042266\tBest loss: 0.042266\tAccuracy: 98.71%\n",
      "4\tValidation loss: 0.054780\tBest loss: 0.042266\tAccuracy: 98.44%\n",
      "5\tValidation loss: 0.049248\tBest loss: 0.042266\tAccuracy: 98.75%\n",
      "6\tValidation loss: 0.059810\tBest loss: 0.042266\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.046912\tBest loss: 0.042266\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.065510\tBest loss: 0.042266\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.053485\tBest loss: 0.042266\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.045914\tBest loss: 0.042266\tAccuracy: 99.06%\n",
      "11\tValidation loss: 0.065920\tBest loss: 0.042266\tAccuracy: 98.44%\n",
      "12\tValidation loss: 0.065350\tBest loss: 0.042266\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.077960\tBest loss: 0.042266\tAccuracy: 98.51%\n",
      "14\tValidation loss: 0.094252\tBest loss: 0.042266\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.068141\tBest loss: 0.042266\tAccuracy: 98.67%\n",
      "16\tValidation loss: 0.052205\tBest loss: 0.042266\tAccuracy: 98.75%\n",
      "17\tValidation loss: 0.071096\tBest loss: 0.042266\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.054652\tBest loss: 0.042266\tAccuracy: 99.06%\n",
      "19\tValidation loss: 0.063973\tBest loss: 0.042266\tAccuracy: 99.06%\n",
      "20\tValidation loss: 0.078665\tBest loss: 0.042266\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.074960\tBest loss: 0.042266\tAccuracy: 98.71%\n",
      "22\tValidation loss: 0.060575\tBest loss: 0.042266\tAccuracy: 98.71%\n",
      "23\tValidation loss: 0.055536\tBest loss: 0.042266\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.114111\tBest loss: 0.042266\tAccuracy: 98.51%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=3, learning_rate=0.01, batch_size=500, activation=<function elu at 0x11591cd08>, total=  13.7s\n",
      "[CV] n_neurons=140, n_hidden_layers=4, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.222839\tBest loss: 0.222839\tAccuracy: 94.25%\n",
      "1\tValidation loss: 1057.522095\tBest loss: 0.222839\tAccuracy: 94.21%\n",
      "2\tValidation loss: 436.648834\tBest loss: 0.222839\tAccuracy: 94.76%\n",
      "3\tValidation loss: 106.913437\tBest loss: 0.222839\tAccuracy: 94.10%\n",
      "4\tValidation loss: 47.812450\tBest loss: 0.222839\tAccuracy: 96.68%\n",
      "5\tValidation loss: 104.341576\tBest loss: 0.222839\tAccuracy: 96.17%\n",
      "6\tValidation loss: 51.866707\tBest loss: 0.222839\tAccuracy: 97.19%\n",
      "7\tValidation loss: 56.246181\tBest loss: 0.222839\tAccuracy: 96.25%\n",
      "8\tValidation loss: 30.737625\tBest loss: 0.222839\tAccuracy: 97.58%\n",
      "9\tValidation loss: 32.763554\tBest loss: 0.222839\tAccuracy: 97.38%\n",
      "10\tValidation loss: 51.420158\tBest loss: 0.222839\tAccuracy: 96.36%\n",
      "11\tValidation loss: 648.637939\tBest loss: 0.222839\tAccuracy: 94.76%\n",
      "12\tValidation loss: 2054.593994\tBest loss: 0.222839\tAccuracy: 97.03%\n",
      "13\tValidation loss: 1949.406616\tBest loss: 0.222839\tAccuracy: 97.19%\n",
      "14\tValidation loss: 844.781494\tBest loss: 0.222839\tAccuracy: 97.69%\n",
      "15\tValidation loss: 1249.389526\tBest loss: 0.222839\tAccuracy: 96.44%\n",
      "16\tValidation loss: 1519.581909\tBest loss: 0.222839\tAccuracy: 95.90%\n",
      "17\tValidation loss: 624.385864\tBest loss: 0.222839\tAccuracy: 97.69%\n",
      "18\tValidation loss: 838.685669\tBest loss: 0.222839\tAccuracy: 97.03%\n",
      "19\tValidation loss: 1082.843872\tBest loss: 0.222839\tAccuracy: 96.29%\n",
      "20\tValidation loss: 695.931641\tBest loss: 0.222839\tAccuracy: 97.81%\n",
      "21\tValidation loss: 589.294006\tBest loss: 0.222839\tAccuracy: 97.69%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=4, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  54.6s\n",
      "[CV] n_neurons=140, n_hidden_layers=4, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 867.388367\tBest loss: 867.388367\tAccuracy: 95.23%\n",
      "1\tValidation loss: 70.034531\tBest loss: 70.034531\tAccuracy: 95.47%\n",
      "2\tValidation loss: 31.693193\tBest loss: 31.693193\tAccuracy: 95.27%\n",
      "3\tValidation loss: 19.153282\tBest loss: 19.153282\tAccuracy: 95.70%\n",
      "4\tValidation loss: 16.820553\tBest loss: 16.820553\tAccuracy: 95.54%\n",
      "5\tValidation loss: 21.633560\tBest loss: 16.820553\tAccuracy: 94.96%\n",
      "6\tValidation loss: 21.185701\tBest loss: 16.820553\tAccuracy: 96.44%\n",
      "7\tValidation loss: 13.116753\tBest loss: 13.116753\tAccuracy: 96.33%\n",
      "8\tValidation loss: 16.391142\tBest loss: 13.116753\tAccuracy: 95.97%\n",
      "9\tValidation loss: 3559.731445\tBest loss: 13.116753\tAccuracy: 88.04%\n",
      "10\tValidation loss: 2456.153320\tBest loss: 13.116753\tAccuracy: 94.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\tValidation loss: 937.574890\tBest loss: 13.116753\tAccuracy: 95.97%\n",
      "12\tValidation loss: 434.385162\tBest loss: 13.116753\tAccuracy: 96.79%\n",
      "13\tValidation loss: 549.790161\tBest loss: 13.116753\tAccuracy: 97.19%\n",
      "14\tValidation loss: 341.048096\tBest loss: 13.116753\tAccuracy: 96.60%\n",
      "15\tValidation loss: 249.659943\tBest loss: 13.116753\tAccuracy: 97.42%\n",
      "16\tValidation loss: 375.104431\tBest loss: 13.116753\tAccuracy: 94.80%\n",
      "17\tValidation loss: 368.775940\tBest loss: 13.116753\tAccuracy: 97.11%\n",
      "18\tValidation loss: 368.942535\tBest loss: 13.116753\tAccuracy: 97.38%\n",
      "19\tValidation loss: 296.239624\tBest loss: 13.116753\tAccuracy: 97.38%\n",
      "20\tValidation loss: 1003.149841\tBest loss: 13.116753\tAccuracy: 97.58%\n",
      "21\tValidation loss: 184.544571\tBest loss: 13.116753\tAccuracy: 98.20%\n",
      "22\tValidation loss: 787.227600\tBest loss: 13.116753\tAccuracy: 97.81%\n",
      "23\tValidation loss: 370.003204\tBest loss: 13.116753\tAccuracy: 98.05%\n",
      "24\tValidation loss: 21498.730469\tBest loss: 13.116753\tAccuracy: 93.08%\n",
      "25\tValidation loss: 6283.419922\tBest loss: 13.116753\tAccuracy: 95.47%\n",
      "26\tValidation loss: 3379.895996\tBest loss: 13.116753\tAccuracy: 96.95%\n",
      "27\tValidation loss: 2069.116455\tBest loss: 13.116753\tAccuracy: 97.77%\n",
      "28\tValidation loss: 2403.322998\tBest loss: 13.116753\tAccuracy: 97.58%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=4, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 1.2min\n",
      "[CV] n_neurons=140, n_hidden_layers=4, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.133987\tBest loss: 0.133987\tAccuracy: 97.15%\n",
      "1\tValidation loss: 0.093427\tBest loss: 0.093427\tAccuracy: 97.46%\n",
      "2\tValidation loss: 850.094727\tBest loss: 0.093427\tAccuracy: 90.34%\n",
      "3\tValidation loss: 280.635071\tBest loss: 0.093427\tAccuracy: 92.69%\n",
      "4\tValidation loss: 149.832809\tBest loss: 0.093427\tAccuracy: 94.84%\n",
      "5\tValidation loss: 268.921814\tBest loss: 0.093427\tAccuracy: 94.14%\n",
      "6\tValidation loss: 185.548111\tBest loss: 0.093427\tAccuracy: 91.52%\n",
      "7\tValidation loss: 43.976597\tBest loss: 0.093427\tAccuracy: 96.99%\n",
      "8\tValidation loss: 59.324581\tBest loss: 0.093427\tAccuracy: 96.99%\n",
      "9\tValidation loss: 45.390156\tBest loss: 0.093427\tAccuracy: 96.48%\n",
      "10\tValidation loss: 156.064133\tBest loss: 0.093427\tAccuracy: 95.00%\n",
      "11\tValidation loss: 38.089024\tBest loss: 0.093427\tAccuracy: 96.21%\n",
      "12\tValidation loss: 27.878134\tBest loss: 0.093427\tAccuracy: 96.95%\n",
      "13\tValidation loss: 51.102329\tBest loss: 0.093427\tAccuracy: 94.80%\n",
      "14\tValidation loss: 75.065582\tBest loss: 0.093427\tAccuracy: 95.62%\n",
      "15\tValidation loss: 27.509993\tBest loss: 0.093427\tAccuracy: 97.42%\n",
      "16\tValidation loss: 33.042801\tBest loss: 0.093427\tAccuracy: 96.79%\n",
      "17\tValidation loss: 5900.899902\tBest loss: 0.093427\tAccuracy: 96.44%\n",
      "18\tValidation loss: 1884.600830\tBest loss: 0.093427\tAccuracy: 97.11%\n",
      "19\tValidation loss: 1813.679077\tBest loss: 0.093427\tAccuracy: 95.23%\n",
      "20\tValidation loss: 656.246094\tBest loss: 0.093427\tAccuracy: 97.62%\n",
      "21\tValidation loss: 715.490112\tBest loss: 0.093427\tAccuracy: 97.50%\n",
      "22\tValidation loss: 1423.753174\tBest loss: 0.093427\tAccuracy: 95.66%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=4, learning_rate=0.05, batch_size=50, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  57.3s\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 40.140434\tBest loss: 40.140434\tAccuracy: 95.07%\n",
      "1\tValidation loss: 29.589579\tBest loss: 29.589579\tAccuracy: 96.60%\n",
      "2\tValidation loss: 72.747162\tBest loss: 29.589579\tAccuracy: 96.87%\n",
      "3\tValidation loss: 114.867851\tBest loss: 29.589579\tAccuracy: 94.10%\n",
      "4\tValidation loss: 83.001122\tBest loss: 29.589579\tAccuracy: 96.99%\n",
      "5\tValidation loss: 95.979950\tBest loss: 29.589579\tAccuracy: 97.38%\n",
      "6\tValidation loss: 151.015930\tBest loss: 29.589579\tAccuracy: 97.22%\n",
      "7\tValidation loss: 124.508255\tBest loss: 29.589579\tAccuracy: 96.25%\n",
      "8\tValidation loss: 136.204941\tBest loss: 29.589579\tAccuracy: 98.12%\n",
      "9\tValidation loss: 156.458908\tBest loss: 29.589579\tAccuracy: 97.62%\n",
      "10\tValidation loss: 156.079575\tBest loss: 29.589579\tAccuracy: 97.69%\n",
      "11\tValidation loss: 102.667564\tBest loss: 29.589579\tAccuracy: 98.48%\n",
      "12\tValidation loss: 258.113007\tBest loss: 29.589579\tAccuracy: 97.22%\n",
      "13\tValidation loss: 202.749786\tBest loss: 29.589579\tAccuracy: 97.69%\n",
      "14\tValidation loss: 410.527374\tBest loss: 29.589579\tAccuracy: 97.97%\n",
      "15\tValidation loss: 262.937256\tBest loss: 29.589579\tAccuracy: 97.93%\n",
      "16\tValidation loss: 199.629593\tBest loss: 29.589579\tAccuracy: 97.85%\n",
      "17\tValidation loss: 376.442230\tBest loss: 29.589579\tAccuracy: 97.73%\n",
      "18\tValidation loss: 379.477020\tBest loss: 29.589579\tAccuracy: 98.20%\n",
      "19\tValidation loss: 412.027069\tBest loss: 29.589579\tAccuracy: 97.34%\n",
      "20\tValidation loss: 287.519409\tBest loss: 29.589579\tAccuracy: 98.12%\n",
      "21\tValidation loss: 401.858124\tBest loss: 29.589579\tAccuracy: 98.36%\n",
      "22\tValidation loss: 326.112793\tBest loss: 29.589579\tAccuracy: 98.20%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 2.3min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 32.293320\tBest loss: 32.293320\tAccuracy: 93.59%\n",
      "1\tValidation loss: 20.894821\tBest loss: 20.894821\tAccuracy: 97.77%\n",
      "2\tValidation loss: 54.111012\tBest loss: 20.894821\tAccuracy: 96.64%\n",
      "3\tValidation loss: 44.688904\tBest loss: 20.894821\tAccuracy: 96.99%\n",
      "4\tValidation loss: 104.891983\tBest loss: 20.894821\tAccuracy: 96.13%\n",
      "5\tValidation loss: 64.850983\tBest loss: 20.894821\tAccuracy: 97.15%\n",
      "6\tValidation loss: 103.796165\tBest loss: 20.894821\tAccuracy: 96.72%\n",
      "7\tValidation loss: 84.443367\tBest loss: 20.894821\tAccuracy: 98.16%\n",
      "8\tValidation loss: 106.258331\tBest loss: 20.894821\tAccuracy: 98.40%\n",
      "9\tValidation loss: 184.215408\tBest loss: 20.894821\tAccuracy: 97.15%\n",
      "10\tValidation loss: 109.259384\tBest loss: 20.894821\tAccuracy: 98.16%\n",
      "11\tValidation loss: 191.553467\tBest loss: 20.894821\tAccuracy: 97.77%\n",
      "12\tValidation loss: 260.061676\tBest loss: 20.894821\tAccuracy: 97.46%\n",
      "13\tValidation loss: 182.777435\tBest loss: 20.894821\tAccuracy: 97.73%\n",
      "14\tValidation loss: 317.015625\tBest loss: 20.894821\tAccuracy: 97.58%\n",
      "15\tValidation loss: 325.543976\tBest loss: 20.894821\tAccuracy: 97.69%\n",
      "16\tValidation loss: 182.615402\tBest loss: 20.894821\tAccuracy: 98.55%\n",
      "17\tValidation loss: 303.188690\tBest loss: 20.894821\tAccuracy: 98.20%\n",
      "18\tValidation loss: 247.974930\tBest loss: 20.894821\tAccuracy: 98.44%\n",
      "19\tValidation loss: 331.281128\tBest loss: 20.894821\tAccuracy: 98.40%\n",
      "20\tValidation loss: 323.563782\tBest loss: 20.894821\tAccuracy: 98.40%\n",
      "21\tValidation loss: 352.082092\tBest loss: 20.894821\tAccuracy: 98.16%\n",
      "22\tValidation loss: 382.103668\tBest loss: 20.894821\tAccuracy: 98.28%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 3.7min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 48.278915\tBest loss: 48.278915\tAccuracy: 95.54%\n",
      "1\tValidation loss: 57.021080\tBest loss: 48.278915\tAccuracy: 97.15%\n",
      "2\tValidation loss: 84.301308\tBest loss: 48.278915\tAccuracy: 95.62%\n",
      "3\tValidation loss: 36.882900\tBest loss: 36.882900\tAccuracy: 97.34%\n",
      "4\tValidation loss: 112.768890\tBest loss: 36.882900\tAccuracy: 96.72%\n",
      "5\tValidation loss: 97.193062\tBest loss: 36.882900\tAccuracy: 97.19%\n",
      "6\tValidation loss: 88.397690\tBest loss: 36.882900\tAccuracy: 96.87%\n",
      "7\tValidation loss: 153.131134\tBest loss: 36.882900\tAccuracy: 96.52%\n",
      "8\tValidation loss: 162.040314\tBest loss: 36.882900\tAccuracy: 97.11%\n",
      "9\tValidation loss: 101.072624\tBest loss: 36.882900\tAccuracy: 98.20%\n",
      "10\tValidation loss: 347.406830\tBest loss: 36.882900\tAccuracy: 95.00%\n",
      "11\tValidation loss: 230.456635\tBest loss: 36.882900\tAccuracy: 97.69%\n",
      "12\tValidation loss: 115.567604\tBest loss: 36.882900\tAccuracy: 98.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\tValidation loss: 149.100708\tBest loss: 36.882900\tAccuracy: 97.22%\n",
      "14\tValidation loss: 277.026917\tBest loss: 36.882900\tAccuracy: 96.56%\n",
      "15\tValidation loss: 227.614883\tBest loss: 36.882900\tAccuracy: 98.08%\n",
      "16\tValidation loss: 320.902191\tBest loss: 36.882900\tAccuracy: 97.73%\n",
      "17\tValidation loss: 247.287964\tBest loss: 36.882900\tAccuracy: 98.20%\n",
      "18\tValidation loss: 268.640259\tBest loss: 36.882900\tAccuracy: 98.16%\n",
      "19\tValidation loss: 314.046295\tBest loss: 36.882900\tAccuracy: 98.32%\n",
      "20\tValidation loss: 392.272186\tBest loss: 36.882900\tAccuracy: 98.16%\n",
      "21\tValidation loss: 307.532074\tBest loss: 36.882900\tAccuracy: 98.28%\n",
      "22\tValidation loss: 570.232666\tBest loss: 36.882900\tAccuracy: 98.71%\n",
      "23\tValidation loss: 494.465881\tBest loss: 36.882900\tAccuracy: 98.24%\n",
      "24\tValidation loss: 464.403839\tBest loss: 36.882900\tAccuracy: 98.20%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 2.5min\n",
      "[CV] n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 1.577904\tBest loss: 1.577904\tAccuracy: 69.39%\n",
      "1\tValidation loss: 66.465080\tBest loss: 1.577904\tAccuracy: 51.76%\n",
      "2\tValidation loss: 174.743408\tBest loss: 1.577904\tAccuracy: 70.52%\n",
      "3\tValidation loss: 92.160744\tBest loss: 1.577904\tAccuracy: 46.72%\n",
      "4\tValidation loss: 1265.631958\tBest loss: 1.577904\tAccuracy: 31.51%\n",
      "5\tValidation loss: 1573.037964\tBest loss: 1.577904\tAccuracy: 44.80%\n",
      "6\tValidation loss: 639.894775\tBest loss: 1.577904\tAccuracy: 46.21%\n",
      "7\tValidation loss: 336.775238\tBest loss: 1.577904\tAccuracy: 60.91%\n",
      "8\tValidation loss: 350.460510\tBest loss: 1.577904\tAccuracy: 44.18%\n",
      "9\tValidation loss: 86.713615\tBest loss: 1.577904\tAccuracy: 82.56%\n",
      "10\tValidation loss: 286.752777\tBest loss: 1.577904\tAccuracy: 56.29%\n",
      "11\tValidation loss: 224.901535\tBest loss: 1.577904\tAccuracy: 65.48%\n",
      "12\tValidation loss: 98.739151\tBest loss: 1.577904\tAccuracy: 65.13%\n",
      "13\tValidation loss: 138.093918\tBest loss: 1.577904\tAccuracy: 62.04%\n",
      "14\tValidation loss: 66.502480\tBest loss: 1.577904\tAccuracy: 86.28%\n",
      "15\tValidation loss: 79.180977\tBest loss: 1.577904\tAccuracy: 88.74%\n",
      "16\tValidation loss: 109.549438\tBest loss: 1.577904\tAccuracy: 76.58%\n",
      "17\tValidation loss: 225.294128\tBest loss: 1.577904\tAccuracy: 86.98%\n",
      "18\tValidation loss: 2286.705078\tBest loss: 1.577904\tAccuracy: 37.18%\n",
      "19\tValidation loss: 149.761627\tBest loss: 1.577904\tAccuracy: 89.37%\n",
      "20\tValidation loss: 136.210190\tBest loss: 1.577904\tAccuracy: 74.51%\n",
      "21\tValidation loss: 182.115738\tBest loss: 1.577904\tAccuracy: 88.08%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.5min\n",
      "[CV] n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 22.698193\tBest loss: 22.698193\tAccuracy: 58.64%\n",
      "1\tValidation loss: 262.312805\tBest loss: 22.698193\tAccuracy: 37.80%\n",
      "2\tValidation loss: 401.147583\tBest loss: 22.698193\tAccuracy: 20.21%\n",
      "3\tValidation loss: 877.547913\tBest loss: 22.698193\tAccuracy: 49.57%\n",
      "4\tValidation loss: 301.187469\tBest loss: 22.698193\tAccuracy: 50.63%\n",
      "5\tValidation loss: 889.927368\tBest loss: 22.698193\tAccuracy: 46.87%\n",
      "6\tValidation loss: 85.381325\tBest loss: 22.698193\tAccuracy: 74.63%\n",
      "7\tValidation loss: 2574.937012\tBest loss: 22.698193\tAccuracy: 44.37%\n",
      "8\tValidation loss: 115.519714\tBest loss: 22.698193\tAccuracy: 71.89%\n",
      "9\tValidation loss: 1340.946899\tBest loss: 22.698193\tAccuracy: 32.10%\n",
      "10\tValidation loss: 1295.179688\tBest loss: 22.698193\tAccuracy: 52.03%\n",
      "11\tValidation loss: 204.795715\tBest loss: 22.698193\tAccuracy: 74.98%\n",
      "12\tValidation loss: 750.889954\tBest loss: 22.698193\tAccuracy: 82.37%\n",
      "13\tValidation loss: 566.379028\tBest loss: 22.698193\tAccuracy: 73.92%\n",
      "14\tValidation loss: 8531.674805\tBest loss: 22.698193\tAccuracy: 89.91%\n",
      "15\tValidation loss: 10494.540039\tBest loss: 22.698193\tAccuracy: 88.90%\n",
      "16\tValidation loss: 9825.033203\tBest loss: 22.698193\tAccuracy: 93.86%\n",
      "17\tValidation loss: 2034.893433\tBest loss: 22.698193\tAccuracy: 72.13%\n",
      "18\tValidation loss: 484.170990\tBest loss: 22.698193\tAccuracy: 94.41%\n",
      "19\tValidation loss: 222.607574\tBest loss: 22.698193\tAccuracy: 95.23%\n",
      "20\tValidation loss: 5597.414062\tBest loss: 22.698193\tAccuracy: 64.35%\n",
      "21\tValidation loss: 437.796021\tBest loss: 22.698193\tAccuracy: 93.71%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.6min\n",
      "[CV] n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 102.525726\tBest loss: 102.525726\tAccuracy: 46.36%\n",
      "1\tValidation loss: 5.229733\tBest loss: 5.229733\tAccuracy: 52.54%\n",
      "2\tValidation loss: 3.218260\tBest loss: 3.218260\tAccuracy: 83.62%\n",
      "3\tValidation loss: 3.852249\tBest loss: 3.218260\tAccuracy: 73.49%\n",
      "4\tValidation loss: 25.152416\tBest loss: 3.218260\tAccuracy: 82.37%\n",
      "5\tValidation loss: 42.349686\tBest loss: 3.218260\tAccuracy: 86.28%\n",
      "6\tValidation loss: 62.438061\tBest loss: 3.218260\tAccuracy: 77.40%\n",
      "7\tValidation loss: 132.440063\tBest loss: 3.218260\tAccuracy: 80.22%\n",
      "8\tValidation loss: 187.178635\tBest loss: 3.218260\tAccuracy: 77.52%\n",
      "9\tValidation loss: 254.267838\tBest loss: 3.218260\tAccuracy: 88.00%\n",
      "10\tValidation loss: 202.511871\tBest loss: 3.218260\tAccuracy: 78.81%\n",
      "11\tValidation loss: 351.410797\tBest loss: 3.218260\tAccuracy: 92.61%\n",
      "12\tValidation loss: 421.961700\tBest loss: 3.218260\tAccuracy: 75.61%\n",
      "13\tValidation loss: 2913.268066\tBest loss: 3.218260\tAccuracy: 75.61%\n",
      "14\tValidation loss: 220.860382\tBest loss: 3.218260\tAccuracy: 93.08%\n",
      "15\tValidation loss: 18348.277344\tBest loss: 3.218260\tAccuracy: 89.52%\n",
      "16\tValidation loss: 268.407440\tBest loss: 3.218260\tAccuracy: 94.64%\n",
      "17\tValidation loss: 594.752625\tBest loss: 3.218260\tAccuracy: 93.75%\n",
      "18\tValidation loss: 686.550598\tBest loss: 3.218260\tAccuracy: 88.31%\n",
      "19\tValidation loss: 1047.001709\tBest loss: 3.218260\tAccuracy: 95.43%\n",
      "20\tValidation loss: 818.817322\tBest loss: 3.218260\tAccuracy: 95.15%\n",
      "21\tValidation loss: 1348.413452\tBest loss: 3.218260\tAccuracy: 94.64%\n",
      "22\tValidation loss: 3900.913330\tBest loss: 3.218260\tAccuracy: 92.65%\n",
      "23\tValidation loss: 815.809082\tBest loss: 3.218260\tAccuracy: 96.05%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=4, learning_rate=0.05, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total= 2.9min\n",
      "[CV] n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.355155\tBest loss: 0.355155\tAccuracy: 93.90%\n",
      "1\tValidation loss: 6.322132\tBest loss: 0.355155\tAccuracy: 94.33%\n",
      "2\tValidation loss: 1.325297\tBest loss: 0.355155\tAccuracy: 95.27%\n",
      "3\tValidation loss: 2.071316\tBest loss: 0.355155\tAccuracy: 83.19%\n",
      "4\tValidation loss: 5.203337\tBest loss: 0.355155\tAccuracy: 94.68%\n",
      "5\tValidation loss: 1.539217\tBest loss: 0.355155\tAccuracy: 96.87%\n",
      "6\tValidation loss: 5.562440\tBest loss: 0.355155\tAccuracy: 96.64%\n",
      "7\tValidation loss: 2.087723\tBest loss: 0.355155\tAccuracy: 95.70%\n",
      "8\tValidation loss: 1.508896\tBest loss: 0.355155\tAccuracy: 95.78%\n",
      "9\tValidation loss: 31.454584\tBest loss: 0.355155\tAccuracy: 96.83%\n",
      "10\tValidation loss: 7.527715\tBest loss: 0.355155\tAccuracy: 96.29%\n",
      "11\tValidation loss: 4.165250\tBest loss: 0.355155\tAccuracy: 96.99%\n",
      "12\tValidation loss: 2.804184\tBest loss: 0.355155\tAccuracy: 97.42%\n",
      "13\tValidation loss: 6.513744\tBest loss: 0.355155\tAccuracy: 97.07%\n",
      "14\tValidation loss: 28.012314\tBest loss: 0.355155\tAccuracy: 96.87%\n",
      "15\tValidation loss: 6.351726\tBest loss: 0.355155\tAccuracy: 98.01%\n",
      "16\tValidation loss: 40.079113\tBest loss: 0.355155\tAccuracy: 97.73%\n",
      "17\tValidation loss: 6.872317\tBest loss: 0.355155\tAccuracy: 97.97%\n",
      "18\tValidation loss: 29.814817\tBest loss: 0.355155\tAccuracy: 96.52%\n",
      "19\tValidation loss: 17.985920\tBest loss: 0.355155\tAccuracy: 96.60%\n",
      "20\tValidation loss: 33.941563\tBest loss: 0.355155\tAccuracy: 97.11%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\tValidation loss: 10.739359\tBest loss: 0.355155\tAccuracy: 97.81%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 3.4min\n",
      "[CV] n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.795707\tBest loss: 0.795707\tAccuracy: 92.77%\n",
      "1\tValidation loss: 0.129703\tBest loss: 0.129703\tAccuracy: 97.07%\n",
      "2\tValidation loss: 2.273809\tBest loss: 0.129703\tAccuracy: 94.96%\n",
      "3\tValidation loss: 1.453610\tBest loss: 0.129703\tAccuracy: 95.54%\n",
      "4\tValidation loss: 0.821984\tBest loss: 0.129703\tAccuracy: 97.07%\n",
      "5\tValidation loss: 1.564268\tBest loss: 0.129703\tAccuracy: 96.33%\n",
      "6\tValidation loss: 4.256584\tBest loss: 0.129703\tAccuracy: 90.70%\n",
      "7\tValidation loss: 4.287102\tBest loss: 0.129703\tAccuracy: 96.64%\n",
      "8\tValidation loss: 1.397358\tBest loss: 0.129703\tAccuracy: 97.54%\n",
      "9\tValidation loss: 0.891933\tBest loss: 0.129703\tAccuracy: 97.50%\n",
      "10\tValidation loss: 9.317422\tBest loss: 0.129703\tAccuracy: 96.72%\n",
      "11\tValidation loss: 3.427190\tBest loss: 0.129703\tAccuracy: 98.08%\n",
      "12\tValidation loss: 12.497323\tBest loss: 0.129703\tAccuracy: 97.34%\n",
      "13\tValidation loss: 5.420619\tBest loss: 0.129703\tAccuracy: 97.85%\n",
      "14\tValidation loss: 12.262768\tBest loss: 0.129703\tAccuracy: 96.33%\n",
      "15\tValidation loss: 12.163407\tBest loss: 0.129703\tAccuracy: 97.46%\n",
      "16\tValidation loss: 3.603588\tBest loss: 0.129703\tAccuracy: 97.93%\n",
      "17\tValidation loss: 15.962962\tBest loss: 0.129703\tAccuracy: 94.33%\n",
      "18\tValidation loss: 21.009567\tBest loss: 0.129703\tAccuracy: 97.89%\n",
      "19\tValidation loss: 11.427223\tBest loss: 0.129703\tAccuracy: 98.36%\n",
      "20\tValidation loss: 59.397160\tBest loss: 0.129703\tAccuracy: 95.66%\n",
      "21\tValidation loss: 12.037967\tBest loss: 0.129703\tAccuracy: 97.89%\n",
      "22\tValidation loss: 91.973183\tBest loss: 0.129703\tAccuracy: 98.16%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 3.6min\n",
      "[CV] n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.127829\tBest loss: 0.127829\tAccuracy: 97.07%\n",
      "1\tValidation loss: 0.131093\tBest loss: 0.127829\tAccuracy: 96.95%\n",
      "2\tValidation loss: 1.494265\tBest loss: 0.127829\tAccuracy: 93.51%\n",
      "3\tValidation loss: 0.592656\tBest loss: 0.127829\tAccuracy: 96.79%\n",
      "4\tValidation loss: 18.359755\tBest loss: 0.127829\tAccuracy: 94.68%\n",
      "5\tValidation loss: 8.325409\tBest loss: 0.127829\tAccuracy: 96.40%\n",
      "6\tValidation loss: 2.720190\tBest loss: 0.127829\tAccuracy: 96.17%\n",
      "7\tValidation loss: 9.478108\tBest loss: 0.127829\tAccuracy: 95.82%\n",
      "8\tValidation loss: 4.750968\tBest loss: 0.127829\tAccuracy: 96.76%\n",
      "9\tValidation loss: 2.974990\tBest loss: 0.127829\tAccuracy: 97.62%\n",
      "10\tValidation loss: 6.757547\tBest loss: 0.127829\tAccuracy: 96.17%\n",
      "11\tValidation loss: 6.241539\tBest loss: 0.127829\tAccuracy: 96.21%\n",
      "12\tValidation loss: 4.631672\tBest loss: 0.127829\tAccuracy: 96.83%\n",
      "13\tValidation loss: 10.513198\tBest loss: 0.127829\tAccuracy: 96.91%\n",
      "14\tValidation loss: 11.333461\tBest loss: 0.127829\tAccuracy: 97.73%\n",
      "15\tValidation loss: 21.855032\tBest loss: 0.127829\tAccuracy: 96.05%\n",
      "16\tValidation loss: 9.712959\tBest loss: 0.127829\tAccuracy: 97.54%\n",
      "17\tValidation loss: 9.404391\tBest loss: 0.127829\tAccuracy: 97.30%\n",
      "18\tValidation loss: 8.933810\tBest loss: 0.127829\tAccuracy: 98.16%\n",
      "19\tValidation loss: 39.819157\tBest loss: 0.127829\tAccuracy: 96.36%\n",
      "20\tValidation loss: 10.879770\tBest loss: 0.127829\tAccuracy: 97.93%\n",
      "21\tValidation loss: 12.053096\tBest loss: 0.127829\tAccuracy: 97.77%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=4, learning_rate=0.01, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 3.4min\n",
      "[CV] n_neurons=70, n_hidden_layers=5, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.105126\tBest loss: 0.105126\tAccuracy: 96.72%\n",
      "1\tValidation loss: 0.060075\tBest loss: 0.060075\tAccuracy: 98.12%\n",
      "2\tValidation loss: 0.074691\tBest loss: 0.060075\tAccuracy: 97.58%\n",
      "3\tValidation loss: 0.076317\tBest loss: 0.060075\tAccuracy: 98.08%\n",
      "4\tValidation loss: 0.055252\tBest loss: 0.055252\tAccuracy: 98.24%\n",
      "5\tValidation loss: 0.053853\tBest loss: 0.053853\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.093640\tBest loss: 0.053853\tAccuracy: 97.69%\n",
      "7\tValidation loss: 0.048998\tBest loss: 0.048998\tAccuracy: 98.63%\n",
      "8\tValidation loss: 0.055375\tBest loss: 0.048998\tAccuracy: 98.71%\n",
      "9\tValidation loss: 0.060768\tBest loss: 0.048998\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.052324\tBest loss: 0.048998\tAccuracy: 98.83%\n",
      "11\tValidation loss: 0.063499\tBest loss: 0.048998\tAccuracy: 98.83%\n",
      "12\tValidation loss: 0.061750\tBest loss: 0.048998\tAccuracy: 98.40%\n",
      "13\tValidation loss: 0.053238\tBest loss: 0.048998\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.066391\tBest loss: 0.048998\tAccuracy: 98.67%\n",
      "15\tValidation loss: 0.061330\tBest loss: 0.048998\tAccuracy: 98.91%\n",
      "16\tValidation loss: 0.048341\tBest loss: 0.048341\tAccuracy: 99.06%\n",
      "17\tValidation loss: 0.061418\tBest loss: 0.048341\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.086446\tBest loss: 0.048341\tAccuracy: 98.75%\n",
      "19\tValidation loss: 0.047604\tBest loss: 0.047604\tAccuracy: 99.02%\n",
      "20\tValidation loss: 0.052545\tBest loss: 0.047604\tAccuracy: 99.10%\n",
      "21\tValidation loss: 0.064487\tBest loss: 0.047604\tAccuracy: 98.98%\n",
      "22\tValidation loss: 0.050600\tBest loss: 0.047604\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.083870\tBest loss: 0.047604\tAccuracy: 98.67%\n",
      "24\tValidation loss: 0.070444\tBest loss: 0.047604\tAccuracy: 98.59%\n",
      "25\tValidation loss: 0.063007\tBest loss: 0.047604\tAccuracy: 98.87%\n",
      "26\tValidation loss: 0.079826\tBest loss: 0.047604\tAccuracy: 98.79%\n",
      "27\tValidation loss: 0.077746\tBest loss: 0.047604\tAccuracy: 98.71%\n",
      "28\tValidation loss: 0.061134\tBest loss: 0.047604\tAccuracy: 98.94%\n",
      "29\tValidation loss: 0.074591\tBest loss: 0.047604\tAccuracy: 98.32%\n",
      "30\tValidation loss: 0.065250\tBest loss: 0.047604\tAccuracy: 98.87%\n",
      "31\tValidation loss: 0.063467\tBest loss: 0.047604\tAccuracy: 98.79%\n",
      "32\tValidation loss: 0.064615\tBest loss: 0.047604\tAccuracy: 98.83%\n",
      "33\tValidation loss: 0.067223\tBest loss: 0.047604\tAccuracy: 98.94%\n",
      "34\tValidation loss: 0.091227\tBest loss: 0.047604\tAccuracy: 98.83%\n",
      "35\tValidation loss: 0.058575\tBest loss: 0.047604\tAccuracy: 99.02%\n",
      "36\tValidation loss: 0.082573\tBest loss: 0.047604\tAccuracy: 98.71%\n",
      "37\tValidation loss: 0.075306\tBest loss: 0.047604\tAccuracy: 98.83%\n",
      "38\tValidation loss: 0.069367\tBest loss: 0.047604\tAccuracy: 98.48%\n",
      "39\tValidation loss: 0.059471\tBest loss: 0.047604\tAccuracy: 98.51%\n",
      "40\tValidation loss: 0.063305\tBest loss: 0.047604\tAccuracy: 98.94%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=5, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  29.0s\n",
      "[CV] n_neurons=70, n_hidden_layers=5, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.108532\tBest loss: 0.108532\tAccuracy: 96.48%\n",
      "1\tValidation loss: 0.071216\tBest loss: 0.071216\tAccuracy: 97.93%\n",
      "2\tValidation loss: 0.059029\tBest loss: 0.059029\tAccuracy: 98.24%\n",
      "3\tValidation loss: 0.065873\tBest loss: 0.059029\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.057648\tBest loss: 0.057648\tAccuracy: 98.24%\n",
      "5\tValidation loss: 0.052622\tBest loss: 0.052622\tAccuracy: 98.36%\n",
      "6\tValidation loss: 0.046660\tBest loss: 0.046660\tAccuracy: 98.51%\n",
      "7\tValidation loss: 0.041140\tBest loss: 0.041140\tAccuracy: 98.83%\n",
      "8\tValidation loss: 0.051379\tBest loss: 0.041140\tAccuracy: 98.44%\n",
      "9\tValidation loss: 0.079523\tBest loss: 0.041140\tAccuracy: 98.44%\n",
      "10\tValidation loss: 0.068041\tBest loss: 0.041140\tAccuracy: 98.28%\n",
      "11\tValidation loss: 0.054907\tBest loss: 0.041140\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.050214\tBest loss: 0.041140\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.056092\tBest loss: 0.041140\tAccuracy: 98.79%\n",
      "14\tValidation loss: 0.078313\tBest loss: 0.041140\tAccuracy: 98.44%\n",
      "15\tValidation loss: 0.068632\tBest loss: 0.041140\tAccuracy: 98.67%\n",
      "16\tValidation loss: 0.066338\tBest loss: 0.041140\tAccuracy: 98.48%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\tValidation loss: 0.049891\tBest loss: 0.041140\tAccuracy: 98.98%\n",
      "18\tValidation loss: 0.056952\tBest loss: 0.041140\tAccuracy: 98.36%\n",
      "19\tValidation loss: 0.074032\tBest loss: 0.041140\tAccuracy: 98.40%\n",
      "20\tValidation loss: 0.073560\tBest loss: 0.041140\tAccuracy: 98.75%\n",
      "21\tValidation loss: 0.057333\tBest loss: 0.041140\tAccuracy: 98.67%\n",
      "22\tValidation loss: 0.051310\tBest loss: 0.041140\tAccuracy: 98.94%\n",
      "23\tValidation loss: 0.078373\tBest loss: 0.041140\tAccuracy: 98.63%\n",
      "24\tValidation loss: 0.054461\tBest loss: 0.041140\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.063005\tBest loss: 0.041140\tAccuracy: 98.48%\n",
      "26\tValidation loss: 0.074449\tBest loss: 0.041140\tAccuracy: 98.87%\n",
      "27\tValidation loss: 0.055398\tBest loss: 0.041140\tAccuracy: 98.87%\n",
      "28\tValidation loss: 0.068957\tBest loss: 0.041140\tAccuracy: 98.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=5, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  22.0s\n",
      "[CV] n_neurons=70, n_hidden_layers=5, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.096820\tBest loss: 0.096820\tAccuracy: 97.19%\n",
      "1\tValidation loss: 0.069583\tBest loss: 0.069583\tAccuracy: 98.16%\n",
      "2\tValidation loss: 0.058646\tBest loss: 0.058646\tAccuracy: 98.08%\n",
      "3\tValidation loss: 0.065706\tBest loss: 0.058646\tAccuracy: 98.44%\n",
      "4\tValidation loss: 0.050510\tBest loss: 0.050510\tAccuracy: 98.32%\n",
      "5\tValidation loss: 0.059459\tBest loss: 0.050510\tAccuracy: 98.12%\n",
      "6\tValidation loss: 0.046991\tBest loss: 0.046991\tAccuracy: 98.63%\n",
      "7\tValidation loss: 0.085116\tBest loss: 0.046991\tAccuracy: 97.77%\n",
      "8\tValidation loss: 0.061159\tBest loss: 0.046991\tAccuracy: 98.48%\n",
      "9\tValidation loss: 0.056580\tBest loss: 0.046991\tAccuracy: 98.40%\n",
      "10\tValidation loss: 0.070341\tBest loss: 0.046991\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.051772\tBest loss: 0.046991\tAccuracy: 98.79%\n",
      "12\tValidation loss: 0.047919\tBest loss: 0.046991\tAccuracy: 98.75%\n",
      "13\tValidation loss: 0.067938\tBest loss: 0.046991\tAccuracy: 98.36%\n",
      "14\tValidation loss: 0.056707\tBest loss: 0.046991\tAccuracy: 98.71%\n",
      "15\tValidation loss: 0.060910\tBest loss: 0.046991\tAccuracy: 98.71%\n",
      "16\tValidation loss: 0.057876\tBest loss: 0.046991\tAccuracy: 98.91%\n",
      "17\tValidation loss: 0.076699\tBest loss: 0.046991\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.070166\tBest loss: 0.046991\tAccuracy: 98.32%\n",
      "19\tValidation loss: 0.057925\tBest loss: 0.046991\tAccuracy: 98.59%\n",
      "20\tValidation loss: 0.061634\tBest loss: 0.046991\tAccuracy: 98.28%\n",
      "21\tValidation loss: 0.058833\tBest loss: 0.046991\tAccuracy: 98.79%\n",
      "22\tValidation loss: 0.067693\tBest loss: 0.046991\tAccuracy: 98.79%\n",
      "23\tValidation loss: 0.059183\tBest loss: 0.046991\tAccuracy: 99.02%\n",
      "24\tValidation loss: 0.054341\tBest loss: 0.046991\tAccuracy: 99.02%\n",
      "25\tValidation loss: 0.072094\tBest loss: 0.046991\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.063065\tBest loss: 0.046991\tAccuracy: 98.71%\n",
      "27\tValidation loss: 0.112772\tBest loss: 0.046991\tAccuracy: 98.63%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=5, learning_rate=0.01, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total=  20.7s\n",
      "[CV] n_neurons=160, n_hidden_layers=5, learning_rate=0.02, batch_size=500, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.168342\tBest loss: 0.168342\tAccuracy: 95.43%\n",
      "1\tValidation loss: 0.097602\tBest loss: 0.097602\tAccuracy: 97.46%\n",
      "2\tValidation loss: 0.088891\tBest loss: 0.088891\tAccuracy: 97.77%\n",
      "3\tValidation loss: 0.085287\tBest loss: 0.085287\tAccuracy: 97.26%\n",
      "4\tValidation loss: 0.066243\tBest loss: 0.066243\tAccuracy: 98.05%\n",
      "5\tValidation loss: 0.075444\tBest loss: 0.066243\tAccuracy: 98.01%\n",
      "6\tValidation loss: 0.068942\tBest loss: 0.066243\tAccuracy: 98.28%\n",
      "7\tValidation loss: 0.072900\tBest loss: 0.066243\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.069097\tBest loss: 0.066243\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.065353\tBest loss: 0.065353\tAccuracy: 97.93%\n",
      "10\tValidation loss: 0.069856\tBest loss: 0.065353\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.093613\tBest loss: 0.065353\tAccuracy: 98.08%\n",
      "12\tValidation loss: 0.086435\tBest loss: 0.065353\tAccuracy: 97.93%\n",
      "13\tValidation loss: 0.069889\tBest loss: 0.065353\tAccuracy: 98.48%\n",
      "14\tValidation loss: 0.068611\tBest loss: 0.065353\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.085774\tBest loss: 0.065353\tAccuracy: 98.24%\n",
      "16\tValidation loss: 0.065195\tBest loss: 0.065195\tAccuracy: 98.48%\n",
      "17\tValidation loss: 0.072720\tBest loss: 0.065195\tAccuracy: 98.16%\n",
      "18\tValidation loss: 0.072305\tBest loss: 0.065195\tAccuracy: 98.55%\n",
      "19\tValidation loss: 0.068971\tBest loss: 0.065195\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.087181\tBest loss: 0.065195\tAccuracy: 98.24%\n",
      "21\tValidation loss: 0.094045\tBest loss: 0.065195\tAccuracy: 98.40%\n",
      "22\tValidation loss: 0.065820\tBest loss: 0.065195\tAccuracy: 98.51%\n",
      "23\tValidation loss: 0.072832\tBest loss: 0.065195\tAccuracy: 98.32%\n",
      "24\tValidation loss: 0.093665\tBest loss: 0.065195\tAccuracy: 97.85%\n",
      "25\tValidation loss: 0.092499\tBest loss: 0.065195\tAccuracy: 98.36%\n",
      "26\tValidation loss: 0.077060\tBest loss: 0.065195\tAccuracy: 98.75%\n",
      "27\tValidation loss: 0.775860\tBest loss: 0.065195\tAccuracy: 69.82%\n",
      "28\tValidation loss: 0.761458\tBest loss: 0.065195\tAccuracy: 82.96%\n",
      "29\tValidation loss: 1.834926\tBest loss: 0.065195\tAccuracy: 65.36%\n",
      "30\tValidation loss: 1.372301\tBest loss: 0.065195\tAccuracy: 76.97%\n",
      "31\tValidation loss: 0.473535\tBest loss: 0.065195\tAccuracy: 87.45%\n",
      "32\tValidation loss: 0.415507\tBest loss: 0.065195\tAccuracy: 92.30%\n",
      "33\tValidation loss: 0.254163\tBest loss: 0.065195\tAccuracy: 92.65%\n",
      "34\tValidation loss: 0.309660\tBest loss: 0.065195\tAccuracy: 92.30%\n",
      "35\tValidation loss: 0.300225\tBest loss: 0.065195\tAccuracy: 92.85%\n",
      "36\tValidation loss: 0.380193\tBest loss: 0.065195\tAccuracy: 93.75%\n",
      "37\tValidation loss: 0.220424\tBest loss: 0.065195\tAccuracy: 94.41%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=5, learning_rate=0.02, batch_size=500, activation=<function relu at 0x117f566a8>, total=  23.7s\n",
      "[CV] n_neurons=160, n_hidden_layers=5, learning_rate=0.02, batch_size=500, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.133673\tBest loss: 0.133673\tAccuracy: 95.97%\n",
      "1\tValidation loss: 0.087266\tBest loss: 0.087266\tAccuracy: 97.30%\n",
      "2\tValidation loss: 0.075486\tBest loss: 0.075486\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.071531\tBest loss: 0.071531\tAccuracy: 97.77%\n",
      "4\tValidation loss: 0.074782\tBest loss: 0.071531\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.083347\tBest loss: 0.071531\tAccuracy: 97.58%\n",
      "6\tValidation loss: 0.071696\tBest loss: 0.071531\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.072287\tBest loss: 0.071531\tAccuracy: 97.89%\n",
      "8\tValidation loss: 0.066738\tBest loss: 0.066738\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.088369\tBest loss: 0.066738\tAccuracy: 97.73%\n",
      "10\tValidation loss: 0.063942\tBest loss: 0.063942\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.061313\tBest loss: 0.061313\tAccuracy: 98.28%\n",
      "12\tValidation loss: 0.076141\tBest loss: 0.061313\tAccuracy: 97.93%\n",
      "13\tValidation loss: 0.073916\tBest loss: 0.061313\tAccuracy: 98.08%\n",
      "14\tValidation loss: 0.079537\tBest loss: 0.061313\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.089717\tBest loss: 0.061313\tAccuracy: 98.08%\n",
      "16\tValidation loss: 0.080997\tBest loss: 0.061313\tAccuracy: 98.28%\n",
      "17\tValidation loss: 0.071069\tBest loss: 0.061313\tAccuracy: 98.36%\n",
      "18\tValidation loss: 0.076052\tBest loss: 0.061313\tAccuracy: 98.51%\n",
      "19\tValidation loss: 0.077783\tBest loss: 0.061313\tAccuracy: 98.28%\n",
      "20\tValidation loss: 0.078700\tBest loss: 0.061313\tAccuracy: 98.32%\n",
      "21\tValidation loss: 0.083007\tBest loss: 0.061313\tAccuracy: 98.36%\n",
      "22\tValidation loss: 0.099804\tBest loss: 0.061313\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.108701\tBest loss: 0.061313\tAccuracy: 98.40%\n",
      "24\tValidation loss: 0.150582\tBest loss: 0.061313\tAccuracy: 97.97%\n",
      "25\tValidation loss: 0.757162\tBest loss: 0.061313\tAccuracy: 92.30%\n",
      "26\tValidation loss: 0.548065\tBest loss: 0.061313\tAccuracy: 86.36%\n",
      "27\tValidation loss: 0.446861\tBest loss: 0.061313\tAccuracy: 91.71%\n",
      "28\tValidation loss: 1.057769\tBest loss: 0.061313\tAccuracy: 90.62%\n",
      "29\tValidation loss: 0.744787\tBest loss: 0.061313\tAccuracy: 73.65%\n",
      "30\tValidation loss: 0.710464\tBest loss: 0.061313\tAccuracy: 77.48%\n",
      "31\tValidation loss: 0.599133\tBest loss: 0.061313\tAccuracy: 77.44%\n",
      "32\tValidation loss: 0.422057\tBest loss: 0.061313\tAccuracy: 78.42%\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neurons=160, n_hidden_layers=5, learning_rate=0.02, batch_size=500, activation=<function relu at 0x117f566a8>, total=  20.6s\n",
      "[CV] n_neurons=160, n_hidden_layers=5, learning_rate=0.02, batch_size=500, activation=<function relu at 0x117f566a8> \n",
      "0\tValidation loss: 0.203552\tBest loss: 0.203552\tAccuracy: 94.33%\n",
      "1\tValidation loss: 0.089378\tBest loss: 0.089378\tAccuracy: 97.38%\n",
      "2\tValidation loss: 0.076377\tBest loss: 0.076377\tAccuracy: 97.77%\n",
      "3\tValidation loss: 0.077040\tBest loss: 0.076377\tAccuracy: 97.89%\n",
      "4\tValidation loss: 0.063292\tBest loss: 0.063292\tAccuracy: 97.77%\n",
      "5\tValidation loss: 0.058091\tBest loss: 0.058091\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.058549\tBest loss: 0.058091\tAccuracy: 98.16%\n",
      "7\tValidation loss: 0.075767\tBest loss: 0.058091\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.076593\tBest loss: 0.058091\tAccuracy: 97.97%\n",
      "9\tValidation loss: 0.058433\tBest loss: 0.058091\tAccuracy: 98.51%\n",
      "10\tValidation loss: 0.062760\tBest loss: 0.058091\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.064922\tBest loss: 0.058091\tAccuracy: 98.40%\n",
      "12\tValidation loss: 0.060802\tBest loss: 0.058091\tAccuracy: 98.36%\n",
      "13\tValidation loss: 0.060299\tBest loss: 0.058091\tAccuracy: 98.48%\n",
      "14\tValidation loss: 0.071047\tBest loss: 0.058091\tAccuracy: 97.85%\n",
      "15\tValidation loss: 0.055718\tBest loss: 0.055718\tAccuracy: 98.44%\n",
      "16\tValidation loss: 0.070275\tBest loss: 0.055718\tAccuracy: 98.36%\n",
      "17\tValidation loss: 0.230022\tBest loss: 0.055718\tAccuracy: 96.33%\n",
      "18\tValidation loss: 0.127083\tBest loss: 0.055718\tAccuracy: 98.08%\n",
      "19\tValidation loss: 0.087007\tBest loss: 0.055718\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.074125\tBest loss: 0.055718\tAccuracy: 98.16%\n",
      "21\tValidation loss: 0.072349\tBest loss: 0.055718\tAccuracy: 98.36%\n",
      "22\tValidation loss: 0.069635\tBest loss: 0.055718\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.064362\tBest loss: 0.055718\tAccuracy: 98.44%\n",
      "24\tValidation loss: 0.079507\tBest loss: 0.055718\tAccuracy: 98.28%\n",
      "25\tValidation loss: 0.101490\tBest loss: 0.055718\tAccuracy: 97.89%\n",
      "26\tValidation loss: 0.070882\tBest loss: 0.055718\tAccuracy: 98.32%\n",
      "27\tValidation loss: 0.071160\tBest loss: 0.055718\tAccuracy: 98.48%\n",
      "28\tValidation loss: 0.080484\tBest loss: 0.055718\tAccuracy: 98.44%\n",
      "29\tValidation loss: 0.084741\tBest loss: 0.055718\tAccuracy: 98.48%\n",
      "30\tValidation loss: 0.102541\tBest loss: 0.055718\tAccuracy: 98.63%\n",
      "31\tValidation loss: 0.112493\tBest loss: 0.055718\tAccuracy: 98.55%\n",
      "32\tValidation loss: 0.080938\tBest loss: 0.055718\tAccuracy: 98.71%\n",
      "33\tValidation loss: 0.104604\tBest loss: 0.055718\tAccuracy: 98.01%\n",
      "34\tValidation loss: 0.105397\tBest loss: 0.055718\tAccuracy: 98.12%\n",
      "35\tValidation loss: 0.100819\tBest loss: 0.055718\tAccuracy: 98.20%\n",
      "36\tValidation loss: 0.098690\tBest loss: 0.055718\tAccuracy: 98.44%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=5, learning_rate=0.02, batch_size=500, activation=<function relu at 0x117f566a8>, total=  23.3s\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.332177\tBest loss: 0.332177\tAccuracy: 95.04%\n",
      "1\tValidation loss: 0.183019\tBest loss: 0.183019\tAccuracy: 96.13%\n",
      "2\tValidation loss: 0.444013\tBest loss: 0.183019\tAccuracy: 94.21%\n",
      "3\tValidation loss: 0.127196\tBest loss: 0.127196\tAccuracy: 97.85%\n",
      "4\tValidation loss: 0.148040\tBest loss: 0.127196\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.260570\tBest loss: 0.127196\tAccuracy: 98.40%\n",
      "6\tValidation loss: 0.165905\tBest loss: 0.127196\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.166452\tBest loss: 0.127196\tAccuracy: 98.08%\n",
      "8\tValidation loss: 1.039513\tBest loss: 0.127196\tAccuracy: 98.20%\n",
      "9\tValidation loss: 0.260355\tBest loss: 0.127196\tAccuracy: 97.89%\n",
      "10\tValidation loss: 0.412861\tBest loss: 0.127196\tAccuracy: 97.65%\n",
      "11\tValidation loss: 0.379054\tBest loss: 0.127196\tAccuracy: 98.08%\n",
      "12\tValidation loss: 0.119352\tBest loss: 0.119352\tAccuracy: 98.59%\n",
      "13\tValidation loss: 0.558753\tBest loss: 0.119352\tAccuracy: 94.92%\n",
      "14\tValidation loss: 0.309762\tBest loss: 0.119352\tAccuracy: 96.64%\n",
      "15\tValidation loss: 0.410777\tBest loss: 0.119352\tAccuracy: 98.08%\n",
      "16\tValidation loss: 0.359846\tBest loss: 0.119352\tAccuracy: 98.08%\n",
      "17\tValidation loss: 0.423178\tBest loss: 0.119352\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.461329\tBest loss: 0.119352\tAccuracy: 97.30%\n",
      "19\tValidation loss: 0.419699\tBest loss: 0.119352\tAccuracy: 98.12%\n",
      "20\tValidation loss: 0.508648\tBest loss: 0.119352\tAccuracy: 98.48%\n",
      "21\tValidation loss: 0.767649\tBest loss: 0.119352\tAccuracy: 98.05%\n",
      "22\tValidation loss: 0.696333\tBest loss: 0.119352\tAccuracy: 97.89%\n",
      "23\tValidation loss: 0.351117\tBest loss: 0.119352\tAccuracy: 98.28%\n",
      "24\tValidation loss: 0.434472\tBest loss: 0.119352\tAccuracy: 98.75%\n",
      "25\tValidation loss: 0.465208\tBest loss: 0.119352\tAccuracy: 98.08%\n",
      "26\tValidation loss: 0.560957\tBest loss: 0.119352\tAccuracy: 97.62%\n",
      "27\tValidation loss: 0.778521\tBest loss: 0.119352\tAccuracy: 98.48%\n",
      "28\tValidation loss: 0.902274\tBest loss: 0.119352\tAccuracy: 97.93%\n",
      "29\tValidation loss: 1.085555\tBest loss: 0.119352\tAccuracy: 98.08%\n",
      "30\tValidation loss: 0.609268\tBest loss: 0.119352\tAccuracy: 97.54%\n",
      "31\tValidation loss: 1.216879\tBest loss: 0.119352\tAccuracy: 98.12%\n",
      "32\tValidation loss: 0.937483\tBest loss: 0.119352\tAccuracy: 98.24%\n",
      "33\tValidation loss: 0.578924\tBest loss: 0.119352\tAccuracy: 98.32%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11591cd08>, total= 3.1min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.135876\tBest loss: 0.135876\tAccuracy: 97.34%\n",
      "1\tValidation loss: 0.141102\tBest loss: 0.135876\tAccuracy: 97.97%\n",
      "2\tValidation loss: 0.203513\tBest loss: 0.135876\tAccuracy: 96.83%\n",
      "3\tValidation loss: 0.284135\tBest loss: 0.135876\tAccuracy: 96.52%\n",
      "4\tValidation loss: 0.215230\tBest loss: 0.135876\tAccuracy: 97.58%\n",
      "5\tValidation loss: 0.221249\tBest loss: 0.135876\tAccuracy: 97.38%\n",
      "6\tValidation loss: 0.182316\tBest loss: 0.135876\tAccuracy: 97.89%\n",
      "7\tValidation loss: 0.318043\tBest loss: 0.135876\tAccuracy: 96.91%\n",
      "8\tValidation loss: 0.243783\tBest loss: 0.135876\tAccuracy: 98.01%\n",
      "9\tValidation loss: 0.257996\tBest loss: 0.135876\tAccuracy: 97.89%\n",
      "10\tValidation loss: 0.265204\tBest loss: 0.135876\tAccuracy: 97.42%\n",
      "11\tValidation loss: 0.617308\tBest loss: 0.135876\tAccuracy: 97.62%\n",
      "12\tValidation loss: 0.707253\tBest loss: 0.135876\tAccuracy: 97.58%\n",
      "13\tValidation loss: 1.047406\tBest loss: 0.135876\tAccuracy: 97.38%\n",
      "14\tValidation loss: 0.493785\tBest loss: 0.135876\tAccuracy: 98.01%\n",
      "15\tValidation loss: 0.631900\tBest loss: 0.135876\tAccuracy: 96.91%\n",
      "16\tValidation loss: 0.423839\tBest loss: 0.135876\tAccuracy: 98.08%\n",
      "17\tValidation loss: 0.481116\tBest loss: 0.135876\tAccuracy: 98.20%\n",
      "18\tValidation loss: 0.503304\tBest loss: 0.135876\tAccuracy: 97.58%\n",
      "19\tValidation loss: 0.757324\tBest loss: 0.135876\tAccuracy: 98.28%\n",
      "20\tValidation loss: 0.284188\tBest loss: 0.135876\tAccuracy: 97.93%\n",
      "21\tValidation loss: 0.387469\tBest loss: 0.135876\tAccuracy: 98.32%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11591cd08>, total= 2.0min\n",
      "[CV] n_neurons=140, n_hidden_layers=2, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.162152\tBest loss: 0.162152\tAccuracy: 97.65%\n",
      "1\tValidation loss: 0.113530\tBest loss: 0.113530\tAccuracy: 98.08%\n",
      "2\tValidation loss: 0.267395\tBest loss: 0.113530\tAccuracy: 95.97%\n",
      "3\tValidation loss: 0.204284\tBest loss: 0.113530\tAccuracy: 97.69%\n",
      "4\tValidation loss: 0.308058\tBest loss: 0.113530\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.088464\tBest loss: 0.088464\tAccuracy: 98.59%\n",
      "6\tValidation loss: 0.546945\tBest loss: 0.088464\tAccuracy: 97.58%\n",
      "7\tValidation loss: 0.185429\tBest loss: 0.088464\tAccuracy: 97.93%\n",
      "8\tValidation loss: 0.362759\tBest loss: 0.088464\tAccuracy: 97.26%\n",
      "9\tValidation loss: 0.816742\tBest loss: 0.088464\tAccuracy: 95.90%\n",
      "10\tValidation loss: 0.357122\tBest loss: 0.088464\tAccuracy: 98.05%\n",
      "11\tValidation loss: 0.245138\tBest loss: 0.088464\tAccuracy: 98.71%\n",
      "12\tValidation loss: 0.300528\tBest loss: 0.088464\tAccuracy: 98.32%\n",
      "13\tValidation loss: 0.283847\tBest loss: 0.088464\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.339888\tBest loss: 0.088464\tAccuracy: 98.48%\n",
      "15\tValidation loss: 1.218997\tBest loss: 0.088464\tAccuracy: 97.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\tValidation loss: 0.329464\tBest loss: 0.088464\tAccuracy: 98.12%\n",
      "17\tValidation loss: 0.291153\tBest loss: 0.088464\tAccuracy: 98.05%\n",
      "18\tValidation loss: 0.337178\tBest loss: 0.088464\tAccuracy: 97.62%\n",
      "19\tValidation loss: 0.864796\tBest loss: 0.088464\tAccuracy: 97.97%\n",
      "20\tValidation loss: 0.665025\tBest loss: 0.088464\tAccuracy: 97.50%\n",
      "21\tValidation loss: 0.360774\tBest loss: 0.088464\tAccuracy: 98.12%\n",
      "22\tValidation loss: 0.314191\tBest loss: 0.088464\tAccuracy: 98.12%\n",
      "23\tValidation loss: 0.433701\tBest loss: 0.088464\tAccuracy: 98.12%\n",
      "24\tValidation loss: 0.505958\tBest loss: 0.088464\tAccuracy: 98.67%\n",
      "25\tValidation loss: 0.298770\tBest loss: 0.088464\tAccuracy: 98.32%\n",
      "26\tValidation loss: 0.500994\tBest loss: 0.088464\tAccuracy: 98.24%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=140, n_hidden_layers=2, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11591cd08>, total= 2.4min\n",
      "[CV] n_neurons=160, n_hidden_layers=4, learning_rate=0.01, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.105928\tBest loss: 0.105928\tAccuracy: 96.76%\n",
      "1\tValidation loss: 0.097158\tBest loss: 0.097158\tAccuracy: 97.65%\n",
      "2\tValidation loss: 0.069333\tBest loss: 0.069333\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.114444\tBest loss: 0.069333\tAccuracy: 96.95%\n",
      "4\tValidation loss: 0.067382\tBest loss: 0.067382\tAccuracy: 98.59%\n",
      "5\tValidation loss: 0.058635\tBest loss: 0.058635\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.164833\tBest loss: 0.058635\tAccuracy: 96.48%\n",
      "7\tValidation loss: 0.091861\tBest loss: 0.058635\tAccuracy: 97.77%\n",
      "8\tValidation loss: 0.068290\tBest loss: 0.058635\tAccuracy: 98.28%\n",
      "9\tValidation loss: 0.055075\tBest loss: 0.055075\tAccuracy: 98.75%\n",
      "10\tValidation loss: 0.073219\tBest loss: 0.055075\tAccuracy: 98.44%\n",
      "11\tValidation loss: 0.050323\tBest loss: 0.050323\tAccuracy: 98.94%\n",
      "12\tValidation loss: 0.078977\tBest loss: 0.050323\tAccuracy: 99.14%\n",
      "13\tValidation loss: 0.134213\tBest loss: 0.050323\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.065931\tBest loss: 0.050323\tAccuracy: 98.83%\n",
      "15\tValidation loss: 0.116157\tBest loss: 0.050323\tAccuracy: 98.91%\n",
      "16\tValidation loss: 0.064901\tBest loss: 0.050323\tAccuracy: 98.79%\n",
      "17\tValidation loss: 0.061117\tBest loss: 0.050323\tAccuracy: 98.79%\n",
      "18\tValidation loss: 0.066492\tBest loss: 0.050323\tAccuracy: 98.91%\n",
      "19\tValidation loss: 0.090154\tBest loss: 0.050323\tAccuracy: 98.83%\n",
      "20\tValidation loss: 0.075590\tBest loss: 0.050323\tAccuracy: 98.94%\n",
      "21\tValidation loss: 0.073469\tBest loss: 0.050323\tAccuracy: 98.98%\n",
      "22\tValidation loss: 0.128472\tBest loss: 0.050323\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.115981\tBest loss: 0.050323\tAccuracy: 97.19%\n",
      "24\tValidation loss: 0.114437\tBest loss: 0.050323\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.088758\tBest loss: 0.050323\tAccuracy: 98.71%\n",
      "26\tValidation loss: 0.193257\tBest loss: 0.050323\tAccuracy: 98.28%\n",
      "27\tValidation loss: 0.106223\tBest loss: 0.050323\tAccuracy: 98.59%\n",
      "28\tValidation loss: 0.083237\tBest loss: 0.050323\tAccuracy: 98.63%\n",
      "29\tValidation loss: 0.130462\tBest loss: 0.050323\tAccuracy: 98.98%\n",
      "30\tValidation loss: 0.089804\tBest loss: 0.050323\tAccuracy: 98.94%\n",
      "31\tValidation loss: 0.101215\tBest loss: 0.050323\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.099268\tBest loss: 0.050323\tAccuracy: 98.98%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=4, learning_rate=0.01, batch_size=100, activation=<function elu at 0x11591cd08>, total=  56.3s\n",
      "[CV] n_neurons=160, n_hidden_layers=4, learning_rate=0.01, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.086529\tBest loss: 0.086529\tAccuracy: 97.50%\n",
      "1\tValidation loss: 0.078604\tBest loss: 0.078604\tAccuracy: 97.97%\n",
      "2\tValidation loss: 0.081908\tBest loss: 0.078604\tAccuracy: 97.93%\n",
      "3\tValidation loss: 0.072158\tBest loss: 0.072158\tAccuracy: 98.40%\n",
      "4\tValidation loss: 0.082167\tBest loss: 0.072158\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.110708\tBest loss: 0.072158\tAccuracy: 98.32%\n",
      "6\tValidation loss: 0.081037\tBest loss: 0.072158\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.107188\tBest loss: 0.072158\tAccuracy: 97.85%\n",
      "8\tValidation loss: 0.085790\tBest loss: 0.072158\tAccuracy: 98.40%\n",
      "9\tValidation loss: 0.161917\tBest loss: 0.072158\tAccuracy: 95.07%\n",
      "10\tValidation loss: 0.139780\tBest loss: 0.072158\tAccuracy: 97.30%\n",
      "11\tValidation loss: 0.101377\tBest loss: 0.072158\tAccuracy: 97.89%\n",
      "12\tValidation loss: 0.082316\tBest loss: 0.072158\tAccuracy: 98.55%\n",
      "13\tValidation loss: 0.095190\tBest loss: 0.072158\tAccuracy: 98.28%\n",
      "14\tValidation loss: 0.084367\tBest loss: 0.072158\tAccuracy: 98.32%\n",
      "15\tValidation loss: 0.080124\tBest loss: 0.072158\tAccuracy: 98.63%\n",
      "16\tValidation loss: 0.110796\tBest loss: 0.072158\tAccuracy: 98.59%\n",
      "17\tValidation loss: 0.079390\tBest loss: 0.072158\tAccuracy: 98.87%\n",
      "18\tValidation loss: 0.105335\tBest loss: 0.072158\tAccuracy: 98.32%\n",
      "19\tValidation loss: 0.097539\tBest loss: 0.072158\tAccuracy: 98.63%\n",
      "20\tValidation loss: 0.135892\tBest loss: 0.072158\tAccuracy: 98.40%\n",
      "21\tValidation loss: 0.188884\tBest loss: 0.072158\tAccuracy: 97.97%\n",
      "22\tValidation loss: 0.125145\tBest loss: 0.072158\tAccuracy: 98.36%\n",
      "23\tValidation loss: 0.116032\tBest loss: 0.072158\tAccuracy: 98.51%\n",
      "24\tValidation loss: 0.203993\tBest loss: 0.072158\tAccuracy: 97.11%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=4, learning_rate=0.01, batch_size=100, activation=<function elu at 0x11591cd08>, total=  42.7s\n",
      "[CV] n_neurons=160, n_hidden_layers=4, learning_rate=0.01, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.084466\tBest loss: 0.084466\tAccuracy: 97.62%\n",
      "1\tValidation loss: 0.071452\tBest loss: 0.071452\tAccuracy: 97.81%\n",
      "2\tValidation loss: 0.084629\tBest loss: 0.071452\tAccuracy: 97.58%\n",
      "3\tValidation loss: 0.061546\tBest loss: 0.061546\tAccuracy: 98.59%\n",
      "4\tValidation loss: 0.064616\tBest loss: 0.061546\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.089910\tBest loss: 0.061546\tAccuracy: 98.55%\n",
      "6\tValidation loss: 0.126969\tBest loss: 0.061546\tAccuracy: 97.30%\n",
      "7\tValidation loss: 0.161891\tBest loss: 0.061546\tAccuracy: 97.30%\n",
      "8\tValidation loss: 0.200700\tBest loss: 0.061546\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.144911\tBest loss: 0.061546\tAccuracy: 95.82%\n",
      "10\tValidation loss: 0.206449\tBest loss: 0.061546\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.283230\tBest loss: 0.061546\tAccuracy: 98.55%\n",
      "12\tValidation loss: 0.071469\tBest loss: 0.061546\tAccuracy: 98.32%\n",
      "13\tValidation loss: 0.079828\tBest loss: 0.061546\tAccuracy: 98.75%\n",
      "14\tValidation loss: 0.120651\tBest loss: 0.061546\tAccuracy: 98.51%\n",
      "15\tValidation loss: 0.144361\tBest loss: 0.061546\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.266753\tBest loss: 0.061546\tAccuracy: 98.01%\n",
      "17\tValidation loss: 0.093664\tBest loss: 0.061546\tAccuracy: 98.20%\n",
      "18\tValidation loss: 0.089004\tBest loss: 0.061546\tAccuracy: 98.63%\n",
      "19\tValidation loss: 0.148425\tBest loss: 0.061546\tAccuracy: 98.16%\n",
      "20\tValidation loss: 0.134364\tBest loss: 0.061546\tAccuracy: 98.48%\n",
      "21\tValidation loss: 0.094202\tBest loss: 0.061546\tAccuracy: 98.59%\n",
      "22\tValidation loss: 0.083830\tBest loss: 0.061546\tAccuracy: 98.63%\n",
      "23\tValidation loss: 0.081902\tBest loss: 0.061546\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.089564\tBest loss: 0.061546\tAccuracy: 98.91%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=4, learning_rate=0.01, batch_size=100, activation=<function elu at 0x11591cd08>, total=  41.1s\n",
      "[CV] n_neurons=120, n_hidden_layers=4, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 38.104839\tBest loss: 38.104839\tAccuracy: 94.33%\n",
      "1\tValidation loss: 9.775408\tBest loss: 9.775408\tAccuracy: 96.36%\n",
      "2\tValidation loss: 110.167664\tBest loss: 9.775408\tAccuracy: 94.02%\n",
      "3\tValidation loss: 57.510452\tBest loss: 9.775408\tAccuracy: 89.09%\n",
      "4\tValidation loss: 8.064628\tBest loss: 8.064628\tAccuracy: 96.05%\n",
      "5\tValidation loss: 31.580416\tBest loss: 8.064628\tAccuracy: 95.23%\n",
      "6\tValidation loss: 15.774464\tBest loss: 8.064628\tAccuracy: 95.54%\n",
      "7\tValidation loss: 129.316605\tBest loss: 8.064628\tAccuracy: 90.15%\n",
      "8\tValidation loss: 92.642082\tBest loss: 8.064628\tAccuracy: 92.22%\n",
      "9\tValidation loss: 5313.506836\tBest loss: 8.064628\tAccuracy: 88.35%\n",
      "10\tValidation loss: 116.947350\tBest loss: 8.064628\tAccuracy: 96.40%\n",
      "11\tValidation loss: 562.620422\tBest loss: 8.064628\tAccuracy: 96.72%\n",
      "12\tValidation loss: 136.351196\tBest loss: 8.064628\tAccuracy: 96.36%\n",
      "13\tValidation loss: 1036.436157\tBest loss: 8.064628\tAccuracy: 96.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\tValidation loss: 179.686172\tBest loss: 8.064628\tAccuracy: 97.30%\n",
      "15\tValidation loss: 3693.688477\tBest loss: 8.064628\tAccuracy: 96.33%\n",
      "16\tValidation loss: 395.608398\tBest loss: 8.064628\tAccuracy: 96.76%\n",
      "17\tValidation loss: 477.472931\tBest loss: 8.064628\tAccuracy: 95.00%\n",
      "18\tValidation loss: 225.485565\tBest loss: 8.064628\tAccuracy: 97.65%\n",
      "19\tValidation loss: 1072.564819\tBest loss: 8.064628\tAccuracy: 96.60%\n",
      "20\tValidation loss: 1296.605957\tBest loss: 8.064628\tAccuracy: 96.52%\n",
      "21\tValidation loss: 519.335876\tBest loss: 8.064628\tAccuracy: 97.50%\n",
      "22\tValidation loss: 205.897964\tBest loss: 8.064628\tAccuracy: 97.07%\n",
      "23\tValidation loss: 350.627869\tBest loss: 8.064628\tAccuracy: 97.11%\n",
      "24\tValidation loss: 920.671326\tBest loss: 8.064628\tAccuracy: 97.26%\n",
      "25\tValidation loss: 895.916443\tBest loss: 8.064628\tAccuracy: 95.93%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=4, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 4.0min\n",
      "[CV] n_neurons=120, n_hidden_layers=4, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 1.228881\tBest loss: 1.228881\tAccuracy: 94.96%\n",
      "1\tValidation loss: 24.789049\tBest loss: 1.228881\tAccuracy: 95.04%\n",
      "2\tValidation loss: 12.957587\tBest loss: 1.228881\tAccuracy: 95.97%\n",
      "3\tValidation loss: 160.900970\tBest loss: 1.228881\tAccuracy: 94.88%\n",
      "4\tValidation loss: 110.084015\tBest loss: 1.228881\tAccuracy: 97.07%\n",
      "5\tValidation loss: 129.527115\tBest loss: 1.228881\tAccuracy: 86.47%\n",
      "6\tValidation loss: 189.217804\tBest loss: 1.228881\tAccuracy: 92.69%\n",
      "7\tValidation loss: 153.678635\tBest loss: 1.228881\tAccuracy: 93.35%\n",
      "8\tValidation loss: 183.215225\tBest loss: 1.228881\tAccuracy: 97.54%\n",
      "9\tValidation loss: 172.512466\tBest loss: 1.228881\tAccuracy: 95.07%\n",
      "10\tValidation loss: 373.157349\tBest loss: 1.228881\tAccuracy: 96.95%\n",
      "11\tValidation loss: 888.109253\tBest loss: 1.228881\tAccuracy: 96.87%\n",
      "12\tValidation loss: 265.068756\tBest loss: 1.228881\tAccuracy: 97.26%\n",
      "13\tValidation loss: 699.781860\tBest loss: 1.228881\tAccuracy: 94.02%\n",
      "14\tValidation loss: 138.700150\tBest loss: 1.228881\tAccuracy: 97.77%\n",
      "15\tValidation loss: 1113.657959\tBest loss: 1.228881\tAccuracy: 97.89%\n",
      "16\tValidation loss: 447.578369\tBest loss: 1.228881\tAccuracy: 97.97%\n",
      "17\tValidation loss: 607.439941\tBest loss: 1.228881\tAccuracy: 97.93%\n",
      "18\tValidation loss: 446.998352\tBest loss: 1.228881\tAccuracy: 97.07%\n",
      "19\tValidation loss: 1096.804199\tBest loss: 1.228881\tAccuracy: 97.93%\n",
      "20\tValidation loss: 385.300446\tBest loss: 1.228881\tAccuracy: 98.32%\n",
      "21\tValidation loss: 722.972107\tBest loss: 1.228881\tAccuracy: 98.05%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=4, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 3.4min\n",
      "[CV] n_neurons=120, n_hidden_layers=4, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510> \n",
      "0\tValidation loss: 0.248797\tBest loss: 0.248797\tAccuracy: 96.17%\n",
      "1\tValidation loss: 75.345299\tBest loss: 0.248797\tAccuracy: 94.49%\n",
      "2\tValidation loss: 18.754709\tBest loss: 0.248797\tAccuracy: 94.64%\n",
      "3\tValidation loss: 4479.616211\tBest loss: 0.248797\tAccuracy: 91.36%\n",
      "4\tValidation loss: 158.804947\tBest loss: 0.248797\tAccuracy: 96.52%\n",
      "5\tValidation loss: 71.648468\tBest loss: 0.248797\tAccuracy: 97.03%\n",
      "6\tValidation loss: 119.419495\tBest loss: 0.248797\tAccuracy: 95.58%\n",
      "7\tValidation loss: 43.822201\tBest loss: 0.248797\tAccuracy: 96.36%\n",
      "8\tValidation loss: 547.850952\tBest loss: 0.248797\tAccuracy: 86.28%\n",
      "9\tValidation loss: 35.771500\tBest loss: 0.248797\tAccuracy: 97.38%\n",
      "10\tValidation loss: 188.405853\tBest loss: 0.248797\tAccuracy: 96.76%\n",
      "11\tValidation loss: 115.801971\tBest loss: 0.248797\tAccuracy: 97.73%\n",
      "12\tValidation loss: 123.739090\tBest loss: 0.248797\tAccuracy: 97.69%\n",
      "13\tValidation loss: 235.813766\tBest loss: 0.248797\tAccuracy: 97.65%\n",
      "14\tValidation loss: 240.856186\tBest loss: 0.248797\tAccuracy: 97.26%\n",
      "15\tValidation loss: 262.059937\tBest loss: 0.248797\tAccuracy: 95.86%\n",
      "16\tValidation loss: 94.590866\tBest loss: 0.248797\tAccuracy: 98.63%\n",
      "17\tValidation loss: 1492.111450\tBest loss: 0.248797\tAccuracy: 95.62%\n",
      "18\tValidation loss: 525.270996\tBest loss: 0.248797\tAccuracy: 97.97%\n",
      "19\tValidation loss: 436.507141\tBest loss: 0.248797\tAccuracy: 98.32%\n",
      "20\tValidation loss: 2655.728760\tBest loss: 0.248797\tAccuracy: 97.93%\n",
      "21\tValidation loss: 766.616638\tBest loss: 0.248797\tAccuracy: 98.08%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=120, n_hidden_layers=4, learning_rate=0.02, batch_size=10, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>, total= 3.2min\n",
      "[CV] n_neurons=10, n_hidden_layers=3, learning_rate=0.02, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.088011\tBest loss: 0.088011\tAccuracy: 97.19%\n",
      "1\tValidation loss: 0.096715\tBest loss: 0.088011\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.083749\tBest loss: 0.083749\tAccuracy: 97.38%\n",
      "3\tValidation loss: 0.082511\tBest loss: 0.082511\tAccuracy: 97.54%\n",
      "4\tValidation loss: 0.080548\tBest loss: 0.080548\tAccuracy: 97.19%\n",
      "5\tValidation loss: 0.076006\tBest loss: 0.076006\tAccuracy: 97.89%\n",
      "6\tValidation loss: 0.091670\tBest loss: 0.076006\tAccuracy: 97.15%\n",
      "7\tValidation loss: 0.083555\tBest loss: 0.076006\tAccuracy: 97.85%\n",
      "8\tValidation loss: 0.091691\tBest loss: 0.076006\tAccuracy: 97.73%\n",
      "9\tValidation loss: 0.070199\tBest loss: 0.070199\tAccuracy: 98.32%\n",
      "10\tValidation loss: 0.092048\tBest loss: 0.070199\tAccuracy: 98.05%\n",
      "11\tValidation loss: 0.064073\tBest loss: 0.064073\tAccuracy: 98.24%\n",
      "12\tValidation loss: 0.074206\tBest loss: 0.064073\tAccuracy: 98.16%\n",
      "13\tValidation loss: 0.084309\tBest loss: 0.064073\tAccuracy: 97.58%\n",
      "14\tValidation loss: 0.080353\tBest loss: 0.064073\tAccuracy: 97.77%\n",
      "15\tValidation loss: 0.078872\tBest loss: 0.064073\tAccuracy: 97.89%\n",
      "16\tValidation loss: 0.078099\tBest loss: 0.064073\tAccuracy: 98.28%\n",
      "17\tValidation loss: 0.080020\tBest loss: 0.064073\tAccuracy: 98.16%\n",
      "18\tValidation loss: 0.095530\tBest loss: 0.064073\tAccuracy: 97.97%\n",
      "19\tValidation loss: 0.089835\tBest loss: 0.064073\tAccuracy: 97.93%\n",
      "20\tValidation loss: 0.096701\tBest loss: 0.064073\tAccuracy: 97.93%\n",
      "21\tValidation loss: 0.082155\tBest loss: 0.064073\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.119040\tBest loss: 0.064073\tAccuracy: 97.26%\n",
      "23\tValidation loss: 0.085794\tBest loss: 0.064073\tAccuracy: 97.81%\n",
      "24\tValidation loss: 0.094894\tBest loss: 0.064073\tAccuracy: 97.89%\n",
      "25\tValidation loss: 0.115619\tBest loss: 0.064073\tAccuracy: 97.46%\n",
      "26\tValidation loss: 0.085053\tBest loss: 0.064073\tAccuracy: 97.73%\n",
      "27\tValidation loss: 0.111770\tBest loss: 0.064073\tAccuracy: 97.73%\n",
      "28\tValidation loss: 0.114466\tBest loss: 0.064073\tAccuracy: 98.08%\n",
      "29\tValidation loss: 0.129788\tBest loss: 0.064073\tAccuracy: 98.12%\n",
      "30\tValidation loss: 0.117003\tBest loss: 0.064073\tAccuracy: 97.81%\n",
      "31\tValidation loss: 0.106430\tBest loss: 0.064073\tAccuracy: 98.01%\n",
      "32\tValidation loss: 0.105378\tBest loss: 0.064073\tAccuracy: 98.05%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, n_hidden_layers=3, learning_rate=0.02, batch_size=100, activation=<function elu at 0x11591cd08>, total=  15.1s\n",
      "[CV] n_neurons=10, n_hidden_layers=3, learning_rate=0.02, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.122776\tBest loss: 0.122776\tAccuracy: 96.33%\n",
      "1\tValidation loss: 0.089257\tBest loss: 0.089257\tAccuracy: 97.62%\n",
      "2\tValidation loss: 0.085885\tBest loss: 0.085885\tAccuracy: 97.42%\n",
      "3\tValidation loss: 0.114536\tBest loss: 0.085885\tAccuracy: 96.76%\n",
      "4\tValidation loss: 0.091020\tBest loss: 0.085885\tAccuracy: 97.50%\n",
      "5\tValidation loss: 0.090293\tBest loss: 0.085885\tAccuracy: 97.54%\n",
      "6\tValidation loss: 0.098432\tBest loss: 0.085885\tAccuracy: 97.26%\n",
      "7\tValidation loss: 0.092352\tBest loss: 0.085885\tAccuracy: 97.26%\n",
      "8\tValidation loss: 0.097741\tBest loss: 0.085885\tAccuracy: 97.65%\n",
      "9\tValidation loss: 0.089844\tBest loss: 0.085885\tAccuracy: 97.38%\n",
      "10\tValidation loss: 0.090291\tBest loss: 0.085885\tAccuracy: 97.69%\n",
      "11\tValidation loss: 0.104150\tBest loss: 0.085885\tAccuracy: 97.42%\n",
      "12\tValidation loss: 0.104957\tBest loss: 0.085885\tAccuracy: 97.34%\n",
      "13\tValidation loss: 0.107122\tBest loss: 0.085885\tAccuracy: 97.69%\n",
      "14\tValidation loss: 0.086893\tBest loss: 0.085885\tAccuracy: 97.81%\n",
      "15\tValidation loss: 0.087159\tBest loss: 0.085885\tAccuracy: 97.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\tValidation loss: 0.114616\tBest loss: 0.085885\tAccuracy: 97.07%\n",
      "17\tValidation loss: 0.097025\tBest loss: 0.085885\tAccuracy: 97.58%\n",
      "18\tValidation loss: 0.131085\tBest loss: 0.085885\tAccuracy: 97.34%\n",
      "19\tValidation loss: 0.096781\tBest loss: 0.085885\tAccuracy: 97.62%\n",
      "20\tValidation loss: 0.134312\tBest loss: 0.085885\tAccuracy: 97.54%\n",
      "21\tValidation loss: 0.101110\tBest loss: 0.085885\tAccuracy: 97.58%\n",
      "22\tValidation loss: 0.115490\tBest loss: 0.085885\tAccuracy: 97.65%\n",
      "23\tValidation loss: 0.151873\tBest loss: 0.085885\tAccuracy: 97.30%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, n_hidden_layers=3, learning_rate=0.02, batch_size=100, activation=<function elu at 0x11591cd08>, total=  10.1s\n",
      "[CV] n_neurons=10, n_hidden_layers=3, learning_rate=0.02, batch_size=100, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.091830\tBest loss: 0.091830\tAccuracy: 97.58%\n",
      "1\tValidation loss: 0.100034\tBest loss: 0.091830\tAccuracy: 97.34%\n",
      "2\tValidation loss: 0.076947\tBest loss: 0.076947\tAccuracy: 97.69%\n",
      "3\tValidation loss: 0.068120\tBest loss: 0.068120\tAccuracy: 98.01%\n",
      "4\tValidation loss: 0.072763\tBest loss: 0.068120\tAccuracy: 98.08%\n",
      "5\tValidation loss: 0.067139\tBest loss: 0.067139\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.086531\tBest loss: 0.067139\tAccuracy: 97.81%\n",
      "7\tValidation loss: 0.094061\tBest loss: 0.067139\tAccuracy: 97.58%\n",
      "8\tValidation loss: 0.080475\tBest loss: 0.067139\tAccuracy: 98.20%\n",
      "9\tValidation loss: 0.082044\tBest loss: 0.067139\tAccuracy: 97.69%\n",
      "10\tValidation loss: 0.150033\tBest loss: 0.067139\tAccuracy: 96.52%\n",
      "11\tValidation loss: 0.089278\tBest loss: 0.067139\tAccuracy: 97.89%\n",
      "12\tValidation loss: 0.110533\tBest loss: 0.067139\tAccuracy: 97.42%\n",
      "13\tValidation loss: 0.113964\tBest loss: 0.067139\tAccuracy: 97.62%\n",
      "14\tValidation loss: 0.086788\tBest loss: 0.067139\tAccuracy: 97.85%\n",
      "15\tValidation loss: 0.113524\tBest loss: 0.067139\tAccuracy: 97.38%\n",
      "16\tValidation loss: 0.094513\tBest loss: 0.067139\tAccuracy: 97.69%\n",
      "17\tValidation loss: 0.097597\tBest loss: 0.067139\tAccuracy: 97.54%\n",
      "18\tValidation loss: 0.091084\tBest loss: 0.067139\tAccuracy: 97.62%\n",
      "19\tValidation loss: 0.119382\tBest loss: 0.067139\tAccuracy: 97.54%\n",
      "20\tValidation loss: 0.153136\tBest loss: 0.067139\tAccuracy: 97.46%\n",
      "21\tValidation loss: 0.107106\tBest loss: 0.067139\tAccuracy: 98.01%\n",
      "22\tValidation loss: 0.106539\tBest loss: 0.067139\tAccuracy: 97.58%\n",
      "23\tValidation loss: 0.114403\tBest loss: 0.067139\tAccuracy: 98.20%\n",
      "24\tValidation loss: 0.143795\tBest loss: 0.067139\tAccuracy: 97.58%\n",
      "25\tValidation loss: 0.101950\tBest loss: 0.067139\tAccuracy: 97.77%\n",
      "26\tValidation loss: 0.124000\tBest loss: 0.067139\tAccuracy: 97.69%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, n_hidden_layers=3, learning_rate=0.02, batch_size=100, activation=<function elu at 0x11591cd08>, total=  11.9s\n",
      "[CV] n_neurons=70, n_hidden_layers=4, learning_rate=0.1, batch_size=500, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 1.507470\tBest loss: 1.507470\tAccuracy: 71.03%\n",
      "1\tValidation loss: 0.726080\tBest loss: 0.726080\tAccuracy: 70.56%\n",
      "2\tValidation loss: 0.597832\tBest loss: 0.597832\tAccuracy: 75.33%\n",
      "3\tValidation loss: 0.555930\tBest loss: 0.555930\tAccuracy: 76.23%\n",
      "4\tValidation loss: 0.609745\tBest loss: 0.555930\tAccuracy: 75.25%\n",
      "5\tValidation loss: 0.450075\tBest loss: 0.450075\tAccuracy: 81.70%\n",
      "6\tValidation loss: 0.297000\tBest loss: 0.297000\tAccuracy: 93.39%\n",
      "7\tValidation loss: 0.293019\tBest loss: 0.293019\tAccuracy: 93.20%\n",
      "8\tValidation loss: 0.222149\tBest loss: 0.222149\tAccuracy: 95.27%\n",
      "9\tValidation loss: 0.235709\tBest loss: 0.222149\tAccuracy: 95.97%\n",
      "10\tValidation loss: 0.216011\tBest loss: 0.216011\tAccuracy: 95.58%\n",
      "11\tValidation loss: 0.195711\tBest loss: 0.195711\tAccuracy: 96.68%\n",
      "12\tValidation loss: 0.177928\tBest loss: 0.177928\tAccuracy: 96.40%\n",
      "13\tValidation loss: 0.155870\tBest loss: 0.155870\tAccuracy: 96.79%\n",
      "14\tValidation loss: 0.157024\tBest loss: 0.155870\tAccuracy: 96.64%\n",
      "15\tValidation loss: 0.160838\tBest loss: 0.155870\tAccuracy: 96.83%\n",
      "16\tValidation loss: 0.143626\tBest loss: 0.143626\tAccuracy: 97.54%\n",
      "17\tValidation loss: 0.147627\tBest loss: 0.143626\tAccuracy: 97.15%\n",
      "18\tValidation loss: 0.150812\tBest loss: 0.143626\tAccuracy: 97.42%\n",
      "19\tValidation loss: 0.164644\tBest loss: 0.143626\tAccuracy: 97.42%\n",
      "20\tValidation loss: 0.152793\tBest loss: 0.143626\tAccuracy: 97.26%\n",
      "21\tValidation loss: 0.181697\tBest loss: 0.143626\tAccuracy: 96.79%\n",
      "22\tValidation loss: 0.167654\tBest loss: 0.143626\tAccuracy: 96.99%\n",
      "23\tValidation loss: 0.146174\tBest loss: 0.143626\tAccuracy: 97.34%\n",
      "24\tValidation loss: 0.157959\tBest loss: 0.143626\tAccuracy: 97.03%\n",
      "25\tValidation loss: 0.143460\tBest loss: 0.143460\tAccuracy: 97.26%\n",
      "26\tValidation loss: 0.140135\tBest loss: 0.140135\tAccuracy: 97.69%\n",
      "27\tValidation loss: 0.127298\tBest loss: 0.127298\tAccuracy: 97.46%\n",
      "28\tValidation loss: 0.150138\tBest loss: 0.127298\tAccuracy: 97.34%\n",
      "29\tValidation loss: 0.149537\tBest loss: 0.127298\tAccuracy: 97.42%\n",
      "30\tValidation loss: 0.136542\tBest loss: 0.127298\tAccuracy: 96.99%\n",
      "31\tValidation loss: 0.146359\tBest loss: 0.127298\tAccuracy: 97.11%\n",
      "32\tValidation loss: 0.149308\tBest loss: 0.127298\tAccuracy: 97.22%\n",
      "33\tValidation loss: 0.213370\tBest loss: 0.127298\tAccuracy: 97.30%\n",
      "34\tValidation loss: 0.321488\tBest loss: 0.127298\tAccuracy: 93.04%\n",
      "35\tValidation loss: 0.145906\tBest loss: 0.127298\tAccuracy: 96.60%\n",
      "36\tValidation loss: 0.152305\tBest loss: 0.127298\tAccuracy: 96.79%\n",
      "37\tValidation loss: 0.139462\tBest loss: 0.127298\tAccuracy: 97.11%\n",
      "38\tValidation loss: 0.162429\tBest loss: 0.127298\tAccuracy: 96.83%\n",
      "39\tValidation loss: 0.146067\tBest loss: 0.127298\tAccuracy: 97.22%\n",
      "40\tValidation loss: 0.143973\tBest loss: 0.127298\tAccuracy: 97.50%\n",
      "41\tValidation loss: 0.170459\tBest loss: 0.127298\tAccuracy: 96.79%\n",
      "42\tValidation loss: 0.177810\tBest loss: 0.127298\tAccuracy: 97.19%\n",
      "43\tValidation loss: 0.168357\tBest loss: 0.127298\tAccuracy: 96.64%\n",
      "44\tValidation loss: 0.143481\tBest loss: 0.127298\tAccuracy: 97.26%\n",
      "45\tValidation loss: 0.148939\tBest loss: 0.127298\tAccuracy: 97.19%\n",
      "46\tValidation loss: 0.117311\tBest loss: 0.117311\tAccuracy: 96.95%\n",
      "47\tValidation loss: 0.148162\tBest loss: 0.117311\tAccuracy: 97.30%\n",
      "48\tValidation loss: 0.132176\tBest loss: 0.117311\tAccuracy: 97.26%\n",
      "49\tValidation loss: 0.154515\tBest loss: 0.117311\tAccuracy: 97.30%\n",
      "50\tValidation loss: 0.190274\tBest loss: 0.117311\tAccuracy: 97.22%\n",
      "51\tValidation loss: 0.190179\tBest loss: 0.117311\tAccuracy: 97.15%\n",
      "52\tValidation loss: 0.144164\tBest loss: 0.117311\tAccuracy: 97.50%\n",
      "53\tValidation loss: 0.158832\tBest loss: 0.117311\tAccuracy: 97.38%\n",
      "54\tValidation loss: 0.275245\tBest loss: 0.117311\tAccuracy: 97.07%\n",
      "55\tValidation loss: 5.434901\tBest loss: 0.117311\tAccuracy: 18.73%\n",
      "56\tValidation loss: 1.685143\tBest loss: 0.117311\tAccuracy: 18.73%\n",
      "57\tValidation loss: 1.630860\tBest loss: 0.117311\tAccuracy: 19.27%\n",
      "58\tValidation loss: 1.656558\tBest loss: 0.117311\tAccuracy: 19.27%\n",
      "59\tValidation loss: 1.662712\tBest loss: 0.117311\tAccuracy: 22.01%\n",
      "60\tValidation loss: 1.650046\tBest loss: 0.117311\tAccuracy: 22.01%\n",
      "61\tValidation loss: 1.627152\tBest loss: 0.117311\tAccuracy: 22.01%\n",
      "62\tValidation loss: 1.635107\tBest loss: 0.117311\tAccuracy: 22.01%\n",
      "63\tValidation loss: 1.670076\tBest loss: 0.117311\tAccuracy: 20.91%\n",
      "64\tValidation loss: 1.658226\tBest loss: 0.117311\tAccuracy: 19.08%\n",
      "65\tValidation loss: 1.630750\tBest loss: 0.117311\tAccuracy: 18.73%\n",
      "66\tValidation loss: 1.626581\tBest loss: 0.117311\tAccuracy: 19.27%\n",
      "67\tValidation loss: 1.705728\tBest loss: 0.117311\tAccuracy: 18.73%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=4, learning_rate=0.1, batch_size=500, activation=<function elu at 0x11591cd08>, total=  34.0s\n",
      "[CV] n_neurons=70, n_hidden_layers=4, learning_rate=0.1, batch_size=500, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.695420\tBest loss: 0.695420\tAccuracy: 84.40%\n",
      "1\tValidation loss: 0.221366\tBest loss: 0.221366\tAccuracy: 94.06%\n",
      "2\tValidation loss: 0.153010\tBest loss: 0.153010\tAccuracy: 95.66%\n",
      "3\tValidation loss: 0.154707\tBest loss: 0.153010\tAccuracy: 95.50%\n",
      "4\tValidation loss: 0.121718\tBest loss: 0.121718\tAccuracy: 96.13%\n",
      "5\tValidation loss: 0.111422\tBest loss: 0.111422\tAccuracy: 96.79%\n",
      "6\tValidation loss: 0.133453\tBest loss: 0.111422\tAccuracy: 96.13%\n",
      "7\tValidation loss: 0.114467\tBest loss: 0.111422\tAccuracy: 96.64%\n",
      "8\tValidation loss: 0.107482\tBest loss: 0.107482\tAccuracy: 96.72%\n",
      "9\tValidation loss: 0.098072\tBest loss: 0.098072\tAccuracy: 96.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\tValidation loss: 0.100965\tBest loss: 0.098072\tAccuracy: 96.99%\n",
      "11\tValidation loss: 0.122092\tBest loss: 0.098072\tAccuracy: 96.76%\n",
      "12\tValidation loss: 0.102746\tBest loss: 0.098072\tAccuracy: 97.15%\n",
      "13\tValidation loss: 0.151858\tBest loss: 0.098072\tAccuracy: 96.44%\n",
      "14\tValidation loss: 0.116812\tBest loss: 0.098072\tAccuracy: 97.38%\n",
      "15\tValidation loss: 0.095530\tBest loss: 0.095530\tAccuracy: 97.62%\n",
      "16\tValidation loss: 0.133223\tBest loss: 0.095530\tAccuracy: 97.19%\n",
      "17\tValidation loss: 0.078801\tBest loss: 0.078801\tAccuracy: 97.73%\n",
      "18\tValidation loss: 0.105441\tBest loss: 0.078801\tAccuracy: 97.19%\n",
      "19\tValidation loss: 0.101543\tBest loss: 0.078801\tAccuracy: 97.62%\n",
      "20\tValidation loss: 0.101990\tBest loss: 0.078801\tAccuracy: 97.42%\n",
      "21\tValidation loss: 0.094157\tBest loss: 0.078801\tAccuracy: 97.42%\n",
      "22\tValidation loss: 0.238702\tBest loss: 0.078801\tAccuracy: 94.72%\n",
      "23\tValidation loss: 0.159883\tBest loss: 0.078801\tAccuracy: 96.33%\n",
      "24\tValidation loss: 0.099233\tBest loss: 0.078801\tAccuracy: 97.69%\n",
      "25\tValidation loss: 0.126771\tBest loss: 0.078801\tAccuracy: 97.46%\n",
      "26\tValidation loss: 0.107365\tBest loss: 0.078801\tAccuracy: 97.77%\n",
      "27\tValidation loss: 0.117605\tBest loss: 0.078801\tAccuracy: 97.73%\n",
      "28\tValidation loss: 0.126370\tBest loss: 0.078801\tAccuracy: 97.50%\n",
      "29\tValidation loss: 0.110589\tBest loss: 0.078801\tAccuracy: 97.50%\n",
      "30\tValidation loss: 0.118075\tBest loss: 0.078801\tAccuracy: 97.81%\n",
      "31\tValidation loss: 0.091008\tBest loss: 0.078801\tAccuracy: 97.77%\n",
      "32\tValidation loss: 0.192400\tBest loss: 0.078801\tAccuracy: 97.11%\n",
      "33\tValidation loss: 0.189052\tBest loss: 0.078801\tAccuracy: 96.29%\n",
      "34\tValidation loss: 0.210678\tBest loss: 0.078801\tAccuracy: 96.40%\n",
      "35\tValidation loss: 0.119646\tBest loss: 0.078801\tAccuracy: 97.07%\n",
      "36\tValidation loss: 0.116321\tBest loss: 0.078801\tAccuracy: 97.11%\n",
      "37\tValidation loss: 0.144416\tBest loss: 0.078801\tAccuracy: 96.64%\n",
      "38\tValidation loss: 0.139694\tBest loss: 0.078801\tAccuracy: 96.87%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=4, learning_rate=0.1, batch_size=500, activation=<function elu at 0x11591cd08>, total=  20.3s\n",
      "[CV] n_neurons=70, n_hidden_layers=4, learning_rate=0.1, batch_size=500, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.555457\tBest loss: 0.555457\tAccuracy: 85.65%\n",
      "1\tValidation loss: 0.289075\tBest loss: 0.289075\tAccuracy: 92.14%\n",
      "2\tValidation loss: 0.239889\tBest loss: 0.239889\tAccuracy: 92.57%\n",
      "3\tValidation loss: 0.173048\tBest loss: 0.173048\tAccuracy: 94.92%\n",
      "4\tValidation loss: 0.153361\tBest loss: 0.153361\tAccuracy: 95.97%\n",
      "5\tValidation loss: 0.152071\tBest loss: 0.152071\tAccuracy: 96.21%\n",
      "6\tValidation loss: 0.147349\tBest loss: 0.147349\tAccuracy: 96.44%\n",
      "7\tValidation loss: 0.140879\tBest loss: 0.140879\tAccuracy: 96.40%\n",
      "8\tValidation loss: 0.155985\tBest loss: 0.140879\tAccuracy: 96.17%\n",
      "9\tValidation loss: 0.124272\tBest loss: 0.124272\tAccuracy: 97.19%\n",
      "10\tValidation loss: 0.150222\tBest loss: 0.124272\tAccuracy: 96.99%\n",
      "11\tValidation loss: 0.130636\tBest loss: 0.124272\tAccuracy: 97.42%\n",
      "12\tValidation loss: 0.145773\tBest loss: 0.124272\tAccuracy: 96.56%\n",
      "13\tValidation loss: 0.155521\tBest loss: 0.124272\tAccuracy: 97.07%\n",
      "14\tValidation loss: 0.137488\tBest loss: 0.124272\tAccuracy: 97.46%\n",
      "15\tValidation loss: 0.164124\tBest loss: 0.124272\tAccuracy: 96.72%\n",
      "16\tValidation loss: 0.145824\tBest loss: 0.124272\tAccuracy: 97.19%\n",
      "17\tValidation loss: 0.189115\tBest loss: 0.124272\tAccuracy: 96.72%\n",
      "18\tValidation loss: 0.173715\tBest loss: 0.124272\tAccuracy: 97.19%\n",
      "19\tValidation loss: 0.162514\tBest loss: 0.124272\tAccuracy: 96.91%\n",
      "20\tValidation loss: 0.162195\tBest loss: 0.124272\tAccuracy: 97.11%\n",
      "21\tValidation loss: 0.150740\tBest loss: 0.124272\tAccuracy: 97.11%\n",
      "22\tValidation loss: 0.169097\tBest loss: 0.124272\tAccuracy: 97.50%\n",
      "23\tValidation loss: 0.165956\tBest loss: 0.124272\tAccuracy: 97.42%\n",
      "24\tValidation loss: 0.185084\tBest loss: 0.124272\tAccuracy: 97.30%\n",
      "25\tValidation loss: 0.178718\tBest loss: 0.124272\tAccuracy: 97.34%\n",
      "26\tValidation loss: 0.211452\tBest loss: 0.124272\tAccuracy: 97.30%\n",
      "27\tValidation loss: 0.189075\tBest loss: 0.124272\tAccuracy: 96.95%\n",
      "28\tValidation loss: 0.194916\tBest loss: 0.124272\tAccuracy: 97.11%\n",
      "29\tValidation loss: 0.215142\tBest loss: 0.124272\tAccuracy: 97.46%\n",
      "30\tValidation loss: 0.269071\tBest loss: 0.124272\tAccuracy: 97.42%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=70, n_hidden_layers=4, learning_rate=0.1, batch_size=500, activation=<function elu at 0x11591cd08>, total=  16.8s\n",
      "[CV] n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=50, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.119205\tBest loss: 0.119205\tAccuracy: 96.33%\n",
      "1\tValidation loss: 0.090616\tBest loss: 0.090616\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.261600\tBest loss: 0.090616\tAccuracy: 95.74%\n",
      "3\tValidation loss: 0.078729\tBest loss: 0.078729\tAccuracy: 97.69%\n",
      "4\tValidation loss: 3.900666\tBest loss: 0.078729\tAccuracy: 77.64%\n",
      "5\tValidation loss: 1.316319\tBest loss: 0.078729\tAccuracy: 41.28%\n",
      "6\tValidation loss: 1.386506\tBest loss: 0.078729\tAccuracy: 35.11%\n",
      "7\tValidation loss: 1.250262\tBest loss: 0.078729\tAccuracy: 39.05%\n",
      "8\tValidation loss: 1.232857\tBest loss: 0.078729\tAccuracy: 38.70%\n",
      "9\tValidation loss: 0.984123\tBest loss: 0.078729\tAccuracy: 55.00%\n",
      "10\tValidation loss: 0.797890\tBest loss: 0.078729\tAccuracy: 60.75%\n",
      "11\tValidation loss: 0.806532\tBest loss: 0.078729\tAccuracy: 60.56%\n",
      "12\tValidation loss: 0.612412\tBest loss: 0.078729\tAccuracy: 95.54%\n",
      "13\tValidation loss: 0.269623\tBest loss: 0.078729\tAccuracy: 95.15%\n",
      "14\tValidation loss: 0.154609\tBest loss: 0.078729\tAccuracy: 97.85%\n",
      "15\tValidation loss: 0.143662\tBest loss: 0.078729\tAccuracy: 97.50%\n",
      "16\tValidation loss: 0.161334\tBest loss: 0.078729\tAccuracy: 98.28%\n",
      "17\tValidation loss: 0.159374\tBest loss: 0.078729\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.199678\tBest loss: 0.078729\tAccuracy: 98.36%\n",
      "19\tValidation loss: 1.555973\tBest loss: 0.078729\tAccuracy: 97.15%\n",
      "20\tValidation loss: 0.164995\tBest loss: 0.078729\tAccuracy: 98.24%\n",
      "21\tValidation loss: 0.127562\tBest loss: 0.078729\tAccuracy: 98.36%\n",
      "22\tValidation loss: 0.135176\tBest loss: 0.078729\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.201302\tBest loss: 0.078729\tAccuracy: 97.93%\n",
      "24\tValidation loss: 0.214617\tBest loss: 0.078729\tAccuracy: 96.95%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=50, activation=<function elu at 0x11591cd08>, total= 1.4min\n",
      "[CV] n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=50, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.151811\tBest loss: 0.151811\tAccuracy: 94.72%\n",
      "1\tValidation loss: 0.151919\tBest loss: 0.151811\tAccuracy: 97.07%\n",
      "2\tValidation loss: 0.097007\tBest loss: 0.097007\tAccuracy: 96.72%\n",
      "3\tValidation loss: 1.151960\tBest loss: 0.097007\tAccuracy: 94.14%\n",
      "4\tValidation loss: 0.096674\tBest loss: 0.096674\tAccuracy: 97.85%\n",
      "5\tValidation loss: 0.084152\tBest loss: 0.084152\tAccuracy: 98.20%\n",
      "6\tValidation loss: 0.088712\tBest loss: 0.084152\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.069916\tBest loss: 0.069916\tAccuracy: 98.28%\n",
      "8\tValidation loss: 0.108545\tBest loss: 0.069916\tAccuracy: 98.24%\n",
      "9\tValidation loss: 0.083167\tBest loss: 0.069916\tAccuracy: 98.36%\n",
      "10\tValidation loss: 0.286965\tBest loss: 0.069916\tAccuracy: 97.77%\n",
      "11\tValidation loss: 0.087717\tBest loss: 0.069916\tAccuracy: 98.36%\n",
      "12\tValidation loss: 0.121149\tBest loss: 0.069916\tAccuracy: 98.24%\n",
      "13\tValidation loss: 0.089945\tBest loss: 0.069916\tAccuracy: 98.28%\n",
      "14\tValidation loss: 0.152929\tBest loss: 0.069916\tAccuracy: 98.16%\n",
      "15\tValidation loss: 0.476410\tBest loss: 0.069916\tAccuracy: 95.43%\n",
      "16\tValidation loss: 0.159491\tBest loss: 0.069916\tAccuracy: 98.36%\n",
      "17\tValidation loss: 0.265075\tBest loss: 0.069916\tAccuracy: 97.89%\n",
      "18\tValidation loss: 0.134547\tBest loss: 0.069916\tAccuracy: 98.32%\n",
      "19\tValidation loss: 0.072143\tBest loss: 0.069916\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.089111\tBest loss: 0.069916\tAccuracy: 97.85%\n",
      "21\tValidation loss: 0.961672\tBest loss: 0.069916\tAccuracy: 60.75%\n",
      "22\tValidation loss: 0.516948\tBest loss: 0.069916\tAccuracy: 78.97%\n",
      "23\tValidation loss: 0.557227\tBest loss: 0.069916\tAccuracy: 75.80%\n",
      "24\tValidation loss: 0.562027\tBest loss: 0.069916\tAccuracy: 80.02%\n",
      "25\tValidation loss: 0.498883\tBest loss: 0.069916\tAccuracy: 79.79%\n",
      "26\tValidation loss: 0.518405\tBest loss: 0.069916\tAccuracy: 80.30%\n",
      "27\tValidation loss: 0.589161\tBest loss: 0.069916\tAccuracy: 76.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\tValidation loss: 0.899422\tBest loss: 0.069916\tAccuracy: 79.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=50, activation=<function elu at 0x11591cd08>, total= 1.6min\n",
      "[CV] n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=50, activation=<function elu at 0x11591cd08> \n",
      "0\tValidation loss: 0.115158\tBest loss: 0.115158\tAccuracy: 96.91%\n",
      "1\tValidation loss: 0.154523\tBest loss: 0.115158\tAccuracy: 96.01%\n",
      "2\tValidation loss: 0.067374\tBest loss: 0.067374\tAccuracy: 98.08%\n",
      "3\tValidation loss: 0.115050\tBest loss: 0.067374\tAccuracy: 97.42%\n",
      "4\tValidation loss: 0.122148\tBest loss: 0.067374\tAccuracy: 97.07%\n",
      "5\tValidation loss: 0.068033\tBest loss: 0.067374\tAccuracy: 98.75%\n",
      "6\tValidation loss: 0.087769\tBest loss: 0.067374\tAccuracy: 98.40%\n",
      "7\tValidation loss: 0.085593\tBest loss: 0.067374\tAccuracy: 98.55%\n",
      "8\tValidation loss: 0.112255\tBest loss: 0.067374\tAccuracy: 98.83%\n",
      "9\tValidation loss: 0.066891\tBest loss: 0.066891\tAccuracy: 98.83%\n",
      "10\tValidation loss: 0.440193\tBest loss: 0.066891\tAccuracy: 91.20%\n",
      "11\tValidation loss: 0.111647\tBest loss: 0.066891\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.535727\tBest loss: 0.066891\tAccuracy: 90.70%\n",
      "13\tValidation loss: 0.138130\tBest loss: 0.066891\tAccuracy: 97.97%\n",
      "14\tValidation loss: 0.088091\tBest loss: 0.066891\tAccuracy: 98.44%\n",
      "15\tValidation loss: 0.081671\tBest loss: 0.066891\tAccuracy: 98.63%\n",
      "16\tValidation loss: 0.087007\tBest loss: 0.066891\tAccuracy: 98.79%\n",
      "17\tValidation loss: 0.138700\tBest loss: 0.066891\tAccuracy: 98.20%\n",
      "18\tValidation loss: 0.146852\tBest loss: 0.066891\tAccuracy: 98.32%\n",
      "19\tValidation loss: 0.136583\tBest loss: 0.066891\tAccuracy: 98.67%\n",
      "20\tValidation loss: 0.489981\tBest loss: 0.066891\tAccuracy: 78.07%\n",
      "21\tValidation loss: 0.438031\tBest loss: 0.066891\tAccuracy: 79.36%\n",
      "22\tValidation loss: 0.177287\tBest loss: 0.066891\tAccuracy: 96.91%\n",
      "23\tValidation loss: 0.115789\tBest loss: 0.066891\tAccuracy: 98.16%\n",
      "24\tValidation loss: 0.119592\tBest loss: 0.066891\tAccuracy: 98.16%\n",
      "25\tValidation loss: 0.135022\tBest loss: 0.066891\tAccuracy: 98.36%\n",
      "26\tValidation loss: 0.380669\tBest loss: 0.066891\tAccuracy: 96.83%\n",
      "27\tValidation loss: 0.161298\tBest loss: 0.066891\tAccuracy: 98.48%\n",
      "28\tValidation loss: 0.220079\tBest loss: 0.066891\tAccuracy: 97.15%\n",
      "29\tValidation loss: 0.231711\tBest loss: 0.066891\tAccuracy: 97.15%\n",
      "30\tValidation loss: 0.106264\tBest loss: 0.066891\tAccuracy: 98.79%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=160, n_hidden_layers=5, learning_rate=0.01, batch_size=50, activation=<function elu at 0x11591cd08>, total= 1.7min\n",
      "[CV] n_neurons=90, n_hidden_layers=5, learning_rate=0.05, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.248479\tBest loss: 0.248479\tAccuracy: 92.81%\n",
      "1\tValidation loss: 0.129498\tBest loss: 0.129498\tAccuracy: 96.17%\n",
      "2\tValidation loss: 0.116301\tBest loss: 0.116301\tAccuracy: 96.56%\n",
      "3\tValidation loss: 0.098120\tBest loss: 0.098120\tAccuracy: 96.87%\n",
      "4\tValidation loss: 0.118365\tBest loss: 0.098120\tAccuracy: 96.48%\n",
      "5\tValidation loss: 0.087605\tBest loss: 0.087605\tAccuracy: 97.15%\n",
      "6\tValidation loss: 0.081016\tBest loss: 0.081016\tAccuracy: 97.38%\n",
      "7\tValidation loss: 0.107258\tBest loss: 0.081016\tAccuracy: 97.11%\n",
      "8\tValidation loss: 0.101302\tBest loss: 0.081016\tAccuracy: 97.11%\n",
      "9\tValidation loss: 0.092336\tBest loss: 0.081016\tAccuracy: 97.58%\n",
      "10\tValidation loss: 0.091204\tBest loss: 0.081016\tAccuracy: 97.42%\n",
      "11\tValidation loss: 0.108300\tBest loss: 0.081016\tAccuracy: 96.79%\n",
      "12\tValidation loss: 0.095116\tBest loss: 0.081016\tAccuracy: 97.07%\n",
      "13\tValidation loss: 0.101098\tBest loss: 0.081016\tAccuracy: 97.22%\n",
      "14\tValidation loss: 0.111672\tBest loss: 0.081016\tAccuracy: 97.07%\n",
      "15\tValidation loss: 0.094495\tBest loss: 0.081016\tAccuracy: 97.03%\n",
      "16\tValidation loss: 0.089576\tBest loss: 0.081016\tAccuracy: 97.26%\n",
      "17\tValidation loss: 0.124148\tBest loss: 0.081016\tAccuracy: 97.30%\n",
      "18\tValidation loss: 0.137736\tBest loss: 0.081016\tAccuracy: 97.07%\n",
      "19\tValidation loss: 0.100439\tBest loss: 0.081016\tAccuracy: 97.62%\n",
      "20\tValidation loss: 0.123463\tBest loss: 0.081016\tAccuracy: 97.30%\n",
      "21\tValidation loss: 0.135082\tBest loss: 0.081016\tAccuracy: 97.30%\n",
      "22\tValidation loss: 0.123852\tBest loss: 0.081016\tAccuracy: 97.11%\n",
      "23\tValidation loss: 0.120079\tBest loss: 0.081016\tAccuracy: 97.38%\n",
      "24\tValidation loss: 0.137502\tBest loss: 0.081016\tAccuracy: 96.91%\n",
      "25\tValidation loss: 0.206838\tBest loss: 0.081016\tAccuracy: 96.60%\n",
      "26\tValidation loss: 3183.599365\tBest loss: 0.081016\tAccuracy: 20.80%\n",
      "27\tValidation loss: 353519.781250\tBest loss: 0.081016\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=5, learning_rate=0.05, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  22.3s\n",
      "[CV] n_neurons=90, n_hidden_layers=5, learning_rate=0.05, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.360577\tBest loss: 0.360577\tAccuracy: 81.70%\n",
      "1\tValidation loss: 0.115626\tBest loss: 0.115626\tAccuracy: 96.87%\n",
      "2\tValidation loss: 0.104745\tBest loss: 0.104745\tAccuracy: 96.91%\n",
      "3\tValidation loss: 0.112613\tBest loss: 0.104745\tAccuracy: 96.91%\n",
      "4\tValidation loss: 0.107481\tBest loss: 0.104745\tAccuracy: 97.19%\n",
      "5\tValidation loss: 0.087455\tBest loss: 0.087455\tAccuracy: 97.50%\n",
      "6\tValidation loss: 0.106056\tBest loss: 0.087455\tAccuracy: 97.30%\n",
      "7\tValidation loss: 0.127757\tBest loss: 0.087455\tAccuracy: 96.64%\n",
      "8\tValidation loss: 0.101285\tBest loss: 0.087455\tAccuracy: 97.34%\n",
      "9\tValidation loss: 0.139565\tBest loss: 0.087455\tAccuracy: 97.15%\n",
      "10\tValidation loss: 0.133392\tBest loss: 0.087455\tAccuracy: 97.34%\n",
      "11\tValidation loss: 0.110229\tBest loss: 0.087455\tAccuracy: 97.34%\n",
      "12\tValidation loss: 0.110162\tBest loss: 0.087455\tAccuracy: 97.77%\n",
      "13\tValidation loss: 0.089202\tBest loss: 0.087455\tAccuracy: 97.62%\n",
      "14\tValidation loss: 0.132544\tBest loss: 0.087455\tAccuracy: 97.69%\n",
      "15\tValidation loss: 74.269432\tBest loss: 0.087455\tAccuracy: 24.98%\n",
      "16\tValidation loss: 30229.228516\tBest loss: 0.087455\tAccuracy: 20.91%\n",
      "17\tValidation loss: 4576.526367\tBest loss: 0.087455\tAccuracy: 19.08%\n",
      "18\tValidation loss: 3035.711182\tBest loss: 0.087455\tAccuracy: 19.08%\n",
      "19\tValidation loss: 1092.892456\tBest loss: 0.087455\tAccuracy: 30.30%\n",
      "20\tValidation loss: 139.552917\tBest loss: 0.087455\tAccuracy: 34.21%\n",
      "21\tValidation loss: 112.728996\tBest loss: 0.087455\tAccuracy: 34.52%\n",
      "22\tValidation loss: 47.992332\tBest loss: 0.087455\tAccuracy: 33.50%\n",
      "23\tValidation loss: 27.650043\tBest loss: 0.087455\tAccuracy: 34.79%\n",
      "24\tValidation loss: 14.998791\tBest loss: 0.087455\tAccuracy: 45.23%\n",
      "25\tValidation loss: 17.361801\tBest loss: 0.087455\tAccuracy: 36.16%\n",
      "26\tValidation loss: 16.669641\tBest loss: 0.087455\tAccuracy: 38.12%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=5, learning_rate=0.05, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  20.3s\n",
      "[CV] n_neurons=90, n_hidden_layers=5, learning_rate=0.05, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378> \n",
      "0\tValidation loss: 0.189113\tBest loss: 0.189113\tAccuracy: 94.37%\n",
      "1\tValidation loss: 0.112338\tBest loss: 0.112338\tAccuracy: 96.87%\n",
      "2\tValidation loss: 0.089376\tBest loss: 0.089376\tAccuracy: 97.07%\n",
      "3\tValidation loss: 0.072230\tBest loss: 0.072230\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.068483\tBest loss: 0.068483\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.085454\tBest loss: 0.068483\tAccuracy: 97.42%\n",
      "6\tValidation loss: 0.075184\tBest loss: 0.068483\tAccuracy: 98.05%\n",
      "7\tValidation loss: 0.066691\tBest loss: 0.066691\tAccuracy: 98.08%\n",
      "8\tValidation loss: 0.069926\tBest loss: 0.066691\tAccuracy: 97.97%\n",
      "9\tValidation loss: 0.067438\tBest loss: 0.066691\tAccuracy: 98.48%\n",
      "10\tValidation loss: 0.068372\tBest loss: 0.066691\tAccuracy: 98.20%\n",
      "11\tValidation loss: 0.058120\tBest loss: 0.058120\tAccuracy: 98.36%\n",
      "12\tValidation loss: 0.057382\tBest loss: 0.057382\tAccuracy: 98.36%\n",
      "13\tValidation loss: 0.060054\tBest loss: 0.057382\tAccuracy: 98.32%\n",
      "14\tValidation loss: 0.072570\tBest loss: 0.057382\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.075557\tBest loss: 0.057382\tAccuracy: 98.16%\n",
      "16\tValidation loss: 0.079002\tBest loss: 0.057382\tAccuracy: 98.32%\n",
      "17\tValidation loss: 0.066401\tBest loss: 0.057382\tAccuracy: 98.12%\n",
      "18\tValidation loss: 0.079835\tBest loss: 0.057382\tAccuracy: 97.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\tValidation loss: 0.081146\tBest loss: 0.057382\tAccuracy: 98.44%\n",
      "20\tValidation loss: 0.073418\tBest loss: 0.057382\tAccuracy: 98.55%\n",
      "21\tValidation loss: 0.087318\tBest loss: 0.057382\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.053943\tBest loss: 0.053943\tAccuracy: 98.48%\n",
      "23\tValidation loss: 0.065597\tBest loss: 0.053943\tAccuracy: 98.59%\n",
      "24\tValidation loss: 0.062902\tBest loss: 0.053943\tAccuracy: 98.44%\n",
      "25\tValidation loss: 0.075969\tBest loss: 0.053943\tAccuracy: 98.28%\n",
      "26\tValidation loss: 0.065109\tBest loss: 0.053943\tAccuracy: 98.36%\n",
      "27\tValidation loss: 0.053559\tBest loss: 0.053559\tAccuracy: 98.67%\n",
      "28\tValidation loss: 0.060791\tBest loss: 0.053559\tAccuracy: 98.63%\n",
      "29\tValidation loss: 0.085653\tBest loss: 0.053559\tAccuracy: 98.67%\n",
      "30\tValidation loss: 0.070067\tBest loss: 0.053559\tAccuracy: 98.36%\n",
      "31\tValidation loss: 0.077907\tBest loss: 0.053559\tAccuracy: 98.51%\n",
      "32\tValidation loss: 0.063332\tBest loss: 0.053559\tAccuracy: 98.28%\n",
      "33\tValidation loss: 0.084227\tBest loss: 0.053559\tAccuracy: 98.32%\n",
      "34\tValidation loss: 0.082318\tBest loss: 0.053559\tAccuracy: 98.83%\n",
      "35\tValidation loss: 3050.349365\tBest loss: 0.053559\tAccuracy: 41.83%\n",
      "36\tValidation loss: 59589.074219\tBest loss: 0.053559\tAccuracy: 19.12%\n",
      "37\tValidation loss: 20582.755859\tBest loss: 0.053559\tAccuracy: 18.73%\n",
      "38\tValidation loss: 6645.645996\tBest loss: 0.053559\tAccuracy: 33.19%\n",
      "39\tValidation loss: 486.571289\tBest loss: 0.053559\tAccuracy: 58.72%\n",
      "40\tValidation loss: 107.372322\tBest loss: 0.053559\tAccuracy: 66.81%\n",
      "41\tValidation loss: 72.482780\tBest loss: 0.053559\tAccuracy: 65.21%\n",
      "42\tValidation loss: 98.477638\tBest loss: 0.053559\tAccuracy: 77.44%\n",
      "43\tValidation loss: 50.094456\tBest loss: 0.053559\tAccuracy: 75.33%\n",
      "44\tValidation loss: 44.939384\tBest loss: 0.053559\tAccuracy: 79.40%\n",
      "45\tValidation loss: 35.503860\tBest loss: 0.053559\tAccuracy: 85.93%\n",
      "46\tValidation loss: 37.484577\tBest loss: 0.053559\tAccuracy: 83.62%\n",
      "47\tValidation loss: 24.668367\tBest loss: 0.053559\tAccuracy: 87.37%\n",
      "48\tValidation loss: 33.776306\tBest loss: 0.053559\tAccuracy: 87.29%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=90, n_hidden_layers=5, learning_rate=0.05, batch_size=500, activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>, total=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 206.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.071300\tBest loss: 0.071300\tAccuracy: 97.69%\n",
      "1\tValidation loss: 0.051112\tBest loss: 0.051112\tAccuracy: 98.32%\n",
      "2\tValidation loss: 0.043619\tBest loss: 0.043619\tAccuracy: 98.55%\n",
      "3\tValidation loss: 0.046507\tBest loss: 0.043619\tAccuracy: 98.55%\n",
      "4\tValidation loss: 0.047780\tBest loss: 0.043619\tAccuracy: 98.51%\n",
      "5\tValidation loss: 0.041740\tBest loss: 0.041740\tAccuracy: 98.75%\n",
      "6\tValidation loss: 0.034142\tBest loss: 0.034142\tAccuracy: 99.14%\n",
      "7\tValidation loss: 0.033952\tBest loss: 0.033952\tAccuracy: 99.14%\n",
      "8\tValidation loss: 0.038483\tBest loss: 0.033952\tAccuracy: 98.71%\n",
      "9\tValidation loss: 0.035515\tBest loss: 0.033952\tAccuracy: 98.71%\n",
      "10\tValidation loss: 0.053552\tBest loss: 0.033952\tAccuracy: 98.75%\n",
      "11\tValidation loss: 0.042323\tBest loss: 0.033952\tAccuracy: 99.06%\n",
      "12\tValidation loss: 0.045019\tBest loss: 0.033952\tAccuracy: 98.87%\n",
      "13\tValidation loss: 0.049483\tBest loss: 0.033952\tAccuracy: 98.98%\n",
      "14\tValidation loss: 0.050271\tBest loss: 0.033952\tAccuracy: 99.06%\n",
      "15\tValidation loss: 0.055791\tBest loss: 0.033952\tAccuracy: 98.91%\n",
      "16\tValidation loss: 0.051201\tBest loss: 0.033952\tAccuracy: 99.02%\n",
      "17\tValidation loss: 0.046201\tBest loss: 0.033952\tAccuracy: 98.94%\n",
      "18\tValidation loss: 0.043412\tBest loss: 0.033952\tAccuracy: 98.87%\n",
      "19\tValidation loss: 0.036700\tBest loss: 0.033952\tAccuracy: 99.26%\n",
      "20\tValidation loss: 0.049525\tBest loss: 0.033952\tAccuracy: 98.98%\n",
      "21\tValidation loss: 0.044239\tBest loss: 0.033952\tAccuracy: 99.14%\n",
      "22\tValidation loss: 0.047272\tBest loss: 0.033952\tAccuracy: 98.91%\n",
      "23\tValidation loss: 0.056136\tBest loss: 0.033952\tAccuracy: 98.94%\n",
      "24\tValidation loss: 0.054287\tBest loss: 0.033952\tAccuracy: 98.98%\n",
      "25\tValidation loss: 0.044881\tBest loss: 0.033952\tAccuracy: 99.14%\n",
      "26\tValidation loss: 0.058926\tBest loss: 0.033952\tAccuracy: 99.02%\n",
      "27\tValidation loss: 0.044076\tBest loss: 0.033952\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.048278\tBest loss: 0.033952\tAccuracy: 99.02%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=DNNClassifier(activation=<function elu at 0x11591cd08>,\n",
       "                                           batch_norm_momentum=None,\n",
       "                                           batch_size=20, dropout_rate=None,\n",
       "                                           initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x1cfb2366a0>,\n",
       "                                           learning_rate=0.01,\n",
       "                                           n_hidden_layers=5, n_neurons=100,\n",
       "                                           optimizer_class=<class 'tensorflow.python.tr...\n",
       "                                                       <function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f378>,\n",
       "                                                       <function leaky_relu.<locals>.parametrized_leaky_relu at 0x1cef47f510>],\n",
       "                                        'batch_size': [10, 50, 100, 500],\n",
       "                                        'learning_rate': [0.01, 0.02, 0.05,\n",
       "                                                          0.1],\n",
       "                                        'n_hidden_layers': [0, 1, 2, 3, 4, 5],\n",
       "                                        'n_neurons': [10, 30, 50, 70, 90, 100,\n",
       "                                                      120, 140, 160]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10, 30, 50, 70, 90, 100, 120, 140, 160],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    \"n_hidden_layers\": [0, 1, 2, 3, 4, 5],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "                                cv=3, random_state=42, verbose=2)\n",
    "rnd_search.fit(X_train1, y_train1, X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)\n",
    "\n",
    "# If you have Scikit-Learn 0.18 or earlier, you should upgrade, or use the fit_params argument:\n",
    "# fit_params = dict(X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)\n",
    "# rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "#                                 fit_params=fit_params, random_state=42, verbose=2)\n",
    "# rnd_search.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 70,\n",
       " 'n_hidden_layers': 3,\n",
       " 'learning_rate': 0.01,\n",
       " 'batch_size': 500,\n",
       " 'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920217941233703"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slightly better, lets see if dropout can make it better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 lets see if dropout can do better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9669020614879806"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(X_train1)\n",
    "accuracy_score(y_train1,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.123689\tBest loss: 0.123689\tAccuracy: 96.33%\n",
      "1\tValidation loss: 0.099210\tBest loss: 0.099210\tAccuracy: 97.42%\n",
      "2\tValidation loss: 0.088182\tBest loss: 0.088182\tAccuracy: 97.73%\n",
      "3\tValidation loss: 0.087262\tBest loss: 0.087262\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.083920\tBest loss: 0.083920\tAccuracy: 98.01%\n",
      "5\tValidation loss: 0.068560\tBest loss: 0.068560\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.083487\tBest loss: 0.068560\tAccuracy: 98.32%\n",
      "7\tValidation loss: 0.079008\tBest loss: 0.068560\tAccuracy: 98.08%\n",
      "8\tValidation loss: 0.071801\tBest loss: 0.068560\tAccuracy: 98.01%\n",
      "9\tValidation loss: 0.079606\tBest loss: 0.068560\tAccuracy: 98.12%\n",
      "10\tValidation loss: 0.067327\tBest loss: 0.067327\tAccuracy: 98.12%\n",
      "11\tValidation loss: 0.071610\tBest loss: 0.067327\tAccuracy: 98.20%\n",
      "12\tValidation loss: 0.070983\tBest loss: 0.067327\tAccuracy: 97.97%\n",
      "13\tValidation loss: 0.075218\tBest loss: 0.067327\tAccuracy: 98.24%\n",
      "14\tValidation loss: 0.073455\tBest loss: 0.067327\tAccuracy: 98.20%\n",
      "15\tValidation loss: 0.074084\tBest loss: 0.067327\tAccuracy: 98.20%\n",
      "16\tValidation loss: 0.066422\tBest loss: 0.066422\tAccuracy: 98.36%\n",
      "17\tValidation loss: 0.069383\tBest loss: 0.066422\tAccuracy: 98.16%\n",
      "18\tValidation loss: 0.069674\tBest loss: 0.066422\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.071418\tBest loss: 0.066422\tAccuracy: 98.40%\n",
      "20\tValidation loss: 0.070916\tBest loss: 0.066422\tAccuracy: 98.16%\n",
      "21\tValidation loss: 0.058984\tBest loss: 0.058984\tAccuracy: 98.40%\n",
      "22\tValidation loss: 0.069340\tBest loss: 0.058984\tAccuracy: 98.12%\n",
      "23\tValidation loss: 0.065104\tBest loss: 0.058984\tAccuracy: 98.48%\n",
      "24\tValidation loss: 0.077475\tBest loss: 0.058984\tAccuracy: 97.97%\n",
      "25\tValidation loss: 0.083516\tBest loss: 0.058984\tAccuracy: 98.08%\n",
      "26\tValidation loss: 0.258808\tBest loss: 0.058984\tAccuracy: 96.25%\n",
      "27\tValidation loss: 0.217900\tBest loss: 0.058984\tAccuracy: 93.32%\n",
      "28\tValidation loss: 0.178640\tBest loss: 0.058984\tAccuracy: 95.15%\n",
      "29\tValidation loss: 0.164920\tBest loss: 0.058984\tAccuracy: 94.18%\n",
      "30\tValidation loss: 0.136080\tBest loss: 0.058984\tAccuracy: 96.56%\n",
      "31\tValidation loss: 0.184269\tBest loss: 0.058984\tAccuracy: 93.20%\n",
      "32\tValidation loss: 0.128008\tBest loss: 0.058984\tAccuracy: 96.33%\n",
      "33\tValidation loss: 0.114842\tBest loss: 0.058984\tAccuracy: 97.42%\n",
      "34\tValidation loss: 0.117674\tBest loss: 0.058984\tAccuracy: 96.40%\n",
      "35\tValidation loss: 0.113623\tBest loss: 0.058984\tAccuracy: 96.36%\n",
      "36\tValidation loss: 0.112161\tBest loss: 0.058984\tAccuracy: 96.48%\n",
      "37\tValidation loss: 0.109931\tBest loss: 0.058984\tAccuracy: 96.68%\n",
      "38\tValidation loss: 0.105395\tBest loss: 0.058984\tAccuracy: 97.62%\n",
      "39\tValidation loss: 0.101036\tBest loss: 0.058984\tAccuracy: 97.89%\n",
      "40\tValidation loss: 0.086522\tBest loss: 0.058984\tAccuracy: 97.54%\n",
      "41\tValidation loss: 0.085702\tBest loss: 0.058984\tAccuracy: 97.62%\n",
      "42\tValidation loss: 0.084419\tBest loss: 0.058984\tAccuracy: 97.89%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1d05e55730>,\n",
       "              batch_norm_momentum=None, batch_size=500, dropout_rate=0.5,\n",
       "              initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x1cfb2366a0>,\n",
       "              learning_rate=0.01, n_hidden_layers=5, n_neurons=90,\n",
       "              optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_dropout = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=500, learning_rate=0.01,\n",
    "                                n_neurons=90, random_state=42,\n",
    "                                dropout_rate=0.5)\n",
    "dnn_clf_dropout.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869624440552637"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_dropout.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like in this case, dropout helped out! now let's try tuning again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:  2.8min remaining:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 1.571826\tBest loss: 1.571826\tAccuracy: 32.53%\n",
      "1\tValidation loss: 1.419230\tBest loss: 1.419230\tAccuracy: 30.34%\n",
      "2\tValidation loss: 1.282631\tBest loss: 1.282631\tAccuracy: 37.45%\n",
      "3\tValidation loss: 1.221306\tBest loss: 1.221306\tAccuracy: 38.62%\n",
      "4\tValidation loss: 1.200274\tBest loss: 1.200274\tAccuracy: 39.68%\n",
      "5\tValidation loss: 1.407448\tBest loss: 1.200274\tAccuracy: 36.16%\n",
      "6\tValidation loss: 2.107155\tBest loss: 1.200274\tAccuracy: 41.24%\n",
      "7\tValidation loss: 1.358904\tBest loss: 1.200274\tAccuracy: 35.65%\n",
      "8\tValidation loss: 1.295915\tBest loss: 1.200274\tAccuracy: 38.90%\n",
      "9\tValidation loss: 1.247043\tBest loss: 1.200274\tAccuracy: 39.01%\n",
      "10\tValidation loss: 1.205229\tBest loss: 1.200274\tAccuracy: 40.42%\n",
      "11\tValidation loss: 1.174334\tBest loss: 1.174334\tAccuracy: 39.52%\n",
      "12\tValidation loss: 1.184945\tBest loss: 1.174334\tAccuracy: 41.28%\n",
      "13\tValidation loss: 1.191212\tBest loss: 1.174334\tAccuracy: 38.86%\n",
      "14\tValidation loss: 1.184260\tBest loss: 1.174334\tAccuracy: 40.34%\n",
      "15\tValidation loss: 1.191917\tBest loss: 1.174334\tAccuracy: 40.54%\n",
      "16\tValidation loss: 1.650778\tBest loss: 1.174334\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.655023\tBest loss: 1.174334\tAccuracy: 22.01%\n",
      "18\tValidation loss: 1.658291\tBest loss: 1.174334\tAccuracy: 19.27%\n",
      "19\tValidation loss: 1.660669\tBest loss: 1.174334\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.625567\tBest loss: 1.174334\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.615424\tBest loss: 1.174334\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.615913\tBest loss: 1.174334\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.634519\tBest loss: 1.174334\tAccuracy: 19.08%\n",
      "24\tValidation loss: 1.614736\tBest loss: 1.174334\tAccuracy: 22.01%\n",
      "25\tValidation loss: 1.629706\tBest loss: 1.174334\tAccuracy: 18.73%\n",
      "26\tValidation loss: 1.697988\tBest loss: 1.174334\tAccuracy: 18.73%\n",
      "27\tValidation loss: 1.650501\tBest loss: 1.174334\tAccuracy: 20.91%\n",
      "28\tValidation loss: 1.621272\tBest loss: 1.174334\tAccuracy: 18.73%\n",
      "29\tValidation loss: 1.643815\tBest loss: 1.174334\tAccuracy: 20.91%\n",
      "30\tValidation loss: 1.676848\tBest loss: 1.174334\tAccuracy: 19.08%\n",
      "31\tValidation loss: 1.629807\tBest loss: 1.174334\tAccuracy: 19.08%\n",
      "32\tValidation loss: 1.646294\tBest loss: 1.174334\tAccuracy: 19.27%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=DNNClassifier(activation=<function elu at 0x11591cd08>,\n",
       "                                           batch_norm_momentum=None,\n",
       "                                           batch_size=20, dropout_rate=None,\n",
       "                                           initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x1cfb2366a0>,\n",
       "                                           learning_rate=0.01,\n",
       "                                           n_hidden_layers=5, n_neurons=100,\n",
       "                                           optimizer_class=<class 'tensorflow.python.tr...\n",
       "                                                       <function leaky_relu.<locals>.parametrized_leaky_relu at 0x1d07256510>,\n",
       "                                                       <function leaky_relu.<locals>.parametrized_leaky_relu at 0x1d07256620>],\n",
       "                                        'batch_size': [10, 50, 100, 500],\n",
       "                                        'dropout_rate': [0.2, 0.3, 0.4, 0.5,\n",
       "                                                         0.6],\n",
       "                                        'learning_rate': [0.01, 0.02, 0.05,\n",
       "                                                          0.1],\n",
       "                                        'n_neurons': [10, 30, 50, 70, 90, 100,\n",
       "                                                      120, 140, 160]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10, 30, 50, 70, 90, 100, 120, 140, 160],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    #\"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "    \"dropout_rate\": [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "}\n",
    "\n",
    "rnd_search_dropout = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=2,\n",
    "                                        cv=3, random_state=42, verbose=2,n_jobs=-1)\n",
    "rnd_search_dropout.fit(X_train1, y_train1, X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: for this class, setting njobs to -1 forces it to compute all fits, then prints out the final fit\n",
    "does not do this if left out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       " 'batch_norm_momentum': None,\n",
       " 'batch_size': 500,\n",
       " 'dropout_rate': None,\n",
       " 'initializer': <tensorflow.python.ops.init_ops.VarianceScaling at 0x1d043d4b38>,\n",
       " 'learning_rate': 0.01,\n",
       " 'n_hidden_layers': 3,\n",
       " 'n_neurons': 70,\n",
       " 'optimizer_class': tensorflow.python.training.adam.AdamOptimizer,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put back inputs and resave\n",
    "clf = DNNClassifier(random_state=42, n_hidden_layers=3, n_neurons=70, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=500, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.065239\tBest loss: 0.065239\tAccuracy: 97.97%\n",
      "1\tValidation loss: 0.051341\tBest loss: 0.051341\tAccuracy: 98.32%\n",
      "2\tValidation loss: 0.035087\tBest loss: 0.035087\tAccuracy: 98.91%\n",
      "3\tValidation loss: 0.064450\tBest loss: 0.035087\tAccuracy: 97.85%\n",
      "4\tValidation loss: 0.029510\tBest loss: 0.029510\tAccuracy: 98.98%\n",
      "5\tValidation loss: 0.040216\tBest loss: 0.029510\tAccuracy: 98.91%\n",
      "6\tValidation loss: 0.037542\tBest loss: 0.029510\tAccuracy: 98.94%\n",
      "7\tValidation loss: 0.030072\tBest loss: 0.029510\tAccuracy: 99.18%\n",
      "8\tValidation loss: 0.035014\tBest loss: 0.029510\tAccuracy: 99.06%\n",
      "9\tValidation loss: 0.034483\tBest loss: 0.029510\tAccuracy: 99.14%\n",
      "10\tValidation loss: 0.040548\tBest loss: 0.029510\tAccuracy: 98.94%\n",
      "11\tValidation loss: 0.047592\tBest loss: 0.029510\tAccuracy: 98.98%\n",
      "12\tValidation loss: 0.037275\tBest loss: 0.029510\tAccuracy: 99.14%\n",
      "13\tValidation loss: 0.052588\tBest loss: 0.029510\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.031130\tBest loss: 0.029510\tAccuracy: 99.26%\n",
      "15\tValidation loss: 0.040496\tBest loss: 0.029510\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.042404\tBest loss: 0.029510\tAccuracy: 99.18%\n",
      "17\tValidation loss: 0.036854\tBest loss: 0.029510\tAccuracy: 99.30%\n",
      "18\tValidation loss: 0.037988\tBest loss: 0.029510\tAccuracy: 99.26%\n",
      "19\tValidation loss: 0.046120\tBest loss: 0.029510\tAccuracy: 99.30%\n",
      "20\tValidation loss: 0.053467\tBest loss: 0.029510\tAccuracy: 99.14%\n",
      "21\tValidation loss: 0.057506\tBest loss: 0.029510\tAccuracy: 99.02%\n",
      "22\tValidation loss: 0.049852\tBest loss: 0.029510\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.042425\tBest loss: 0.029510\tAccuracy: 99.10%\n",
      "24\tValidation loss: 0.028487\tBest loss: 0.028487\tAccuracy: 99.49%\n",
      "25\tValidation loss: 0.060322\tBest loss: 0.028487\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.075999\tBest loss: 0.028487\tAccuracy: 98.94%\n",
      "27\tValidation loss: 0.042762\tBest loss: 0.028487\tAccuracy: 99.26%\n",
      "28\tValidation loss: 0.046355\tBest loss: 0.028487\tAccuracy: 99.37%\n",
      "29\tValidation loss: 0.039246\tBest loss: 0.028487\tAccuracy: 99.30%\n",
      "30\tValidation loss: 0.050592\tBest loss: 0.028487\tAccuracy: 99.22%\n",
      "31\tValidation loss: 0.042089\tBest loss: 0.028487\tAccuracy: 99.30%\n",
      "32\tValidation loss: 0.047686\tBest loss: 0.028487\tAccuracy: 99.18%\n",
      "33\tValidation loss: 0.074613\tBest loss: 0.028487\tAccuracy: 98.87%\n",
      "34\tValidation loss: 0.059884\tBest loss: 0.028487\tAccuracy: 98.98%\n",
      "35\tValidation loss: 0.059778\tBest loss: 0.028487\tAccuracy: 98.94%\n",
      "36\tValidation loss: 0.042016\tBest loss: 0.028487\tAccuracy: 99.18%\n",
      "37\tValidation loss: 0.033819\tBest loss: 0.028487\tAccuracy: 99.41%\n",
      "38\tValidation loss: 0.037276\tBest loss: 0.028487\tAccuracy: 99.41%\n",
      "39\tValidation loss: 0.038458\tBest loss: 0.028487\tAccuracy: 99.41%\n",
      "40\tValidation loss: 0.033631\tBest loss: 0.028487\tAccuracy: 99.45%\n",
      "41\tValidation loss: 0.033623\tBest loss: 0.028487\tAccuracy: 99.49%\n",
      "42\tValidation loss: 0.033826\tBest loss: 0.028487\tAccuracy: 99.49%\n",
      "43\tValidation loss: 0.034016\tBest loss: 0.028487\tAccuracy: 99.49%\n",
      "44\tValidation loss: 0.034212\tBest loss: 0.028487\tAccuracy: 99.45%\n",
      "45\tValidation loss: 0.034430\tBest loss: 0.028487\tAccuracy: 99.45%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x11591cd08>,\n",
       "              batch_norm_momentum=None, batch_size=500, dropout_rate=None,\n",
       "              initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x1cfb2366a0>,\n",
       "              learning_rate=0.01, n_hidden_layers=3, n_neurons=70,\n",
       "              optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train1, y_train1, X_valid=X_valid1, y_valid=y_valid1, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save(\"./my_best_mnist_model_0_to_4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Transfer learning\n",
    "\n",
    "Create a new DNN that reuses all the pretrained hidden layers of the previous models, freezes the, and repalces the softmax output layer with a new one\n",
    "\n",
    "lets load the best model's graph and get a handle on all the importnatn operations we will need. note that instead oc reating a new osftmax output layer, we will just reuse the existing one (since it has the same number of outputs as the existing one). we will reinitialize its paramteres before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To freeze the lower layers, we will eclude their variables from the optimizers list of trainable variabls keeping only the layer's trainables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                     scope='logits')\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate,name='Adam2')\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits,y,1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='accuracy')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.2\n",
    "\n",
    "Train thos on digits 5 to 9, using only 100 images per digit, and time how long it takes. Can you get a higher accuracy despite a smaller number of training samples\n",
    "\n",
    "Notes: We have brought in layers from a model trained on 0 to 4, add new layers and train to find the wights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_full = X_train[y_train >= 5]\n",
    "y_train2_full = y_train[y_train >= 5] - 5\n",
    "X_valid2_full = X_valid[y_valid >= 5]\n",
    "y_valid2_full = y_valid[y_valid >= 5] - 5\n",
    "X_test2 = X_test[y_test >= 5]\n",
    "y_test2 = y_test[y_test >= 5] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only keep 100 instances for each class, and 30 for the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return(np.concatenate(Xs),np.concatenate(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 3.027237\tBest loss: 3.027237\tAccuracy: 46.00%\n",
      "1\tValidation loss: 1.965874\tBest loss: 1.965874\tAccuracy: 52.00%\n",
      "2\tValidation loss: 1.638982\tBest loss: 1.638982\tAccuracy: 58.67%\n",
      "3\tValidation loss: 1.453271\tBest loss: 1.453271\tAccuracy: 60.00%\n",
      "4\tValidation loss: 1.326349\tBest loss: 1.326349\tAccuracy: 64.67%\n",
      "5\tValidation loss: 1.229301\tBest loss: 1.229301\tAccuracy: 64.67%\n",
      "6\tValidation loss: 1.160103\tBest loss: 1.160103\tAccuracy: 64.00%\n",
      "7\tValidation loss: 1.103175\tBest loss: 1.103175\tAccuracy: 66.00%\n",
      "8\tValidation loss: 1.059844\tBest loss: 1.059844\tAccuracy: 66.67%\n",
      "9\tValidation loss: 1.025271\tBest loss: 1.025271\tAccuracy: 68.00%\n",
      "10\tValidation loss: 0.996466\tBest loss: 0.996466\tAccuracy: 68.00%\n",
      "11\tValidation loss: 0.977692\tBest loss: 0.977692\tAccuracy: 67.33%\n",
      "12\tValidation loss: 0.955237\tBest loss: 0.955237\tAccuracy: 68.67%\n",
      "13\tValidation loss: 0.934359\tBest loss: 0.934359\tAccuracy: 69.33%\n",
      "14\tValidation loss: 0.921360\tBest loss: 0.921360\tAccuracy: 69.33%\n",
      "15\tValidation loss: 0.907221\tBest loss: 0.907221\tAccuracy: 70.00%\n",
      "16\tValidation loss: 0.897425\tBest loss: 0.897425\tAccuracy: 68.67%\n",
      "17\tValidation loss: 0.889516\tBest loss: 0.889516\tAccuracy: 68.67%\n",
      "18\tValidation loss: 0.876744\tBest loss: 0.876744\tAccuracy: 69.33%\n",
      "19\tValidation loss: 0.866823\tBest loss: 0.866823\tAccuracy: 68.67%\n",
      "20\tValidation loss: 0.860273\tBest loss: 0.860273\tAccuracy: 69.33%\n",
      "21\tValidation loss: 0.855644\tBest loss: 0.855644\tAccuracy: 68.67%\n",
      "22\tValidation loss: 0.845729\tBest loss: 0.845729\tAccuracy: 68.67%\n",
      "23\tValidation loss: 0.840634\tBest loss: 0.840634\tAccuracy: 68.67%\n",
      "24\tValidation loss: 0.832982\tBest loss: 0.832982\tAccuracy: 68.67%\n",
      "25\tValidation loss: 0.830272\tBest loss: 0.830272\tAccuracy: 68.67%\n",
      "26\tValidation loss: 0.824234\tBest loss: 0.824234\tAccuracy: 68.67%\n",
      "27\tValidation loss: 0.818667\tBest loss: 0.818667\tAccuracy: 68.67%\n",
      "28\tValidation loss: 0.817122\tBest loss: 0.817122\tAccuracy: 68.67%\n",
      "29\tValidation loss: 0.811604\tBest loss: 0.811604\tAccuracy: 68.67%\n",
      "30\tValidation loss: 0.809721\tBest loss: 0.809721\tAccuracy: 69.33%\n",
      "31\tValidation loss: 0.805099\tBest loss: 0.805099\tAccuracy: 69.33%\n",
      "32\tValidation loss: 0.803006\tBest loss: 0.803006\tAccuracy: 70.00%\n",
      "33\tValidation loss: 0.800064\tBest loss: 0.800064\tAccuracy: 70.00%\n",
      "34\tValidation loss: 0.791875\tBest loss: 0.791875\tAccuracy: 70.00%\n",
      "35\tValidation loss: 0.790636\tBest loss: 0.790636\tAccuracy: 70.00%\n",
      "36\tValidation loss: 0.788227\tBest loss: 0.788227\tAccuracy: 70.00%\n",
      "37\tValidation loss: 0.783271\tBest loss: 0.783271\tAccuracy: 70.00%\n",
      "38\tValidation loss: 0.780650\tBest loss: 0.780650\tAccuracy: 70.00%\n",
      "39\tValidation loss: 0.778418\tBest loss: 0.778418\tAccuracy: 70.00%\n",
      "40\tValidation loss: 0.775293\tBest loss: 0.775293\tAccuracy: 70.00%\n",
      "41\tValidation loss: 0.773312\tBest loss: 0.773312\tAccuracy: 70.00%\n",
      "42\tValidation loss: 0.769555\tBest loss: 0.769555\tAccuracy: 71.33%\n",
      "43\tValidation loss: 0.767759\tBest loss: 0.767759\tAccuracy: 71.33%\n",
      "44\tValidation loss: 0.765881\tBest loss: 0.765881\tAccuracy: 71.33%\n",
      "45\tValidation loss: 0.764386\tBest loss: 0.764386\tAccuracy: 71.33%\n",
      "46\tValidation loss: 0.762300\tBest loss: 0.762300\tAccuracy: 71.33%\n",
      "47\tValidation loss: 0.760128\tBest loss: 0.760128\tAccuracy: 71.33%\n",
      "48\tValidation loss: 0.759015\tBest loss: 0.759015\tAccuracy: 71.33%\n",
      "49\tValidation loss: 0.756873\tBest loss: 0.756873\tAccuracy: 71.33%\n",
      "50\tValidation loss: 0.754632\tBest loss: 0.754632\tAccuracy: 72.67%\n",
      "51\tValidation loss: 0.753390\tBest loss: 0.753390\tAccuracy: 72.67%\n",
      "52\tValidation loss: 0.751702\tBest loss: 0.751702\tAccuracy: 72.67%\n",
      "53\tValidation loss: 0.750183\tBest loss: 0.750183\tAccuracy: 72.67%\n",
      "54\tValidation loss: 0.747568\tBest loss: 0.747568\tAccuracy: 73.33%\n",
      "55\tValidation loss: 0.746145\tBest loss: 0.746145\tAccuracy: 73.33%\n",
      "56\tValidation loss: 0.744615\tBest loss: 0.744615\tAccuracy: 73.33%\n",
      "57\tValidation loss: 0.745108\tBest loss: 0.744615\tAccuracy: 73.33%\n",
      "58\tValidation loss: 0.743955\tBest loss: 0.743955\tAccuracy: 73.33%\n",
      "59\tValidation loss: 0.742293\tBest loss: 0.742293\tAccuracy: 73.33%\n",
      "60\tValidation loss: 0.741050\tBest loss: 0.741050\tAccuracy: 73.33%\n",
      "61\tValidation loss: 0.739732\tBest loss: 0.739732\tAccuracy: 73.33%\n",
      "62\tValidation loss: 0.737553\tBest loss: 0.737553\tAccuracy: 73.33%\n",
      "63\tValidation loss: 0.735245\tBest loss: 0.735245\tAccuracy: 73.33%\n",
      "64\tValidation loss: 0.733721\tBest loss: 0.733721\tAccuracy: 73.33%\n",
      "65\tValidation loss: 0.731717\tBest loss: 0.731717\tAccuracy: 73.33%\n",
      "66\tValidation loss: 0.730853\tBest loss: 0.730853\tAccuracy: 72.67%\n",
      "67\tValidation loss: 0.729670\tBest loss: 0.729670\tAccuracy: 73.33%\n",
      "68\tValidation loss: 0.730099\tBest loss: 0.729670\tAccuracy: 72.67%\n",
      "69\tValidation loss: 0.729278\tBest loss: 0.729278\tAccuracy: 73.33%\n",
      "70\tValidation loss: 0.728712\tBest loss: 0.728712\tAccuracy: 73.33%\n",
      "71\tValidation loss: 0.726775\tBest loss: 0.726775\tAccuracy: 73.33%\n",
      "72\tValidation loss: 0.726064\tBest loss: 0.726064\tAccuracy: 72.00%\n",
      "73\tValidation loss: 0.726290\tBest loss: 0.726064\tAccuracy: 72.67%\n",
      "74\tValidation loss: 0.723515\tBest loss: 0.723515\tAccuracy: 72.00%\n",
      "75\tValidation loss: 0.722446\tBest loss: 0.722446\tAccuracy: 72.00%\n",
      "76\tValidation loss: 0.721424\tBest loss: 0.721424\tAccuracy: 72.67%\n",
      "77\tValidation loss: 0.722617\tBest loss: 0.721424\tAccuracy: 72.67%\n",
      "78\tValidation loss: 0.721003\tBest loss: 0.721003\tAccuracy: 72.67%\n",
      "79\tValidation loss: 0.719298\tBest loss: 0.719298\tAccuracy: 72.67%\n",
      "80\tValidation loss: 0.718019\tBest loss: 0.718019\tAccuracy: 72.67%\n",
      "81\tValidation loss: 0.718295\tBest loss: 0.718019\tAccuracy: 72.67%\n",
      "82\tValidation loss: 0.717390\tBest loss: 0.717390\tAccuracy: 72.67%\n",
      "83\tValidation loss: 0.716524\tBest loss: 0.716524\tAccuracy: 73.33%\n",
      "84\tValidation loss: 0.717009\tBest loss: 0.716524\tAccuracy: 73.33%\n",
      "85\tValidation loss: 0.715742\tBest loss: 0.715742\tAccuracy: 73.33%\n",
      "86\tValidation loss: 0.714537\tBest loss: 0.714537\tAccuracy: 73.33%\n",
      "87\tValidation loss: 0.712410\tBest loss: 0.712410\tAccuracy: 72.00%\n",
      "88\tValidation loss: 0.712092\tBest loss: 0.712092\tAccuracy: 73.33%\n",
      "89\tValidation loss: 0.711048\tBest loss: 0.711048\tAccuracy: 72.67%\n",
      "90\tValidation loss: 0.710186\tBest loss: 0.710186\tAccuracy: 73.33%\n",
      "91\tValidation loss: 0.709675\tBest loss: 0.709675\tAccuracy: 73.33%\n",
      "92\tValidation loss: 0.708330\tBest loss: 0.708330\tAccuracy: 72.67%\n",
      "93\tValidation loss: 0.707861\tBest loss: 0.707861\tAccuracy: 72.67%\n",
      "94\tValidation loss: 0.707496\tBest loss: 0.707496\tAccuracy: 72.67%\n",
      "95\tValidation loss: 0.706729\tBest loss: 0.706729\tAccuracy: 72.67%\n",
      "96\tValidation loss: 0.705999\tBest loss: 0.705999\tAccuracy: 72.00%\n",
      "97\tValidation loss: 0.704479\tBest loss: 0.704479\tAccuracy: 72.67%\n",
      "98\tValidation loss: 0.704950\tBest loss: 0.704479\tAccuracy: 72.67%\n",
      "99\tValidation loss: 0.705101\tBest loss: 0.704479\tAccuracy: 73.33%\n",
      "100\tValidation loss: 0.704641\tBest loss: 0.704479\tAccuracy: 72.67%\n",
      "101\tValidation loss: 0.704005\tBest loss: 0.704005\tAccuracy: 72.67%\n",
      "102\tValidation loss: 0.703531\tBest loss: 0.703531\tAccuracy: 73.33%\n",
      "103\tValidation loss: 0.703392\tBest loss: 0.703392\tAccuracy: 72.67%\n",
      "104\tValidation loss: 0.703604\tBest loss: 0.703392\tAccuracy: 73.33%\n",
      "105\tValidation loss: 0.701880\tBest loss: 0.701880\tAccuracy: 73.33%\n",
      "106\tValidation loss: 0.700654\tBest loss: 0.700654\tAccuracy: 73.33%\n",
      "107\tValidation loss: 0.700305\tBest loss: 0.700305\tAccuracy: 72.67%\n",
      "108\tValidation loss: 0.699710\tBest loss: 0.699710\tAccuracy: 72.67%\n",
      "109\tValidation loss: 0.699905\tBest loss: 0.699710\tAccuracy: 73.33%\n",
      "110\tValidation loss: 0.699612\tBest loss: 0.699612\tAccuracy: 73.33%\n",
      "111\tValidation loss: 0.698940\tBest loss: 0.698940\tAccuracy: 73.33%\n",
      "112\tValidation loss: 0.698401\tBest loss: 0.698401\tAccuracy: 72.67%\n",
      "113\tValidation loss: 0.697130\tBest loss: 0.697130\tAccuracy: 73.33%\n",
      "114\tValidation loss: 0.697051\tBest loss: 0.697051\tAccuracy: 73.33%\n",
      "115\tValidation loss: 0.695586\tBest loss: 0.695586\tAccuracy: 73.33%\n",
      "116\tValidation loss: 0.694772\tBest loss: 0.694772\tAccuracy: 73.33%\n",
      "117\tValidation loss: 0.694316\tBest loss: 0.694316\tAccuracy: 74.00%\n",
      "118\tValidation loss: 0.694182\tBest loss: 0.694182\tAccuracy: 73.33%\n",
      "119\tValidation loss: 0.694576\tBest loss: 0.694182\tAccuracy: 73.33%\n",
      "120\tValidation loss: 0.694481\tBest loss: 0.694182\tAccuracy: 73.33%\n",
      "121\tValidation loss: 0.693862\tBest loss: 0.693862\tAccuracy: 73.33%\n",
      "122\tValidation loss: 0.692684\tBest loss: 0.692684\tAccuracy: 73.33%\n",
      "123\tValidation loss: 0.692640\tBest loss: 0.692640\tAccuracy: 74.00%\n",
      "124\tValidation loss: 0.692130\tBest loss: 0.692130\tAccuracy: 74.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 0.691612\tBest loss: 0.691612\tAccuracy: 74.00%\n",
      "126\tValidation loss: 0.691691\tBest loss: 0.691612\tAccuracy: 74.00%\n",
      "127\tValidation loss: 0.691084\tBest loss: 0.691084\tAccuracy: 74.00%\n",
      "128\tValidation loss: 0.690755\tBest loss: 0.690755\tAccuracy: 74.00%\n",
      "129\tValidation loss: 0.690037\tBest loss: 0.690037\tAccuracy: 73.33%\n",
      "130\tValidation loss: 0.689544\tBest loss: 0.689544\tAccuracy: 73.33%\n",
      "131\tValidation loss: 0.689147\tBest loss: 0.689147\tAccuracy: 73.33%\n",
      "132\tValidation loss: 0.689066\tBest loss: 0.689066\tAccuracy: 73.33%\n",
      "133\tValidation loss: 0.688710\tBest loss: 0.688710\tAccuracy: 73.33%\n",
      "134\tValidation loss: 0.688644\tBest loss: 0.688644\tAccuracy: 74.00%\n",
      "135\tValidation loss: 0.688555\tBest loss: 0.688555\tAccuracy: 74.00%\n",
      "136\tValidation loss: 0.687519\tBest loss: 0.687519\tAccuracy: 74.00%\n",
      "137\tValidation loss: 0.687636\tBest loss: 0.687519\tAccuracy: 74.00%\n",
      "138\tValidation loss: 0.687065\tBest loss: 0.687065\tAccuracy: 74.00%\n",
      "139\tValidation loss: 0.686631\tBest loss: 0.686631\tAccuracy: 74.00%\n",
      "140\tValidation loss: 0.686769\tBest loss: 0.686631\tAccuracy: 74.00%\n",
      "141\tValidation loss: 0.686216\tBest loss: 0.686216\tAccuracy: 74.00%\n",
      "142\tValidation loss: 0.686282\tBest loss: 0.686216\tAccuracy: 74.00%\n",
      "143\tValidation loss: 0.685991\tBest loss: 0.685991\tAccuracy: 74.00%\n",
      "144\tValidation loss: 0.685738\tBest loss: 0.685738\tAccuracy: 74.00%\n",
      "145\tValidation loss: 0.685390\tBest loss: 0.685390\tAccuracy: 74.00%\n",
      "146\tValidation loss: 0.684737\tBest loss: 0.684737\tAccuracy: 74.00%\n",
      "147\tValidation loss: 0.684202\tBest loss: 0.684202\tAccuracy: 74.00%\n",
      "148\tValidation loss: 0.683913\tBest loss: 0.683913\tAccuracy: 74.00%\n",
      "149\tValidation loss: 0.684002\tBest loss: 0.683913\tAccuracy: 74.00%\n",
      "150\tValidation loss: 0.684541\tBest loss: 0.683913\tAccuracy: 74.00%\n",
      "151\tValidation loss: 0.683430\tBest loss: 0.683430\tAccuracy: 74.67%\n",
      "152\tValidation loss: 0.682545\tBest loss: 0.682545\tAccuracy: 74.67%\n",
      "153\tValidation loss: 0.682520\tBest loss: 0.682520\tAccuracy: 74.67%\n",
      "154\tValidation loss: 0.682114\tBest loss: 0.682114\tAccuracy: 74.67%\n",
      "155\tValidation loss: 0.681852\tBest loss: 0.681852\tAccuracy: 74.67%\n",
      "156\tValidation loss: 0.681680\tBest loss: 0.681680\tAccuracy: 74.67%\n",
      "157\tValidation loss: 0.681789\tBest loss: 0.681680\tAccuracy: 74.67%\n",
      "158\tValidation loss: 0.680965\tBest loss: 0.680965\tAccuracy: 74.67%\n",
      "159\tValidation loss: 0.680704\tBest loss: 0.680704\tAccuracy: 74.67%\n",
      "160\tValidation loss: 0.680954\tBest loss: 0.680704\tAccuracy: 74.67%\n",
      "161\tValidation loss: 0.681191\tBest loss: 0.680704\tAccuracy: 74.67%\n",
      "162\tValidation loss: 0.681232\tBest loss: 0.680704\tAccuracy: 74.67%\n",
      "163\tValidation loss: 0.680297\tBest loss: 0.680297\tAccuracy: 74.67%\n",
      "164\tValidation loss: 0.680149\tBest loss: 0.680149\tAccuracy: 74.67%\n",
      "165\tValidation loss: 0.679768\tBest loss: 0.679768\tAccuracy: 74.67%\n",
      "166\tValidation loss: 0.679614\tBest loss: 0.679614\tAccuracy: 74.67%\n",
      "167\tValidation loss: 0.679814\tBest loss: 0.679614\tAccuracy: 74.67%\n",
      "168\tValidation loss: 0.680064\tBest loss: 0.679614\tAccuracy: 74.67%\n",
      "169\tValidation loss: 0.678743\tBest loss: 0.678743\tAccuracy: 74.67%\n",
      "170\tValidation loss: 0.678969\tBest loss: 0.678743\tAccuracy: 74.67%\n",
      "171\tValidation loss: 0.678588\tBest loss: 0.678588\tAccuracy: 74.67%\n",
      "172\tValidation loss: 0.678186\tBest loss: 0.678186\tAccuracy: 74.67%\n",
      "173\tValidation loss: 0.677762\tBest loss: 0.677762\tAccuracy: 74.67%\n",
      "174\tValidation loss: 0.677561\tBest loss: 0.677561\tAccuracy: 74.67%\n",
      "175\tValidation loss: 0.677565\tBest loss: 0.677561\tAccuracy: 74.67%\n",
      "176\tValidation loss: 0.677197\tBest loss: 0.677197\tAccuracy: 74.67%\n",
      "177\tValidation loss: 0.677421\tBest loss: 0.677197\tAccuracy: 74.67%\n",
      "178\tValidation loss: 0.677246\tBest loss: 0.677197\tAccuracy: 74.67%\n",
      "179\tValidation loss: 0.676502\tBest loss: 0.676502\tAccuracy: 74.67%\n",
      "180\tValidation loss: 0.676488\tBest loss: 0.676488\tAccuracy: 74.67%\n",
      "181\tValidation loss: 0.675747\tBest loss: 0.675747\tAccuracy: 74.67%\n",
      "182\tValidation loss: 0.675564\tBest loss: 0.675564\tAccuracy: 74.67%\n",
      "183\tValidation loss: 0.675137\tBest loss: 0.675137\tAccuracy: 74.00%\n",
      "184\tValidation loss: 0.675119\tBest loss: 0.675119\tAccuracy: 74.00%\n",
      "185\tValidation loss: 0.674448\tBest loss: 0.674448\tAccuracy: 74.00%\n",
      "186\tValidation loss: 0.674954\tBest loss: 0.674448\tAccuracy: 74.00%\n",
      "187\tValidation loss: 0.674611\tBest loss: 0.674448\tAccuracy: 74.00%\n",
      "188\tValidation loss: 0.674428\tBest loss: 0.674428\tAccuracy: 74.00%\n",
      "189\tValidation loss: 0.674640\tBest loss: 0.674428\tAccuracy: 74.00%\n",
      "190\tValidation loss: 0.674237\tBest loss: 0.674237\tAccuracy: 74.00%\n",
      "191\tValidation loss: 0.674743\tBest loss: 0.674237\tAccuracy: 74.00%\n",
      "192\tValidation loss: 0.674154\tBest loss: 0.674154\tAccuracy: 74.00%\n",
      "193\tValidation loss: 0.674083\tBest loss: 0.674083\tAccuracy: 74.00%\n",
      "194\tValidation loss: 0.674271\tBest loss: 0.674083\tAccuracy: 74.00%\n",
      "195\tValidation loss: 0.674300\tBest loss: 0.674083\tAccuracy: 74.00%\n",
      "196\tValidation loss: 0.674126\tBest loss: 0.674083\tAccuracy: 74.00%\n",
      "197\tValidation loss: 0.673644\tBest loss: 0.673644\tAccuracy: 74.00%\n",
      "198\tValidation loss: 0.673786\tBest loss: 0.673644\tAccuracy: 74.00%\n",
      "199\tValidation loss: 0.673253\tBest loss: 0.673253\tAccuracy: 74.00%\n",
      "200\tValidation loss: 0.673072\tBest loss: 0.673072\tAccuracy: 74.00%\n",
      "201\tValidation loss: 0.672751\tBest loss: 0.672751\tAccuracy: 74.00%\n",
      "202\tValidation loss: 0.672523\tBest loss: 0.672523\tAccuracy: 74.00%\n",
      "203\tValidation loss: 0.672617\tBest loss: 0.672523\tAccuracy: 74.00%\n",
      "204\tValidation loss: 0.673074\tBest loss: 0.672523\tAccuracy: 74.00%\n",
      "205\tValidation loss: 0.673021\tBest loss: 0.672523\tAccuracy: 74.00%\n",
      "206\tValidation loss: 0.672833\tBest loss: 0.672523\tAccuracy: 74.00%\n",
      "207\tValidation loss: 0.672205\tBest loss: 0.672205\tAccuracy: 74.00%\n",
      "208\tValidation loss: 0.671788\tBest loss: 0.671788\tAccuracy: 74.00%\n",
      "209\tValidation loss: 0.671476\tBest loss: 0.671476\tAccuracy: 74.00%\n",
      "210\tValidation loss: 0.671597\tBest loss: 0.671476\tAccuracy: 74.00%\n",
      "211\tValidation loss: 0.671572\tBest loss: 0.671476\tAccuracy: 74.00%\n",
      "212\tValidation loss: 0.671384\tBest loss: 0.671384\tAccuracy: 74.00%\n",
      "213\tValidation loss: 0.671039\tBest loss: 0.671039\tAccuracy: 74.00%\n",
      "214\tValidation loss: 0.671100\tBest loss: 0.671039\tAccuracy: 74.00%\n",
      "215\tValidation loss: 0.670374\tBest loss: 0.670374\tAccuracy: 74.00%\n",
      "216\tValidation loss: 0.670126\tBest loss: 0.670126\tAccuracy: 74.00%\n",
      "217\tValidation loss: 0.670216\tBest loss: 0.670126\tAccuracy: 74.00%\n",
      "218\tValidation loss: 0.670163\tBest loss: 0.670126\tAccuracy: 74.00%\n",
      "219\tValidation loss: 0.669795\tBest loss: 0.669795\tAccuracy: 74.00%\n",
      "220\tValidation loss: 0.669838\tBest loss: 0.669795\tAccuracy: 74.00%\n",
      "221\tValidation loss: 0.669683\tBest loss: 0.669683\tAccuracy: 74.00%\n",
      "222\tValidation loss: 0.669595\tBest loss: 0.669595\tAccuracy: 74.00%\n",
      "223\tValidation loss: 0.669493\tBest loss: 0.669493\tAccuracy: 74.00%\n",
      "224\tValidation loss: 0.668803\tBest loss: 0.668803\tAccuracy: 74.00%\n",
      "225\tValidation loss: 0.668694\tBest loss: 0.668694\tAccuracy: 74.00%\n",
      "226\tValidation loss: 0.667985\tBest loss: 0.667985\tAccuracy: 74.00%\n",
      "227\tValidation loss: 0.667789\tBest loss: 0.667789\tAccuracy: 74.00%\n",
      "228\tValidation loss: 0.667893\tBest loss: 0.667789\tAccuracy: 74.00%\n",
      "229\tValidation loss: 0.668611\tBest loss: 0.667789\tAccuracy: 74.00%\n",
      "230\tValidation loss: 0.668510\tBest loss: 0.667789\tAccuracy: 74.00%\n",
      "231\tValidation loss: 0.668404\tBest loss: 0.667789\tAccuracy: 74.00%\n",
      "232\tValidation loss: 0.667778\tBest loss: 0.667778\tAccuracy: 74.00%\n",
      "233\tValidation loss: 0.667754\tBest loss: 0.667754\tAccuracy: 74.00%\n",
      "234\tValidation loss: 0.667194\tBest loss: 0.667194\tAccuracy: 74.00%\n",
      "235\tValidation loss: 0.667140\tBest loss: 0.667140\tAccuracy: 74.00%\n",
      "236\tValidation loss: 0.667440\tBest loss: 0.667140\tAccuracy: 74.00%\n",
      "237\tValidation loss: 0.667300\tBest loss: 0.667140\tAccuracy: 74.00%\n",
      "238\tValidation loss: 0.667254\tBest loss: 0.667140\tAccuracy: 74.00%\n",
      "239\tValidation loss: 0.667743\tBest loss: 0.667140\tAccuracy: 74.00%\n",
      "240\tValidation loss: 0.667276\tBest loss: 0.667140\tAccuracy: 74.00%\n",
      "241\tValidation loss: 0.667183\tBest loss: 0.667140\tAccuracy: 74.00%\n",
      "242\tValidation loss: 0.666759\tBest loss: 0.666759\tAccuracy: 74.00%\n",
      "243\tValidation loss: 0.666361\tBest loss: 0.666361\tAccuracy: 74.00%\n",
      "244\tValidation loss: 0.666349\tBest loss: 0.666349\tAccuracy: 74.00%\n",
      "245\tValidation loss: 0.666505\tBest loss: 0.666349\tAccuracy: 74.00%\n",
      "246\tValidation loss: 0.665894\tBest loss: 0.665894\tAccuracy: 74.00%\n",
      "247\tValidation loss: 0.666153\tBest loss: 0.665894\tAccuracy: 74.00%\n",
      "248\tValidation loss: 0.666494\tBest loss: 0.665894\tAccuracy: 74.00%\n",
      "249\tValidation loss: 0.666529\tBest loss: 0.665894\tAccuracy: 74.00%\n",
      "250\tValidation loss: 0.666615\tBest loss: 0.665894\tAccuracy: 74.00%\n",
      "251\tValidation loss: 0.666339\tBest loss: 0.665894\tAccuracy: 74.00%\n",
      "252\tValidation loss: 0.666521\tBest loss: 0.665894\tAccuracy: 74.00%\n",
      "253\tValidation loss: 0.666024\tBest loss: 0.665894\tAccuracy: 74.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\tValidation loss: 0.665891\tBest loss: 0.665891\tAccuracy: 74.00%\n",
      "255\tValidation loss: 0.666074\tBest loss: 0.665891\tAccuracy: 74.00%\n",
      "256\tValidation loss: 0.665990\tBest loss: 0.665891\tAccuracy: 74.00%\n",
      "257\tValidation loss: 0.665833\tBest loss: 0.665833\tAccuracy: 74.00%\n",
      "258\tValidation loss: 0.665486\tBest loss: 0.665486\tAccuracy: 74.00%\n",
      "259\tValidation loss: 0.665723\tBest loss: 0.665486\tAccuracy: 74.00%\n",
      "260\tValidation loss: 0.665593\tBest loss: 0.665486\tAccuracy: 74.00%\n",
      "261\tValidation loss: 0.665787\tBest loss: 0.665486\tAccuracy: 74.00%\n",
      "262\tValidation loss: 0.665383\tBest loss: 0.665383\tAccuracy: 74.00%\n",
      "263\tValidation loss: 0.665075\tBest loss: 0.665075\tAccuracy: 74.00%\n",
      "264\tValidation loss: 0.664729\tBest loss: 0.664729\tAccuracy: 74.00%\n",
      "265\tValidation loss: 0.664631\tBest loss: 0.664631\tAccuracy: 74.00%\n",
      "266\tValidation loss: 0.664908\tBest loss: 0.664631\tAccuracy: 74.00%\n",
      "267\tValidation loss: 0.665216\tBest loss: 0.664631\tAccuracy: 74.00%\n",
      "268\tValidation loss: 0.664885\tBest loss: 0.664631\tAccuracy: 74.00%\n",
      "269\tValidation loss: 0.664539\tBest loss: 0.664539\tAccuracy: 74.00%\n",
      "270\tValidation loss: 0.664159\tBest loss: 0.664159\tAccuracy: 74.00%\n",
      "271\tValidation loss: 0.664144\tBest loss: 0.664144\tAccuracy: 74.00%\n",
      "272\tValidation loss: 0.664248\tBest loss: 0.664144\tAccuracy: 74.00%\n",
      "273\tValidation loss: 0.664115\tBest loss: 0.664115\tAccuracy: 74.00%\n",
      "274\tValidation loss: 0.663984\tBest loss: 0.663984\tAccuracy: 74.00%\n",
      "275\tValidation loss: 0.663939\tBest loss: 0.663939\tAccuracy: 74.00%\n",
      "276\tValidation loss: 0.664075\tBest loss: 0.663939\tAccuracy: 74.00%\n",
      "277\tValidation loss: 0.663904\tBest loss: 0.663904\tAccuracy: 74.00%\n",
      "278\tValidation loss: 0.663505\tBest loss: 0.663505\tAccuracy: 74.00%\n",
      "279\tValidation loss: 0.663198\tBest loss: 0.663198\tAccuracy: 74.00%\n",
      "280\tValidation loss: 0.663808\tBest loss: 0.663198\tAccuracy: 74.00%\n",
      "281\tValidation loss: 0.663992\tBest loss: 0.663198\tAccuracy: 74.00%\n",
      "282\tValidation loss: 0.663428\tBest loss: 0.663198\tAccuracy: 74.00%\n",
      "283\tValidation loss: 0.663884\tBest loss: 0.663198\tAccuracy: 74.00%\n",
      "284\tValidation loss: 0.663470\tBest loss: 0.663198\tAccuracy: 74.00%\n",
      "285\tValidation loss: 0.663293\tBest loss: 0.663198\tAccuracy: 74.00%\n",
      "286\tValidation loss: 0.663075\tBest loss: 0.663075\tAccuracy: 74.00%\n",
      "287\tValidation loss: 0.662981\tBest loss: 0.662981\tAccuracy: 74.00%\n",
      "288\tValidation loss: 0.662899\tBest loss: 0.662899\tAccuracy: 74.00%\n",
      "289\tValidation loss: 0.663221\tBest loss: 0.662899\tAccuracy: 74.00%\n",
      "290\tValidation loss: 0.663119\tBest loss: 0.662899\tAccuracy: 74.00%\n",
      "291\tValidation loss: 0.663022\tBest loss: 0.662899\tAccuracy: 74.00%\n",
      "292\tValidation loss: 0.662830\tBest loss: 0.662830\tAccuracy: 74.00%\n",
      "293\tValidation loss: 0.662452\tBest loss: 0.662452\tAccuracy: 74.00%\n",
      "294\tValidation loss: 0.662348\tBest loss: 0.662348\tAccuracy: 74.00%\n",
      "295\tValidation loss: 0.662474\tBest loss: 0.662348\tAccuracy: 74.00%\n",
      "296\tValidation loss: 0.662279\tBest loss: 0.662279\tAccuracy: 74.00%\n",
      "297\tValidation loss: 0.662412\tBest loss: 0.662279\tAccuracy: 74.00%\n",
      "298\tValidation loss: 0.662213\tBest loss: 0.662213\tAccuracy: 74.00%\n",
      "299\tValidation loss: 0.661898\tBest loss: 0.661898\tAccuracy: 74.00%\n",
      "300\tValidation loss: 0.662338\tBest loss: 0.661898\tAccuracy: 74.00%\n",
      "301\tValidation loss: 0.662195\tBest loss: 0.661898\tAccuracy: 74.00%\n",
      "302\tValidation loss: 0.662061\tBest loss: 0.661898\tAccuracy: 74.00%\n",
      "303\tValidation loss: 0.662007\tBest loss: 0.661898\tAccuracy: 74.00%\n",
      "304\tValidation loss: 0.661746\tBest loss: 0.661746\tAccuracy: 74.00%\n",
      "305\tValidation loss: 0.661643\tBest loss: 0.661643\tAccuracy: 74.00%\n",
      "306\tValidation loss: 0.661889\tBest loss: 0.661643\tAccuracy: 74.00%\n",
      "307\tValidation loss: 0.662096\tBest loss: 0.661643\tAccuracy: 74.00%\n",
      "308\tValidation loss: 0.661896\tBest loss: 0.661643\tAccuracy: 74.00%\n",
      "309\tValidation loss: 0.661979\tBest loss: 0.661643\tAccuracy: 74.00%\n",
      "310\tValidation loss: 0.662150\tBest loss: 0.661643\tAccuracy: 74.00%\n",
      "311\tValidation loss: 0.661654\tBest loss: 0.661643\tAccuracy: 74.00%\n",
      "312\tValidation loss: 0.661570\tBest loss: 0.661570\tAccuracy: 74.00%\n",
      "313\tValidation loss: 0.661423\tBest loss: 0.661423\tAccuracy: 74.00%\n",
      "314\tValidation loss: 0.661593\tBest loss: 0.661423\tAccuracy: 74.00%\n",
      "315\tValidation loss: 0.661503\tBest loss: 0.661423\tAccuracy: 74.00%\n",
      "316\tValidation loss: 0.661224\tBest loss: 0.661224\tAccuracy: 74.00%\n",
      "317\tValidation loss: 0.660968\tBest loss: 0.660968\tAccuracy: 74.00%\n",
      "318\tValidation loss: 0.661220\tBest loss: 0.660968\tAccuracy: 74.00%\n",
      "319\tValidation loss: 0.660968\tBest loss: 0.660968\tAccuracy: 74.00%\n",
      "320\tValidation loss: 0.660837\tBest loss: 0.660837\tAccuracy: 74.00%\n",
      "321\tValidation loss: 0.660928\tBest loss: 0.660837\tAccuracy: 74.00%\n",
      "322\tValidation loss: 0.660595\tBest loss: 0.660595\tAccuracy: 74.00%\n",
      "323\tValidation loss: 0.660844\tBest loss: 0.660595\tAccuracy: 74.00%\n",
      "324\tValidation loss: 0.660774\tBest loss: 0.660595\tAccuracy: 74.00%\n",
      "325\tValidation loss: 0.661042\tBest loss: 0.660595\tAccuracy: 74.00%\n",
      "326\tValidation loss: 0.660772\tBest loss: 0.660595\tAccuracy: 74.00%\n",
      "327\tValidation loss: 0.660765\tBest loss: 0.660595\tAccuracy: 74.00%\n",
      "328\tValidation loss: 0.660513\tBest loss: 0.660513\tAccuracy: 74.00%\n",
      "329\tValidation loss: 0.660319\tBest loss: 0.660319\tAccuracy: 74.00%\n",
      "330\tValidation loss: 0.659898\tBest loss: 0.659898\tAccuracy: 74.00%\n",
      "331\tValidation loss: 0.659789\tBest loss: 0.659789\tAccuracy: 74.00%\n",
      "332\tValidation loss: 0.659940\tBest loss: 0.659789\tAccuracy: 74.00%\n",
      "333\tValidation loss: 0.659813\tBest loss: 0.659789\tAccuracy: 74.00%\n",
      "334\tValidation loss: 0.659729\tBest loss: 0.659729\tAccuracy: 74.67%\n",
      "335\tValidation loss: 0.659604\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "336\tValidation loss: 0.659836\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "337\tValidation loss: 0.659929\tBest loss: 0.659604\tAccuracy: 74.67%\n",
      "338\tValidation loss: 0.660100\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "339\tValidation loss: 0.660264\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "340\tValidation loss: 0.660266\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "341\tValidation loss: 0.660353\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "342\tValidation loss: 0.660033\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "343\tValidation loss: 0.659827\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "344\tValidation loss: 0.659697\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "345\tValidation loss: 0.659822\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "346\tValidation loss: 0.659980\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "347\tValidation loss: 0.659740\tBest loss: 0.659604\tAccuracy: 74.00%\n",
      "348\tValidation loss: 0.659543\tBest loss: 0.659543\tAccuracy: 74.00%\n",
      "349\tValidation loss: 0.659319\tBest loss: 0.659319\tAccuracy: 74.00%\n",
      "350\tValidation loss: 0.659468\tBest loss: 0.659319\tAccuracy: 74.00%\n",
      "351\tValidation loss: 0.659494\tBest loss: 0.659319\tAccuracy: 74.00%\n",
      "352\tValidation loss: 0.659452\tBest loss: 0.659319\tAccuracy: 74.00%\n",
      "353\tValidation loss: 0.659440\tBest loss: 0.659319\tAccuracy: 74.00%\n",
      "354\tValidation loss: 0.659519\tBest loss: 0.659319\tAccuracy: 74.00%\n",
      "355\tValidation loss: 0.659451\tBest loss: 0.659319\tAccuracy: 74.00%\n",
      "356\tValidation loss: 0.659366\tBest loss: 0.659319\tAccuracy: 74.00%\n",
      "357\tValidation loss: 0.659008\tBest loss: 0.659008\tAccuracy: 74.00%\n",
      "358\tValidation loss: 0.659216\tBest loss: 0.659008\tAccuracy: 74.00%\n",
      "359\tValidation loss: 0.659178\tBest loss: 0.659008\tAccuracy: 74.00%\n",
      "360\tValidation loss: 0.658890\tBest loss: 0.658890\tAccuracy: 74.00%\n",
      "361\tValidation loss: 0.659248\tBest loss: 0.658890\tAccuracy: 74.00%\n",
      "362\tValidation loss: 0.658993\tBest loss: 0.658890\tAccuracy: 74.00%\n",
      "363\tValidation loss: 0.659235\tBest loss: 0.658890\tAccuracy: 74.00%\n",
      "364\tValidation loss: 0.659311\tBest loss: 0.658890\tAccuracy: 74.00%\n",
      "365\tValidation loss: 0.659127\tBest loss: 0.658890\tAccuracy: 74.00%\n",
      "366\tValidation loss: 0.658876\tBest loss: 0.658876\tAccuracy: 74.00%\n",
      "367\tValidation loss: 0.658831\tBest loss: 0.658831\tAccuracy: 74.00%\n",
      "368\tValidation loss: 0.658646\tBest loss: 0.658646\tAccuracy: 74.00%\n",
      "369\tValidation loss: 0.658813\tBest loss: 0.658646\tAccuracy: 74.00%\n",
      "370\tValidation loss: 0.658629\tBest loss: 0.658629\tAccuracy: 74.00%\n",
      "371\tValidation loss: 0.658577\tBest loss: 0.658577\tAccuracy: 74.00%\n",
      "372\tValidation loss: 0.658378\tBest loss: 0.658378\tAccuracy: 74.67%\n",
      "373\tValidation loss: 0.658502\tBest loss: 0.658378\tAccuracy: 74.00%\n",
      "374\tValidation loss: 0.658766\tBest loss: 0.658378\tAccuracy: 74.67%\n",
      "375\tValidation loss: 0.658547\tBest loss: 0.658378\tAccuracy: 74.67%\n",
      "376\tValidation loss: 0.658431\tBest loss: 0.658378\tAccuracy: 74.67%\n",
      "377\tValidation loss: 0.658607\tBest loss: 0.658378\tAccuracy: 74.67%\n",
      "378\tValidation loss: 0.658445\tBest loss: 0.658378\tAccuracy: 74.67%\n",
      "379\tValidation loss: 0.658349\tBest loss: 0.658349\tAccuracy: 74.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\tValidation loss: 0.658386\tBest loss: 0.658349\tAccuracy: 74.67%\n",
      "381\tValidation loss: 0.658568\tBest loss: 0.658349\tAccuracy: 74.67%\n",
      "382\tValidation loss: 0.658466\tBest loss: 0.658349\tAccuracy: 74.67%\n",
      "383\tValidation loss: 0.658480\tBest loss: 0.658349\tAccuracy: 74.67%\n",
      "384\tValidation loss: 0.658492\tBest loss: 0.658349\tAccuracy: 74.67%\n",
      "385\tValidation loss: 0.658475\tBest loss: 0.658349\tAccuracy: 74.67%\n",
      "386\tValidation loss: 0.658057\tBest loss: 0.658057\tAccuracy: 74.67%\n",
      "387\tValidation loss: 0.658126\tBest loss: 0.658057\tAccuracy: 74.67%\n",
      "388\tValidation loss: 0.658245\tBest loss: 0.658057\tAccuracy: 74.00%\n",
      "389\tValidation loss: 0.658103\tBest loss: 0.658057\tAccuracy: 74.67%\n",
      "390\tValidation loss: 0.658082\tBest loss: 0.658057\tAccuracy: 74.67%\n",
      "391\tValidation loss: 0.658165\tBest loss: 0.658057\tAccuracy: 74.67%\n",
      "392\tValidation loss: 0.658049\tBest loss: 0.658049\tAccuracy: 74.67%\n",
      "393\tValidation loss: 0.658170\tBest loss: 0.658049\tAccuracy: 74.67%\n",
      "394\tValidation loss: 0.658217\tBest loss: 0.658049\tAccuracy: 74.67%\n",
      "395\tValidation loss: 0.658130\tBest loss: 0.658049\tAccuracy: 74.67%\n",
      "396\tValidation loss: 0.658010\tBest loss: 0.658010\tAccuracy: 74.67%\n",
      "397\tValidation loss: 0.657986\tBest loss: 0.657986\tAccuracy: 74.67%\n",
      "398\tValidation loss: 0.658101\tBest loss: 0.657986\tAccuracy: 74.67%\n",
      "399\tValidation loss: 0.658244\tBest loss: 0.657986\tAccuracy: 74.67%\n",
      "400\tValidation loss: 0.658040\tBest loss: 0.657986\tAccuracy: 74.67%\n",
      "401\tValidation loss: 0.658013\tBest loss: 0.657986\tAccuracy: 74.67%\n",
      "402\tValidation loss: 0.658075\tBest loss: 0.657986\tAccuracy: 74.67%\n",
      "403\tValidation loss: 0.657717\tBest loss: 0.657717\tAccuracy: 74.67%\n",
      "404\tValidation loss: 0.657511\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "405\tValidation loss: 0.657538\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "406\tValidation loss: 0.657709\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "407\tValidation loss: 0.658047\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "408\tValidation loss: 0.658040\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "409\tValidation loss: 0.657844\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "410\tValidation loss: 0.657963\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "411\tValidation loss: 0.658108\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "412\tValidation loss: 0.658003\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "413\tValidation loss: 0.657903\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "414\tValidation loss: 0.657779\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "415\tValidation loss: 0.657522\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "416\tValidation loss: 0.657754\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "417\tValidation loss: 0.657849\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "418\tValidation loss: 0.657646\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "419\tValidation loss: 0.657976\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "420\tValidation loss: 0.657911\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "421\tValidation loss: 0.657883\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "422\tValidation loss: 0.657867\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "423\tValidation loss: 0.657882\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "424\tValidation loss: 0.657527\tBest loss: 0.657511\tAccuracy: 74.67%\n",
      "425\tValidation loss: 0.657414\tBest loss: 0.657414\tAccuracy: 74.67%\n",
      "426\tValidation loss: 0.657168\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "427\tValidation loss: 0.657373\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "428\tValidation loss: 0.657629\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "429\tValidation loss: 0.657552\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "430\tValidation loss: 0.657326\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "431\tValidation loss: 0.657465\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "432\tValidation loss: 0.657907\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "433\tValidation loss: 0.657861\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "434\tValidation loss: 0.657684\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "435\tValidation loss: 0.657447\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "436\tValidation loss: 0.657388\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "437\tValidation loss: 0.657594\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "438\tValidation loss: 0.657369\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "439\tValidation loss: 0.657291\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "440\tValidation loss: 0.657204\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "441\tValidation loss: 0.657331\tBest loss: 0.657168\tAccuracy: 74.67%\n",
      "442\tValidation loss: 0.657045\tBest loss: 0.657045\tAccuracy: 74.67%\n",
      "443\tValidation loss: 0.656960\tBest loss: 0.656960\tAccuracy: 74.67%\n",
      "444\tValidation loss: 0.657156\tBest loss: 0.656960\tAccuracy: 74.67%\n",
      "445\tValidation loss: 0.657050\tBest loss: 0.656960\tAccuracy: 74.67%\n",
      "446\tValidation loss: 0.656964\tBest loss: 0.656960\tAccuracy: 74.67%\n",
      "447\tValidation loss: 0.656790\tBest loss: 0.656790\tAccuracy: 74.67%\n",
      "448\tValidation loss: 0.656682\tBest loss: 0.656682\tAccuracy: 74.67%\n",
      "449\tValidation loss: 0.656727\tBest loss: 0.656682\tAccuracy: 74.67%\n",
      "450\tValidation loss: 0.656906\tBest loss: 0.656682\tAccuracy: 74.67%\n",
      "451\tValidation loss: 0.657010\tBest loss: 0.656682\tAccuracy: 74.67%\n",
      "452\tValidation loss: 0.657323\tBest loss: 0.656682\tAccuracy: 74.67%\n",
      "453\tValidation loss: 0.657398\tBest loss: 0.656682\tAccuracy: 74.67%\n",
      "454\tValidation loss: 0.657127\tBest loss: 0.656682\tAccuracy: 74.67%\n",
      "455\tValidation loss: 0.657104\tBest loss: 0.656682\tAccuracy: 74.67%\n",
      "456\tValidation loss: 0.656944\tBest loss: 0.656682\tAccuracy: 74.67%\n",
      "457\tValidation loss: 0.656680\tBest loss: 0.656680\tAccuracy: 74.67%\n",
      "458\tValidation loss: 0.656567\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "459\tValidation loss: 0.656890\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "460\tValidation loss: 0.656967\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "461\tValidation loss: 0.657133\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "462\tValidation loss: 0.657103\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "463\tValidation loss: 0.657124\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "464\tValidation loss: 0.657089\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "465\tValidation loss: 0.657041\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "466\tValidation loss: 0.657020\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "467\tValidation loss: 0.656972\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "468\tValidation loss: 0.657172\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "469\tValidation loss: 0.657253\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "470\tValidation loss: 0.657008\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "471\tValidation loss: 0.657114\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "472\tValidation loss: 0.657211\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "473\tValidation loss: 0.657156\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "474\tValidation loss: 0.657167\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "475\tValidation loss: 0.657382\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "476\tValidation loss: 0.657110\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "477\tValidation loss: 0.657221\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "478\tValidation loss: 0.657270\tBest loss: 0.656567\tAccuracy: 74.67%\n",
      "Early stopping!\n",
      "Total training time: 29.9s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 74.84\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess,\"./my_best_mnist_model_0_to_4\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "        \n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess,\"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}\".format(acc_test*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the reduced accuracy with a lower training set size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3\n",
    "\n",
    "Try caching the layers and train the model again, how much faster is it now?\n",
    "\n",
    "Start by getting a handle on the output of the frozen layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden3_out = tf.get_default_graph().get_tensor_by_name(\"hidden3_out:0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train again, but this time is different. First we compute the output of the top frozen layer at the beginning (both for the training set and the validation set) and we cache it. This speeds up training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 2.686994\tBest loss: 2.686994\tAccuracy: 48.00%\n",
      "1\tValidation loss: 1.871404\tBest loss: 1.871404\tAccuracy: 56.67%\n",
      "2\tValidation loss: 1.602814\tBest loss: 1.602814\tAccuracy: 58.67%\n",
      "3\tValidation loss: 1.435791\tBest loss: 1.435791\tAccuracy: 62.67%\n",
      "4\tValidation loss: 1.310696\tBest loss: 1.310696\tAccuracy: 66.00%\n",
      "5\tValidation loss: 1.226040\tBest loss: 1.226040\tAccuracy: 66.00%\n",
      "6\tValidation loss: 1.147280\tBest loss: 1.147280\tAccuracy: 67.33%\n",
      "7\tValidation loss: 1.093107\tBest loss: 1.093107\tAccuracy: 67.33%\n",
      "8\tValidation loss: 1.054426\tBest loss: 1.054426\tAccuracy: 66.67%\n",
      "9\tValidation loss: 1.020394\tBest loss: 1.020394\tAccuracy: 67.33%\n",
      "10\tValidation loss: 0.990768\tBest loss: 0.990768\tAccuracy: 67.33%\n",
      "11\tValidation loss: 0.965672\tBest loss: 0.965672\tAccuracy: 66.00%\n",
      "12\tValidation loss: 0.950094\tBest loss: 0.950094\tAccuracy: 67.33%\n",
      "13\tValidation loss: 0.933014\tBest loss: 0.933014\tAccuracy: 67.33%\n",
      "14\tValidation loss: 0.914585\tBest loss: 0.914585\tAccuracy: 68.67%\n",
      "15\tValidation loss: 0.901046\tBest loss: 0.901046\tAccuracy: 69.33%\n",
      "16\tValidation loss: 0.890938\tBest loss: 0.890938\tAccuracy: 68.67%\n",
      "17\tValidation loss: 0.880267\tBest loss: 0.880267\tAccuracy: 68.67%\n",
      "18\tValidation loss: 0.869702\tBest loss: 0.869702\tAccuracy: 68.67%\n",
      "19\tValidation loss: 0.862529\tBest loss: 0.862529\tAccuracy: 68.00%\n",
      "20\tValidation loss: 0.856035\tBest loss: 0.856035\tAccuracy: 68.00%\n",
      "21\tValidation loss: 0.848632\tBest loss: 0.848632\tAccuracy: 68.00%\n",
      "22\tValidation loss: 0.842165\tBest loss: 0.842165\tAccuracy: 68.00%\n",
      "23\tValidation loss: 0.834233\tBest loss: 0.834233\tAccuracy: 68.00%\n",
      "24\tValidation loss: 0.826985\tBest loss: 0.826985\tAccuracy: 68.00%\n",
      "25\tValidation loss: 0.821479\tBest loss: 0.821479\tAccuracy: 68.00%\n",
      "26\tValidation loss: 0.817964\tBest loss: 0.817964\tAccuracy: 68.00%\n",
      "27\tValidation loss: 0.812115\tBest loss: 0.812115\tAccuracy: 68.00%\n",
      "28\tValidation loss: 0.808585\tBest loss: 0.808585\tAccuracy: 68.67%\n",
      "29\tValidation loss: 0.804787\tBest loss: 0.804787\tAccuracy: 68.67%\n",
      "30\tValidation loss: 0.797471\tBest loss: 0.797471\tAccuracy: 68.67%\n",
      "31\tValidation loss: 0.796846\tBest loss: 0.796846\tAccuracy: 68.67%\n",
      "32\tValidation loss: 0.795900\tBest loss: 0.795900\tAccuracy: 68.67%\n",
      "33\tValidation loss: 0.790190\tBest loss: 0.790190\tAccuracy: 70.00%\n",
      "34\tValidation loss: 0.784632\tBest loss: 0.784632\tAccuracy: 70.00%\n",
      "35\tValidation loss: 0.783590\tBest loss: 0.783590\tAccuracy: 70.67%\n",
      "36\tValidation loss: 0.781881\tBest loss: 0.781881\tAccuracy: 70.00%\n",
      "37\tValidation loss: 0.778015\tBest loss: 0.778015\tAccuracy: 70.00%\n",
      "38\tValidation loss: 0.775187\tBest loss: 0.775187\tAccuracy: 72.00%\n",
      "39\tValidation loss: 0.771605\tBest loss: 0.771605\tAccuracy: 72.00%\n",
      "40\tValidation loss: 0.769854\tBest loss: 0.769854\tAccuracy: 72.00%\n",
      "41\tValidation loss: 0.765999\tBest loss: 0.765999\tAccuracy: 72.00%\n",
      "42\tValidation loss: 0.764673\tBest loss: 0.764673\tAccuracy: 71.33%\n",
      "43\tValidation loss: 0.762140\tBest loss: 0.762140\tAccuracy: 72.00%\n",
      "44\tValidation loss: 0.758751\tBest loss: 0.758751\tAccuracy: 72.00%\n",
      "45\tValidation loss: 0.757369\tBest loss: 0.757369\tAccuracy: 72.00%\n",
      "46\tValidation loss: 0.756993\tBest loss: 0.756993\tAccuracy: 72.00%\n",
      "47\tValidation loss: 0.755807\tBest loss: 0.755807\tAccuracy: 72.67%\n",
      "48\tValidation loss: 0.752429\tBest loss: 0.752429\tAccuracy: 73.33%\n",
      "49\tValidation loss: 0.751271\tBest loss: 0.751271\tAccuracy: 72.67%\n",
      "50\tValidation loss: 0.748385\tBest loss: 0.748385\tAccuracy: 72.67%\n",
      "51\tValidation loss: 0.745398\tBest loss: 0.745398\tAccuracy: 74.00%\n",
      "52\tValidation loss: 0.745469\tBest loss: 0.745398\tAccuracy: 74.00%\n",
      "53\tValidation loss: 0.744470\tBest loss: 0.744470\tAccuracy: 74.00%\n",
      "54\tValidation loss: 0.741897\tBest loss: 0.741897\tAccuracy: 74.00%\n",
      "55\tValidation loss: 0.741713\tBest loss: 0.741713\tAccuracy: 73.33%\n",
      "56\tValidation loss: 0.740244\tBest loss: 0.740244\tAccuracy: 72.67%\n",
      "57\tValidation loss: 0.736943\tBest loss: 0.736943\tAccuracy: 73.33%\n",
      "58\tValidation loss: 0.735743\tBest loss: 0.735743\tAccuracy: 72.67%\n",
      "59\tValidation loss: 0.736680\tBest loss: 0.735743\tAccuracy: 73.33%\n",
      "60\tValidation loss: 0.735161\tBest loss: 0.735161\tAccuracy: 73.33%\n",
      "61\tValidation loss: 0.734483\tBest loss: 0.734483\tAccuracy: 72.67%\n",
      "62\tValidation loss: 0.731088\tBest loss: 0.731088\tAccuracy: 73.33%\n",
      "63\tValidation loss: 0.730128\tBest loss: 0.730128\tAccuracy: 73.33%\n",
      "64\tValidation loss: 0.729455\tBest loss: 0.729455\tAccuracy: 72.67%\n",
      "65\tValidation loss: 0.728695\tBest loss: 0.728695\tAccuracy: 72.67%\n",
      "66\tValidation loss: 0.726707\tBest loss: 0.726707\tAccuracy: 73.33%\n",
      "67\tValidation loss: 0.725179\tBest loss: 0.725179\tAccuracy: 72.67%\n",
      "68\tValidation loss: 0.723229\tBest loss: 0.723229\tAccuracy: 72.67%\n",
      "69\tValidation loss: 0.722771\tBest loss: 0.722771\tAccuracy: 72.67%\n",
      "70\tValidation loss: 0.721659\tBest loss: 0.721659\tAccuracy: 72.67%\n",
      "71\tValidation loss: 0.722559\tBest loss: 0.721659\tAccuracy: 72.67%\n",
      "72\tValidation loss: 0.722531\tBest loss: 0.721659\tAccuracy: 72.67%\n",
      "73\tValidation loss: 0.720545\tBest loss: 0.720545\tAccuracy: 72.67%\n",
      "74\tValidation loss: 0.719398\tBest loss: 0.719398\tAccuracy: 72.67%\n",
      "75\tValidation loss: 0.718705\tBest loss: 0.718705\tAccuracy: 72.67%\n",
      "76\tValidation loss: 0.717243\tBest loss: 0.717243\tAccuracy: 72.67%\n",
      "77\tValidation loss: 0.715774\tBest loss: 0.715774\tAccuracy: 72.67%\n",
      "78\tValidation loss: 0.715375\tBest loss: 0.715375\tAccuracy: 72.67%\n",
      "79\tValidation loss: 0.714437\tBest loss: 0.714437\tAccuracy: 72.67%\n",
      "80\tValidation loss: 0.712734\tBest loss: 0.712734\tAccuracy: 72.67%\n",
      "81\tValidation loss: 0.712729\tBest loss: 0.712729\tAccuracy: 72.67%\n",
      "82\tValidation loss: 0.710725\tBest loss: 0.710725\tAccuracy: 72.67%\n",
      "83\tValidation loss: 0.710238\tBest loss: 0.710238\tAccuracy: 72.67%\n",
      "84\tValidation loss: 0.709360\tBest loss: 0.709360\tAccuracy: 72.67%\n",
      "85\tValidation loss: 0.707976\tBest loss: 0.707976\tAccuracy: 72.67%\n",
      "86\tValidation loss: 0.706421\tBest loss: 0.706421\tAccuracy: 74.00%\n",
      "87\tValidation loss: 0.706351\tBest loss: 0.706351\tAccuracy: 72.67%\n",
      "88\tValidation loss: 0.706327\tBest loss: 0.706327\tAccuracy: 73.33%\n",
      "89\tValidation loss: 0.706016\tBest loss: 0.706016\tAccuracy: 72.67%\n",
      "90\tValidation loss: 0.705727\tBest loss: 0.705727\tAccuracy: 73.33%\n",
      "91\tValidation loss: 0.705014\tBest loss: 0.705014\tAccuracy: 73.33%\n",
      "92\tValidation loss: 0.704017\tBest loss: 0.704017\tAccuracy: 74.00%\n",
      "93\tValidation loss: 0.703738\tBest loss: 0.703738\tAccuracy: 73.33%\n",
      "94\tValidation loss: 0.701729\tBest loss: 0.701729\tAccuracy: 74.00%\n",
      "95\tValidation loss: 0.700640\tBest loss: 0.700640\tAccuracy: 73.33%\n",
      "96\tValidation loss: 0.700561\tBest loss: 0.700561\tAccuracy: 74.00%\n",
      "97\tValidation loss: 0.700319\tBest loss: 0.700319\tAccuracy: 74.00%\n",
      "98\tValidation loss: 0.699281\tBest loss: 0.699281\tAccuracy: 74.00%\n",
      "99\tValidation loss: 0.697876\tBest loss: 0.697876\tAccuracy: 74.00%\n",
      "100\tValidation loss: 0.698145\tBest loss: 0.697876\tAccuracy: 74.00%\n",
      "101\tValidation loss: 0.698035\tBest loss: 0.697876\tAccuracy: 74.00%\n",
      "102\tValidation loss: 0.697223\tBest loss: 0.697223\tAccuracy: 73.33%\n",
      "103\tValidation loss: 0.696922\tBest loss: 0.696922\tAccuracy: 73.33%\n",
      "104\tValidation loss: 0.696528\tBest loss: 0.696528\tAccuracy: 73.33%\n",
      "105\tValidation loss: 0.696593\tBest loss: 0.696528\tAccuracy: 74.00%\n",
      "106\tValidation loss: 0.695389\tBest loss: 0.695389\tAccuracy: 74.00%\n",
      "107\tValidation loss: 0.695844\tBest loss: 0.695389\tAccuracy: 74.00%\n",
      "108\tValidation loss: 0.694317\tBest loss: 0.694317\tAccuracy: 73.33%\n",
      "109\tValidation loss: 0.693354\tBest loss: 0.693354\tAccuracy: 73.33%\n",
      "110\tValidation loss: 0.693653\tBest loss: 0.693354\tAccuracy: 74.00%\n",
      "111\tValidation loss: 0.694057\tBest loss: 0.693354\tAccuracy: 74.00%\n",
      "112\tValidation loss: 0.693217\tBest loss: 0.693217\tAccuracy: 74.00%\n",
      "113\tValidation loss: 0.691403\tBest loss: 0.691403\tAccuracy: 73.33%\n",
      "114\tValidation loss: 0.691718\tBest loss: 0.691403\tAccuracy: 74.00%\n",
      "115\tValidation loss: 0.691507\tBest loss: 0.691403\tAccuracy: 74.00%\n",
      "116\tValidation loss: 0.691815\tBest loss: 0.691403\tAccuracy: 74.00%\n",
      "117\tValidation loss: 0.690359\tBest loss: 0.690359\tAccuracy: 74.00%\n",
      "118\tValidation loss: 0.690349\tBest loss: 0.690349\tAccuracy: 74.00%\n",
      "119\tValidation loss: 0.688992\tBest loss: 0.688992\tAccuracy: 74.00%\n",
      "120\tValidation loss: 0.689569\tBest loss: 0.688992\tAccuracy: 74.00%\n",
      "121\tValidation loss: 0.688971\tBest loss: 0.688971\tAccuracy: 74.00%\n",
      "122\tValidation loss: 0.688760\tBest loss: 0.688760\tAccuracy: 74.00%\n",
      "123\tValidation loss: 0.688914\tBest loss: 0.688760\tAccuracy: 74.00%\n",
      "124\tValidation loss: 0.688735\tBest loss: 0.688735\tAccuracy: 74.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 0.687370\tBest loss: 0.687370\tAccuracy: 74.00%\n",
      "126\tValidation loss: 0.686833\tBest loss: 0.686833\tAccuracy: 74.00%\n",
      "127\tValidation loss: 0.686621\tBest loss: 0.686621\tAccuracy: 74.00%\n",
      "128\tValidation loss: 0.686049\tBest loss: 0.686049\tAccuracy: 74.00%\n",
      "129\tValidation loss: 0.686183\tBest loss: 0.686049\tAccuracy: 74.00%\n",
      "130\tValidation loss: 0.686412\tBest loss: 0.686049\tAccuracy: 74.67%\n",
      "131\tValidation loss: 0.686172\tBest loss: 0.686049\tAccuracy: 74.67%\n",
      "132\tValidation loss: 0.685767\tBest loss: 0.685767\tAccuracy: 74.00%\n",
      "133\tValidation loss: 0.684623\tBest loss: 0.684623\tAccuracy: 74.67%\n",
      "134\tValidation loss: 0.684407\tBest loss: 0.684407\tAccuracy: 74.67%\n",
      "135\tValidation loss: 0.683400\tBest loss: 0.683400\tAccuracy: 74.67%\n",
      "136\tValidation loss: 0.682777\tBest loss: 0.682777\tAccuracy: 74.67%\n",
      "137\tValidation loss: 0.683154\tBest loss: 0.682777\tAccuracy: 74.67%\n",
      "138\tValidation loss: 0.682833\tBest loss: 0.682777\tAccuracy: 74.67%\n",
      "139\tValidation loss: 0.682289\tBest loss: 0.682289\tAccuracy: 74.67%\n",
      "140\tValidation loss: 0.682475\tBest loss: 0.682289\tAccuracy: 74.67%\n",
      "141\tValidation loss: 0.682539\tBest loss: 0.682289\tAccuracy: 74.67%\n",
      "142\tValidation loss: 0.682058\tBest loss: 0.682058\tAccuracy: 74.67%\n",
      "143\tValidation loss: 0.681915\tBest loss: 0.681915\tAccuracy: 74.67%\n",
      "144\tValidation loss: 0.681830\tBest loss: 0.681830\tAccuracy: 74.67%\n",
      "145\tValidation loss: 0.680900\tBest loss: 0.680900\tAccuracy: 74.67%\n",
      "146\tValidation loss: 0.679731\tBest loss: 0.679731\tAccuracy: 74.67%\n",
      "147\tValidation loss: 0.679927\tBest loss: 0.679731\tAccuracy: 74.67%\n",
      "148\tValidation loss: 0.680135\tBest loss: 0.679731\tAccuracy: 74.67%\n",
      "149\tValidation loss: 0.679396\tBest loss: 0.679396\tAccuracy: 74.67%\n",
      "150\tValidation loss: 0.679547\tBest loss: 0.679396\tAccuracy: 74.67%\n",
      "151\tValidation loss: 0.678963\tBest loss: 0.678963\tAccuracy: 74.67%\n",
      "152\tValidation loss: 0.678482\tBest loss: 0.678482\tAccuracy: 74.67%\n",
      "153\tValidation loss: 0.678763\tBest loss: 0.678482\tAccuracy: 74.67%\n",
      "154\tValidation loss: 0.678486\tBest loss: 0.678482\tAccuracy: 74.67%\n",
      "155\tValidation loss: 0.677738\tBest loss: 0.677738\tAccuracy: 74.67%\n",
      "156\tValidation loss: 0.677798\tBest loss: 0.677738\tAccuracy: 74.67%\n",
      "157\tValidation loss: 0.677111\tBest loss: 0.677111\tAccuracy: 74.67%\n",
      "158\tValidation loss: 0.676295\tBest loss: 0.676295\tAccuracy: 74.67%\n",
      "159\tValidation loss: 0.676618\tBest loss: 0.676295\tAccuracy: 74.67%\n",
      "160\tValidation loss: 0.676495\tBest loss: 0.676295\tAccuracy: 74.67%\n",
      "161\tValidation loss: 0.676886\tBest loss: 0.676295\tAccuracy: 74.67%\n",
      "162\tValidation loss: 0.676831\tBest loss: 0.676295\tAccuracy: 74.67%\n",
      "163\tValidation loss: 0.676068\tBest loss: 0.676068\tAccuracy: 74.67%\n",
      "164\tValidation loss: 0.675758\tBest loss: 0.675758\tAccuracy: 74.67%\n",
      "165\tValidation loss: 0.675122\tBest loss: 0.675122\tAccuracy: 74.67%\n",
      "166\tValidation loss: 0.675165\tBest loss: 0.675122\tAccuracy: 74.67%\n",
      "167\tValidation loss: 0.675460\tBest loss: 0.675122\tAccuracy: 74.67%\n",
      "168\tValidation loss: 0.674739\tBest loss: 0.674739\tAccuracy: 74.67%\n",
      "169\tValidation loss: 0.674897\tBest loss: 0.674739\tAccuracy: 74.67%\n",
      "170\tValidation loss: 0.674861\tBest loss: 0.674739\tAccuracy: 74.67%\n",
      "171\tValidation loss: 0.674611\tBest loss: 0.674611\tAccuracy: 74.67%\n",
      "172\tValidation loss: 0.674586\tBest loss: 0.674586\tAccuracy: 74.67%\n",
      "173\tValidation loss: 0.673984\tBest loss: 0.673984\tAccuracy: 74.67%\n",
      "174\tValidation loss: 0.673719\tBest loss: 0.673719\tAccuracy: 74.67%\n",
      "175\tValidation loss: 0.673475\tBest loss: 0.673475\tAccuracy: 74.67%\n",
      "176\tValidation loss: 0.673050\tBest loss: 0.673050\tAccuracy: 74.67%\n",
      "177\tValidation loss: 0.672624\tBest loss: 0.672624\tAccuracy: 74.67%\n",
      "178\tValidation loss: 0.673059\tBest loss: 0.672624\tAccuracy: 74.67%\n",
      "179\tValidation loss: 0.673227\tBest loss: 0.672624\tAccuracy: 74.67%\n",
      "180\tValidation loss: 0.672980\tBest loss: 0.672624\tAccuracy: 74.67%\n",
      "181\tValidation loss: 0.672570\tBest loss: 0.672570\tAccuracy: 74.67%\n",
      "182\tValidation loss: 0.673049\tBest loss: 0.672570\tAccuracy: 74.67%\n",
      "183\tValidation loss: 0.672992\tBest loss: 0.672570\tAccuracy: 74.67%\n",
      "184\tValidation loss: 0.672594\tBest loss: 0.672570\tAccuracy: 74.67%\n",
      "185\tValidation loss: 0.672179\tBest loss: 0.672179\tAccuracy: 74.67%\n",
      "186\tValidation loss: 0.671813\tBest loss: 0.671813\tAccuracy: 74.67%\n",
      "187\tValidation loss: 0.671685\tBest loss: 0.671685\tAccuracy: 74.67%\n",
      "188\tValidation loss: 0.671558\tBest loss: 0.671558\tAccuracy: 74.67%\n",
      "189\tValidation loss: 0.671406\tBest loss: 0.671406\tAccuracy: 74.67%\n",
      "190\tValidation loss: 0.671273\tBest loss: 0.671273\tAccuracy: 74.67%\n",
      "191\tValidation loss: 0.670814\tBest loss: 0.670814\tAccuracy: 74.67%\n",
      "192\tValidation loss: 0.670277\tBest loss: 0.670277\tAccuracy: 74.67%\n",
      "193\tValidation loss: 0.670237\tBest loss: 0.670237\tAccuracy: 74.67%\n",
      "194\tValidation loss: 0.669848\tBest loss: 0.669848\tAccuracy: 74.67%\n",
      "195\tValidation loss: 0.670040\tBest loss: 0.669848\tAccuracy: 74.67%\n",
      "196\tValidation loss: 0.670415\tBest loss: 0.669848\tAccuracy: 74.67%\n",
      "197\tValidation loss: 0.670323\tBest loss: 0.669848\tAccuracy: 74.67%\n",
      "198\tValidation loss: 0.670260\tBest loss: 0.669848\tAccuracy: 74.67%\n",
      "199\tValidation loss: 0.669635\tBest loss: 0.669635\tAccuracy: 74.67%\n",
      "200\tValidation loss: 0.668832\tBest loss: 0.668832\tAccuracy: 74.67%\n",
      "201\tValidation loss: 0.668840\tBest loss: 0.668832\tAccuracy: 74.67%\n",
      "202\tValidation loss: 0.668697\tBest loss: 0.668697\tAccuracy: 74.67%\n",
      "203\tValidation loss: 0.668459\tBest loss: 0.668459\tAccuracy: 74.67%\n",
      "204\tValidation loss: 0.668301\tBest loss: 0.668301\tAccuracy: 74.67%\n",
      "205\tValidation loss: 0.667924\tBest loss: 0.667924\tAccuracy: 74.67%\n",
      "206\tValidation loss: 0.668251\tBest loss: 0.667924\tAccuracy: 74.67%\n",
      "207\tValidation loss: 0.668380\tBest loss: 0.667924\tAccuracy: 74.67%\n",
      "208\tValidation loss: 0.668082\tBest loss: 0.667924\tAccuracy: 74.67%\n",
      "209\tValidation loss: 0.667729\tBest loss: 0.667729\tAccuracy: 74.67%\n",
      "210\tValidation loss: 0.667930\tBest loss: 0.667729\tAccuracy: 74.67%\n",
      "211\tValidation loss: 0.667801\tBest loss: 0.667729\tAccuracy: 74.67%\n",
      "212\tValidation loss: 0.667992\tBest loss: 0.667729\tAccuracy: 74.67%\n",
      "213\tValidation loss: 0.667976\tBest loss: 0.667729\tAccuracy: 74.67%\n",
      "214\tValidation loss: 0.668101\tBest loss: 0.667729\tAccuracy: 74.00%\n",
      "215\tValidation loss: 0.667586\tBest loss: 0.667586\tAccuracy: 74.00%\n",
      "216\tValidation loss: 0.667932\tBest loss: 0.667586\tAccuracy: 74.00%\n",
      "217\tValidation loss: 0.667276\tBest loss: 0.667276\tAccuracy: 74.00%\n",
      "218\tValidation loss: 0.667493\tBest loss: 0.667276\tAccuracy: 74.00%\n",
      "219\tValidation loss: 0.666703\tBest loss: 0.666703\tAccuracy: 74.00%\n",
      "220\tValidation loss: 0.667329\tBest loss: 0.666703\tAccuracy: 74.00%\n",
      "221\tValidation loss: 0.666842\tBest loss: 0.666703\tAccuracy: 74.00%\n",
      "222\tValidation loss: 0.666892\tBest loss: 0.666703\tAccuracy: 74.00%\n",
      "223\tValidation loss: 0.666886\tBest loss: 0.666703\tAccuracy: 74.00%\n",
      "224\tValidation loss: 0.666442\tBest loss: 0.666442\tAccuracy: 74.00%\n",
      "225\tValidation loss: 0.666408\tBest loss: 0.666408\tAccuracy: 74.00%\n",
      "226\tValidation loss: 0.666297\tBest loss: 0.666297\tAccuracy: 74.00%\n",
      "227\tValidation loss: 0.666016\tBest loss: 0.666016\tAccuracy: 74.00%\n",
      "228\tValidation loss: 0.665803\tBest loss: 0.665803\tAccuracy: 74.00%\n",
      "229\tValidation loss: 0.665561\tBest loss: 0.665561\tAccuracy: 74.00%\n",
      "230\tValidation loss: 0.665354\tBest loss: 0.665354\tAccuracy: 74.00%\n",
      "231\tValidation loss: 0.665326\tBest loss: 0.665326\tAccuracy: 74.00%\n",
      "232\tValidation loss: 0.665486\tBest loss: 0.665326\tAccuracy: 74.00%\n",
      "233\tValidation loss: 0.664976\tBest loss: 0.664976\tAccuracy: 74.00%\n",
      "234\tValidation loss: 0.665301\tBest loss: 0.664976\tAccuracy: 74.00%\n",
      "235\tValidation loss: 0.665157\tBest loss: 0.664976\tAccuracy: 74.00%\n",
      "236\tValidation loss: 0.665186\tBest loss: 0.664976\tAccuracy: 74.00%\n",
      "237\tValidation loss: 0.664950\tBest loss: 0.664950\tAccuracy: 74.00%\n",
      "238\tValidation loss: 0.665206\tBest loss: 0.664950\tAccuracy: 74.00%\n",
      "239\tValidation loss: 0.664834\tBest loss: 0.664834\tAccuracy: 74.00%\n",
      "240\tValidation loss: 0.664404\tBest loss: 0.664404\tAccuracy: 74.00%\n",
      "241\tValidation loss: 0.664226\tBest loss: 0.664226\tAccuracy: 74.00%\n",
      "242\tValidation loss: 0.664203\tBest loss: 0.664203\tAccuracy: 74.00%\n",
      "243\tValidation loss: 0.663751\tBest loss: 0.663751\tAccuracy: 74.00%\n",
      "244\tValidation loss: 0.663483\tBest loss: 0.663483\tAccuracy: 74.00%\n",
      "245\tValidation loss: 0.663268\tBest loss: 0.663268\tAccuracy: 74.00%\n",
      "246\tValidation loss: 0.663408\tBest loss: 0.663268\tAccuracy: 74.00%\n",
      "247\tValidation loss: 0.663193\tBest loss: 0.663193\tAccuracy: 74.00%\n",
      "248\tValidation loss: 0.663758\tBest loss: 0.663193\tAccuracy: 74.00%\n",
      "249\tValidation loss: 0.663396\tBest loss: 0.663193\tAccuracy: 74.00%\n",
      "250\tValidation loss: 0.663226\tBest loss: 0.663193\tAccuracy: 74.00%\n",
      "251\tValidation loss: 0.663584\tBest loss: 0.663193\tAccuracy: 74.00%\n",
      "252\tValidation loss: 0.663688\tBest loss: 0.663193\tAccuracy: 74.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\tValidation loss: 0.663692\tBest loss: 0.663193\tAccuracy: 74.00%\n",
      "254\tValidation loss: 0.663745\tBest loss: 0.663193\tAccuracy: 74.00%\n",
      "255\tValidation loss: 0.663361\tBest loss: 0.663193\tAccuracy: 74.00%\n",
      "256\tValidation loss: 0.662838\tBest loss: 0.662838\tAccuracy: 74.00%\n",
      "257\tValidation loss: 0.662941\tBest loss: 0.662838\tAccuracy: 74.00%\n",
      "258\tValidation loss: 0.662331\tBest loss: 0.662331\tAccuracy: 74.00%\n",
      "259\tValidation loss: 0.662562\tBest loss: 0.662331\tAccuracy: 74.00%\n",
      "260\tValidation loss: 0.662883\tBest loss: 0.662331\tAccuracy: 74.00%\n",
      "261\tValidation loss: 0.663077\tBest loss: 0.662331\tAccuracy: 74.00%\n",
      "262\tValidation loss: 0.662527\tBest loss: 0.662331\tAccuracy: 74.00%\n",
      "263\tValidation loss: 0.662533\tBest loss: 0.662331\tAccuracy: 74.00%\n",
      "264\tValidation loss: 0.662356\tBest loss: 0.662331\tAccuracy: 74.00%\n",
      "265\tValidation loss: 0.662253\tBest loss: 0.662253\tAccuracy: 74.00%\n",
      "266\tValidation loss: 0.662347\tBest loss: 0.662253\tAccuracy: 74.00%\n",
      "267\tValidation loss: 0.662505\tBest loss: 0.662253\tAccuracy: 74.00%\n",
      "268\tValidation loss: 0.662189\tBest loss: 0.662189\tAccuracy: 74.00%\n",
      "269\tValidation loss: 0.661992\tBest loss: 0.661992\tAccuracy: 74.00%\n",
      "270\tValidation loss: 0.662520\tBest loss: 0.661992\tAccuracy: 74.00%\n",
      "271\tValidation loss: 0.662199\tBest loss: 0.661992\tAccuracy: 74.00%\n",
      "272\tValidation loss: 0.661714\tBest loss: 0.661714\tAccuracy: 74.00%\n",
      "273\tValidation loss: 0.661318\tBest loss: 0.661318\tAccuracy: 74.00%\n",
      "274\tValidation loss: 0.661506\tBest loss: 0.661318\tAccuracy: 74.00%\n",
      "275\tValidation loss: 0.661722\tBest loss: 0.661318\tAccuracy: 74.00%\n",
      "276\tValidation loss: 0.661564\tBest loss: 0.661318\tAccuracy: 74.00%\n",
      "277\tValidation loss: 0.661544\tBest loss: 0.661318\tAccuracy: 74.00%\n",
      "278\tValidation loss: 0.661435\tBest loss: 0.661318\tAccuracy: 74.00%\n",
      "279\tValidation loss: 0.661429\tBest loss: 0.661318\tAccuracy: 74.00%\n",
      "280\tValidation loss: 0.661336\tBest loss: 0.661318\tAccuracy: 74.00%\n",
      "281\tValidation loss: 0.661005\tBest loss: 0.661005\tAccuracy: 74.00%\n",
      "282\tValidation loss: 0.660715\tBest loss: 0.660715\tAccuracy: 74.00%\n",
      "283\tValidation loss: 0.660696\tBest loss: 0.660696\tAccuracy: 74.00%\n",
      "284\tValidation loss: 0.660793\tBest loss: 0.660696\tAccuracy: 74.00%\n",
      "285\tValidation loss: 0.660784\tBest loss: 0.660696\tAccuracy: 74.00%\n",
      "286\tValidation loss: 0.660801\tBest loss: 0.660696\tAccuracy: 74.00%\n",
      "287\tValidation loss: 0.660586\tBest loss: 0.660586\tAccuracy: 74.00%\n",
      "288\tValidation loss: 0.660339\tBest loss: 0.660339\tAccuracy: 74.00%\n",
      "289\tValidation loss: 0.660074\tBest loss: 0.660074\tAccuracy: 74.00%\n",
      "290\tValidation loss: 0.659895\tBest loss: 0.659895\tAccuracy: 74.00%\n",
      "291\tValidation loss: 0.659874\tBest loss: 0.659874\tAccuracy: 74.00%\n",
      "292\tValidation loss: 0.660197\tBest loss: 0.659874\tAccuracy: 74.00%\n",
      "293\tValidation loss: 0.660110\tBest loss: 0.659874\tAccuracy: 74.00%\n",
      "294\tValidation loss: 0.659993\tBest loss: 0.659874\tAccuracy: 74.00%\n",
      "295\tValidation loss: 0.660205\tBest loss: 0.659874\tAccuracy: 74.00%\n",
      "296\tValidation loss: 0.659947\tBest loss: 0.659874\tAccuracy: 74.00%\n",
      "297\tValidation loss: 0.659508\tBest loss: 0.659508\tAccuracy: 74.00%\n",
      "298\tValidation loss: 0.659464\tBest loss: 0.659464\tAccuracy: 74.00%\n",
      "299\tValidation loss: 0.659446\tBest loss: 0.659446\tAccuracy: 74.00%\n",
      "300\tValidation loss: 0.659526\tBest loss: 0.659446\tAccuracy: 74.00%\n",
      "301\tValidation loss: 0.659341\tBest loss: 0.659341\tAccuracy: 74.00%\n",
      "302\tValidation loss: 0.658977\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "303\tValidation loss: 0.659178\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "304\tValidation loss: 0.659362\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "305\tValidation loss: 0.659322\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "306\tValidation loss: 0.659622\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "307\tValidation loss: 0.659486\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "308\tValidation loss: 0.659464\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "309\tValidation loss: 0.659258\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "310\tValidation loss: 0.659371\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "311\tValidation loss: 0.659053\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "312\tValidation loss: 0.659340\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "313\tValidation loss: 0.659169\tBest loss: 0.658977\tAccuracy: 74.00%\n",
      "314\tValidation loss: 0.658678\tBest loss: 0.658678\tAccuracy: 74.00%\n",
      "315\tValidation loss: 0.658912\tBest loss: 0.658678\tAccuracy: 74.00%\n",
      "316\tValidation loss: 0.658659\tBest loss: 0.658659\tAccuracy: 74.00%\n",
      "317\tValidation loss: 0.658594\tBest loss: 0.658594\tAccuracy: 74.00%\n",
      "318\tValidation loss: 0.659075\tBest loss: 0.658594\tAccuracy: 74.00%\n",
      "319\tValidation loss: 0.658975\tBest loss: 0.658594\tAccuracy: 74.00%\n",
      "320\tValidation loss: 0.658972\tBest loss: 0.658594\tAccuracy: 74.00%\n",
      "321\tValidation loss: 0.658737\tBest loss: 0.658594\tAccuracy: 74.00%\n",
      "322\tValidation loss: 0.658533\tBest loss: 0.658533\tAccuracy: 74.00%\n",
      "323\tValidation loss: 0.658338\tBest loss: 0.658338\tAccuracy: 74.00%\n",
      "324\tValidation loss: 0.658759\tBest loss: 0.658338\tAccuracy: 74.00%\n",
      "325\tValidation loss: 0.658504\tBest loss: 0.658338\tAccuracy: 74.00%\n",
      "326\tValidation loss: 0.658344\tBest loss: 0.658338\tAccuracy: 74.00%\n",
      "327\tValidation loss: 0.658455\tBest loss: 0.658338\tAccuracy: 74.00%\n",
      "328\tValidation loss: 0.658363\tBest loss: 0.658338\tAccuracy: 74.00%\n",
      "329\tValidation loss: 0.658234\tBest loss: 0.658234\tAccuracy: 74.00%\n",
      "330\tValidation loss: 0.658446\tBest loss: 0.658234\tAccuracy: 74.00%\n",
      "331\tValidation loss: 0.658094\tBest loss: 0.658094\tAccuracy: 74.00%\n",
      "332\tValidation loss: 0.658414\tBest loss: 0.658094\tAccuracy: 74.00%\n",
      "333\tValidation loss: 0.658136\tBest loss: 0.658094\tAccuracy: 74.00%\n",
      "334\tValidation loss: 0.658076\tBest loss: 0.658076\tAccuracy: 74.00%\n",
      "335\tValidation loss: 0.657808\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "336\tValidation loss: 0.658117\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "337\tValidation loss: 0.658467\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "338\tValidation loss: 0.658164\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "339\tValidation loss: 0.658102\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "340\tValidation loss: 0.658297\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "341\tValidation loss: 0.658058\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "342\tValidation loss: 0.658116\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "343\tValidation loss: 0.657901\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "344\tValidation loss: 0.658020\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "345\tValidation loss: 0.658175\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "346\tValidation loss: 0.657812\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "347\tValidation loss: 0.658010\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "348\tValidation loss: 0.658168\tBest loss: 0.657808\tAccuracy: 74.00%\n",
      "349\tValidation loss: 0.657441\tBest loss: 0.657441\tAccuracy: 74.00%\n",
      "350\tValidation loss: 0.657665\tBest loss: 0.657441\tAccuracy: 74.00%\n",
      "351\tValidation loss: 0.657472\tBest loss: 0.657441\tAccuracy: 74.00%\n",
      "352\tValidation loss: 0.657730\tBest loss: 0.657441\tAccuracy: 74.00%\n",
      "353\tValidation loss: 0.657845\tBest loss: 0.657441\tAccuracy: 74.00%\n",
      "354\tValidation loss: 0.657521\tBest loss: 0.657441\tAccuracy: 74.00%\n",
      "355\tValidation loss: 0.657210\tBest loss: 0.657210\tAccuracy: 74.00%\n",
      "356\tValidation loss: 0.657609\tBest loss: 0.657210\tAccuracy: 74.00%\n",
      "357\tValidation loss: 0.657224\tBest loss: 0.657210\tAccuracy: 74.00%\n",
      "358\tValidation loss: 0.657165\tBest loss: 0.657165\tAccuracy: 74.00%\n",
      "359\tValidation loss: 0.657502\tBest loss: 0.657165\tAccuracy: 74.00%\n",
      "360\tValidation loss: 0.657454\tBest loss: 0.657165\tAccuracy: 74.00%\n",
      "361\tValidation loss: 0.657315\tBest loss: 0.657165\tAccuracy: 74.00%\n",
      "362\tValidation loss: 0.657086\tBest loss: 0.657086\tAccuracy: 74.00%\n",
      "363\tValidation loss: 0.657215\tBest loss: 0.657086\tAccuracy: 74.00%\n",
      "364\tValidation loss: 0.657317\tBest loss: 0.657086\tAccuracy: 74.00%\n",
      "365\tValidation loss: 0.657121\tBest loss: 0.657086\tAccuracy: 74.00%\n",
      "366\tValidation loss: 0.657066\tBest loss: 0.657066\tAccuracy: 74.00%\n",
      "367\tValidation loss: 0.656891\tBest loss: 0.656891\tAccuracy: 74.00%\n",
      "368\tValidation loss: 0.656576\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "369\tValidation loss: 0.656723\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "370\tValidation loss: 0.656896\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "371\tValidation loss: 0.657330\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "372\tValidation loss: 0.657146\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "373\tValidation loss: 0.657411\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "374\tValidation loss: 0.657339\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "375\tValidation loss: 0.657443\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "376\tValidation loss: 0.657326\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "377\tValidation loss: 0.657269\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "378\tValidation loss: 0.657003\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "379\tValidation loss: 0.656938\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "380\tValidation loss: 0.656874\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "381\tValidation loss: 0.657017\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "382\tValidation loss: 0.656763\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "383\tValidation loss: 0.656862\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "384\tValidation loss: 0.656870\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "385\tValidation loss: 0.656864\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "386\tValidation loss: 0.656888\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "387\tValidation loss: 0.656677\tBest loss: 0.656576\tAccuracy: 74.00%\n",
      "388\tValidation loss: 0.656489\tBest loss: 0.656489\tAccuracy: 74.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\tValidation loss: 0.656413\tBest loss: 0.656413\tAccuracy: 74.00%\n",
      "390\tValidation loss: 0.656259\tBest loss: 0.656259\tAccuracy: 74.00%\n",
      "391\tValidation loss: 0.656108\tBest loss: 0.656108\tAccuracy: 74.00%\n",
      "392\tValidation loss: 0.656388\tBest loss: 0.656108\tAccuracy: 74.00%\n",
      "393\tValidation loss: 0.656367\tBest loss: 0.656108\tAccuracy: 74.00%\n",
      "394\tValidation loss: 0.656302\tBest loss: 0.656108\tAccuracy: 74.00%\n",
      "395\tValidation loss: 0.656000\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "396\tValidation loss: 0.656330\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "397\tValidation loss: 0.656461\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "398\tValidation loss: 0.656386\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "399\tValidation loss: 0.656440\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "400\tValidation loss: 0.656668\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "401\tValidation loss: 0.656741\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "402\tValidation loss: 0.656668\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "403\tValidation loss: 0.656680\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "404\tValidation loss: 0.656326\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "405\tValidation loss: 0.656171\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "406\tValidation loss: 0.656008\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "407\tValidation loss: 0.656020\tBest loss: 0.656000\tAccuracy: 74.00%\n",
      "408\tValidation loss: 0.655811\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "409\tValidation loss: 0.656269\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "410\tValidation loss: 0.656243\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "411\tValidation loss: 0.656167\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "412\tValidation loss: 0.655974\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "413\tValidation loss: 0.656090\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "414\tValidation loss: 0.656115\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "415\tValidation loss: 0.656175\tBest loss: 0.655811\tAccuracy: 74.67%\n",
      "416\tValidation loss: 0.656198\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "417\tValidation loss: 0.656119\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "418\tValidation loss: 0.656155\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "419\tValidation loss: 0.656133\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "420\tValidation loss: 0.656049\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "421\tValidation loss: 0.656171\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "422\tValidation loss: 0.656175\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "423\tValidation loss: 0.656084\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "424\tValidation loss: 0.656024\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "425\tValidation loss: 0.656046\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "426\tValidation loss: 0.655981\tBest loss: 0.655811\tAccuracy: 74.00%\n",
      "427\tValidation loss: 0.655797\tBest loss: 0.655797\tAccuracy: 74.00%\n",
      "428\tValidation loss: 0.655671\tBest loss: 0.655671\tAccuracy: 74.00%\n",
      "429\tValidation loss: 0.655805\tBest loss: 0.655671\tAccuracy: 74.00%\n",
      "430\tValidation loss: 0.655903\tBest loss: 0.655671\tAccuracy: 74.00%\n",
      "431\tValidation loss: 0.655711\tBest loss: 0.655671\tAccuracy: 74.00%\n",
      "432\tValidation loss: 0.655897\tBest loss: 0.655671\tAccuracy: 74.00%\n",
      "433\tValidation loss: 0.655839\tBest loss: 0.655671\tAccuracy: 74.00%\n",
      "434\tValidation loss: 0.655818\tBest loss: 0.655671\tAccuracy: 74.00%\n",
      "435\tValidation loss: 0.655734\tBest loss: 0.655671\tAccuracy: 74.67%\n",
      "436\tValidation loss: 0.655631\tBest loss: 0.655631\tAccuracy: 74.67%\n",
      "437\tValidation loss: 0.655497\tBest loss: 0.655497\tAccuracy: 74.67%\n",
      "438\tValidation loss: 0.655518\tBest loss: 0.655497\tAccuracy: 74.67%\n",
      "439\tValidation loss: 0.655369\tBest loss: 0.655369\tAccuracy: 74.67%\n",
      "440\tValidation loss: 0.655474\tBest loss: 0.655369\tAccuracy: 74.67%\n",
      "441\tValidation loss: 0.655692\tBest loss: 0.655369\tAccuracy: 74.67%\n",
      "442\tValidation loss: 0.655537\tBest loss: 0.655369\tAccuracy: 74.00%\n",
      "443\tValidation loss: 0.655668\tBest loss: 0.655369\tAccuracy: 74.67%\n",
      "444\tValidation loss: 0.656002\tBest loss: 0.655369\tAccuracy: 74.00%\n",
      "445\tValidation loss: 0.655782\tBest loss: 0.655369\tAccuracy: 74.00%\n",
      "446\tValidation loss: 0.655595\tBest loss: 0.655369\tAccuracy: 74.67%\n",
      "447\tValidation loss: 0.655588\tBest loss: 0.655369\tAccuracy: 74.67%\n",
      "448\tValidation loss: 0.655392\tBest loss: 0.655369\tAccuracy: 74.67%\n",
      "449\tValidation loss: 0.655206\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "450\tValidation loss: 0.655343\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "451\tValidation loss: 0.655537\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "452\tValidation loss: 0.655417\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "453\tValidation loss: 0.655628\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "454\tValidation loss: 0.655662\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "455\tValidation loss: 0.655593\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "456\tValidation loss: 0.655215\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "457\tValidation loss: 0.655363\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "458\tValidation loss: 0.655580\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "459\tValidation loss: 0.655422\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "460\tValidation loss: 0.655472\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "461\tValidation loss: 0.655242\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "462\tValidation loss: 0.655284\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "463\tValidation loss: 0.655329\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "464\tValidation loss: 0.655347\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "465\tValidation loss: 0.655434\tBest loss: 0.655206\tAccuracy: 74.67%\n",
      "466\tValidation loss: 0.655077\tBest loss: 0.655077\tAccuracy: 74.67%\n",
      "467\tValidation loss: 0.654894\tBest loss: 0.654894\tAccuracy: 74.67%\n",
      "468\tValidation loss: 0.654998\tBest loss: 0.654894\tAccuracy: 74.67%\n",
      "469\tValidation loss: 0.655007\tBest loss: 0.654894\tAccuracy: 74.67%\n",
      "470\tValidation loss: 0.655007\tBest loss: 0.654894\tAccuracy: 74.67%\n",
      "471\tValidation loss: 0.655079\tBest loss: 0.654894\tAccuracy: 74.67%\n",
      "472\tValidation loss: 0.655149\tBest loss: 0.654894\tAccuracy: 74.67%\n",
      "473\tValidation loss: 0.655195\tBest loss: 0.654894\tAccuracy: 74.67%\n",
      "474\tValidation loss: 0.654756\tBest loss: 0.654756\tAccuracy: 74.67%\n",
      "475\tValidation loss: 0.654929\tBest loss: 0.654756\tAccuracy: 74.67%\n",
      "476\tValidation loss: 0.654901\tBest loss: 0.654756\tAccuracy: 74.67%\n",
      "477\tValidation loss: 0.654979\tBest loss: 0.654756\tAccuracy: 74.67%\n",
      "478\tValidation loss: 0.654749\tBest loss: 0.654749\tAccuracy: 74.67%\n",
      "479\tValidation loss: 0.654678\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "480\tValidation loss: 0.654681\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "481\tValidation loss: 0.654860\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "482\tValidation loss: 0.654785\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "483\tValidation loss: 0.654727\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "484\tValidation loss: 0.654920\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "485\tValidation loss: 0.654906\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "486\tValidation loss: 0.655105\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "487\tValidation loss: 0.655199\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "488\tValidation loss: 0.655308\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "489\tValidation loss: 0.655206\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "490\tValidation loss: 0.655348\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "491\tValidation loss: 0.655389\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "492\tValidation loss: 0.655233\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "493\tValidation loss: 0.655265\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "494\tValidation loss: 0.655301\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "495\tValidation loss: 0.655440\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "496\tValidation loss: 0.655447\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "497\tValidation loss: 0.655487\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "498\tValidation loss: 0.655317\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "499\tValidation loss: 0.655252\tBest loss: 0.654678\tAccuracy: 74.67%\n",
      "Early stopping!\n",
      "Total training time: 20.2s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 74.92%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    hidden3_train = hidden3_out.eval(feed_dict={X: X_train2, y: y_train2})\n",
    "    hidden3_valid = hidden3_out.eval(feed_dict={X: X_valid2, y: y_valid2})\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx,len(X_train2) // batch_size):\n",
    "            h3_batch,y_batch = hidden3_train[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={hidden3_out: h3_batch, y: y_batch})\n",
    "        \n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden3_out: hidden3_valid, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))\n",
    "                                     \n",
    "                                     \n",
    "                                     \n",
    "                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4\n",
    "\n",
    "Try again reusing just four hiddne layers instead of five."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model again make the adjustments\n",
    "\n",
    "NOTE:\n",
    "\n",
    "My best model did not go past three layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_outputs = 5\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3_out = tf.get_default_graph().get_tensor_by_name(\"hidden3_out:0\")\n",
    "logits = tf.layers.dense(hidden3_out, n_outputs, kernel_initializer=he_init, name=\"new_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retrain but freeze all layes except for the new output layer\n",
    "\n",
    "note the output layer has weights as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                     scope='new_logits')\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate,name='Adam2')\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 3.940953\tBest loss: 3.940953\tAccuracy: 32.00%\n",
      "1\tValidation loss: 3.934259\tBest loss: 3.934259\tAccuracy: 32.00%\n",
      "2\tValidation loss: 3.927693\tBest loss: 3.927693\tAccuracy: 32.00%\n",
      "3\tValidation loss: 3.921140\tBest loss: 3.921140\tAccuracy: 32.00%\n",
      "4\tValidation loss: 3.914660\tBest loss: 3.914660\tAccuracy: 32.00%\n",
      "5\tValidation loss: 3.908267\tBest loss: 3.908267\tAccuracy: 32.00%\n",
      "6\tValidation loss: 3.901932\tBest loss: 3.901932\tAccuracy: 32.00%\n",
      "7\tValidation loss: 3.895660\tBest loss: 3.895660\tAccuracy: 32.00%\n",
      "8\tValidation loss: 3.889436\tBest loss: 3.889436\tAccuracy: 32.00%\n",
      "9\tValidation loss: 3.883257\tBest loss: 3.883257\tAccuracy: 32.00%\n",
      "10\tValidation loss: 3.877084\tBest loss: 3.877084\tAccuracy: 32.00%\n",
      "11\tValidation loss: 3.870926\tBest loss: 3.870926\tAccuracy: 32.67%\n",
      "12\tValidation loss: 3.864837\tBest loss: 3.864837\tAccuracy: 32.67%\n",
      "13\tValidation loss: 3.858735\tBest loss: 3.858735\tAccuracy: 32.67%\n",
      "14\tValidation loss: 3.852686\tBest loss: 3.852686\tAccuracy: 32.67%\n",
      "15\tValidation loss: 3.846723\tBest loss: 3.846723\tAccuracy: 32.67%\n",
      "16\tValidation loss: 3.840774\tBest loss: 3.840774\tAccuracy: 32.67%\n",
      "17\tValidation loss: 3.834802\tBest loss: 3.834802\tAccuracy: 32.67%\n",
      "18\tValidation loss: 3.828835\tBest loss: 3.828835\tAccuracy: 32.67%\n",
      "19\tValidation loss: 3.822866\tBest loss: 3.822866\tAccuracy: 32.67%\n",
      "20\tValidation loss: 3.816881\tBest loss: 3.816881\tAccuracy: 32.67%\n",
      "21\tValidation loss: 3.810932\tBest loss: 3.810932\tAccuracy: 32.67%\n",
      "22\tValidation loss: 3.804978\tBest loss: 3.804978\tAccuracy: 32.67%\n",
      "23\tValidation loss: 3.799030\tBest loss: 3.799030\tAccuracy: 32.67%\n",
      "24\tValidation loss: 3.793123\tBest loss: 3.793123\tAccuracy: 32.67%\n",
      "25\tValidation loss: 3.787271\tBest loss: 3.787271\tAccuracy: 33.33%\n",
      "26\tValidation loss: 3.781427\tBest loss: 3.781427\tAccuracy: 33.33%\n",
      "27\tValidation loss: 3.775585\tBest loss: 3.775585\tAccuracy: 33.33%\n",
      "28\tValidation loss: 3.769783\tBest loss: 3.769783\tAccuracy: 34.00%\n",
      "29\tValidation loss: 3.763982\tBest loss: 3.763982\tAccuracy: 34.00%\n",
      "30\tValidation loss: 3.758187\tBest loss: 3.758187\tAccuracy: 34.00%\n",
      "31\tValidation loss: 3.752443\tBest loss: 3.752443\tAccuracy: 34.00%\n",
      "32\tValidation loss: 3.746730\tBest loss: 3.746730\tAccuracy: 34.00%\n",
      "33\tValidation loss: 3.741122\tBest loss: 3.741122\tAccuracy: 34.00%\n",
      "34\tValidation loss: 3.735450\tBest loss: 3.735450\tAccuracy: 34.00%\n",
      "35\tValidation loss: 3.729838\tBest loss: 3.729838\tAccuracy: 34.00%\n",
      "36\tValidation loss: 3.724236\tBest loss: 3.724236\tAccuracy: 34.00%\n",
      "37\tValidation loss: 3.718719\tBest loss: 3.718719\tAccuracy: 34.00%\n",
      "38\tValidation loss: 3.713169\tBest loss: 3.713169\tAccuracy: 34.00%\n",
      "39\tValidation loss: 3.707603\tBest loss: 3.707603\tAccuracy: 34.00%\n",
      "40\tValidation loss: 3.702060\tBest loss: 3.702060\tAccuracy: 34.00%\n",
      "41\tValidation loss: 3.696599\tBest loss: 3.696599\tAccuracy: 34.00%\n",
      "42\tValidation loss: 3.691111\tBest loss: 3.691111\tAccuracy: 34.00%\n",
      "43\tValidation loss: 3.685604\tBest loss: 3.685604\tAccuracy: 34.00%\n",
      "44\tValidation loss: 3.680131\tBest loss: 3.680131\tAccuracy: 34.00%\n",
      "45\tValidation loss: 3.674617\tBest loss: 3.674617\tAccuracy: 34.00%\n",
      "46\tValidation loss: 3.669201\tBest loss: 3.669201\tAccuracy: 34.00%\n",
      "47\tValidation loss: 3.663795\tBest loss: 3.663795\tAccuracy: 34.00%\n",
      "48\tValidation loss: 3.658471\tBest loss: 3.658471\tAccuracy: 34.00%\n",
      "49\tValidation loss: 3.653117\tBest loss: 3.653117\tAccuracy: 34.00%\n",
      "50\tValidation loss: 3.647751\tBest loss: 3.647751\tAccuracy: 34.00%\n",
      "51\tValidation loss: 3.642418\tBest loss: 3.642418\tAccuracy: 34.00%\n",
      "52\tValidation loss: 3.637065\tBest loss: 3.637065\tAccuracy: 34.00%\n",
      "53\tValidation loss: 3.631680\tBest loss: 3.631680\tAccuracy: 34.00%\n",
      "54\tValidation loss: 3.626324\tBest loss: 3.626324\tAccuracy: 34.00%\n",
      "55\tValidation loss: 3.620969\tBest loss: 3.620969\tAccuracy: 34.00%\n",
      "56\tValidation loss: 3.615657\tBest loss: 3.615657\tAccuracy: 34.00%\n",
      "57\tValidation loss: 3.610370\tBest loss: 3.610370\tAccuracy: 34.67%\n",
      "58\tValidation loss: 3.605085\tBest loss: 3.605085\tAccuracy: 34.67%\n",
      "59\tValidation loss: 3.599796\tBest loss: 3.599796\tAccuracy: 34.67%\n",
      "60\tValidation loss: 3.594537\tBest loss: 3.594537\tAccuracy: 34.67%\n",
      "61\tValidation loss: 3.589252\tBest loss: 3.589252\tAccuracy: 34.67%\n",
      "62\tValidation loss: 3.583926\tBest loss: 3.583926\tAccuracy: 34.67%\n",
      "63\tValidation loss: 3.578644\tBest loss: 3.578644\tAccuracy: 34.67%\n",
      "64\tValidation loss: 3.573397\tBest loss: 3.573397\tAccuracy: 35.33%\n",
      "65\tValidation loss: 3.568125\tBest loss: 3.568125\tAccuracy: 35.33%\n",
      "66\tValidation loss: 3.562818\tBest loss: 3.562818\tAccuracy: 35.33%\n",
      "67\tValidation loss: 3.557547\tBest loss: 3.557547\tAccuracy: 35.33%\n",
      "68\tValidation loss: 3.552294\tBest loss: 3.552294\tAccuracy: 35.33%\n",
      "69\tValidation loss: 3.547008\tBest loss: 3.547008\tAccuracy: 35.33%\n",
      "70\tValidation loss: 3.541754\tBest loss: 3.541754\tAccuracy: 36.00%\n",
      "71\tValidation loss: 3.536499\tBest loss: 3.536499\tAccuracy: 36.00%\n",
      "72\tValidation loss: 3.531294\tBest loss: 3.531294\tAccuracy: 36.00%\n",
      "73\tValidation loss: 3.526098\tBest loss: 3.526098\tAccuracy: 36.00%\n",
      "74\tValidation loss: 3.520959\tBest loss: 3.520959\tAccuracy: 36.00%\n",
      "75\tValidation loss: 3.515808\tBest loss: 3.515808\tAccuracy: 36.00%\n",
      "76\tValidation loss: 3.510640\tBest loss: 3.510640\tAccuracy: 36.67%\n",
      "77\tValidation loss: 3.505448\tBest loss: 3.505448\tAccuracy: 36.67%\n",
      "78\tValidation loss: 3.500240\tBest loss: 3.500240\tAccuracy: 36.67%\n",
      "79\tValidation loss: 3.495062\tBest loss: 3.495062\tAccuracy: 36.67%\n",
      "80\tValidation loss: 3.489880\tBest loss: 3.489880\tAccuracy: 36.67%\n",
      "81\tValidation loss: 3.484722\tBest loss: 3.484722\tAccuracy: 36.67%\n",
      "82\tValidation loss: 3.479620\tBest loss: 3.479620\tAccuracy: 36.67%\n",
      "83\tValidation loss: 3.474551\tBest loss: 3.474551\tAccuracy: 36.67%\n",
      "84\tValidation loss: 3.469504\tBest loss: 3.469504\tAccuracy: 36.67%\n",
      "85\tValidation loss: 3.464394\tBest loss: 3.464394\tAccuracy: 36.67%\n",
      "86\tValidation loss: 3.459250\tBest loss: 3.459250\tAccuracy: 36.67%\n",
      "87\tValidation loss: 3.454097\tBest loss: 3.454097\tAccuracy: 36.67%\n",
      "88\tValidation loss: 3.448913\tBest loss: 3.448913\tAccuracy: 36.67%\n",
      "89\tValidation loss: 3.443793\tBest loss: 3.443793\tAccuracy: 36.67%\n",
      "90\tValidation loss: 3.438698\tBest loss: 3.438698\tAccuracy: 36.67%\n",
      "91\tValidation loss: 3.433600\tBest loss: 3.433600\tAccuracy: 36.67%\n",
      "92\tValidation loss: 3.428483\tBest loss: 3.428483\tAccuracy: 36.67%\n",
      "93\tValidation loss: 3.423411\tBest loss: 3.423411\tAccuracy: 36.67%\n",
      "94\tValidation loss: 3.418363\tBest loss: 3.418363\tAccuracy: 36.67%\n",
      "95\tValidation loss: 3.413336\tBest loss: 3.413336\tAccuracy: 36.67%\n",
      "96\tValidation loss: 3.408309\tBest loss: 3.408309\tAccuracy: 36.67%\n",
      "97\tValidation loss: 3.403314\tBest loss: 3.403314\tAccuracy: 37.33%\n",
      "98\tValidation loss: 3.398388\tBest loss: 3.398388\tAccuracy: 37.33%\n",
      "99\tValidation loss: 3.393474\tBest loss: 3.393474\tAccuracy: 37.33%\n",
      "100\tValidation loss: 3.388595\tBest loss: 3.388595\tAccuracy: 37.33%\n",
      "101\tValidation loss: 3.383773\tBest loss: 3.383773\tAccuracy: 37.33%\n",
      "102\tValidation loss: 3.378953\tBest loss: 3.378953\tAccuracy: 37.33%\n",
      "103\tValidation loss: 3.374139\tBest loss: 3.374139\tAccuracy: 37.33%\n",
      "104\tValidation loss: 3.369329\tBest loss: 3.369329\tAccuracy: 37.33%\n",
      "105\tValidation loss: 3.364514\tBest loss: 3.364514\tAccuracy: 37.33%\n",
      "106\tValidation loss: 3.359721\tBest loss: 3.359721\tAccuracy: 37.33%\n",
      "107\tValidation loss: 3.354887\tBest loss: 3.354887\tAccuracy: 37.33%\n",
      "108\tValidation loss: 3.350054\tBest loss: 3.350054\tAccuracy: 37.33%\n",
      "109\tValidation loss: 3.345248\tBest loss: 3.345248\tAccuracy: 37.33%\n",
      "110\tValidation loss: 3.340416\tBest loss: 3.340416\tAccuracy: 37.33%\n",
      "111\tValidation loss: 3.335607\tBest loss: 3.335607\tAccuracy: 37.33%\n",
      "112\tValidation loss: 3.330770\tBest loss: 3.330770\tAccuracy: 37.33%\n",
      "113\tValidation loss: 3.325900\tBest loss: 3.325900\tAccuracy: 37.33%\n",
      "114\tValidation loss: 3.321026\tBest loss: 3.321026\tAccuracy: 37.33%\n",
      "115\tValidation loss: 3.316137\tBest loss: 3.316137\tAccuracy: 37.33%\n",
      "116\tValidation loss: 3.311213\tBest loss: 3.311213\tAccuracy: 37.33%\n",
      "117\tValidation loss: 3.306248\tBest loss: 3.306248\tAccuracy: 38.00%\n",
      "118\tValidation loss: 3.301301\tBest loss: 3.301301\tAccuracy: 38.00%\n",
      "119\tValidation loss: 3.296362\tBest loss: 3.296362\tAccuracy: 38.00%\n",
      "120\tValidation loss: 3.291421\tBest loss: 3.291421\tAccuracy: 38.00%\n",
      "121\tValidation loss: 3.286477\tBest loss: 3.286477\tAccuracy: 38.00%\n",
      "122\tValidation loss: 3.281523\tBest loss: 3.281523\tAccuracy: 38.00%\n",
      "123\tValidation loss: 3.276614\tBest loss: 3.276614\tAccuracy: 38.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\tValidation loss: 3.271804\tBest loss: 3.271804\tAccuracy: 38.00%\n",
      "125\tValidation loss: 3.266965\tBest loss: 3.266965\tAccuracy: 37.33%\n",
      "126\tValidation loss: 3.262149\tBest loss: 3.262149\tAccuracy: 37.33%\n",
      "127\tValidation loss: 3.257360\tBest loss: 3.257360\tAccuracy: 37.33%\n",
      "128\tValidation loss: 3.252563\tBest loss: 3.252563\tAccuracy: 37.33%\n",
      "129\tValidation loss: 3.247738\tBest loss: 3.247738\tAccuracy: 37.33%\n",
      "130\tValidation loss: 3.242912\tBest loss: 3.242912\tAccuracy: 37.33%\n",
      "131\tValidation loss: 3.238105\tBest loss: 3.238105\tAccuracy: 37.33%\n",
      "132\tValidation loss: 3.233262\tBest loss: 3.233262\tAccuracy: 37.33%\n",
      "133\tValidation loss: 3.228399\tBest loss: 3.228399\tAccuracy: 37.33%\n",
      "134\tValidation loss: 3.223554\tBest loss: 3.223554\tAccuracy: 37.33%\n",
      "135\tValidation loss: 3.218796\tBest loss: 3.218796\tAccuracy: 37.33%\n",
      "136\tValidation loss: 3.214027\tBest loss: 3.214027\tAccuracy: 37.33%\n",
      "137\tValidation loss: 3.209248\tBest loss: 3.209248\tAccuracy: 37.33%\n",
      "138\tValidation loss: 3.204473\tBest loss: 3.204473\tAccuracy: 37.33%\n",
      "139\tValidation loss: 3.199716\tBest loss: 3.199716\tAccuracy: 37.33%\n",
      "140\tValidation loss: 3.195000\tBest loss: 3.195000\tAccuracy: 37.33%\n",
      "141\tValidation loss: 3.190296\tBest loss: 3.190296\tAccuracy: 37.33%\n",
      "142\tValidation loss: 3.185551\tBest loss: 3.185551\tAccuracy: 37.33%\n",
      "143\tValidation loss: 3.180798\tBest loss: 3.180798\tAccuracy: 37.33%\n",
      "144\tValidation loss: 3.176040\tBest loss: 3.176040\tAccuracy: 38.00%\n",
      "145\tValidation loss: 3.171315\tBest loss: 3.171315\tAccuracy: 38.00%\n",
      "146\tValidation loss: 3.166604\tBest loss: 3.166604\tAccuracy: 38.00%\n",
      "147\tValidation loss: 3.162025\tBest loss: 3.162025\tAccuracy: 38.00%\n",
      "148\tValidation loss: 3.157420\tBest loss: 3.157420\tAccuracy: 38.00%\n",
      "149\tValidation loss: 3.152876\tBest loss: 3.152876\tAccuracy: 38.00%\n",
      "150\tValidation loss: 3.148327\tBest loss: 3.148327\tAccuracy: 38.00%\n",
      "151\tValidation loss: 3.143770\tBest loss: 3.143770\tAccuracy: 38.00%\n",
      "152\tValidation loss: 3.139225\tBest loss: 3.139225\tAccuracy: 38.00%\n",
      "153\tValidation loss: 3.134667\tBest loss: 3.134667\tAccuracy: 37.33%\n",
      "154\tValidation loss: 3.130091\tBest loss: 3.130091\tAccuracy: 37.33%\n",
      "155\tValidation loss: 3.125529\tBest loss: 3.125529\tAccuracy: 38.00%\n",
      "156\tValidation loss: 3.120959\tBest loss: 3.120959\tAccuracy: 38.00%\n",
      "157\tValidation loss: 3.116465\tBest loss: 3.116465\tAccuracy: 38.00%\n",
      "158\tValidation loss: 3.111946\tBest loss: 3.111946\tAccuracy: 38.00%\n",
      "159\tValidation loss: 3.107421\tBest loss: 3.107421\tAccuracy: 38.00%\n",
      "160\tValidation loss: 3.102919\tBest loss: 3.102919\tAccuracy: 38.00%\n",
      "161\tValidation loss: 3.098416\tBest loss: 3.098416\tAccuracy: 38.00%\n",
      "162\tValidation loss: 3.093887\tBest loss: 3.093887\tAccuracy: 38.00%\n",
      "163\tValidation loss: 3.089334\tBest loss: 3.089334\tAccuracy: 38.00%\n",
      "164\tValidation loss: 3.084804\tBest loss: 3.084804\tAccuracy: 38.00%\n",
      "165\tValidation loss: 3.080346\tBest loss: 3.080346\tAccuracy: 38.00%\n",
      "166\tValidation loss: 3.075922\tBest loss: 3.075922\tAccuracy: 38.00%\n",
      "167\tValidation loss: 3.071531\tBest loss: 3.071531\tAccuracy: 38.00%\n",
      "168\tValidation loss: 3.067140\tBest loss: 3.067140\tAccuracy: 38.00%\n",
      "169\tValidation loss: 3.062706\tBest loss: 3.062706\tAccuracy: 38.00%\n",
      "170\tValidation loss: 3.058281\tBest loss: 3.058281\tAccuracy: 38.00%\n",
      "171\tValidation loss: 3.053834\tBest loss: 3.053834\tAccuracy: 38.00%\n",
      "172\tValidation loss: 3.049351\tBest loss: 3.049351\tAccuracy: 38.00%\n",
      "173\tValidation loss: 3.044944\tBest loss: 3.044944\tAccuracy: 38.00%\n",
      "174\tValidation loss: 3.040555\tBest loss: 3.040555\tAccuracy: 38.00%\n",
      "175\tValidation loss: 3.036190\tBest loss: 3.036190\tAccuracy: 38.00%\n",
      "176\tValidation loss: 3.031790\tBest loss: 3.031790\tAccuracy: 38.00%\n",
      "177\tValidation loss: 3.027370\tBest loss: 3.027370\tAccuracy: 38.00%\n",
      "178\tValidation loss: 3.022956\tBest loss: 3.022956\tAccuracy: 38.67%\n",
      "179\tValidation loss: 3.018526\tBest loss: 3.018526\tAccuracy: 38.67%\n",
      "180\tValidation loss: 3.014154\tBest loss: 3.014154\tAccuracy: 38.67%\n",
      "181\tValidation loss: 3.009806\tBest loss: 3.009806\tAccuracy: 38.67%\n",
      "182\tValidation loss: 3.005399\tBest loss: 3.005399\tAccuracy: 38.67%\n",
      "183\tValidation loss: 3.001020\tBest loss: 3.001020\tAccuracy: 38.67%\n",
      "184\tValidation loss: 2.996639\tBest loss: 2.996639\tAccuracy: 38.67%\n",
      "185\tValidation loss: 2.992262\tBest loss: 2.992262\tAccuracy: 38.00%\n",
      "186\tValidation loss: 2.987923\tBest loss: 2.987923\tAccuracy: 38.00%\n",
      "187\tValidation loss: 2.983570\tBest loss: 2.983570\tAccuracy: 38.00%\n",
      "188\tValidation loss: 2.979192\tBest loss: 2.979192\tAccuracy: 38.00%\n",
      "189\tValidation loss: 2.974783\tBest loss: 2.974783\tAccuracy: 38.00%\n",
      "190\tValidation loss: 2.970370\tBest loss: 2.970370\tAccuracy: 38.00%\n",
      "191\tValidation loss: 2.965948\tBest loss: 2.965948\tAccuracy: 38.00%\n",
      "192\tValidation loss: 2.961496\tBest loss: 2.961496\tAccuracy: 38.00%\n",
      "193\tValidation loss: 2.957064\tBest loss: 2.957064\tAccuracy: 38.00%\n",
      "194\tValidation loss: 2.952601\tBest loss: 2.952601\tAccuracy: 38.00%\n",
      "195\tValidation loss: 2.948122\tBest loss: 2.948122\tAccuracy: 38.00%\n",
      "196\tValidation loss: 2.943654\tBest loss: 2.943654\tAccuracy: 38.00%\n",
      "197\tValidation loss: 2.939195\tBest loss: 2.939195\tAccuracy: 38.00%\n",
      "198\tValidation loss: 2.934741\tBest loss: 2.934741\tAccuracy: 38.00%\n",
      "199\tValidation loss: 2.930288\tBest loss: 2.930288\tAccuracy: 38.00%\n",
      "200\tValidation loss: 2.925837\tBest loss: 2.925837\tAccuracy: 38.00%\n",
      "201\tValidation loss: 2.921406\tBest loss: 2.921406\tAccuracy: 38.00%\n",
      "202\tValidation loss: 2.916993\tBest loss: 2.916993\tAccuracy: 38.00%\n",
      "203\tValidation loss: 2.912587\tBest loss: 2.912587\tAccuracy: 38.00%\n",
      "204\tValidation loss: 2.908201\tBest loss: 2.908201\tAccuracy: 38.67%\n",
      "205\tValidation loss: 2.903846\tBest loss: 2.903846\tAccuracy: 38.67%\n",
      "206\tValidation loss: 2.899464\tBest loss: 2.899464\tAccuracy: 38.67%\n",
      "207\tValidation loss: 2.895084\tBest loss: 2.895084\tAccuracy: 38.67%\n",
      "208\tValidation loss: 2.890718\tBest loss: 2.890718\tAccuracy: 38.67%\n",
      "209\tValidation loss: 2.886371\tBest loss: 2.886371\tAccuracy: 38.67%\n",
      "210\tValidation loss: 2.882047\tBest loss: 2.882047\tAccuracy: 38.67%\n",
      "211\tValidation loss: 2.877790\tBest loss: 2.877790\tAccuracy: 38.67%\n",
      "212\tValidation loss: 2.873478\tBest loss: 2.873478\tAccuracy: 38.67%\n",
      "213\tValidation loss: 2.869145\tBest loss: 2.869145\tAccuracy: 38.67%\n",
      "214\tValidation loss: 2.864775\tBest loss: 2.864775\tAccuracy: 38.67%\n",
      "215\tValidation loss: 2.860481\tBest loss: 2.860481\tAccuracy: 39.33%\n",
      "216\tValidation loss: 2.856149\tBest loss: 2.856149\tAccuracy: 39.33%\n",
      "217\tValidation loss: 2.851897\tBest loss: 2.851897\tAccuracy: 39.33%\n",
      "218\tValidation loss: 2.847710\tBest loss: 2.847710\tAccuracy: 39.33%\n",
      "219\tValidation loss: 2.843482\tBest loss: 2.843482\tAccuracy: 39.33%\n",
      "220\tValidation loss: 2.839229\tBest loss: 2.839229\tAccuracy: 39.33%\n",
      "221\tValidation loss: 2.834975\tBest loss: 2.834975\tAccuracy: 39.33%\n",
      "222\tValidation loss: 2.830701\tBest loss: 2.830701\tAccuracy: 39.33%\n",
      "223\tValidation loss: 2.826428\tBest loss: 2.826428\tAccuracy: 39.33%\n",
      "224\tValidation loss: 2.822106\tBest loss: 2.822106\tAccuracy: 39.33%\n",
      "225\tValidation loss: 2.817779\tBest loss: 2.817779\tAccuracy: 39.33%\n",
      "226\tValidation loss: 2.813478\tBest loss: 2.813478\tAccuracy: 39.33%\n",
      "227\tValidation loss: 2.809201\tBest loss: 2.809201\tAccuracy: 39.33%\n",
      "228\tValidation loss: 2.804938\tBest loss: 2.804938\tAccuracy: 39.33%\n",
      "229\tValidation loss: 2.800668\tBest loss: 2.800668\tAccuracy: 39.33%\n",
      "230\tValidation loss: 2.796382\tBest loss: 2.796382\tAccuracy: 38.67%\n",
      "231\tValidation loss: 2.792102\tBest loss: 2.792102\tAccuracy: 38.67%\n",
      "232\tValidation loss: 2.787812\tBest loss: 2.787812\tAccuracy: 39.33%\n",
      "233\tValidation loss: 2.783508\tBest loss: 2.783508\tAccuracy: 39.33%\n",
      "234\tValidation loss: 2.779231\tBest loss: 2.779231\tAccuracy: 39.33%\n",
      "235\tValidation loss: 2.774968\tBest loss: 2.774968\tAccuracy: 39.33%\n",
      "236\tValidation loss: 2.770693\tBest loss: 2.770693\tAccuracy: 39.33%\n",
      "237\tValidation loss: 2.766418\tBest loss: 2.766418\tAccuracy: 39.33%\n",
      "238\tValidation loss: 2.762132\tBest loss: 2.762132\tAccuracy: 39.33%\n",
      "239\tValidation loss: 2.757886\tBest loss: 2.757886\tAccuracy: 39.33%\n",
      "240\tValidation loss: 2.753621\tBest loss: 2.753621\tAccuracy: 38.67%\n",
      "241\tValidation loss: 2.749329\tBest loss: 2.749329\tAccuracy: 38.67%\n",
      "242\tValidation loss: 2.745071\tBest loss: 2.745071\tAccuracy: 38.67%\n",
      "243\tValidation loss: 2.740803\tBest loss: 2.740803\tAccuracy: 38.67%\n",
      "244\tValidation loss: 2.736517\tBest loss: 2.736517\tAccuracy: 38.67%\n",
      "245\tValidation loss: 2.732212\tBest loss: 2.732212\tAccuracy: 39.33%\n",
      "246\tValidation loss: 2.727905\tBest loss: 2.727905\tAccuracy: 39.33%\n",
      "247\tValidation loss: 2.723688\tBest loss: 2.723688\tAccuracy: 39.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\tValidation loss: 2.719511\tBest loss: 2.719511\tAccuracy: 39.33%\n",
      "249\tValidation loss: 2.715317\tBest loss: 2.715317\tAccuracy: 40.00%\n",
      "250\tValidation loss: 2.711099\tBest loss: 2.711099\tAccuracy: 40.00%\n",
      "251\tValidation loss: 2.706926\tBest loss: 2.706926\tAccuracy: 40.00%\n",
      "252\tValidation loss: 2.702697\tBest loss: 2.702697\tAccuracy: 40.00%\n",
      "253\tValidation loss: 2.698464\tBest loss: 2.698464\tAccuracy: 40.00%\n",
      "254\tValidation loss: 2.694255\tBest loss: 2.694255\tAccuracy: 40.00%\n",
      "255\tValidation loss: 2.690052\tBest loss: 2.690052\tAccuracy: 40.00%\n",
      "256\tValidation loss: 2.685896\tBest loss: 2.685896\tAccuracy: 40.00%\n",
      "257\tValidation loss: 2.681713\tBest loss: 2.681713\tAccuracy: 40.00%\n",
      "258\tValidation loss: 2.677539\tBest loss: 2.677539\tAccuracy: 40.00%\n",
      "259\tValidation loss: 2.673432\tBest loss: 2.673432\tAccuracy: 40.67%\n",
      "260\tValidation loss: 2.669352\tBest loss: 2.669352\tAccuracy: 40.67%\n",
      "261\tValidation loss: 2.665251\tBest loss: 2.665251\tAccuracy: 41.33%\n",
      "262\tValidation loss: 2.661172\tBest loss: 2.661172\tAccuracy: 41.33%\n",
      "263\tValidation loss: 2.657151\tBest loss: 2.657151\tAccuracy: 41.33%\n",
      "264\tValidation loss: 2.653149\tBest loss: 2.653149\tAccuracy: 41.33%\n",
      "265\tValidation loss: 2.649155\tBest loss: 2.649155\tAccuracy: 41.33%\n",
      "266\tValidation loss: 2.645157\tBest loss: 2.645157\tAccuracy: 41.33%\n",
      "267\tValidation loss: 2.641175\tBest loss: 2.641175\tAccuracy: 41.33%\n",
      "268\tValidation loss: 2.637213\tBest loss: 2.637213\tAccuracy: 41.33%\n",
      "269\tValidation loss: 2.633270\tBest loss: 2.633270\tAccuracy: 41.33%\n",
      "270\tValidation loss: 2.629325\tBest loss: 2.629325\tAccuracy: 41.33%\n",
      "271\tValidation loss: 2.625385\tBest loss: 2.625385\tAccuracy: 41.33%\n",
      "272\tValidation loss: 2.621444\tBest loss: 2.621444\tAccuracy: 41.33%\n",
      "273\tValidation loss: 2.617483\tBest loss: 2.617483\tAccuracy: 41.33%\n",
      "274\tValidation loss: 2.613562\tBest loss: 2.613562\tAccuracy: 41.33%\n",
      "275\tValidation loss: 2.609618\tBest loss: 2.609618\tAccuracy: 41.33%\n",
      "276\tValidation loss: 2.605730\tBest loss: 2.605730\tAccuracy: 41.33%\n",
      "277\tValidation loss: 2.601788\tBest loss: 2.601788\tAccuracy: 41.33%\n",
      "278\tValidation loss: 2.597821\tBest loss: 2.597821\tAccuracy: 42.00%\n",
      "279\tValidation loss: 2.593857\tBest loss: 2.593857\tAccuracy: 42.00%\n",
      "280\tValidation loss: 2.589916\tBest loss: 2.589916\tAccuracy: 42.00%\n",
      "281\tValidation loss: 2.585970\tBest loss: 2.585970\tAccuracy: 42.00%\n",
      "282\tValidation loss: 2.582026\tBest loss: 2.582026\tAccuracy: 42.00%\n",
      "283\tValidation loss: 2.578091\tBest loss: 2.578091\tAccuracy: 42.00%\n",
      "284\tValidation loss: 2.574237\tBest loss: 2.574237\tAccuracy: 42.00%\n",
      "285\tValidation loss: 2.570347\tBest loss: 2.570347\tAccuracy: 42.00%\n",
      "286\tValidation loss: 2.566456\tBest loss: 2.566456\tAccuracy: 42.00%\n",
      "287\tValidation loss: 2.562620\tBest loss: 2.562620\tAccuracy: 42.00%\n",
      "288\tValidation loss: 2.558757\tBest loss: 2.558757\tAccuracy: 42.00%\n",
      "289\tValidation loss: 2.554929\tBest loss: 2.554929\tAccuracy: 42.00%\n",
      "290\tValidation loss: 2.551060\tBest loss: 2.551060\tAccuracy: 42.00%\n",
      "291\tValidation loss: 2.547167\tBest loss: 2.547167\tAccuracy: 42.00%\n",
      "292\tValidation loss: 2.543267\tBest loss: 2.543267\tAccuracy: 42.00%\n",
      "293\tValidation loss: 2.539373\tBest loss: 2.539373\tAccuracy: 42.00%\n",
      "294\tValidation loss: 2.535461\tBest loss: 2.535461\tAccuracy: 42.00%\n",
      "295\tValidation loss: 2.531552\tBest loss: 2.531552\tAccuracy: 42.00%\n",
      "296\tValidation loss: 2.527610\tBest loss: 2.527610\tAccuracy: 42.67%\n",
      "297\tValidation loss: 2.523738\tBest loss: 2.523738\tAccuracy: 42.67%\n",
      "298\tValidation loss: 2.519866\tBest loss: 2.519866\tAccuracy: 42.67%\n",
      "299\tValidation loss: 2.515979\tBest loss: 2.515979\tAccuracy: 42.67%\n",
      "300\tValidation loss: 2.512131\tBest loss: 2.512131\tAccuracy: 42.67%\n",
      "301\tValidation loss: 2.508285\tBest loss: 2.508285\tAccuracy: 42.67%\n",
      "302\tValidation loss: 2.504478\tBest loss: 2.504478\tAccuracy: 42.67%\n",
      "303\tValidation loss: 2.500643\tBest loss: 2.500643\tAccuracy: 42.67%\n",
      "304\tValidation loss: 2.496837\tBest loss: 2.496837\tAccuracy: 42.67%\n",
      "305\tValidation loss: 2.493005\tBest loss: 2.493005\tAccuracy: 42.67%\n",
      "306\tValidation loss: 2.489141\tBest loss: 2.489141\tAccuracy: 42.67%\n",
      "307\tValidation loss: 2.485283\tBest loss: 2.485283\tAccuracy: 42.67%\n",
      "308\tValidation loss: 2.481481\tBest loss: 2.481481\tAccuracy: 42.67%\n",
      "309\tValidation loss: 2.477713\tBest loss: 2.477713\tAccuracy: 42.67%\n",
      "310\tValidation loss: 2.473937\tBest loss: 2.473937\tAccuracy: 42.67%\n",
      "311\tValidation loss: 2.470239\tBest loss: 2.470239\tAccuracy: 42.67%\n",
      "312\tValidation loss: 2.466525\tBest loss: 2.466525\tAccuracy: 42.67%\n",
      "313\tValidation loss: 2.462784\tBest loss: 2.462784\tAccuracy: 42.67%\n",
      "314\tValidation loss: 2.459041\tBest loss: 2.459041\tAccuracy: 42.67%\n",
      "315\tValidation loss: 2.455334\tBest loss: 2.455334\tAccuracy: 42.67%\n",
      "316\tValidation loss: 2.451623\tBest loss: 2.451623\tAccuracy: 42.67%\n",
      "317\tValidation loss: 2.447930\tBest loss: 2.447930\tAccuracy: 42.67%\n",
      "318\tValidation loss: 2.444224\tBest loss: 2.444224\tAccuracy: 42.67%\n",
      "319\tValidation loss: 2.440498\tBest loss: 2.440498\tAccuracy: 42.67%\n",
      "320\tValidation loss: 2.436805\tBest loss: 2.436805\tAccuracy: 42.67%\n",
      "321\tValidation loss: 2.433119\tBest loss: 2.433119\tAccuracy: 42.67%\n",
      "322\tValidation loss: 2.429411\tBest loss: 2.429411\tAccuracy: 42.67%\n",
      "323\tValidation loss: 2.425750\tBest loss: 2.425750\tAccuracy: 42.67%\n",
      "324\tValidation loss: 2.422042\tBest loss: 2.422042\tAccuracy: 42.67%\n",
      "325\tValidation loss: 2.418321\tBest loss: 2.418321\tAccuracy: 42.67%\n",
      "326\tValidation loss: 2.414618\tBest loss: 2.414618\tAccuracy: 42.67%\n",
      "327\tValidation loss: 2.410909\tBest loss: 2.410909\tAccuracy: 42.67%\n",
      "328\tValidation loss: 2.407199\tBest loss: 2.407199\tAccuracy: 42.67%\n",
      "329\tValidation loss: 2.403447\tBest loss: 2.403447\tAccuracy: 42.67%\n",
      "330\tValidation loss: 2.399710\tBest loss: 2.399710\tAccuracy: 42.67%\n",
      "331\tValidation loss: 2.395940\tBest loss: 2.395940\tAccuracy: 42.67%\n",
      "332\tValidation loss: 2.392257\tBest loss: 2.392257\tAccuracy: 43.33%\n",
      "333\tValidation loss: 2.388627\tBest loss: 2.388627\tAccuracy: 43.33%\n",
      "334\tValidation loss: 2.384990\tBest loss: 2.384990\tAccuracy: 43.33%\n",
      "335\tValidation loss: 2.381422\tBest loss: 2.381422\tAccuracy: 43.33%\n",
      "336\tValidation loss: 2.377832\tBest loss: 2.377832\tAccuracy: 43.33%\n",
      "337\tValidation loss: 2.374237\tBest loss: 2.374237\tAccuracy: 43.33%\n",
      "338\tValidation loss: 2.370653\tBest loss: 2.370653\tAccuracy: 43.33%\n",
      "339\tValidation loss: 2.367062\tBest loss: 2.367062\tAccuracy: 43.33%\n",
      "340\tValidation loss: 2.363484\tBest loss: 2.363484\tAccuracy: 43.33%\n",
      "341\tValidation loss: 2.359867\tBest loss: 2.359867\tAccuracy: 43.33%\n",
      "342\tValidation loss: 2.356294\tBest loss: 2.356294\tAccuracy: 44.00%\n",
      "343\tValidation loss: 2.352780\tBest loss: 2.352780\tAccuracy: 44.00%\n",
      "344\tValidation loss: 2.349238\tBest loss: 2.349238\tAccuracy: 44.00%\n",
      "345\tValidation loss: 2.345705\tBest loss: 2.345705\tAccuracy: 44.00%\n",
      "346\tValidation loss: 2.342125\tBest loss: 2.342125\tAccuracy: 44.00%\n",
      "347\tValidation loss: 2.338530\tBest loss: 2.338530\tAccuracy: 44.00%\n",
      "348\tValidation loss: 2.334950\tBest loss: 2.334950\tAccuracy: 44.00%\n",
      "349\tValidation loss: 2.331354\tBest loss: 2.331354\tAccuracy: 44.00%\n",
      "350\tValidation loss: 2.327786\tBest loss: 2.327786\tAccuracy: 44.00%\n",
      "351\tValidation loss: 2.324212\tBest loss: 2.324212\tAccuracy: 44.00%\n",
      "352\tValidation loss: 2.320614\tBest loss: 2.320614\tAccuracy: 44.00%\n",
      "353\tValidation loss: 2.317011\tBest loss: 2.317011\tAccuracy: 44.00%\n",
      "354\tValidation loss: 2.313378\tBest loss: 2.313378\tAccuracy: 44.00%\n",
      "355\tValidation loss: 2.309733\tBest loss: 2.309733\tAccuracy: 44.67%\n",
      "356\tValidation loss: 2.306104\tBest loss: 2.306104\tAccuracy: 44.67%\n",
      "357\tValidation loss: 2.302509\tBest loss: 2.302509\tAccuracy: 44.67%\n",
      "358\tValidation loss: 2.298936\tBest loss: 2.298936\tAccuracy: 44.67%\n",
      "359\tValidation loss: 2.295326\tBest loss: 2.295326\tAccuracy: 44.67%\n",
      "360\tValidation loss: 2.291727\tBest loss: 2.291727\tAccuracy: 44.67%\n",
      "361\tValidation loss: 2.288111\tBest loss: 2.288111\tAccuracy: 44.67%\n",
      "362\tValidation loss: 2.284519\tBest loss: 2.284519\tAccuracy: 44.67%\n",
      "363\tValidation loss: 2.280946\tBest loss: 2.280946\tAccuracy: 44.67%\n",
      "364\tValidation loss: 2.277348\tBest loss: 2.277348\tAccuracy: 44.67%\n",
      "365\tValidation loss: 2.273797\tBest loss: 2.273797\tAccuracy: 44.67%\n",
      "366\tValidation loss: 2.270239\tBest loss: 2.270239\tAccuracy: 44.67%\n",
      "367\tValidation loss: 2.266673\tBest loss: 2.266673\tAccuracy: 44.67%\n",
      "368\tValidation loss: 2.263123\tBest loss: 2.263123\tAccuracy: 44.67%\n",
      "369\tValidation loss: 2.259617\tBest loss: 2.259617\tAccuracy: 44.67%\n",
      "370\tValidation loss: 2.256120\tBest loss: 2.256120\tAccuracy: 44.67%\n",
      "371\tValidation loss: 2.252663\tBest loss: 2.252663\tAccuracy: 44.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\tValidation loss: 2.249161\tBest loss: 2.249161\tAccuracy: 44.67%\n",
      "373\tValidation loss: 2.245621\tBest loss: 2.245621\tAccuracy: 44.67%\n",
      "374\tValidation loss: 2.242069\tBest loss: 2.242069\tAccuracy: 44.67%\n",
      "375\tValidation loss: 2.238514\tBest loss: 2.238514\tAccuracy: 44.67%\n",
      "376\tValidation loss: 2.234949\tBest loss: 2.234949\tAccuracy: 44.67%\n",
      "377\tValidation loss: 2.231388\tBest loss: 2.231388\tAccuracy: 44.67%\n",
      "378\tValidation loss: 2.227790\tBest loss: 2.227790\tAccuracy: 44.67%\n",
      "379\tValidation loss: 2.224214\tBest loss: 2.224214\tAccuracy: 44.67%\n",
      "380\tValidation loss: 2.220648\tBest loss: 2.220648\tAccuracy: 44.67%\n",
      "381\tValidation loss: 2.217123\tBest loss: 2.217123\tAccuracy: 44.67%\n",
      "382\tValidation loss: 2.213639\tBest loss: 2.213639\tAccuracy: 45.33%\n",
      "383\tValidation loss: 2.210176\tBest loss: 2.210176\tAccuracy: 45.33%\n",
      "384\tValidation loss: 2.206741\tBest loss: 2.206741\tAccuracy: 45.33%\n",
      "385\tValidation loss: 2.203270\tBest loss: 2.203270\tAccuracy: 45.33%\n",
      "386\tValidation loss: 2.199765\tBest loss: 2.199765\tAccuracy: 45.33%\n",
      "387\tValidation loss: 2.196311\tBest loss: 2.196311\tAccuracy: 45.33%\n",
      "388\tValidation loss: 2.192851\tBest loss: 2.192851\tAccuracy: 45.33%\n",
      "389\tValidation loss: 2.189422\tBest loss: 2.189422\tAccuracy: 45.33%\n",
      "390\tValidation loss: 2.186000\tBest loss: 2.186000\tAccuracy: 45.33%\n",
      "391\tValidation loss: 2.182557\tBest loss: 2.182557\tAccuracy: 45.33%\n",
      "392\tValidation loss: 2.179098\tBest loss: 2.179098\tAccuracy: 44.67%\n",
      "393\tValidation loss: 2.175643\tBest loss: 2.175643\tAccuracy: 44.67%\n",
      "394\tValidation loss: 2.172205\tBest loss: 2.172205\tAccuracy: 44.67%\n",
      "395\tValidation loss: 2.168767\tBest loss: 2.168767\tAccuracy: 44.67%\n",
      "396\tValidation loss: 2.165346\tBest loss: 2.165346\tAccuracy: 44.67%\n",
      "397\tValidation loss: 2.161928\tBest loss: 2.161928\tAccuracy: 44.67%\n",
      "398\tValidation loss: 2.158527\tBest loss: 2.158527\tAccuracy: 44.67%\n",
      "399\tValidation loss: 2.155152\tBest loss: 2.155152\tAccuracy: 44.67%\n",
      "400\tValidation loss: 2.151814\tBest loss: 2.151814\tAccuracy: 44.67%\n",
      "401\tValidation loss: 2.148473\tBest loss: 2.148473\tAccuracy: 44.67%\n",
      "402\tValidation loss: 2.145145\tBest loss: 2.145145\tAccuracy: 44.67%\n",
      "403\tValidation loss: 2.141834\tBest loss: 2.141834\tAccuracy: 44.67%\n",
      "404\tValidation loss: 2.138569\tBest loss: 2.138569\tAccuracy: 44.67%\n",
      "405\tValidation loss: 2.135347\tBest loss: 2.135347\tAccuracy: 44.67%\n",
      "406\tValidation loss: 2.132140\tBest loss: 2.132140\tAccuracy: 44.67%\n",
      "407\tValidation loss: 2.128942\tBest loss: 2.128942\tAccuracy: 44.67%\n",
      "408\tValidation loss: 2.125747\tBest loss: 2.125747\tAccuracy: 45.33%\n",
      "409\tValidation loss: 2.122537\tBest loss: 2.122537\tAccuracy: 45.33%\n",
      "410\tValidation loss: 2.119339\tBest loss: 2.119339\tAccuracy: 45.33%\n",
      "411\tValidation loss: 2.116252\tBest loss: 2.116252\tAccuracy: 45.33%\n",
      "412\tValidation loss: 2.113152\tBest loss: 2.113152\tAccuracy: 45.33%\n",
      "413\tValidation loss: 2.110033\tBest loss: 2.110033\tAccuracy: 45.33%\n",
      "414\tValidation loss: 2.106901\tBest loss: 2.106901\tAccuracy: 45.33%\n",
      "415\tValidation loss: 2.103754\tBest loss: 2.103754\tAccuracy: 45.33%\n",
      "416\tValidation loss: 2.100580\tBest loss: 2.100580\tAccuracy: 45.33%\n",
      "417\tValidation loss: 2.097388\tBest loss: 2.097388\tAccuracy: 45.33%\n",
      "418\tValidation loss: 2.094202\tBest loss: 2.094202\tAccuracy: 45.33%\n",
      "419\tValidation loss: 2.091034\tBest loss: 2.091034\tAccuracy: 45.33%\n",
      "420\tValidation loss: 2.087883\tBest loss: 2.087883\tAccuracy: 45.33%\n",
      "421\tValidation loss: 2.084718\tBest loss: 2.084718\tAccuracy: 45.33%\n",
      "422\tValidation loss: 2.081517\tBest loss: 2.081517\tAccuracy: 45.33%\n",
      "423\tValidation loss: 2.078341\tBest loss: 2.078341\tAccuracy: 45.33%\n",
      "424\tValidation loss: 2.075145\tBest loss: 2.075145\tAccuracy: 45.33%\n",
      "425\tValidation loss: 2.071985\tBest loss: 2.071985\tAccuracy: 45.33%\n",
      "426\tValidation loss: 2.068851\tBest loss: 2.068851\tAccuracy: 45.33%\n",
      "427\tValidation loss: 2.065751\tBest loss: 2.065751\tAccuracy: 45.33%\n",
      "428\tValidation loss: 2.062671\tBest loss: 2.062671\tAccuracy: 45.33%\n",
      "429\tValidation loss: 2.059577\tBest loss: 2.059577\tAccuracy: 45.33%\n",
      "430\tValidation loss: 2.056501\tBest loss: 2.056501\tAccuracy: 45.33%\n",
      "431\tValidation loss: 2.053461\tBest loss: 2.053461\tAccuracy: 45.33%\n",
      "432\tValidation loss: 2.050418\tBest loss: 2.050418\tAccuracy: 46.00%\n",
      "433\tValidation loss: 2.047354\tBest loss: 2.047354\tAccuracy: 46.00%\n",
      "434\tValidation loss: 2.044279\tBest loss: 2.044279\tAccuracy: 46.00%\n",
      "435\tValidation loss: 2.041208\tBest loss: 2.041208\tAccuracy: 46.67%\n",
      "436\tValidation loss: 2.038161\tBest loss: 2.038161\tAccuracy: 46.67%\n",
      "437\tValidation loss: 2.035150\tBest loss: 2.035150\tAccuracy: 46.67%\n",
      "438\tValidation loss: 2.032121\tBest loss: 2.032121\tAccuracy: 46.67%\n",
      "439\tValidation loss: 2.029102\tBest loss: 2.029102\tAccuracy: 46.67%\n",
      "440\tValidation loss: 2.026082\tBest loss: 2.026082\tAccuracy: 46.67%\n",
      "441\tValidation loss: 2.023065\tBest loss: 2.023065\tAccuracy: 47.33%\n",
      "442\tValidation loss: 2.020032\tBest loss: 2.020032\tAccuracy: 47.33%\n",
      "443\tValidation loss: 2.016984\tBest loss: 2.016984\tAccuracy: 47.33%\n",
      "444\tValidation loss: 2.013947\tBest loss: 2.013947\tAccuracy: 47.33%\n",
      "445\tValidation loss: 2.010910\tBest loss: 2.010910\tAccuracy: 47.33%\n",
      "446\tValidation loss: 2.007860\tBest loss: 2.007860\tAccuracy: 47.33%\n",
      "447\tValidation loss: 2.004824\tBest loss: 2.004824\tAccuracy: 47.33%\n",
      "448\tValidation loss: 2.001786\tBest loss: 2.001786\tAccuracy: 47.33%\n",
      "449\tValidation loss: 1.998743\tBest loss: 1.998743\tAccuracy: 47.33%\n",
      "450\tValidation loss: 1.995723\tBest loss: 1.995723\tAccuracy: 47.33%\n",
      "451\tValidation loss: 1.992717\tBest loss: 1.992717\tAccuracy: 47.33%\n",
      "452\tValidation loss: 1.989769\tBest loss: 1.989769\tAccuracy: 47.33%\n",
      "453\tValidation loss: 1.986830\tBest loss: 1.986830\tAccuracy: 47.33%\n",
      "454\tValidation loss: 1.983861\tBest loss: 1.983861\tAccuracy: 47.33%\n",
      "455\tValidation loss: 1.980919\tBest loss: 1.980919\tAccuracy: 47.33%\n",
      "456\tValidation loss: 1.977983\tBest loss: 1.977983\tAccuracy: 47.33%\n",
      "457\tValidation loss: 1.975082\tBest loss: 1.975082\tAccuracy: 47.33%\n",
      "458\tValidation loss: 1.972187\tBest loss: 1.972187\tAccuracy: 47.33%\n",
      "459\tValidation loss: 1.969326\tBest loss: 1.969326\tAccuracy: 47.33%\n",
      "460\tValidation loss: 1.966460\tBest loss: 1.966460\tAccuracy: 47.33%\n",
      "461\tValidation loss: 1.963630\tBest loss: 1.963630\tAccuracy: 47.33%\n",
      "462\tValidation loss: 1.960815\tBest loss: 1.960815\tAccuracy: 47.33%\n",
      "463\tValidation loss: 1.958055\tBest loss: 1.958055\tAccuracy: 47.33%\n",
      "464\tValidation loss: 1.955300\tBest loss: 1.955300\tAccuracy: 47.33%\n",
      "465\tValidation loss: 1.952547\tBest loss: 1.952547\tAccuracy: 47.33%\n",
      "466\tValidation loss: 1.949851\tBest loss: 1.949851\tAccuracy: 47.33%\n",
      "467\tValidation loss: 1.947152\tBest loss: 1.947152\tAccuracy: 47.33%\n",
      "468\tValidation loss: 1.944424\tBest loss: 1.944424\tAccuracy: 47.33%\n",
      "469\tValidation loss: 1.941706\tBest loss: 1.941706\tAccuracy: 47.33%\n",
      "470\tValidation loss: 1.938985\tBest loss: 1.938985\tAccuracy: 47.33%\n",
      "471\tValidation loss: 1.936270\tBest loss: 1.936270\tAccuracy: 47.33%\n",
      "472\tValidation loss: 1.933549\tBest loss: 1.933549\tAccuracy: 47.33%\n",
      "473\tValidation loss: 1.930822\tBest loss: 1.930822\tAccuracy: 47.33%\n",
      "474\tValidation loss: 1.928099\tBest loss: 1.928099\tAccuracy: 47.33%\n",
      "475\tValidation loss: 1.925385\tBest loss: 1.925385\tAccuracy: 47.33%\n",
      "476\tValidation loss: 1.922707\tBest loss: 1.922707\tAccuracy: 47.33%\n",
      "477\tValidation loss: 1.920032\tBest loss: 1.920032\tAccuracy: 47.33%\n",
      "478\tValidation loss: 1.917383\tBest loss: 1.917383\tAccuracy: 47.33%\n",
      "479\tValidation loss: 1.914733\tBest loss: 1.914733\tAccuracy: 47.33%\n",
      "480\tValidation loss: 1.912059\tBest loss: 1.912059\tAccuracy: 47.33%\n",
      "481\tValidation loss: 1.909395\tBest loss: 1.909395\tAccuracy: 47.33%\n",
      "482\tValidation loss: 1.906739\tBest loss: 1.906739\tAccuracy: 47.33%\n",
      "483\tValidation loss: 1.904085\tBest loss: 1.904085\tAccuracy: 47.33%\n",
      "484\tValidation loss: 1.901418\tBest loss: 1.901418\tAccuracy: 48.00%\n",
      "485\tValidation loss: 1.898742\tBest loss: 1.898742\tAccuracy: 48.00%\n",
      "486\tValidation loss: 1.896034\tBest loss: 1.896034\tAccuracy: 48.00%\n",
      "487\tValidation loss: 1.893326\tBest loss: 1.893326\tAccuracy: 48.00%\n",
      "488\tValidation loss: 1.890621\tBest loss: 1.890621\tAccuracy: 48.00%\n",
      "489\tValidation loss: 1.887879\tBest loss: 1.887879\tAccuracy: 48.00%\n",
      "490\tValidation loss: 1.885159\tBest loss: 1.885159\tAccuracy: 48.00%\n",
      "491\tValidation loss: 1.882444\tBest loss: 1.882444\tAccuracy: 48.00%\n",
      "492\tValidation loss: 1.879732\tBest loss: 1.879732\tAccuracy: 48.00%\n",
      "493\tValidation loss: 1.877012\tBest loss: 1.877012\tAccuracy: 48.00%\n",
      "494\tValidation loss: 1.874299\tBest loss: 1.874299\tAccuracy: 48.00%\n",
      "495\tValidation loss: 1.871601\tBest loss: 1.871601\tAccuracy: 48.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\tValidation loss: 1.869019\tBest loss: 1.869019\tAccuracy: 48.00%\n",
      "497\tValidation loss: 1.866434\tBest loss: 1.866434\tAccuracy: 48.00%\n",
      "498\tValidation loss: 1.863843\tBest loss: 1.863843\tAccuracy: 48.00%\n",
      "499\tValidation loss: 1.861261\tBest loss: 1.861261\tAccuracy: 48.00%\n",
      "500\tValidation loss: 1.858656\tBest loss: 1.858656\tAccuracy: 48.00%\n",
      "501\tValidation loss: 1.856065\tBest loss: 1.856065\tAccuracy: 48.00%\n",
      "502\tValidation loss: 1.853440\tBest loss: 1.853440\tAccuracy: 48.00%\n",
      "503\tValidation loss: 1.850871\tBest loss: 1.850871\tAccuracy: 47.33%\n",
      "504\tValidation loss: 1.848249\tBest loss: 1.848249\tAccuracy: 47.33%\n",
      "505\tValidation loss: 1.845639\tBest loss: 1.845639\tAccuracy: 47.33%\n",
      "506\tValidation loss: 1.843061\tBest loss: 1.843061\tAccuracy: 47.33%\n",
      "507\tValidation loss: 1.840497\tBest loss: 1.840497\tAccuracy: 47.33%\n",
      "508\tValidation loss: 1.837930\tBest loss: 1.837930\tAccuracy: 46.67%\n",
      "509\tValidation loss: 1.835418\tBest loss: 1.835418\tAccuracy: 46.67%\n",
      "510\tValidation loss: 1.832886\tBest loss: 1.832886\tAccuracy: 46.67%\n",
      "511\tValidation loss: 1.830385\tBest loss: 1.830385\tAccuracy: 46.67%\n",
      "512\tValidation loss: 1.827891\tBest loss: 1.827891\tAccuracy: 46.67%\n",
      "513\tValidation loss: 1.825423\tBest loss: 1.825423\tAccuracy: 46.67%\n",
      "514\tValidation loss: 1.822911\tBest loss: 1.822911\tAccuracy: 46.67%\n",
      "515\tValidation loss: 1.820391\tBest loss: 1.820391\tAccuracy: 47.33%\n",
      "516\tValidation loss: 1.817925\tBest loss: 1.817925\tAccuracy: 47.33%\n",
      "517\tValidation loss: 1.815447\tBest loss: 1.815447\tAccuracy: 47.33%\n",
      "518\tValidation loss: 1.812983\tBest loss: 1.812983\tAccuracy: 47.33%\n",
      "519\tValidation loss: 1.810547\tBest loss: 1.810547\tAccuracy: 47.33%\n",
      "520\tValidation loss: 1.808094\tBest loss: 1.808094\tAccuracy: 47.33%\n",
      "521\tValidation loss: 1.805677\tBest loss: 1.805677\tAccuracy: 47.33%\n",
      "522\tValidation loss: 1.803250\tBest loss: 1.803250\tAccuracy: 47.33%\n",
      "523\tValidation loss: 1.800810\tBest loss: 1.800810\tAccuracy: 47.33%\n",
      "524\tValidation loss: 1.798402\tBest loss: 1.798402\tAccuracy: 47.33%\n",
      "525\tValidation loss: 1.795990\tBest loss: 1.795990\tAccuracy: 47.33%\n",
      "526\tValidation loss: 1.793583\tBest loss: 1.793583\tAccuracy: 47.33%\n",
      "527\tValidation loss: 1.791171\tBest loss: 1.791171\tAccuracy: 47.33%\n",
      "528\tValidation loss: 1.788767\tBest loss: 1.788767\tAccuracy: 47.33%\n",
      "529\tValidation loss: 1.786351\tBest loss: 1.786351\tAccuracy: 47.33%\n",
      "530\tValidation loss: 1.783927\tBest loss: 1.783927\tAccuracy: 47.33%\n",
      "531\tValidation loss: 1.781590\tBest loss: 1.781590\tAccuracy: 47.33%\n",
      "532\tValidation loss: 1.779255\tBest loss: 1.779255\tAccuracy: 47.33%\n",
      "533\tValidation loss: 1.776933\tBest loss: 1.776933\tAccuracy: 47.33%\n",
      "534\tValidation loss: 1.774596\tBest loss: 1.774596\tAccuracy: 47.33%\n",
      "535\tValidation loss: 1.772291\tBest loss: 1.772291\tAccuracy: 47.33%\n",
      "536\tValidation loss: 1.769986\tBest loss: 1.769986\tAccuracy: 47.33%\n",
      "537\tValidation loss: 1.767682\tBest loss: 1.767682\tAccuracy: 47.33%\n",
      "538\tValidation loss: 1.765415\tBest loss: 1.765415\tAccuracy: 47.33%\n",
      "539\tValidation loss: 1.763125\tBest loss: 1.763125\tAccuracy: 47.33%\n",
      "540\tValidation loss: 1.760850\tBest loss: 1.760850\tAccuracy: 47.33%\n",
      "541\tValidation loss: 1.758582\tBest loss: 1.758582\tAccuracy: 47.33%\n",
      "542\tValidation loss: 1.756311\tBest loss: 1.756311\tAccuracy: 47.33%\n",
      "543\tValidation loss: 1.754051\tBest loss: 1.754051\tAccuracy: 47.33%\n",
      "544\tValidation loss: 1.751789\tBest loss: 1.751789\tAccuracy: 47.33%\n",
      "545\tValidation loss: 1.749547\tBest loss: 1.749547\tAccuracy: 48.00%\n",
      "546\tValidation loss: 1.747301\tBest loss: 1.747301\tAccuracy: 48.00%\n",
      "547\tValidation loss: 1.745056\tBest loss: 1.745056\tAccuracy: 48.00%\n",
      "548\tValidation loss: 1.742809\tBest loss: 1.742809\tAccuracy: 48.67%\n",
      "549\tValidation loss: 1.740573\tBest loss: 1.740573\tAccuracy: 48.67%\n",
      "550\tValidation loss: 1.738330\tBest loss: 1.738330\tAccuracy: 48.67%\n",
      "551\tValidation loss: 1.736068\tBest loss: 1.736068\tAccuracy: 48.67%\n",
      "552\tValidation loss: 1.733819\tBest loss: 1.733819\tAccuracy: 48.67%\n",
      "553\tValidation loss: 1.731546\tBest loss: 1.731546\tAccuracy: 48.67%\n",
      "554\tValidation loss: 1.729341\tBest loss: 1.729341\tAccuracy: 48.67%\n",
      "555\tValidation loss: 1.727182\tBest loss: 1.727182\tAccuracy: 48.67%\n",
      "556\tValidation loss: 1.725016\tBest loss: 1.725016\tAccuracy: 48.67%\n",
      "557\tValidation loss: 1.722870\tBest loss: 1.722870\tAccuracy: 48.67%\n",
      "558\tValidation loss: 1.720727\tBest loss: 1.720727\tAccuracy: 48.67%\n",
      "559\tValidation loss: 1.718584\tBest loss: 1.718584\tAccuracy: 48.67%\n",
      "560\tValidation loss: 1.716504\tBest loss: 1.716504\tAccuracy: 48.67%\n",
      "561\tValidation loss: 1.714385\tBest loss: 1.714385\tAccuracy: 48.67%\n",
      "562\tValidation loss: 1.712236\tBest loss: 1.712236\tAccuracy: 48.67%\n",
      "563\tValidation loss: 1.710073\tBest loss: 1.710073\tAccuracy: 48.67%\n",
      "564\tValidation loss: 1.707914\tBest loss: 1.707914\tAccuracy: 48.67%\n",
      "565\tValidation loss: 1.705767\tBest loss: 1.705767\tAccuracy: 48.67%\n",
      "566\tValidation loss: 1.703612\tBest loss: 1.703612\tAccuracy: 48.67%\n",
      "567\tValidation loss: 1.701479\tBest loss: 1.701479\tAccuracy: 48.67%\n",
      "568\tValidation loss: 1.699381\tBest loss: 1.699381\tAccuracy: 48.67%\n",
      "569\tValidation loss: 1.697268\tBest loss: 1.697268\tAccuracy: 49.33%\n",
      "570\tValidation loss: 1.695175\tBest loss: 1.695175\tAccuracy: 49.33%\n",
      "571\tValidation loss: 1.693157\tBest loss: 1.693157\tAccuracy: 49.33%\n",
      "572\tValidation loss: 1.691157\tBest loss: 1.691157\tAccuracy: 49.33%\n",
      "573\tValidation loss: 1.689166\tBest loss: 1.689166\tAccuracy: 49.33%\n",
      "574\tValidation loss: 1.687214\tBest loss: 1.687214\tAccuracy: 49.33%\n",
      "575\tValidation loss: 1.685271\tBest loss: 1.685271\tAccuracy: 49.33%\n",
      "576\tValidation loss: 1.683329\tBest loss: 1.683329\tAccuracy: 49.33%\n",
      "577\tValidation loss: 1.681364\tBest loss: 1.681364\tAccuracy: 49.33%\n",
      "578\tValidation loss: 1.679396\tBest loss: 1.679396\tAccuracy: 49.33%\n",
      "579\tValidation loss: 1.677413\tBest loss: 1.677413\tAccuracy: 49.33%\n",
      "580\tValidation loss: 1.675407\tBest loss: 1.675407\tAccuracy: 49.33%\n",
      "581\tValidation loss: 1.673448\tBest loss: 1.673448\tAccuracy: 49.33%\n",
      "582\tValidation loss: 1.671497\tBest loss: 1.671497\tAccuracy: 48.67%\n",
      "583\tValidation loss: 1.669571\tBest loss: 1.669571\tAccuracy: 48.67%\n",
      "584\tValidation loss: 1.667608\tBest loss: 1.667608\tAccuracy: 48.67%\n",
      "585\tValidation loss: 1.665681\tBest loss: 1.665681\tAccuracy: 48.67%\n",
      "586\tValidation loss: 1.663813\tBest loss: 1.663813\tAccuracy: 48.67%\n",
      "587\tValidation loss: 1.661977\tBest loss: 1.661977\tAccuracy: 48.67%\n",
      "588\tValidation loss: 1.660095\tBest loss: 1.660095\tAccuracy: 48.67%\n",
      "589\tValidation loss: 1.658242\tBest loss: 1.658242\tAccuracy: 48.67%\n",
      "590\tValidation loss: 1.656375\tBest loss: 1.656375\tAccuracy: 48.67%\n",
      "591\tValidation loss: 1.654535\tBest loss: 1.654535\tAccuracy: 48.67%\n",
      "592\tValidation loss: 1.652649\tBest loss: 1.652649\tAccuracy: 48.00%\n",
      "593\tValidation loss: 1.650768\tBest loss: 1.650768\tAccuracy: 48.67%\n",
      "594\tValidation loss: 1.648878\tBest loss: 1.648878\tAccuracy: 48.67%\n",
      "595\tValidation loss: 1.646982\tBest loss: 1.646982\tAccuracy: 48.67%\n",
      "596\tValidation loss: 1.645100\tBest loss: 1.645100\tAccuracy: 48.67%\n",
      "597\tValidation loss: 1.643242\tBest loss: 1.643242\tAccuracy: 48.67%\n",
      "598\tValidation loss: 1.641362\tBest loss: 1.641362\tAccuracy: 48.67%\n",
      "599\tValidation loss: 1.639501\tBest loss: 1.639501\tAccuracy: 48.67%\n",
      "600\tValidation loss: 1.637630\tBest loss: 1.637630\tAccuracy: 48.67%\n",
      "601\tValidation loss: 1.635774\tBest loss: 1.635774\tAccuracy: 48.67%\n",
      "602\tValidation loss: 1.633969\tBest loss: 1.633969\tAccuracy: 48.67%\n",
      "603\tValidation loss: 1.632196\tBest loss: 1.632196\tAccuracy: 48.67%\n",
      "604\tValidation loss: 1.630389\tBest loss: 1.630389\tAccuracy: 48.67%\n",
      "605\tValidation loss: 1.628594\tBest loss: 1.628594\tAccuracy: 48.67%\n",
      "606\tValidation loss: 1.626766\tBest loss: 1.626766\tAccuracy: 48.67%\n",
      "607\tValidation loss: 1.625004\tBest loss: 1.625004\tAccuracy: 48.67%\n",
      "608\tValidation loss: 1.623198\tBest loss: 1.623198\tAccuracy: 48.67%\n",
      "609\tValidation loss: 1.621360\tBest loss: 1.621360\tAccuracy: 48.67%\n",
      "610\tValidation loss: 1.619567\tBest loss: 1.619567\tAccuracy: 48.67%\n",
      "611\tValidation loss: 1.617774\tBest loss: 1.617774\tAccuracy: 48.67%\n",
      "612\tValidation loss: 1.615989\tBest loss: 1.615989\tAccuracy: 48.67%\n",
      "613\tValidation loss: 1.614223\tBest loss: 1.614223\tAccuracy: 48.67%\n",
      "614\tValidation loss: 1.612470\tBest loss: 1.612470\tAccuracy: 48.67%\n",
      "615\tValidation loss: 1.610697\tBest loss: 1.610697\tAccuracy: 48.67%\n",
      "616\tValidation loss: 1.608916\tBest loss: 1.608916\tAccuracy: 48.67%\n",
      "617\tValidation loss: 1.607144\tBest loss: 1.607144\tAccuracy: 48.67%\n",
      "618\tValidation loss: 1.605357\tBest loss: 1.605357\tAccuracy: 48.67%\n",
      "619\tValidation loss: 1.603641\tBest loss: 1.603641\tAccuracy: 48.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620\tValidation loss: 1.601936\tBest loss: 1.601936\tAccuracy: 48.67%\n",
      "621\tValidation loss: 1.600224\tBest loss: 1.600224\tAccuracy: 48.67%\n",
      "622\tValidation loss: 1.598523\tBest loss: 1.598523\tAccuracy: 48.67%\n",
      "623\tValidation loss: 1.596804\tBest loss: 1.596804\tAccuracy: 48.67%\n",
      "624\tValidation loss: 1.595037\tBest loss: 1.595037\tAccuracy: 48.67%\n",
      "625\tValidation loss: 1.593331\tBest loss: 1.593331\tAccuracy: 48.67%\n",
      "626\tValidation loss: 1.591640\tBest loss: 1.591640\tAccuracy: 48.67%\n",
      "627\tValidation loss: 1.589923\tBest loss: 1.589923\tAccuracy: 48.67%\n",
      "628\tValidation loss: 1.588213\tBest loss: 1.588213\tAccuracy: 48.67%\n",
      "629\tValidation loss: 1.586515\tBest loss: 1.586515\tAccuracy: 48.67%\n",
      "630\tValidation loss: 1.584792\tBest loss: 1.584792\tAccuracy: 48.67%\n",
      "631\tValidation loss: 1.583056\tBest loss: 1.583056\tAccuracy: 48.67%\n",
      "632\tValidation loss: 1.581314\tBest loss: 1.581314\tAccuracy: 48.67%\n",
      "633\tValidation loss: 1.579574\tBest loss: 1.579574\tAccuracy: 48.67%\n",
      "634\tValidation loss: 1.577803\tBest loss: 1.577803\tAccuracy: 48.67%\n",
      "635\tValidation loss: 1.576168\tBest loss: 1.576168\tAccuracy: 48.67%\n",
      "636\tValidation loss: 1.574502\tBest loss: 1.574502\tAccuracy: 48.67%\n",
      "637\tValidation loss: 1.572845\tBest loss: 1.572845\tAccuracy: 48.67%\n",
      "638\tValidation loss: 1.571173\tBest loss: 1.571173\tAccuracy: 48.67%\n",
      "639\tValidation loss: 1.569489\tBest loss: 1.569489\tAccuracy: 48.67%\n",
      "640\tValidation loss: 1.567782\tBest loss: 1.567782\tAccuracy: 48.67%\n",
      "641\tValidation loss: 1.566113\tBest loss: 1.566113\tAccuracy: 48.67%\n",
      "642\tValidation loss: 1.564431\tBest loss: 1.564431\tAccuracy: 48.67%\n",
      "643\tValidation loss: 1.562756\tBest loss: 1.562756\tAccuracy: 48.67%\n",
      "644\tValidation loss: 1.561121\tBest loss: 1.561121\tAccuracy: 48.67%\n",
      "645\tValidation loss: 1.559492\tBest loss: 1.559492\tAccuracy: 48.67%\n",
      "646\tValidation loss: 1.557847\tBest loss: 1.557847\tAccuracy: 48.67%\n",
      "647\tValidation loss: 1.556198\tBest loss: 1.556198\tAccuracy: 48.67%\n",
      "648\tValidation loss: 1.554533\tBest loss: 1.554533\tAccuracy: 48.67%\n",
      "649\tValidation loss: 1.552904\tBest loss: 1.552904\tAccuracy: 48.67%\n",
      "650\tValidation loss: 1.551270\tBest loss: 1.551270\tAccuracy: 48.67%\n",
      "651\tValidation loss: 1.549631\tBest loss: 1.549631\tAccuracy: 48.67%\n",
      "652\tValidation loss: 1.547980\tBest loss: 1.547980\tAccuracy: 48.67%\n",
      "653\tValidation loss: 1.546383\tBest loss: 1.546383\tAccuracy: 48.67%\n",
      "654\tValidation loss: 1.544772\tBest loss: 1.544772\tAccuracy: 48.67%\n",
      "655\tValidation loss: 1.543167\tBest loss: 1.543167\tAccuracy: 48.67%\n",
      "656\tValidation loss: 1.541553\tBest loss: 1.541553\tAccuracy: 48.67%\n",
      "657\tValidation loss: 1.539956\tBest loss: 1.539956\tAccuracy: 48.67%\n",
      "658\tValidation loss: 1.538336\tBest loss: 1.538336\tAccuracy: 48.67%\n",
      "659\tValidation loss: 1.536737\tBest loss: 1.536737\tAccuracy: 48.67%\n",
      "660\tValidation loss: 1.535158\tBest loss: 1.535158\tAccuracy: 48.67%\n",
      "661\tValidation loss: 1.533599\tBest loss: 1.533599\tAccuracy: 48.67%\n",
      "662\tValidation loss: 1.532052\tBest loss: 1.532052\tAccuracy: 48.67%\n",
      "663\tValidation loss: 1.530490\tBest loss: 1.530490\tAccuracy: 48.67%\n",
      "664\tValidation loss: 1.528933\tBest loss: 1.528933\tAccuracy: 48.67%\n",
      "665\tValidation loss: 1.527360\tBest loss: 1.527360\tAccuracy: 48.67%\n",
      "666\tValidation loss: 1.525796\tBest loss: 1.525796\tAccuracy: 48.67%\n",
      "667\tValidation loss: 1.524220\tBest loss: 1.524220\tAccuracy: 48.67%\n",
      "668\tValidation loss: 1.522650\tBest loss: 1.522650\tAccuracy: 48.67%\n",
      "669\tValidation loss: 1.521063\tBest loss: 1.521063\tAccuracy: 48.67%\n",
      "670\tValidation loss: 1.519498\tBest loss: 1.519498\tAccuracy: 48.67%\n",
      "671\tValidation loss: 1.517915\tBest loss: 1.517915\tAccuracy: 48.67%\n",
      "672\tValidation loss: 1.516377\tBest loss: 1.516377\tAccuracy: 48.67%\n",
      "673\tValidation loss: 1.514821\tBest loss: 1.514821\tAccuracy: 48.67%\n",
      "674\tValidation loss: 1.513272\tBest loss: 1.513272\tAccuracy: 49.33%\n",
      "675\tValidation loss: 1.511733\tBest loss: 1.511733\tAccuracy: 50.00%\n",
      "676\tValidation loss: 1.510183\tBest loss: 1.510183\tAccuracy: 50.00%\n",
      "677\tValidation loss: 1.508672\tBest loss: 1.508672\tAccuracy: 50.00%\n",
      "678\tValidation loss: 1.507173\tBest loss: 1.507173\tAccuracy: 50.00%\n",
      "679\tValidation loss: 1.505710\tBest loss: 1.505710\tAccuracy: 50.00%\n",
      "680\tValidation loss: 1.504202\tBest loss: 1.504202\tAccuracy: 50.00%\n",
      "681\tValidation loss: 1.502708\tBest loss: 1.502708\tAccuracy: 50.00%\n",
      "682\tValidation loss: 1.501230\tBest loss: 1.501230\tAccuracy: 50.00%\n",
      "683\tValidation loss: 1.499790\tBest loss: 1.499790\tAccuracy: 50.00%\n",
      "684\tValidation loss: 1.498322\tBest loss: 1.498322\tAccuracy: 50.00%\n",
      "685\tValidation loss: 1.496860\tBest loss: 1.496860\tAccuracy: 50.00%\n",
      "686\tValidation loss: 1.495410\tBest loss: 1.495410\tAccuracy: 50.67%\n",
      "687\tValidation loss: 1.493985\tBest loss: 1.493985\tAccuracy: 50.67%\n",
      "688\tValidation loss: 1.492572\tBest loss: 1.492572\tAccuracy: 50.67%\n",
      "689\tValidation loss: 1.491168\tBest loss: 1.491168\tAccuracy: 50.67%\n",
      "690\tValidation loss: 1.489767\tBest loss: 1.489767\tAccuracy: 50.67%\n",
      "691\tValidation loss: 1.488386\tBest loss: 1.488386\tAccuracy: 50.67%\n",
      "692\tValidation loss: 1.487000\tBest loss: 1.487000\tAccuracy: 50.67%\n",
      "693\tValidation loss: 1.485578\tBest loss: 1.485578\tAccuracy: 50.67%\n",
      "694\tValidation loss: 1.484181\tBest loss: 1.484181\tAccuracy: 50.67%\n",
      "695\tValidation loss: 1.482771\tBest loss: 1.482771\tAccuracy: 50.67%\n",
      "696\tValidation loss: 1.481370\tBest loss: 1.481370\tAccuracy: 50.67%\n",
      "697\tValidation loss: 1.479995\tBest loss: 1.479995\tAccuracy: 50.67%\n",
      "698\tValidation loss: 1.478592\tBest loss: 1.478592\tAccuracy: 50.67%\n",
      "699\tValidation loss: 1.477199\tBest loss: 1.477199\tAccuracy: 50.67%\n",
      "700\tValidation loss: 1.475823\tBest loss: 1.475823\tAccuracy: 50.67%\n",
      "701\tValidation loss: 1.474490\tBest loss: 1.474490\tAccuracy: 50.67%\n",
      "702\tValidation loss: 1.473136\tBest loss: 1.473136\tAccuracy: 50.67%\n",
      "703\tValidation loss: 1.471788\tBest loss: 1.471788\tAccuracy: 50.67%\n",
      "704\tValidation loss: 1.470432\tBest loss: 1.470432\tAccuracy: 50.67%\n",
      "705\tValidation loss: 1.469090\tBest loss: 1.469090\tAccuracy: 50.67%\n",
      "706\tValidation loss: 1.467787\tBest loss: 1.467787\tAccuracy: 50.67%\n",
      "707\tValidation loss: 1.466447\tBest loss: 1.466447\tAccuracy: 50.67%\n",
      "708\tValidation loss: 1.465085\tBest loss: 1.465085\tAccuracy: 50.67%\n",
      "709\tValidation loss: 1.463739\tBest loss: 1.463739\tAccuracy: 50.67%\n",
      "710\tValidation loss: 1.462375\tBest loss: 1.462375\tAccuracy: 50.67%\n",
      "711\tValidation loss: 1.461024\tBest loss: 1.461024\tAccuracy: 50.67%\n",
      "712\tValidation loss: 1.459656\tBest loss: 1.459656\tAccuracy: 51.33%\n",
      "713\tValidation loss: 1.458298\tBest loss: 1.458298\tAccuracy: 51.33%\n",
      "714\tValidation loss: 1.456912\tBest loss: 1.456912\tAccuracy: 51.33%\n",
      "715\tValidation loss: 1.455508\tBest loss: 1.455508\tAccuracy: 51.33%\n",
      "716\tValidation loss: 1.454133\tBest loss: 1.454133\tAccuracy: 51.33%\n",
      "717\tValidation loss: 1.452754\tBest loss: 1.452754\tAccuracy: 51.33%\n",
      "718\tValidation loss: 1.451412\tBest loss: 1.451412\tAccuracy: 51.33%\n",
      "719\tValidation loss: 1.450068\tBest loss: 1.450068\tAccuracy: 51.33%\n",
      "720\tValidation loss: 1.448724\tBest loss: 1.448724\tAccuracy: 51.33%\n",
      "721\tValidation loss: 1.447365\tBest loss: 1.447365\tAccuracy: 51.33%\n",
      "722\tValidation loss: 1.445971\tBest loss: 1.445971\tAccuracy: 51.33%\n",
      "723\tValidation loss: 1.444600\tBest loss: 1.444600\tAccuracy: 51.33%\n",
      "724\tValidation loss: 1.443224\tBest loss: 1.443224\tAccuracy: 52.00%\n",
      "725\tValidation loss: 1.441878\tBest loss: 1.441878\tAccuracy: 52.00%\n",
      "726\tValidation loss: 1.440558\tBest loss: 1.440558\tAccuracy: 52.00%\n",
      "727\tValidation loss: 1.439232\tBest loss: 1.439232\tAccuracy: 52.00%\n",
      "728\tValidation loss: 1.437921\tBest loss: 1.437921\tAccuracy: 52.00%\n",
      "729\tValidation loss: 1.436610\tBest loss: 1.436610\tAccuracy: 52.00%\n",
      "730\tValidation loss: 1.435300\tBest loss: 1.435300\tAccuracy: 52.00%\n",
      "731\tValidation loss: 1.433987\tBest loss: 1.433987\tAccuracy: 52.00%\n",
      "732\tValidation loss: 1.432661\tBest loss: 1.432661\tAccuracy: 52.00%\n",
      "733\tValidation loss: 1.431332\tBest loss: 1.431332\tAccuracy: 52.00%\n",
      "734\tValidation loss: 1.429992\tBest loss: 1.429992\tAccuracy: 52.00%\n",
      "735\tValidation loss: 1.428654\tBest loss: 1.428654\tAccuracy: 52.00%\n",
      "736\tValidation loss: 1.427365\tBest loss: 1.427365\tAccuracy: 52.00%\n",
      "737\tValidation loss: 1.426083\tBest loss: 1.426083\tAccuracy: 52.00%\n",
      "738\tValidation loss: 1.424788\tBest loss: 1.424788\tAccuracy: 52.00%\n",
      "739\tValidation loss: 1.423482\tBest loss: 1.423482\tAccuracy: 52.00%\n",
      "740\tValidation loss: 1.422172\tBest loss: 1.422172\tAccuracy: 52.00%\n",
      "741\tValidation loss: 1.420858\tBest loss: 1.420858\tAccuracy: 52.00%\n",
      "742\tValidation loss: 1.419539\tBest loss: 1.419539\tAccuracy: 52.00%\n",
      "743\tValidation loss: 1.418228\tBest loss: 1.418228\tAccuracy: 52.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744\tValidation loss: 1.416942\tBest loss: 1.416942\tAccuracy: 52.00%\n",
      "745\tValidation loss: 1.415644\tBest loss: 1.415644\tAccuracy: 52.00%\n",
      "746\tValidation loss: 1.414356\tBest loss: 1.414356\tAccuracy: 52.00%\n",
      "747\tValidation loss: 1.413083\tBest loss: 1.413083\tAccuracy: 52.00%\n",
      "748\tValidation loss: 1.411836\tBest loss: 1.411836\tAccuracy: 52.00%\n",
      "749\tValidation loss: 1.410550\tBest loss: 1.410550\tAccuracy: 52.00%\n",
      "750\tValidation loss: 1.409269\tBest loss: 1.409269\tAccuracy: 52.00%\n",
      "751\tValidation loss: 1.407989\tBest loss: 1.407989\tAccuracy: 52.00%\n",
      "752\tValidation loss: 1.406708\tBest loss: 1.406708\tAccuracy: 52.00%\n",
      "753\tValidation loss: 1.405407\tBest loss: 1.405407\tAccuracy: 52.00%\n",
      "754\tValidation loss: 1.404128\tBest loss: 1.404128\tAccuracy: 52.00%\n",
      "755\tValidation loss: 1.402858\tBest loss: 1.402858\tAccuracy: 52.00%\n",
      "756\tValidation loss: 1.401586\tBest loss: 1.401586\tAccuracy: 52.00%\n",
      "757\tValidation loss: 1.400313\tBest loss: 1.400313\tAccuracy: 52.00%\n",
      "758\tValidation loss: 1.399067\tBest loss: 1.399067\tAccuracy: 52.00%\n",
      "759\tValidation loss: 1.397802\tBest loss: 1.397802\tAccuracy: 52.00%\n",
      "760\tValidation loss: 1.396549\tBest loss: 1.396549\tAccuracy: 52.00%\n",
      "761\tValidation loss: 1.395310\tBest loss: 1.395310\tAccuracy: 52.00%\n",
      "762\tValidation loss: 1.394051\tBest loss: 1.394051\tAccuracy: 52.00%\n",
      "763\tValidation loss: 1.392823\tBest loss: 1.392823\tAccuracy: 52.00%\n",
      "764\tValidation loss: 1.391605\tBest loss: 1.391605\tAccuracy: 52.00%\n",
      "765\tValidation loss: 1.390365\tBest loss: 1.390365\tAccuracy: 52.00%\n",
      "766\tValidation loss: 1.389131\tBest loss: 1.389131\tAccuracy: 52.00%\n",
      "767\tValidation loss: 1.387906\tBest loss: 1.387906\tAccuracy: 52.67%\n",
      "768\tValidation loss: 1.386683\tBest loss: 1.386683\tAccuracy: 52.67%\n",
      "769\tValidation loss: 1.385497\tBest loss: 1.385497\tAccuracy: 52.67%\n",
      "770\tValidation loss: 1.384294\tBest loss: 1.384294\tAccuracy: 52.67%\n",
      "771\tValidation loss: 1.383108\tBest loss: 1.383108\tAccuracy: 52.67%\n",
      "772\tValidation loss: 1.381905\tBest loss: 1.381905\tAccuracy: 52.67%\n",
      "773\tValidation loss: 1.380729\tBest loss: 1.380729\tAccuracy: 52.67%\n",
      "774\tValidation loss: 1.379596\tBest loss: 1.379596\tAccuracy: 52.67%\n",
      "775\tValidation loss: 1.378469\tBest loss: 1.378469\tAccuracy: 52.67%\n",
      "776\tValidation loss: 1.377308\tBest loss: 1.377308\tAccuracy: 52.67%\n",
      "777\tValidation loss: 1.376177\tBest loss: 1.376177\tAccuracy: 52.67%\n",
      "778\tValidation loss: 1.375041\tBest loss: 1.375041\tAccuracy: 52.67%\n",
      "779\tValidation loss: 1.373887\tBest loss: 1.373887\tAccuracy: 52.67%\n",
      "780\tValidation loss: 1.372768\tBest loss: 1.372768\tAccuracy: 52.67%\n",
      "781\tValidation loss: 1.371630\tBest loss: 1.371630\tAccuracy: 52.67%\n",
      "782\tValidation loss: 1.370485\tBest loss: 1.370485\tAccuracy: 52.67%\n",
      "783\tValidation loss: 1.369359\tBest loss: 1.369359\tAccuracy: 52.67%\n",
      "784\tValidation loss: 1.368226\tBest loss: 1.368226\tAccuracy: 52.67%\n",
      "785\tValidation loss: 1.367089\tBest loss: 1.367089\tAccuracy: 52.67%\n",
      "786\tValidation loss: 1.365967\tBest loss: 1.365967\tAccuracy: 52.67%\n",
      "787\tValidation loss: 1.364844\tBest loss: 1.364844\tAccuracy: 52.67%\n",
      "788\tValidation loss: 1.363703\tBest loss: 1.363703\tAccuracy: 52.67%\n",
      "789\tValidation loss: 1.362557\tBest loss: 1.362557\tAccuracy: 52.67%\n",
      "790\tValidation loss: 1.361452\tBest loss: 1.361452\tAccuracy: 52.67%\n",
      "791\tValidation loss: 1.360365\tBest loss: 1.360365\tAccuracy: 52.67%\n",
      "792\tValidation loss: 1.359276\tBest loss: 1.359276\tAccuracy: 52.67%\n",
      "793\tValidation loss: 1.358189\tBest loss: 1.358189\tAccuracy: 52.67%\n",
      "794\tValidation loss: 1.357115\tBest loss: 1.357115\tAccuracy: 52.67%\n",
      "795\tValidation loss: 1.356023\tBest loss: 1.356023\tAccuracy: 52.67%\n",
      "796\tValidation loss: 1.354930\tBest loss: 1.354930\tAccuracy: 53.33%\n",
      "797\tValidation loss: 1.353814\tBest loss: 1.353814\tAccuracy: 53.33%\n",
      "798\tValidation loss: 1.352685\tBest loss: 1.352685\tAccuracy: 53.33%\n",
      "799\tValidation loss: 1.351592\tBest loss: 1.351592\tAccuracy: 53.33%\n",
      "800\tValidation loss: 1.350505\tBest loss: 1.350505\tAccuracy: 53.33%\n",
      "801\tValidation loss: 1.349435\tBest loss: 1.349435\tAccuracy: 53.33%\n",
      "802\tValidation loss: 1.348388\tBest loss: 1.348388\tAccuracy: 53.33%\n",
      "803\tValidation loss: 1.347336\tBest loss: 1.347336\tAccuracy: 53.33%\n",
      "804\tValidation loss: 1.346256\tBest loss: 1.346256\tAccuracy: 53.33%\n",
      "805\tValidation loss: 1.345155\tBest loss: 1.345155\tAccuracy: 53.33%\n",
      "806\tValidation loss: 1.344059\tBest loss: 1.344059\tAccuracy: 53.33%\n",
      "807\tValidation loss: 1.342957\tBest loss: 1.342957\tAccuracy: 54.00%\n",
      "808\tValidation loss: 1.341849\tBest loss: 1.341849\tAccuracy: 54.00%\n",
      "809\tValidation loss: 1.340716\tBest loss: 1.340716\tAccuracy: 54.00%\n",
      "810\tValidation loss: 1.339609\tBest loss: 1.339609\tAccuracy: 54.00%\n",
      "811\tValidation loss: 1.338515\tBest loss: 1.338515\tAccuracy: 54.00%\n",
      "812\tValidation loss: 1.337452\tBest loss: 1.337452\tAccuracy: 54.00%\n",
      "813\tValidation loss: 1.336380\tBest loss: 1.336380\tAccuracy: 54.00%\n",
      "814\tValidation loss: 1.335296\tBest loss: 1.335296\tAccuracy: 54.00%\n",
      "815\tValidation loss: 1.334246\tBest loss: 1.334246\tAccuracy: 54.00%\n",
      "816\tValidation loss: 1.333197\tBest loss: 1.333197\tAccuracy: 54.00%\n",
      "817\tValidation loss: 1.332140\tBest loss: 1.332140\tAccuracy: 54.00%\n",
      "818\tValidation loss: 1.331062\tBest loss: 1.331062\tAccuracy: 54.00%\n",
      "819\tValidation loss: 1.330019\tBest loss: 1.330019\tAccuracy: 54.00%\n",
      "820\tValidation loss: 1.329005\tBest loss: 1.329005\tAccuracy: 54.00%\n",
      "821\tValidation loss: 1.328016\tBest loss: 1.328016\tAccuracy: 54.67%\n",
      "822\tValidation loss: 1.327005\tBest loss: 1.327005\tAccuracy: 55.33%\n",
      "823\tValidation loss: 1.325988\tBest loss: 1.325988\tAccuracy: 55.33%\n",
      "824\tValidation loss: 1.324944\tBest loss: 1.324944\tAccuracy: 55.33%\n",
      "825\tValidation loss: 1.323876\tBest loss: 1.323876\tAccuracy: 55.33%\n",
      "826\tValidation loss: 1.322824\tBest loss: 1.322824\tAccuracy: 55.33%\n",
      "827\tValidation loss: 1.321776\tBest loss: 1.321776\tAccuracy: 55.33%\n",
      "828\tValidation loss: 1.320759\tBest loss: 1.320759\tAccuracy: 55.33%\n",
      "829\tValidation loss: 1.319727\tBest loss: 1.319727\tAccuracy: 55.33%\n",
      "830\tValidation loss: 1.318682\tBest loss: 1.318682\tAccuracy: 55.33%\n",
      "831\tValidation loss: 1.317654\tBest loss: 1.317654\tAccuracy: 55.33%\n",
      "832\tValidation loss: 1.316618\tBest loss: 1.316618\tAccuracy: 55.33%\n",
      "833\tValidation loss: 1.315580\tBest loss: 1.315580\tAccuracy: 56.00%\n",
      "834\tValidation loss: 1.314547\tBest loss: 1.314547\tAccuracy: 56.00%\n",
      "835\tValidation loss: 1.313519\tBest loss: 1.313519\tAccuracy: 56.00%\n",
      "836\tValidation loss: 1.312477\tBest loss: 1.312477\tAccuracy: 56.00%\n",
      "837\tValidation loss: 1.311417\tBest loss: 1.311417\tAccuracy: 56.00%\n",
      "838\tValidation loss: 1.310363\tBest loss: 1.310363\tAccuracy: 56.00%\n",
      "839\tValidation loss: 1.309304\tBest loss: 1.309304\tAccuracy: 56.00%\n",
      "840\tValidation loss: 1.308248\tBest loss: 1.308248\tAccuracy: 56.00%\n",
      "841\tValidation loss: 1.307189\tBest loss: 1.307189\tAccuracy: 56.00%\n",
      "842\tValidation loss: 1.306118\tBest loss: 1.306118\tAccuracy: 56.00%\n",
      "843\tValidation loss: 1.305062\tBest loss: 1.305062\tAccuracy: 56.00%\n",
      "844\tValidation loss: 1.304020\tBest loss: 1.304020\tAccuracy: 56.00%\n",
      "845\tValidation loss: 1.302987\tBest loss: 1.302987\tAccuracy: 56.00%\n",
      "846\tValidation loss: 1.301998\tBest loss: 1.301998\tAccuracy: 56.00%\n",
      "847\tValidation loss: 1.300977\tBest loss: 1.300977\tAccuracy: 56.00%\n",
      "848\tValidation loss: 1.299949\tBest loss: 1.299949\tAccuracy: 56.00%\n",
      "849\tValidation loss: 1.298924\tBest loss: 1.298924\tAccuracy: 56.00%\n",
      "850\tValidation loss: 1.297879\tBest loss: 1.297879\tAccuracy: 56.00%\n",
      "851\tValidation loss: 1.296852\tBest loss: 1.296852\tAccuracy: 56.00%\n",
      "852\tValidation loss: 1.295842\tBest loss: 1.295842\tAccuracy: 56.00%\n",
      "853\tValidation loss: 1.294855\tBest loss: 1.294855\tAccuracy: 56.67%\n",
      "854\tValidation loss: 1.293881\tBest loss: 1.293881\tAccuracy: 56.67%\n",
      "855\tValidation loss: 1.292901\tBest loss: 1.292901\tAccuracy: 56.67%\n",
      "856\tValidation loss: 1.291900\tBest loss: 1.291900\tAccuracy: 56.67%\n",
      "857\tValidation loss: 1.290886\tBest loss: 1.290886\tAccuracy: 56.67%\n",
      "858\tValidation loss: 1.289860\tBest loss: 1.289860\tAccuracy: 56.67%\n",
      "859\tValidation loss: 1.288857\tBest loss: 1.288857\tAccuracy: 56.67%\n",
      "860\tValidation loss: 1.287840\tBest loss: 1.287840\tAccuracy: 56.67%\n",
      "861\tValidation loss: 1.286832\tBest loss: 1.286832\tAccuracy: 56.67%\n",
      "862\tValidation loss: 1.285834\tBest loss: 1.285834\tAccuracy: 56.67%\n",
      "863\tValidation loss: 1.284820\tBest loss: 1.284820\tAccuracy: 56.67%\n",
      "864\tValidation loss: 1.283808\tBest loss: 1.283808\tAccuracy: 56.67%\n",
      "865\tValidation loss: 1.282795\tBest loss: 1.282795\tAccuracy: 56.67%\n",
      "866\tValidation loss: 1.281768\tBest loss: 1.281768\tAccuracy: 56.67%\n",
      "867\tValidation loss: 1.280720\tBest loss: 1.280720\tAccuracy: 56.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868\tValidation loss: 1.279680\tBest loss: 1.279680\tAccuracy: 56.67%\n",
      "869\tValidation loss: 1.278656\tBest loss: 1.278656\tAccuracy: 56.67%\n",
      "870\tValidation loss: 1.277630\tBest loss: 1.277630\tAccuracy: 57.33%\n",
      "871\tValidation loss: 1.276606\tBest loss: 1.276606\tAccuracy: 57.33%\n",
      "872\tValidation loss: 1.275612\tBest loss: 1.275612\tAccuracy: 57.33%\n",
      "873\tValidation loss: 1.274615\tBest loss: 1.274615\tAccuracy: 57.33%\n",
      "874\tValidation loss: 1.273629\tBest loss: 1.273629\tAccuracy: 57.33%\n",
      "875\tValidation loss: 1.272658\tBest loss: 1.272658\tAccuracy: 57.33%\n",
      "876\tValidation loss: 1.271692\tBest loss: 1.271692\tAccuracy: 57.33%\n",
      "877\tValidation loss: 1.270710\tBest loss: 1.270710\tAccuracy: 57.33%\n",
      "878\tValidation loss: 1.269716\tBest loss: 1.269716\tAccuracy: 57.33%\n",
      "879\tValidation loss: 1.268715\tBest loss: 1.268715\tAccuracy: 57.33%\n",
      "880\tValidation loss: 1.267756\tBest loss: 1.267756\tAccuracy: 57.33%\n",
      "881\tValidation loss: 1.266827\tBest loss: 1.266827\tAccuracy: 57.33%\n",
      "882\tValidation loss: 1.265861\tBest loss: 1.265861\tAccuracy: 57.33%\n",
      "883\tValidation loss: 1.264881\tBest loss: 1.264881\tAccuracy: 57.33%\n",
      "884\tValidation loss: 1.263921\tBest loss: 1.263921\tAccuracy: 57.33%\n",
      "885\tValidation loss: 1.262971\tBest loss: 1.262971\tAccuracy: 57.33%\n",
      "886\tValidation loss: 1.262033\tBest loss: 1.262033\tAccuracy: 57.33%\n",
      "887\tValidation loss: 1.261104\tBest loss: 1.261104\tAccuracy: 57.33%\n",
      "888\tValidation loss: 1.260173\tBest loss: 1.260173\tAccuracy: 57.33%\n",
      "889\tValidation loss: 1.259221\tBest loss: 1.259221\tAccuracy: 57.33%\n",
      "890\tValidation loss: 1.258274\tBest loss: 1.258274\tAccuracy: 57.33%\n",
      "891\tValidation loss: 1.257338\tBest loss: 1.257338\tAccuracy: 57.33%\n",
      "892\tValidation loss: 1.256413\tBest loss: 1.256413\tAccuracy: 57.33%\n",
      "893\tValidation loss: 1.255452\tBest loss: 1.255452\tAccuracy: 57.33%\n",
      "894\tValidation loss: 1.254487\tBest loss: 1.254487\tAccuracy: 57.33%\n",
      "895\tValidation loss: 1.253533\tBest loss: 1.253533\tAccuracy: 57.33%\n",
      "896\tValidation loss: 1.252576\tBest loss: 1.252576\tAccuracy: 57.33%\n",
      "897\tValidation loss: 1.251619\tBest loss: 1.251619\tAccuracy: 58.00%\n",
      "898\tValidation loss: 1.250662\tBest loss: 1.250662\tAccuracy: 58.00%\n",
      "899\tValidation loss: 1.249700\tBest loss: 1.249700\tAccuracy: 58.00%\n",
      "900\tValidation loss: 1.248742\tBest loss: 1.248742\tAccuracy: 58.00%\n",
      "901\tValidation loss: 1.247803\tBest loss: 1.247803\tAccuracy: 58.00%\n",
      "902\tValidation loss: 1.246861\tBest loss: 1.246861\tAccuracy: 58.00%\n",
      "903\tValidation loss: 1.245913\tBest loss: 1.245913\tAccuracy: 58.00%\n",
      "904\tValidation loss: 1.244949\tBest loss: 1.244949\tAccuracy: 58.00%\n",
      "905\tValidation loss: 1.243989\tBest loss: 1.243989\tAccuracy: 58.00%\n",
      "906\tValidation loss: 1.243022\tBest loss: 1.243022\tAccuracy: 58.00%\n",
      "907\tValidation loss: 1.242060\tBest loss: 1.242060\tAccuracy: 58.00%\n",
      "908\tValidation loss: 1.241140\tBest loss: 1.241140\tAccuracy: 58.00%\n",
      "909\tValidation loss: 1.240223\tBest loss: 1.240223\tAccuracy: 58.00%\n",
      "910\tValidation loss: 1.239299\tBest loss: 1.239299\tAccuracy: 58.00%\n",
      "911\tValidation loss: 1.238361\tBest loss: 1.238361\tAccuracy: 58.00%\n",
      "912\tValidation loss: 1.237439\tBest loss: 1.237439\tAccuracy: 58.00%\n",
      "913\tValidation loss: 1.236511\tBest loss: 1.236511\tAccuracy: 58.00%\n",
      "914\tValidation loss: 1.235604\tBest loss: 1.235604\tAccuracy: 58.00%\n",
      "915\tValidation loss: 1.234684\tBest loss: 1.234684\tAccuracy: 58.00%\n",
      "916\tValidation loss: 1.233752\tBest loss: 1.233752\tAccuracy: 58.00%\n",
      "917\tValidation loss: 1.232847\tBest loss: 1.232847\tAccuracy: 58.00%\n",
      "918\tValidation loss: 1.231948\tBest loss: 1.231948\tAccuracy: 58.00%\n",
      "919\tValidation loss: 1.231039\tBest loss: 1.231039\tAccuracy: 58.00%\n",
      "920\tValidation loss: 1.230138\tBest loss: 1.230138\tAccuracy: 58.00%\n",
      "921\tValidation loss: 1.229242\tBest loss: 1.229242\tAccuracy: 58.00%\n",
      "922\tValidation loss: 1.228322\tBest loss: 1.228322\tAccuracy: 58.00%\n",
      "923\tValidation loss: 1.227429\tBest loss: 1.227429\tAccuracy: 58.00%\n",
      "924\tValidation loss: 1.226524\tBest loss: 1.226524\tAccuracy: 58.00%\n",
      "925\tValidation loss: 1.225628\tBest loss: 1.225628\tAccuracy: 58.00%\n",
      "926\tValidation loss: 1.224723\tBest loss: 1.224723\tAccuracy: 58.00%\n",
      "927\tValidation loss: 1.223801\tBest loss: 1.223801\tAccuracy: 58.00%\n",
      "928\tValidation loss: 1.222896\tBest loss: 1.222896\tAccuracy: 58.00%\n",
      "929\tValidation loss: 1.222043\tBest loss: 1.222043\tAccuracy: 58.00%\n",
      "930\tValidation loss: 1.221183\tBest loss: 1.221183\tAccuracy: 58.00%\n",
      "931\tValidation loss: 1.220336\tBest loss: 1.220336\tAccuracy: 58.00%\n",
      "932\tValidation loss: 1.219508\tBest loss: 1.219508\tAccuracy: 58.00%\n",
      "933\tValidation loss: 1.218673\tBest loss: 1.218673\tAccuracy: 58.00%\n",
      "934\tValidation loss: 1.217852\tBest loss: 1.217852\tAccuracy: 58.00%\n",
      "935\tValidation loss: 1.217018\tBest loss: 1.217018\tAccuracy: 58.00%\n",
      "936\tValidation loss: 1.216183\tBest loss: 1.216183\tAccuracy: 58.00%\n",
      "937\tValidation loss: 1.215329\tBest loss: 1.215329\tAccuracy: 58.00%\n",
      "938\tValidation loss: 1.214457\tBest loss: 1.214457\tAccuracy: 58.00%\n",
      "939\tValidation loss: 1.213615\tBest loss: 1.213615\tAccuracy: 58.00%\n",
      "940\tValidation loss: 1.212795\tBest loss: 1.212795\tAccuracy: 58.00%\n",
      "941\tValidation loss: 1.211958\tBest loss: 1.211958\tAccuracy: 58.00%\n",
      "942\tValidation loss: 1.211120\tBest loss: 1.211120\tAccuracy: 58.00%\n",
      "943\tValidation loss: 1.210269\tBest loss: 1.210269\tAccuracy: 58.00%\n",
      "944\tValidation loss: 1.209407\tBest loss: 1.209407\tAccuracy: 58.00%\n",
      "945\tValidation loss: 1.208571\tBest loss: 1.208571\tAccuracy: 58.00%\n",
      "946\tValidation loss: 1.207713\tBest loss: 1.207713\tAccuracy: 58.00%\n",
      "947\tValidation loss: 1.206854\tBest loss: 1.206854\tAccuracy: 58.67%\n",
      "948\tValidation loss: 1.206017\tBest loss: 1.206017\tAccuracy: 58.67%\n",
      "949\tValidation loss: 1.205179\tBest loss: 1.205179\tAccuracy: 58.67%\n",
      "950\tValidation loss: 1.204365\tBest loss: 1.204365\tAccuracy: 58.67%\n",
      "951\tValidation loss: 1.203537\tBest loss: 1.203537\tAccuracy: 58.67%\n",
      "952\tValidation loss: 1.202696\tBest loss: 1.202696\tAccuracy: 58.67%\n",
      "953\tValidation loss: 1.201866\tBest loss: 1.201866\tAccuracy: 58.67%\n",
      "954\tValidation loss: 1.201049\tBest loss: 1.201049\tAccuracy: 58.67%\n",
      "955\tValidation loss: 1.200231\tBest loss: 1.200231\tAccuracy: 58.67%\n",
      "956\tValidation loss: 1.199416\tBest loss: 1.199416\tAccuracy: 58.67%\n",
      "957\tValidation loss: 1.198598\tBest loss: 1.198598\tAccuracy: 58.67%\n",
      "958\tValidation loss: 1.197759\tBest loss: 1.197759\tAccuracy: 58.67%\n",
      "959\tValidation loss: 1.196915\tBest loss: 1.196915\tAccuracy: 59.33%\n",
      "960\tValidation loss: 1.196060\tBest loss: 1.196060\tAccuracy: 59.33%\n",
      "961\tValidation loss: 1.195223\tBest loss: 1.195223\tAccuracy: 59.33%\n",
      "962\tValidation loss: 1.194379\tBest loss: 1.194379\tAccuracy: 59.33%\n",
      "963\tValidation loss: 1.193515\tBest loss: 1.193515\tAccuracy: 59.33%\n",
      "964\tValidation loss: 1.192640\tBest loss: 1.192640\tAccuracy: 59.33%\n",
      "965\tValidation loss: 1.191829\tBest loss: 1.191829\tAccuracy: 59.33%\n",
      "966\tValidation loss: 1.191003\tBest loss: 1.191003\tAccuracy: 59.33%\n",
      "967\tValidation loss: 1.190184\tBest loss: 1.190184\tAccuracy: 59.33%\n",
      "968\tValidation loss: 1.189353\tBest loss: 1.189353\tAccuracy: 59.33%\n",
      "969\tValidation loss: 1.188535\tBest loss: 1.188535\tAccuracy: 59.33%\n",
      "970\tValidation loss: 1.187724\tBest loss: 1.187724\tAccuracy: 59.33%\n",
      "971\tValidation loss: 1.186905\tBest loss: 1.186905\tAccuracy: 59.33%\n",
      "972\tValidation loss: 1.186094\tBest loss: 1.186094\tAccuracy: 59.33%\n",
      "973\tValidation loss: 1.185264\tBest loss: 1.185264\tAccuracy: 59.33%\n",
      "974\tValidation loss: 1.184442\tBest loss: 1.184442\tAccuracy: 59.33%\n",
      "975\tValidation loss: 1.183614\tBest loss: 1.183614\tAccuracy: 59.33%\n",
      "976\tValidation loss: 1.182794\tBest loss: 1.182794\tAccuracy: 59.33%\n",
      "977\tValidation loss: 1.181959\tBest loss: 1.181959\tAccuracy: 59.33%\n",
      "978\tValidation loss: 1.181115\tBest loss: 1.181115\tAccuracy: 59.33%\n",
      "979\tValidation loss: 1.180266\tBest loss: 1.180266\tAccuracy: 59.33%\n",
      "980\tValidation loss: 1.179421\tBest loss: 1.179421\tAccuracy: 59.33%\n",
      "981\tValidation loss: 1.178573\tBest loss: 1.178573\tAccuracy: 59.33%\n",
      "982\tValidation loss: 1.177728\tBest loss: 1.177728\tAccuracy: 59.33%\n",
      "983\tValidation loss: 1.176875\tBest loss: 1.176875\tAccuracy: 59.33%\n",
      "984\tValidation loss: 1.176031\tBest loss: 1.176031\tAccuracy: 59.33%\n",
      "985\tValidation loss: 1.175230\tBest loss: 1.175230\tAccuracy: 59.33%\n",
      "986\tValidation loss: 1.174420\tBest loss: 1.174420\tAccuracy: 59.33%\n",
      "987\tValidation loss: 1.173602\tBest loss: 1.173602\tAccuracy: 59.33%\n",
      "988\tValidation loss: 1.172814\tBest loss: 1.172814\tAccuracy: 59.33%\n",
      "989\tValidation loss: 1.172006\tBest loss: 1.172006\tAccuracy: 59.33%\n",
      "990\tValidation loss: 1.171205\tBest loss: 1.171205\tAccuracy: 59.33%\n",
      "991\tValidation loss: 1.170431\tBest loss: 1.170431\tAccuracy: 59.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992\tValidation loss: 1.169673\tBest loss: 1.169673\tAccuracy: 59.33%\n",
      "993\tValidation loss: 1.168921\tBest loss: 1.168921\tAccuracy: 59.33%\n",
      "994\tValidation loss: 1.168166\tBest loss: 1.168166\tAccuracy: 60.00%\n",
      "995\tValidation loss: 1.167418\tBest loss: 1.167418\tAccuracy: 60.00%\n",
      "996\tValidation loss: 1.166658\tBest loss: 1.166658\tAccuracy: 60.00%\n",
      "997\tValidation loss: 1.165880\tBest loss: 1.165880\tAccuracy: 60.00%\n",
      "998\tValidation loss: 1.165089\tBest loss: 1.165089\tAccuracy: 60.00%\n",
      "999\tValidation loss: 1.164297\tBest loss: 1.164297\tAccuracy: 60.00%\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_three_frozen\n",
      "Final test accuracy: 51.68%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_three_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_three_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5 now freeze the twp two hidden layers and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'X' type=Placeholder>,\n",
       " <tf.Operation 'y' type=Placeholder>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'hidden1/kernel/Initializer/truncated_normal' type=Add>,\n",
       " <tf.Operation 'hidden1/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden1/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/bias/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/MatMul' type=MatMul>,\n",
       " <tf.Operation 'hidden1/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'hidden1_out' type=Elu>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'hidden2/kernel/Initializer/truncated_normal' type=Add>,\n",
       " <tf.Operation 'hidden2/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden2/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden2/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/bias/read' type=Identity>,\n",
       " <tf.Operation 'hidden2/MatMul' type=MatMul>,\n",
       " <tf.Operation 'hidden2/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'hidden2_out' type=Elu>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'hidden3/kernel/Initializer/truncated_normal' type=Add>,\n",
       " <tf.Operation 'hidden3/kernel' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/kernel/read' type=Identity>,\n",
       " <tf.Operation 'hidden3/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden3/bias' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/bias/read' type=Identity>,\n",
       " <tf.Operation 'hidden3/MatMul' type=MatMul>,\n",
       " <tf.Operation 'hidden3/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'hidden3_out' type=Elu>,\n",
       " <tf.Operation 'logits/kernel/Initializer/truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'logits/kernel/Initializer/truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'logits/kernel/Initializer/truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'logits/kernel/Initializer/truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'logits/kernel/Initializer/truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'logits/kernel/Initializer/truncated_normal' type=Add>,\n",
       " <tf.Operation 'logits/kernel' type=VariableV2>,\n",
       " <tf.Operation 'logits/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'logits/kernel/read' type=Identity>,\n",
       " <tf.Operation 'logits/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'logits/bias' type=VariableV2>,\n",
       " <tf.Operation 'logits/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'logits/bias/read' type=Identity>,\n",
       " <tf.Operation 'logits/MatMul' type=MatMul>,\n",
       " <tf.Operation 'logits/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'Y_proba' type=Softmax>,\n",
       " <tf.Operation 'SparseSoftmaxCrossEntropyWithLogits/Shape' type=Shape>,\n",
       " <tf.Operation 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' type=SparseSoftmaxCrossEntropyWithLogits>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'loss' type=Mean>,\n",
       " <tf.Operation 'gradients/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/grad_ys_0' type=Const>,\n",
       " <tf.Operation 'gradients/Fill' type=Fill>,\n",
       " <tf.Operation 'gradients/loss_grad/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/loss_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/loss_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'gradients/loss_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/loss_grad/Shape_2' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Const' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Prod' type=Prod>,\n",
       " <tf.Operation 'gradients/loss_grad/Const_1' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Prod_1' type=Prod>,\n",
       " <tf.Operation 'gradients/loss_grad/Maximum/y' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Maximum' type=Maximum>,\n",
       " <tf.Operation 'gradients/loss_grad/floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'gradients/loss_grad/Cast' type=Cast>,\n",
       " <tf.Operation 'gradients/loss_grad/truediv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient' type=PreventGradient>,\n",
       " <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/logits/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'gradients/logits/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/logits/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/logits/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/logits/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/logits/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/logits/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/logits/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/logits/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden3_out_grad/EluGrad' type=EluGrad>,\n",
       " <tf.Operation 'gradients/hidden3/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'gradients/hidden3/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/hidden3/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden3/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden3/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/hidden3/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/hidden3/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/hidden3/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden3/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden2_out_grad/EluGrad' type=EluGrad>,\n",
       " <tf.Operation 'gradients/hidden2/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'gradients/hidden2/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/hidden2/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden2/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden2/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/hidden2/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/hidden2/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/hidden2/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden2/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden1_out_grad/EluGrad' type=EluGrad>,\n",
       " <tf.Operation 'gradients/hidden1/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'gradients/hidden1/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/hidden1/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden1/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden1/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/hidden1/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/hidden1/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/hidden1/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/hidden1/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'beta1_power/initial_value' type=Const>,\n",
       " <tf.Operation 'beta1_power' type=VariableV2>,\n",
       " <tf.Operation 'beta1_power/Assign' type=Assign>,\n",
       " <tf.Operation 'beta1_power/read' type=Identity>,\n",
       " <tf.Operation 'beta2_power/initial_value' type=Const>,\n",
       " <tf.Operation 'beta2_power' type=VariableV2>,\n",
       " <tf.Operation 'beta2_power/Assign' type=Assign>,\n",
       " <tf.Operation 'beta2_power/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/kernel/Adam/Initializer/zeros/shape_as_tensor' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Adam/Initializer/zeros/Const' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Adam/Initializer/zeros' type=Fill>,\n",
       " <tf.Operation 'hidden1/kernel/Adam' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/kernel/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/kernel/Adam/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/kernel/Adam_1/Initializer/zeros/shape_as_tensor' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Adam_1/Initializer/zeros/Const' type=Const>,\n",
       " <tf.Operation 'hidden1/kernel/Adam_1/Initializer/zeros' type=Fill>,\n",
       " <tf.Operation 'hidden1/kernel/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/kernel/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/kernel/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/bias/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden1/bias/Adam' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/bias/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/bias/Adam/read' type=Identity>,\n",
       " <tf.Operation 'hidden1/bias/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden1/bias/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'hidden1/bias/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden1/bias/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'hidden2/kernel/Adam/Initializer/zeros/shape_as_tensor' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Adam/Initializer/zeros/Const' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Adam/Initializer/zeros' type=Fill>,\n",
       " <tf.Operation 'hidden2/kernel/Adam' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/kernel/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/kernel/Adam/read' type=Identity>,\n",
       " <tf.Operation 'hidden2/kernel/Adam_1/Initializer/zeros/shape_as_tensor' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Adam_1/Initializer/zeros/Const' type=Const>,\n",
       " <tf.Operation 'hidden2/kernel/Adam_1/Initializer/zeros' type=Fill>,\n",
       " <tf.Operation 'hidden2/kernel/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/kernel/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/kernel/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'hidden2/bias/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden2/bias/Adam' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/bias/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/bias/Adam/read' type=Identity>,\n",
       " <tf.Operation 'hidden2/bias/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden2/bias/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'hidden2/bias/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden2/bias/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'hidden3/kernel/Adam/Initializer/zeros/shape_as_tensor' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Adam/Initializer/zeros/Const' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Adam/Initializer/zeros' type=Fill>,\n",
       " <tf.Operation 'hidden3/kernel/Adam' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/kernel/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/kernel/Adam/read' type=Identity>,\n",
       " <tf.Operation 'hidden3/kernel/Adam_1/Initializer/zeros/shape_as_tensor' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Adam_1/Initializer/zeros/Const' type=Const>,\n",
       " <tf.Operation 'hidden3/kernel/Adam_1/Initializer/zeros' type=Fill>,\n",
       " <tf.Operation 'hidden3/kernel/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/kernel/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/kernel/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'hidden3/bias/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden3/bias/Adam' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/bias/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/bias/Adam/read' type=Identity>,\n",
       " <tf.Operation 'hidden3/bias/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'hidden3/bias/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'hidden3/bias/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'hidden3/bias/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'logits/kernel/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'logits/kernel/Adam' type=VariableV2>,\n",
       " <tf.Operation 'logits/kernel/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'logits/kernel/Adam/read' type=Identity>,\n",
       " <tf.Operation 'logits/kernel/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'logits/kernel/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'logits/kernel/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'logits/kernel/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'logits/bias/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'logits/bias/Adam' type=VariableV2>,\n",
       " <tf.Operation 'logits/bias/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'logits/bias/Adam/read' type=Identity>,\n",
       " <tf.Operation 'logits/bias/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'logits/bias/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'logits/bias/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'logits/bias/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'Adam/learning_rate' type=Const>,\n",
       " <tf.Operation 'Adam/beta1' type=Const>,\n",
       " <tf.Operation 'Adam/beta2' type=Const>,\n",
       " <tf.Operation 'Adam/epsilon' type=Const>,\n",
       " <tf.Operation 'Adam/update_hidden1/kernel/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_hidden1/bias/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_hidden2/kernel/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_hidden2/bias/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_hidden3/kernel/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_hidden3/bias/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_logits/kernel/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_logits/bias/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/mul' type=Mul>,\n",
       " <tf.Operation 'Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'Adam/mul_1' type=Mul>,\n",
       " <tf.Operation 'Adam/Assign_1' type=Assign>,\n",
       " <tf.Operation 'Adam' type=NoOp>,\n",
       " <tf.Operation 'in_top_k/InTopKV2/k' type=Const>,\n",
       " <tf.Operation 'in_top_k/InTopKV2' type=InTopKV2>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'Const_1' type=Const>,\n",
       " <tf.Operation 'accuracy' type=Mean>,\n",
       " <tf.Operation 'init' type=NoOp>,\n",
       " <tf.Operation 'save/filename/input' type=Const>,\n",
       " <tf.Operation 'save/filename' type=PlaceholderWithDefault>,\n",
       " <tf.Operation 'save/Const' type=PlaceholderWithDefault>,\n",
       " <tf.Operation 'save/SaveV2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/SaveV2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/SaveV2' type=SaveV2>,\n",
       " <tf.Operation 'save/control_dependency' type=Identity>,\n",
       " <tf.Operation 'save/RestoreV2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign' type=Assign>,\n",
       " <tf.Operation 'save/Assign_1' type=Assign>,\n",
       " <tf.Operation 'save/Assign_2' type=Assign>,\n",
       " <tf.Operation 'save/Assign_3' type=Assign>,\n",
       " <tf.Operation 'save/Assign_4' type=Assign>,\n",
       " <tf.Operation 'save/Assign_5' type=Assign>,\n",
       " <tf.Operation 'save/Assign_6' type=Assign>,\n",
       " <tf.Operation 'save/Assign_7' type=Assign>,\n",
       " <tf.Operation 'save/Assign_8' type=Assign>,\n",
       " <tf.Operation 'save/Assign_9' type=Assign>,\n",
       " <tf.Operation 'save/Assign_10' type=Assign>,\n",
       " <tf.Operation 'save/Assign_11' type=Assign>,\n",
       " <tf.Operation 'save/Assign_12' type=Assign>,\n",
       " <tf.Operation 'save/Assign_13' type=Assign>,\n",
       " <tf.Operation 'save/Assign_14' type=Assign>,\n",
       " <tf.Operation 'save/Assign_15' type=Assign>,\n",
       " <tf.Operation 'save/Assign_16' type=Assign>,\n",
       " <tf.Operation 'save/Assign_17' type=Assign>,\n",
       " <tf.Operation 'save/Assign_18' type=Assign>,\n",
       " <tf.Operation 'save/Assign_19' type=Assign>,\n",
       " <tf.Operation 'save/Assign_20' type=Assign>,\n",
       " <tf.Operation 'save/Assign_21' type=Assign>,\n",
       " <tf.Operation 'save/Assign_22' type=Assign>,\n",
       " <tf.Operation 'save/Assign_23' type=Assign>,\n",
       " <tf.Operation 'save/Assign_24' type=Assign>,\n",
       " <tf.Operation 'save/Assign_25' type=Assign>,\n",
       " <tf.Operation 'save/restore_all' type=NoOp>,\n",
       " <tf.Operation 'new_logits/kernel/Initializer/truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'new_logits/kernel/Initializer/truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'new_logits/kernel/Initializer/truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'new_logits/kernel/Initializer/truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'new_logits/kernel/Initializer/truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'new_logits/kernel/Initializer/truncated_normal' type=Add>,\n",
       " <tf.Operation 'new_logits/kernel' type=VariableV2>,\n",
       " <tf.Operation 'new_logits/kernel/Assign' type=Assign>,\n",
       " <tf.Operation 'new_logits/kernel/read' type=Identity>,\n",
       " <tf.Operation 'new_logits/bias/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'new_logits/bias' type=VariableV2>,\n",
       " <tf.Operation 'new_logits/bias/Assign' type=Assign>,\n",
       " <tf.Operation 'new_logits/bias/read' type=Identity>,\n",
       " <tf.Operation 'new_logits/MatMul' type=MatMul>,\n",
       " <tf.Operation 'new_logits/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'Softmax' type=Softmax>,\n",
       " <tf.Operation 'SparseSoftmaxCrossEntropyWithLogits/Shape_1' type=Shape>,\n",
       " <tf.Operation 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_1' type=SparseSoftmaxCrossEntropyWithLogits>,\n",
       " <tf.Operation 'Const_2' type=Const>,\n",
       " <tf.Operation 'Mean' type=Mean>,\n",
       " <tf.Operation 'in_top_k/InTopKV2_1/k' type=Const>,\n",
       " <tf.Operation 'in_top_k/InTopKV2_1' type=InTopKV2>,\n",
       " <tf.Operation 'Cast_1' type=Cast>,\n",
       " <tf.Operation 'Const_3' type=Const>,\n",
       " <tf.Operation 'accuracy_1' type=Mean>,\n",
       " <tf.Operation 'gradients/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/grad_ys_0_1' type=Const>,\n",
       " <tf.Operation 'gradients/Fill_1' type=Fill>,\n",
       " <tf.Operation 'gradients/Mean_grad/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape_2' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Const' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Prod' type=Prod>,\n",
       " <tf.Operation 'gradients/Mean_grad/Const_1' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Prod_1' type=Prod>,\n",
       " <tf.Operation 'gradients/Mean_grad/Maximum/y' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Maximum' type=Maximum>,\n",
       " <tf.Operation 'gradients/Mean_grad/floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'gradients/Mean_grad/Cast' type=Cast>,\n",
       " <tf.Operation 'gradients/Mean_grad/truediv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/zeros_like_1' type=ZerosLike>,\n",
       " <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_1_grad/PreventGradient' type=PreventGradient>,\n",
       " <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_1_grad/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_1_grad/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_1_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/new_logits/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'gradients/new_logits/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/new_logits/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/new_logits/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/new_logits/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/new_logits/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/new_logits/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/new_logits/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/new_logits/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'new_logits/kernel/Adam2/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'new_logits/kernel/Adam2' type=VariableV2>,\n",
       " <tf.Operation 'new_logits/kernel/Adam2/Assign' type=Assign>,\n",
       " <tf.Operation 'new_logits/kernel/Adam2/read' type=Identity>,\n",
       " <tf.Operation 'new_logits/kernel/Adam2_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'new_logits/kernel/Adam2_1' type=VariableV2>,\n",
       " <tf.Operation 'new_logits/kernel/Adam2_1/Assign' type=Assign>,\n",
       " <tf.Operation 'new_logits/kernel/Adam2_1/read' type=Identity>,\n",
       " <tf.Operation 'new_logits/bias/Adam2/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'new_logits/bias/Adam2' type=VariableV2>,\n",
       " <tf.Operation 'new_logits/bias/Adam2/Assign' type=Assign>,\n",
       " <tf.Operation 'new_logits/bias/Adam2/read' type=Identity>,\n",
       " <tf.Operation 'new_logits/bias/Adam2_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'new_logits/bias/Adam2_1' type=VariableV2>,\n",
       " <tf.Operation 'new_logits/bias/Adam2_1/Assign' type=Assign>,\n",
       " <tf.Operation 'new_logits/bias/Adam2_1/read' type=Identity>,\n",
       " <tf.Operation 'Adam2/lr' type=Const>,\n",
       " <tf.Operation 'Adam2/rho' type=Const>,\n",
       " <tf.Operation 'Adam2/epsilon' type=Const>,\n",
       " <tf.Operation 'Adam2/update_new_logits/kernel/ApplyAdadelta' type=ApplyAdadelta>,\n",
       " <tf.Operation 'Adam2/update_new_logits/bias/ApplyAdadelta' type=ApplyAdadelta>,\n",
       " <tf.Operation 'Adam2' type=NoOp>,\n",
       " <tf.Operation 'init_1' type=NoOp>,\n",
       " <tf.Operation 'save/filename_1/input' type=Const>,\n",
       " <tf.Operation 'save/filename_1' type=PlaceholderWithDefault>,\n",
       " <tf.Operation 'save/Const_1' type=PlaceholderWithDefault>,\n",
       " <tf.Operation 'save/SaveV2_1/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/SaveV2_1/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/SaveV2_1' type=SaveV2>,\n",
       " <tf.Operation 'save/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'save/RestoreV2_1/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_1/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_1' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_26' type=Assign>,\n",
       " <tf.Operation 'save/Assign_27' type=Assign>,\n",
       " <tf.Operation 'save/Assign_28' type=Assign>,\n",
       " <tf.Operation 'save/Assign_29' type=Assign>,\n",
       " <tf.Operation 'save/Assign_30' type=Assign>,\n",
       " <tf.Operation 'save/Assign_31' type=Assign>,\n",
       " <tf.Operation 'save/Assign_32' type=Assign>,\n",
       " <tf.Operation 'save/Assign_33' type=Assign>,\n",
       " <tf.Operation 'save/Assign_34' type=Assign>,\n",
       " <tf.Operation 'save/Assign_35' type=Assign>,\n",
       " <tf.Operation 'save/Assign_36' type=Assign>,\n",
       " <tf.Operation 'save/Assign_37' type=Assign>,\n",
       " <tf.Operation 'save/Assign_38' type=Assign>,\n",
       " <tf.Operation 'save/Assign_39' type=Assign>,\n",
       " <tf.Operation 'save/Assign_40' type=Assign>,\n",
       " <tf.Operation 'save/Assign_41' type=Assign>,\n",
       " <tf.Operation 'save/Assign_42' type=Assign>,\n",
       " <tf.Operation 'save/Assign_43' type=Assign>,\n",
       " <tf.Operation 'save/Assign_44' type=Assign>,\n",
       " <tf.Operation 'save/Assign_45' type=Assign>,\n",
       " <tf.Operation 'save/Assign_46' type=Assign>,\n",
       " <tf.Operation 'save/Assign_47' type=Assign>,\n",
       " <tf.Operation 'save/Assign_48' type=Assign>,\n",
       " <tf.Operation 'save/Assign_49' type=Assign>,\n",
       " <tf.Operation 'save/Assign_50' type=Assign>,\n",
       " <tf.Operation 'save/Assign_51' type=Assign>,\n",
       " <tf.Operation 'save/Assign_52' type=Assign>,\n",
       " <tf.Operation 'save/Assign_53' type=Assign>,\n",
       " <tf.Operation 'save/Assign_54' type=Assign>,\n",
       " <tf.Operation 'save/Assign_55' type=Assign>,\n",
       " <tf.Operation 'save/Assign_56' type=Assign>,\n",
       " <tf.Operation 'save/Assign_57' type=Assign>,\n",
       " <tf.Operation 'save/restore_all_1' type=NoOp>]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[23]|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam3\")\n",
    "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "two_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_three_frozen\n",
      "0\tValidation loss: 0.496272\tBest loss: 0.496272\tAccuracy: 80.00%\n",
      "1\tValidation loss: 0.317117\tBest loss: 0.317117\tAccuracy: 89.33%\n",
      "2\tValidation loss: 0.384775\tBest loss: 0.317117\tAccuracy: 87.33%\n",
      "3\tValidation loss: 0.373420\tBest loss: 0.317117\tAccuracy: 88.67%\n",
      "4\tValidation loss: 0.387891\tBest loss: 0.317117\tAccuracy: 91.33%\n",
      "5\tValidation loss: 0.609382\tBest loss: 0.317117\tAccuracy: 88.00%\n",
      "6\tValidation loss: 0.551100\tBest loss: 0.317117\tAccuracy: 86.67%\n",
      "7\tValidation loss: 0.364332\tBest loss: 0.317117\tAccuracy: 91.33%\n",
      "8\tValidation loss: 0.275254\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "9\tValidation loss: 0.313090\tBest loss: 0.275254\tAccuracy: 94.00%\n",
      "10\tValidation loss: 0.381343\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "11\tValidation loss: 0.356873\tBest loss: 0.275254\tAccuracy: 92.67%\n",
      "12\tValidation loss: 0.343862\tBest loss: 0.275254\tAccuracy: 92.00%\n",
      "13\tValidation loss: 0.359327\tBest loss: 0.275254\tAccuracy: 92.67%\n",
      "14\tValidation loss: 0.355298\tBest loss: 0.275254\tAccuracy: 92.67%\n",
      "15\tValidation loss: 0.358471\tBest loss: 0.275254\tAccuracy: 92.67%\n",
      "16\tValidation loss: 0.358243\tBest loss: 0.275254\tAccuracy: 92.67%\n",
      "17\tValidation loss: 0.363026\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "18\tValidation loss: 0.362786\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "19\tValidation loss: 0.363650\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "20\tValidation loss: 0.366475\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "21\tValidation loss: 0.368375\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "22\tValidation loss: 0.369756\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "23\tValidation loss: 0.370877\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "24\tValidation loss: 0.373723\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "25\tValidation loss: 0.372466\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "26\tValidation loss: 0.376363\tBest loss: 0.275254\tAccuracy: 93.33%\n",
      "27\tValidation loss: 0.376622\tBest loss: 0.275254\tAccuracy: 94.00%\n",
      "28\tValidation loss: 0.376904\tBest loss: 0.275254\tAccuracy: 94.00%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
      "Final test accuracy: 87.35%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_three_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = two_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam4\")\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "no_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
      "0\tValidation loss: 0.604754\tBest loss: 0.604754\tAccuracy: 84.00%\n",
      "1\tValidation loss: 0.663624\tBest loss: 0.604754\tAccuracy: 90.67%\n",
      "2\tValidation loss: 0.353705\tBest loss: 0.353705\tAccuracy: 96.00%\n",
      "3\tValidation loss: 0.351660\tBest loss: 0.351660\tAccuracy: 92.67%\n",
      "4\tValidation loss: 0.438391\tBest loss: 0.351660\tAccuracy: 93.33%\n",
      "5\tValidation loss: 0.356255\tBest loss: 0.351660\tAccuracy: 94.67%\n",
      "6\tValidation loss: 0.291531\tBest loss: 0.291531\tAccuracy: 96.67%\n",
      "7\tValidation loss: 0.376335\tBest loss: 0.291531\tAccuracy: 95.33%\n",
      "8\tValidation loss: 0.545685\tBest loss: 0.291531\tAccuracy: 93.33%\n",
      "9\tValidation loss: 0.597176\tBest loss: 0.291531\tAccuracy: 92.00%\n",
      "10\tValidation loss: 0.438206\tBest loss: 0.291531\tAccuracy: 92.67%\n",
      "11\tValidation loss: 0.558558\tBest loss: 0.291531\tAccuracy: 94.67%\n",
      "12\tValidation loss: 0.643385\tBest loss: 0.291531\tAccuracy: 94.00%\n",
      "13\tValidation loss: 0.897515\tBest loss: 0.291531\tAccuracy: 90.67%\n",
      "14\tValidation loss: 1.267574\tBest loss: 0.291531\tAccuracy: 89.33%\n",
      "15\tValidation loss: 0.654177\tBest loss: 0.291531\tAccuracy: 90.67%\n",
      "16\tValidation loss: 0.898189\tBest loss: 0.291531\tAccuracy: 92.00%\n",
      "17\tValidation loss: 1.304714\tBest loss: 0.291531\tAccuracy: 93.33%\n",
      "18\tValidation loss: 1.597462\tBest loss: 0.291531\tAccuracy: 94.67%\n",
      "19\tValidation loss: 0.876122\tBest loss: 0.291531\tAccuracy: 96.00%\n",
      "20\tValidation loss: 0.841170\tBest loss: 0.291531\tAccuracy: 96.00%\n",
      "21\tValidation loss: 0.846741\tBest loss: 0.291531\tAccuracy: 96.00%\n",
      "22\tValidation loss: 0.846089\tBest loss: 0.291531\tAccuracy: 96.00%\n",
      "23\tValidation loss: 0.845000\tBest loss: 0.291531\tAccuracy: 96.00%\n",
      "24\tValidation loss: 0.845031\tBest loss: 0.291531\tAccuracy: 96.00%\n",
      "25\tValidation loss: 0.844526\tBest loss: 0.291531\tAccuracy: 96.00%\n",
      "26\tValidation loss: 0.845018\tBest loss: 0.291531\tAccuracy: 96.00%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_no_frozen\n",
      "Final test accuracy: 91.28%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = no_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    no_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare this to a DNN trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.674617\tBest loss: 0.674617\tAccuracy: 80.67%\n",
      "1\tValidation loss: 0.584844\tBest loss: 0.584844\tAccuracy: 88.67%\n",
      "2\tValidation loss: 0.647287\tBest loss: 0.584844\tAccuracy: 84.00%\n",
      "3\tValidation loss: 0.530468\tBest loss: 0.530468\tAccuracy: 87.33%\n",
      "4\tValidation loss: 0.683234\tBest loss: 0.530468\tAccuracy: 90.67%\n",
      "5\tValidation loss: 0.537549\tBest loss: 0.530468\tAccuracy: 89.33%\n",
      "6\tValidation loss: 0.676585\tBest loss: 0.530468\tAccuracy: 90.67%\n",
      "7\tValidation loss: 0.770103\tBest loss: 0.530468\tAccuracy: 88.00%\n",
      "8\tValidation loss: 0.758075\tBest loss: 0.530468\tAccuracy: 90.67%\n",
      "9\tValidation loss: 0.565575\tBest loss: 0.530468\tAccuracy: 90.00%\n",
      "10\tValidation loss: 0.736492\tBest loss: 0.530468\tAccuracy: 90.00%\n",
      "11\tValidation loss: 0.932942\tBest loss: 0.530468\tAccuracy: 92.00%\n",
      "12\tValidation loss: 1.059795\tBest loss: 0.530468\tAccuracy: 90.67%\n",
      "13\tValidation loss: 1.105182\tBest loss: 0.530468\tAccuracy: 90.67%\n",
      "14\tValidation loss: 1.111506\tBest loss: 0.530468\tAccuracy: 91.33%\n",
      "15\tValidation loss: 2.310834\tBest loss: 0.530468\tAccuracy: 88.00%\n",
      "16\tValidation loss: 1.990372\tBest loss: 0.530468\tAccuracy: 86.67%\n",
      "17\tValidation loss: 2.242507\tBest loss: 0.530468\tAccuracy: 90.67%\n",
      "18\tValidation loss: 2.143360\tBest loss: 0.530468\tAccuracy: 90.67%\n",
      "19\tValidation loss: 2.121782\tBest loss: 0.530468\tAccuracy: 92.00%\n",
      "20\tValidation loss: 2.119782\tBest loss: 0.530468\tAccuracy: 92.00%\n",
      "21\tValidation loss: 2.118733\tBest loss: 0.530468\tAccuracy: 92.00%\n",
      "22\tValidation loss: 2.118518\tBest loss: 0.530468\tAccuracy: 92.00%\n",
      "23\tValidation loss: 2.119540\tBest loss: 0.530468\tAccuracy: 92.00%\n",
      "24\tValidation loss: 2.119694\tBest loss: 0.530468\tAccuracy: 92.00%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x11591cd08>,\n",
       "              batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "              initializer=<tensorflow.python.ops.init_ops.VarianceScaling object at 0x1cfb2366a0>,\n",
       "              learning_rate=0.01, n_hidden_layers=4, n_neurons=100,\n",
       "              optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_5_to_9 = DNNClassifier(n_hidden_layers=4, random_state=42)\n",
    "dnn_clf_5_to_9.fit(X_train2, y_train2, n_epochs=1000, X_valid=X_valid2, y_valid=y_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8479736679695535"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_5_to_9.predict(X_test2)\n",
    "accuracy_score(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network from transfer learning increased from 85 to 91%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Pretraining an aux task\n",
    "\n",
    "create a DNN that predicts whether or not two images are the same. then use the lower layers on this network to train MNSIT classification using very little training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Start by building two DNNs (let's call them DNN A and B), both similar to the one you built earlier but without the output layer: each DNN should have five hidden layers of 100 neurons each, He initialization, and ELU activation. Next, add one more hidden layer with 10 units on top of both DNNs. You should use TensorFlow's concat() function with axis=1 to concatenate the outputs of both DNNs along the horizontal axis, then feed the result to the hidden layer. Finally, add an output layer with a single neuron using the logistic activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 2, n_inputs), name=\"X\")\n",
    "X1, X2 = tf.unstack(X, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reponse is 0 is they are different 1 if images are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'unstack:1' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create handles for the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn1 = dnn(X1, name=\"DNN_A\")\n",
    "dnn2 = dnn(X2, name=\"DNN_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'DNN_B/hidden5/Elu:0' shape=(?, 100) dtype=float32>"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_outputs = tf.concat([dnn1,dnn2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100)])"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100)])"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "default is 100??? from the dnn function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, 200) dtype=float32>"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'unstack:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(200)])"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets add an extra hideen layer with just 10 neurons and the output layer with a sinlge neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.layers.dense(dnn_outputs, units=10, activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "logits = tf.layers.dense(hidden, units=1, kernel_initializer=he_init)\n",
    "y_proba = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.cast(tf.greater_equal(logits, 0), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the cost function\n",
    "y_as_float = tf.cast(y, tf.float32)\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_as_float, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.95\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure accuracy\n",
    "y_pred_correct = tf.equal(y_pred, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(y_pred_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2\n",
    "\n",
    "split the MNIST training set in two sets: split #1 should containing 55,000 images, and split #2 should contain contain 5,000 images. Create a function that generates a training batch where each instance is a pair of MNIST images picked from split #1. Half of the training instances should be pairs of images that belong to the same class, while the other half should be images from different classes. For each pair, the training label should be 0 if the images are from the same class, or 1 if they are from different classes.\n",
    "\n",
    "The MNIST dataset returned by TensorFlow's input_data() function is already split into 3 parts: a training set (55,000 instances), a validation set (5,000 instances) and a test set (10,000 instances). \n",
    "\n",
    "Let's use the first set to generate the training set composed image pairs, and we will use the second set for the second phase of the exercise (to train a regular MNIST classifier). We will use the third set as the test set for both phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train\n",
    "y_train1 = y_train\n",
    "\n",
    "X_train2 = X_valid\n",
    "y_train2 = y_valid\n",
    "\n",
    "X_test = X_test\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets write a function that generates pairs of images, half represetning the same digit, and the other half as diffeent digits. \n",
    "* first decide how many pairs sme and paris different\n",
    "* batch size //2 but we to handle th case where it is odd\n",
    "* generate random paris and pik the right number of same pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(images, labels, batch_size):\n",
    "    size1 = batch_size // 2\n",
    "    size2 = batch_size - size1\n",
    "    if size1 != size2 and np.random.rand() > 0.5:\n",
    "        size1, size2 = size2, size1\n",
    "    X = []\n",
    "    y = []\n",
    "    while len(X) < size1:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if rnd_idx1 != rnd_idx2 and labels[rnd_idx1] == labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([1])\n",
    "    while len(X) < batch_size:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if labels[rnd_idx1] != labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([0])\n",
    "    rnd_indices = np.random.permutation(batch_size)\n",
    "    return np.array(X)[rnd_indices], np.array(y)[rnd_indices]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 2, 784), dtype('float32'))"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape or type of each batch\n",
    "X_batch.shape, X_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAMHCAYAAAB/uRZKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2dedzM9fr/XziWw7FnS1Ip4muNhBNFSJRsiZO+bc43qhNuu0SWEiVOKZ1o72svtOKU+JIQpURITrLvsu/n98f5va/7GjNzz8x9z8znM9f9ev5zXo/3zHzm7e51rrne2/XO8e9//xuEWCKn1x0gJN7Q1MQcNDUxB01NzEFTE3PQ1MQcf4jwOuf7YidHFj7Lv3fsBP29GamJOWhqYg6ampiDpibmiDRQ9Jx27dqJnj17NgDgu+++k7aaNWsmvU/ZjbVr14q+9dZbRXfu3Fn02LFjk9qnjGCkJuagqYk5fJ9+fPrpp6Jz5PjPlOSqVaukjelH4jhw4AAA4Pbbb5e2PXv2iM6Z058x0Z+9IiQL0NTEHL5JP86ePSu6d+/eIdsds2bNEt21a9fEdiwbM3DgQADA9u3bPe5JbDBSE3PQ1MQcvkk/Tp48KXrChAke9iR7M2nSJNGTJ08GkD7rBAQuuPTo0SN5HYsBRmpiDt9EauIdJ06cED106FDRrnzGfffdJ23PPPOM6DJlyiShd7HDSE3MQVMTc/gm/Xj//fejfm/btm0T2JPsxyOPPCJaL4OXKFECADBixAhp82vKoWGkJuagqYk5fJN+rFy5Mur31qtXL4E9yR588MEHoufMmRPyPW6m47LLLktKn+IFIzUxR44IpXwTXodiy5YtAIBKlSpJ2/nz5zP8jD7OVaNGjcR0LPP4uu7Hzp07AQT+vfU89f/8z/+InjhxYqK7Ew9Y94PYh6Ym5vB8oDhy5EgAkVMOAGjTpg0AoEqVKgntkzWOHj0q+o477gAAHD9+XNp0CjdmzJjkdSxBMFITc9DUxByepx+///57zO9dtGhRxPe60f3ll1+eqX5Zwu2LBtJnjvQe6bS0NNEFCxZMXscSBCM1MQdNTczhyeLLTz/9JLpJkyYAAneHxQOXfpQrVy7k66NGjRJdu3bteH617xZf9LYCtx2hevXq0rZkyRLRmU0/3ALOJ598Im3Tpk0Tfemll4r+29/+BgCoWLFipr7rIrj4QuzjyUDR7dMFgPLlywOILlL/+c9/BhBYh2Lr1q0h37tx48aA/72Ybdu2iZ4/fz4Au4PKXbt2iXaR+KGHHgpqi4apU6eK1vusDx8+DCC6/45ffPEFAGD9+vVRf28sMFITc9DUxByepB/FihUTrQcQkdi/fz+AwF1lmUUvy0cYLKc8+t9XuHBhAOmDtYxwKVr//v2lTQ/+Qn2Hnv/WaY1eqj927Fg03c40jNTEHDQ1MYcn6Yc+uhXuKFEows1kOAoVKiT62muvDfouzebNm0W7EbubibGAK5gOBFaOzZMnT4afc4cIAKBZs2YAgJ9//lnadHqh5/f79esX9KxrrrlG9Pjx40UvXLgwwz5kFUZqYg7PNzTFE31z1JtvvgkAaN++vbS5+ejsgI6Ge/fuFR3pEO306dNFb9q0CUBgdO7evbvoF154QXSkXwC9gukGm7qPbmU5HjBSE3PQ1MQcptKPsmXLiu7WrRuA8CmH/hkuWrRoYjuWorh55iFDhkibnt+OlHKEo3jx4gCA+vXrZ6F34WGkJuagqYk5PNlPrZdJW7duDSC6I1rxpG/fvqJHjx4dz0f7bj+13n3odtPp9QG3+xEA8ubNm6nvOHfuHIDAHYF6Sd1VDQDS1xBWrFiRqe+6CO6nJvahqYk5PK+lt2DBAgCBtz4dOnQobs/XBxJ0bbgWLVqIzp8/f9y+Dz5MP3RR9VdffRVA4ILKww8/LPree++N+rn6Jq99+/YBCLxLXpPAGn1MP4h9PI/UDn1187hx47L8PLdvWC/F1qpVK8vPjQLfRWo9eGvcuDGAwE1KYTsTYo90pPfqX8Z//OMfolu2bCk6s/PbYWCkJvahqYk5fJN+nD59WvRLL70ketCgQaLdXGg4XMoBpJ9Yvu666+LVxWjxXfqhcSfx//73v0ubPiGuj9c1bNgQAJAzZ+TYV6BAAQCBg9KSJUtmrbPRwfSD2IemJubwTfphCF+nHwZh+kHsQ1MTc9DUxBw0NTEHTU3MQVMTc9DUxBw0NTEHTU3MQVMTc9DUxBw0NTEHTU3MQVMTc9DUxBw0NTEHTU3MQVMTc9DUxBw0NTEHTU3MQVMTc9DUxBw0NTEHTU3MQVMTcyTkclB3A5S+VPLo0aOi33rrLdH58uUDAHTq1Cnks9q0aSP6xhtvBJB+uSQhoWCkJuagqYk5ElL1dPHixQCAm2++OTMfD0vp0qUBAH/961+lrUOHDqKrV68e1+/LJKx6mlxY9ZTYJyGR+qeffgIQeDeivrXJRVwAqFatGgDg4MGD0rZjxw7R+tqMmTNnBn3XH/6QPtYdOnSoaHdNc2avJc4CjNTJhZGa2IemJuZI6PUYFy5cCNkezW1P0gHVv/PnzwMA7rjjDmmbN29eyM+9++67AIAuXbpE/V1xIiXSD3ftMgCsX78+pHaXihYqVEja5s6dK9rd9AUAd955JwBg/Pjx8e9sxjD9IPahqYk5fH87l05hVq5cCSD9pw4A9u7dK7pdu3aiXfqRP3/+RHfxYjxLP44cOSJazxTp2aQzZ84AACZPnixte/bsycrXAgBy584NIP1SViD9ctEEw/SD2IemJuZIyC69eLJ69WrR9evXD3q9V69eovv37y/ag7TDMz788EMAQO/evaVt8+bNSe3D2bNnAQDvvfeetCUp/QiCkZqYw5eR+tdffxXdqlWroNe7d+8uetCgQaIvueSShPbLrxw4cABA+Ohcr1490Tly/Gdc9dBDD0lbgwYNRF9zzTUZfteJEydEFy5cOPbOJgFGamIOmpqYw5fpR48ePUTv379ftBsIPv3009KWK1eu5HXMp7ijcHqe+rbbbhN99dVXi45li0Io9K7IULRt2zZLz48HjNTEHDQ1MYcvl8n/+Mc/is6TJ4/oDRs2AADKlCmT9D7FQErs0sssc+bMER0q1Vi2bJnoUOsKCYDL5MQ+vhwovvTSS6L1IdsKFSoAAO6//35pq1Gjhui6deuKLlu2LACgZMmSiepmtkTvodZUrFgRAHDDDTckszshYaQm5qCpiTl8mX40b95cdLdu3US//fbbAICJEydGfIYbTN50003S1r59e9G33nqr6IIFC2a+s9kMtx/7Ytxe9qzOg8cD73tASJyhqYk5fDlPHQ53LOmzzz6Tto8++ki0O+4FALt3787wWTrleP/99wEAzZo1i0c3Tc9T6xmmb775RrTbOfnKK68ku0ucpyb2oamJOXw5+xEOt6DStWtXadNaF3b/6quvAADr1q2TNleNFQhMYdzpdJ3K3HLLLfHqdrbAT1sXGKmJOXwfqfVA9uTJkwCAn3/+Wdpc1VQgcPDXokWLgP8FAg+mrlmzRvSYMWMABNYNcZVbAeDSSy/N/D/AAK78GBC+Roir++EHGKmJOWhqYg5fph/udi8AmDBhgugnn3wSQODtXuXLlxddpEiRqL+jZs2aot3yu967PXz4cNGvvvpq1M+1yPPPPy/6t99+C/meJk2aJKs7EWGkJuagqYk5fJN+LFmyRPTAgQNFf/3116JHjx4NALj33nulLbO7wnTRcZd+aA4dOpSp52YnmjZtKrpOnToe9iQQRmpiDs8jtYuYrVu3ljY9UNQDtn79+kX9XHeVht7/6yI9EFif2W2U0jUtdLHJ7E64a0703LQf9lE7/NMTQuIETU3M4Xn64dIAnXJopk6dKnrjxo1RP9fVtXa1QjLCpR2bNm2StiuvvDLq77LOO++8E7LdbTDzG4zUxBw0NTGH58e53K4vXaXzu+++S8h36XJm7vYuIL0Ay2WXXRaPrzF3nKt48eKi9R3y06dPF92xY8ek9knB41zEPjQ1MYfn6YdDX/K5dOlS0bNmzRLtZkJ0vTZ9R4m+BPOKK64AAFSqVEnaWrZsKVofLogzZtKPrVu3AgCqVq0qbW5RCwjcsefhfTtMP4h9fBOpDWEmUvft2xdA4H5qXRJu/vz5Se9TCBipiX1oamIOz5fJiX/55ZdfgtoiXR7qBxipiTloamIOph8kLC7V0JVO/XCnSyQYqYk5OE8df8zMU6cInKcm9qGpiTloamIOmpqYg6Ym5qCpiTloamIOmpqYg6Ym5qCpiTloamIOmpqYg6Ym5qCpiTloamIOmpqYg6Ym5qCpiTloamIOmpqYg6Ym5shWdT90zYqVK1eK/vbbbwEAtWrVSnqfMsvRo0dF60tPI+GuBdm2bVvUn9EVB3LkSD+8XbRoUdHdu3cP+tyyZctEP/DAA6LvuusuAEC+fPmi7kMsMFITc9DUxBzmi9m4wuEAMHbsWNH63x3n9CMpxWwGDx4setSoUVn4ysiESz8yS5UqVQAACxYskLYyZcpk9nEsZkPsQ1MTcyRt9uP1118XPXToUNETJ04EANxxxx1RP+v06dOijxw5Ilrf5OVG4xMmTJA2/TNaqlQp0X69Yzsr6J9zd/c6ENusR6JYv349AGDQoEHSpv2RM2fWYi0jNTFHQiP1jBkzRD/66KOidaR96qmnAIS/uvnAgQOi3cDi3LlzIZ+1fft20R9++CEA4MyZMyGfW6xYMdElS5YM/4/wKaH6rKPz8uXLRev54EWLFmX43NWrV4uuXr06ACB37txR90v/N1+zZo3oUFdtvPPOO6L1L2qBAgWi/r5QMFITc9DUxBwJnaceMmSI6BEjRmTlUWHRg4rrr79e9IoVKzL8nBugAkC3bt3i2aWkzFPrFMwtO3/xxRfS9o9//EN0586ds9ClzPPaa6+JDrWMrtED/hjTD85TE/vQ1MQcCU0/9E6yN954Q7SeT9aj7Ui0adMGQODPU+XKlUVfe+21olu1apXhszZv3iy6QoUKUfchCpJ+58sPP/wAIHCu/8KFC6L1jEec/61BzJ49W/SDDz4oWqcXjg4dOoieMmWK6Fy5csXylUw/iH1oamKOhC6+FCxYUHSPHj1C6qyiU5yKFSsGvV66dGnR7du3D9me6rhFkiVLlkjbyZMnRSc65dBMmjRJdKiUQ3PppZeKjjHlyBBGamKOlD/OtXjxYtG7d+8Oer1q1aqiX3zxRdFZ3TTjRy6//PKkfp+OxK+88goAYOnSpRE/535Re/bsmZB+2fsvS7I9NDUxR0qmH6dOnRI9bNiwDN/bokUL0RZTDi/55JNPRD/xxBNRf27atGkAgPLly8e9TwAjNTEITU3MkZLpx4YNG0SvWrUq5HvcrEc858QJ0K9fP9F6NikSzz33nOhq1arFtU8Xw0hNzJFSkXrv3r0AgAEDBoR8XR8wdfuldRvJHA0aNBCtj4mFQv+9dT2StLS0+HcsDIzUxBw0NTFHSv02uw078+fPD/m63k984403JqVP1jh+/Lho93fWKUe4smN58uQBEHhsr3fv3onoYkQYqYk5aGpiDt+nH/pYkj4G5ihUqJBofXqZRI/ebacrw44cOTLDz+mjdM888wwAoHXr1nHuXewwUhNz0NTEHL5PP/S9IW53l6Zx48aiL7nkkqT0yQKHDh0SrYvd/POf/8zwc5UqVRL98ccfi77iiivi17kswkhNzOH7SK2rYTpKlCghWpcPI5H55ptvAAAPP/ywtH3//fcZfuaWW24RPXnyZNGJ2g+dVRipiTloamIOX6YfM2fODKkd+mcvC7c6ZRsOHjwo2l1NEinlAICrr74aQOTBo99gpCbmoKmJOXyTfvz444+in376adF6mdzdXaJvdSKR6dOnj+hwOxwdes5aH8FKJRipiTl8E6l1nepwg5j+/fsDANq2bZuUPqUy+lYzd011OHSdaP0rmaqDcEZqYg6ampjDN+nH3LlzQ7brGhHhTpGTYH777TfRa9euDXr9mmuuEf3yyy+LtrApjJGamIOmJubwPP1wl1w2atRI2ooUKSJaX6Gg79gmGVOqVCnR+noMd0e4vqzTQsqhYaQm5qCpiTkSejloNiXpl4Nmc3g5KLEPTU3MQVMTc9DUxBw0NTEHTU3MQVMTc9DUxBw0NTEHTU3MQVMTc9DUxBw0NTEHTU3MQVMTc3h+nCsS58+fF+1Kk02fPl3aZs+eLXrDhg2iixYtCgD49NNPpa1evXoJ6yfxD4zUxBw0NTGHL9OPHTt2iB49erToUPe/aPS92YcPHwYAzJs3T9p0+vH555+L3rlzJwDgpptukja/3meSEfponi5m89FHHwW999prrxX9X//1X6ILFiwo+k9/+lO8u5gUGKmJOXxz8FZH1F69eoneuHFj0Ht1FG3evLnor7/+WnSBAgUAAEuXLpW2XLlyiW7ZsmXQd+v6GLo/uj0KPDt4265dO9F6AB0L+j7EGjVqAAisinrPPfeI1r+MHsKDt8Q+NDUxh2/Sj1q1aonWRdfz5Mkj2l1o+cwzz0ibSzMA4IsvvhB95swZAMBtt90mbcePHxfdsGFD0WvWrAnqT5s2bUR/8MEHUf4rAHiYflSuXFm0nrOPJ61atRI9ZMgQ0XXr1k3I90UB0w9iH5qamMPz9GPatGkAAkfVuk/NmjUTHelmKc3Zs2cBAMuWLZO2Tp06id6zZ0/QZ/LmzSu6RYsWomOcSfAs/di6davod999NyuPApC+xeDnn3+Wtv3794vW1VJXrVoFwJP5faYfxD6eryi61cNwvxglSpSI+lnbtm0T/eCDDwIIHDyGw11XrAc+Xbp0ifp7/YKOkoMHD87y89wzdHR+8cUXRY8YMUK0W1uIcVCdEBipiTloamIOzweKJ06cABC4FK0HcYULFxbt0gs9Nz158mTR+npnfTmmQ1+v0b59e9Fu05S+iiMLmKtPrdMPvflp7969oitVqgQgcfPjGcCBIrEPTU3M4Xn64Zg4caLoRx99NOR7SpYsCQC4+eabpW3GjBkh3+tSFD03nZaWJlovKccZM+nH1KlTAQCPPPKItLl96gCQM2d6THRH7PSOviTB9IPYh6Ym5vBN+uGWtQHgrbfeEu125kWDHpmPHDkSAHDnnXdmvXOxkXLph04p9AKUOz4XziM6nRs7dmyCehcRph/EPp4vkzty584tWh+Q1Yc/jx07luEz9Oc8iNAphbs+Gwg8Bvbll18GvVcPCHv27Cnaw+icIYzUxBw0NTGHb9IPfdSqd+/eoiOlHJq5c+eKLlu2LADgqaeeynrnDOHKuOljWaFSDiB9rn/SpEnS1rlz5wT2Lj4wUhNz0NTEHL5JP/QOO10STBegcXPPt9xyi7TpYjZ6N9nw4cMBBB7RGjhwYBx7nJq4jf0LFiwI+brePuDKlcVYzCck+r/Nvn37AAQe4NCvFylSRLQrg/bQQw9F/V2M1MQcnq8ouv3QehOTXl2sU6eO6JUrVwZ9XpcV69u3r+gVK1YASN8EBQCbN28WncDih75eUWzQoAGAwBJtpUuXFr1u3TrRxYoVy/BZW7ZsEe0OOOuDzrqeytq1a0WHGvz/8Y9/FF2zZk3R7he3adOm4brBFUViH5qamMOT9EMPCq6//noAgTUr3NEgAPi///s/0ZFOlutrM0LNp86cOVO0Ps4VZ3ydfowZMwYA0L9/f2nTx+MqVqwY9bO+++67qN+rj9K5EnM6pejYsaPoqlWrRv1cMP0g2QGampjDk/RDF1X/+9//DiDw50mXzMpsmuDmp/VMii728q9//StTz40CX6cfrhqsPub22WefiT516lSmnut2WZYrV07adCVUPTN13XXXZeo7wsD0g9iHpibm8GSZXO/6cgwYMEB0ZlOOKVOmiNZph+O+++7L1HMt4YrY65p348aNE62P0p0+fRpAYNGaKlWqiH788cdF33DDDQACK6HqWZVkwkhNzJG0SK1v2dJHiRytW7fO1HPXr18v+r333svwva66KQlED9z1dgW391oPHt312H6GkZqYg6Ym5vBknlrvlz1y5AgAoHjx4tJWvXp10foST4cuNabTGvcsTbVq1UQvX75ctN4VFmd8PU9tEM5TE/vQ1MQcnqQf+hiPq5L5+++/x/U7XNry+uuvS1upUqXi+h1hYPqRXJh+EPvQ1MQcnp9RdOfcXIVNIPAyyk8++STDz+sC7E888YToJk2aAABy5MhKNpApmH4kF6YfxD6eR2qDMFInF0ZqYh+ampiDpibmoKmJOWhqYg6ampiDpibmoKmJOWhqYg6ampiDpibmoKmJOWhqYg6ampiDpibmoKmJOWhqYg6ampjDN9c4xwN9k1eXLl0AAEOHDpW2WK4CJqkLIzUxB01NzGEq/dA3bm3btg0AMGvWLGlj+pE9YKQm5qCpiTlMpR+HDh0Kagt1vwyxDSM1MUfKR+qlS5eKHjx4cNDrrVq1SmZ3iA9gpCbmoKmJOVI+/dA3bh0/flx0vnz5AAB33XVX0vtEvIWRmpiDpibmSMn0Y8eOHaJHjhwZ8j233347AKBs2bJJ6ZNlzpw5I3rt2rWi9b3wW7duDWr79ttvRe/evTvD79DXnOTJk0e0uzalZMmSUfeXkZqYg6Ym5kjJ9OPtt98WrS8V1TdxpaWlJbVPlpkzZ47oxx57TPS+ffsy9bw//OE/tqtZs6a0FStWTLReRIsl7XAwUhNzpGSk1nPTmoYNG4quX79+srpjitOnT4uePn06AOCBBx6Qtly5com+4oorRA8ZMgRA4K9lrVq1RJcpU0a0e0+JEiXi1OtAGKmJOWhqYo6USj++//57AMBXX30V8vU6deoksztmOHHihOgaNWqI3rx5M4DAlEKf2K9Xr14Sehc7jNTEHDQ1MUdKpR9uNH7w4EFpc3OeANC2bduk9ylV0UvfTZo0Ee1SDiB9xqJNmzbS9tRTT4V8XuXKlQEA7du3l7Ybb7wxLn2NFUZqYg7fR+pTp06JXrNmTdDrnTt3Fu1VZEhFnnzySdErVqwI+Z5du3YBACZOnBjxefPnzwcQuMLboEED0TlzJi9+MlITc9DUxBy+Tz+effZZ0Z999lnQ64laarWO3ih01VVXiW7UqJFot+FIDyTdMbmL6datGwBgyZIl0nb+/HnRTD8IyQI0NTFHjn//+98ZvZ7hi4lCF6jRO8TcHKpentUpSZEiRZLQu4jkiPyWsCTt733hwoWQ7bGkCa6yLJB+fK5cuXLSpvdh6/WEOBP092akJuagqYk5fDn7MWnSJNF62dbRuHFj0T5JOVKOzM5GbN++XXT37t1Fu6NdAwYMkLYEphwZwkhNzOHLSB1u2dbtl+ah2tC4wRoALFq0SLTekORuK9Pz1HruOW/evKJdvW89GO/Xr5/o/fv3ix4xYgSAwG0LXsFITcxBUxNz+GaeWu/THTZsmOiCBQuK/vDDDwEElqjyIZ7NU1esWFH0zz//nOF7dZ2N4sWLiy5cuLDojRs3AgCOHj0qbTpVmTp1qmid4iQZzlMT+9DUxByepx979+4FELhTTBdP13Ohr7zySqK7Ew88Sz90mvDSSy+JXrVqleiFCxdG/TyX+unC9a5oDeCbNQKmH8Q+nsxT6322rr60js6aDh06JKVPFtCD6kGDBnnYE29hpCbmoKmJOTwZKO7Zs0d06dKlg16/5557RL/55puic+fOnYjuxJuU2E9tCA4UiX1oamIOT2Y/9FKrSz/0Eu+oUaNEp0jKQXwEIzUxB01NzOH5MrlBOPuRXDj7QexDUxNz0NTEHDQ1MQdNTcxBUxNz0NTEHDQ1MQdNTcxBUxNz0NTEHDQ1MQdNTcxBUxNz0NTEHDQ1MQdNTcxBUxNz0NTEHDQ1MQdNTcxBUxNz0NTEHDQ1MQdNTcxBUxNz+PJu8njSsWNH0cuXLxc9ffp00fXr109qn5KBvpu8cePGokuVKgUAGDx4sLQ9/PDDoi1UmWWkJuagqYk5fJl+XH755aJ79uwpOi0tLcPPff3110Hv1SmHZtu2baItph/6QtAcOdILg+7btw8A0KNHD2n75z//KVpf+NmwYUMAQPv27aWtaNGi8e9snGGkJubwTX1qHYXHjRsX8j3uOuGZM2dm+ft+++030eXKlcvy8xS+qE/966+/itYDRf3vjtiZ/++NatWqSdvQoUNFt2vXLgs9jBusT03sQ1MTc/gm/dCDQz2Iiyd6blrPX8cZX6Qfml27donev39/0Ovr1q0T/cILL4h2g0090NT3n//tb38TPWLEiPh0NnaYfhD70NTEHJ6nHy4NCDejUa9ePdFulqJDhw7Stn37dtG9e/cO+rye2Yhl5J8FfJd+xMLx48dFN2nSBEDgnLemdu3aor/88ksAQIECBRLYu5Aw/SD28WRFMdKg0M1HA8CMGTMyfFakAd/zzz8fY++yNzrSLly4EADQsmVLaVuyZIloHcGHDx8OABg9enSiuxgRRmpiDpqamCNpA0WdRtx9991Br8eScmj0HKrGDRCTNDjUpPRAMRSbNm0SXbduXdFHjx4VXaVKFQDA2rVrk9ex/8CBIrEPTU3MkbTZD71nWacajrFjx0b9rEj7qoHAfdgka1SsWFG0XjfQ+7DXr1+f1D5lBCM1MQdNTcyRtPRDL1fHMrsRCr00Hg6LR7RIdDBSE3P48uBtONySerjNT/rXgJE6+8JITcxBUxNzpFT6Ee6UuYM78hKP3lYRYYuFZzBSE3PQ1MQcKZV+zJo1K8PXE3hCnPx/9K7IcDskvYaRmpjD95Fab14KdfQrlo1QJHNs2bJF9LfffhvyPeXLl09WdyLCSE3MQVMTc/g+/dA1p0PB5fDEcfLkSQBAnz59pO3AgQMh3ztkyJCk9CkaGKmJOWhqYg7Py46FQqccDRo0CHrdg1JisWDmNPnu3bsBAGXLlg35uj6WN2XKFABAzpxJj5M8TU7sQ1MTc/hy9iPSnS7cjZccFi9eDCD8brxixYqJ9iDtCIt/ekJInPBNpNbXMoTbuOQGiNy4lBxWr14NIPzGJX2/op9gpCbmoKmJOTxPP9zOu1BXW1wMB4j+YuDAgaI9vB4jCEZqYg6ampjD8/Qj0glxvRTLWQ9/4QqtA/5IOxyM1J2Y1OEAABWESURBVMQcnkdqV+9Yb1LS9OrVK5ndIYo6deoEtelfzieffDKZ3YkaRmpiDpqamMOX+6lTHDP7qVME7qcm9qGpiTloamIOmpqYg6Ym5qCpiTloamIOmpqYg6Ym5qCpiTloamIOmpqYg6Ym5qCpiTloamIOmpqYg6Ym5qCpiTk8P01O/MWiRYtEN27cGAAwdOjQTD3rqaeeikOPYoeRmpiDpibm4Gny+JNyp8lDpRzxRqcwcU5LeJqc2IemJuZI6OzH9u3bRZ84cSLqz33++eeiN2zYEPT6nj17RM+YMSOTvUvnnnvuAQAMGzZM2ipUqJDl56YKOv1IFO6mr2TASE3MkdCBYosWLUQvWLAgK49KCvny5RPtrnsAgBtuuCGWx6TcQDHc7VsO/be4+eabRccy4EvgnDUHisQ+NDUxR0IHin662jcaSpQoIbpatWoe9iTxRDM4dGmHTjk0Xi2DRyK1XEdIFNDUxBwJnf3YunWr6M6dO4veuHGj6EOHDgEAKlWqJG25c+fO8LmlSpUSre8g0fzyyy8AgOeeey7q/uo7TlauXBn15y4iJWY/9HJ4uFQkgjf8Amc/iH082dCkI/XOnTsBAA0aNJC2vHnzZvk73LXQke5p1MyePVv0nXfemdmvTolIHWluGkjfhKQHiuEGjR7CSE3sQ1MTc5jaTz1//nzRbdu2BQCcOnUq4uceeOABAMDkyZOlLZqf5zCYST8iEW75PMkw/SD2oamJOVI+/dAzKffdd5/oSPPMjRo1Eu1mPYoWLRqPLqVE+hHvI1xupsSDpXOmH8Q+NDUxR8qnH/Xq1RMdKeXInz+/aD1yv/766+PZpZRIP8Kh0xI3o6FTCn3kTePeq/+uSYLpB7FPSkVqN+fct29faXvttddEnz17Nugzesn9/fffF92yZctEdBFI8UgdiUhRO4H1PcLBSE3sQ1MTc/i+6umBAwdE9+nTBwDw9ttvR/xcwYIFAQSmKglMOYiPYKQm5qCpiTl8n35MmDBBdDRph+Puu+8GAAwePDjufSL+hpGamIOmJubwZfqhF1SefvrpqD93xx13iNZpC8leMFITc/gmUutjV88++6zoc+fOZfi5kiVLitbLsnny5Ilf57I5epNTuA1NfoKRmpiDpibm8E368cQTT4j+9ddfo/7cG2+8IbpWrVrx7JIZQu2si+UkeCzXZ/ihEiojNTEHTU3M4Xn6cfLkSQDAlClTIr7XFWDp37+/tN16662J6Zhx9AlynX7oTf4u7YhmxiOz95cnAkZqYg5PjnMdO3ZMtCv5pY9ahaNIkSIAgIMHDyaiW/HCd8e5knFNc6SrNBIIj3MR+9DUxByeDBQ//vhj0dGkHQ533TKJDZ0SuDRBD/4ye42zHhz6qRg7IzUxB01NzOFJ+rF48eKo39uxY0fR48ePT0R3shUuTdDpQrhdeKHSEg+K1cQMIzUxB01NzOFJ+lGuXLmo31ujRg3RuXLlSkR3sj0+v1IuZhipiTk8idRuaRwAli1bBgD49NNPpa1EiRKiy5Qpk7yOERMwUhNz0NTEHClVdD1F8N0uPeNwlx6xD01NzEFTE3PQ1MQcNDUxB01NzEFTE3PQ1MQcNDUxB01NzEFTE3PQ1MQcNDUxh+dVT4l/+eKLLwAEXrC6fPly0TfccIPor776CoA/jtwxUhNz+HI/9c6dO0XrCqkbN24EAIwaNUraChcuLHrevHmiXS3rAQMGSFvt2rVFt2/fPo49DiDl9lOfOHFCtLv+Gkj/e54/fz7k57R33nnnHQDAvffem4guZgT3UxP70NTEHL5JP7Zt2yZaX8e8efNm0e5n8MyZMyGfof8tLv3Q5M6dW3RaWproRx55BABw2WWXxdrtUKRE+vH999+Lfvzxx0UvWbIk6L1Vq1YV/eOPP4rWf+/WrVsDAObOnRvXfkYB0w9iH5qamMPzeerPPvsMAHD//fdL2/79+zP8jL53vHPnzqIjpR9z5swRPXr0aNFNmzYFELf0w9ccP34cANCnTx9p0ymHLjs2btw4AEClSpWkTacXnTp1Eh0uJfQCRmpiDs8j9bPPPgsgfHTWg0YXXXPmTP//4jXXXBP1dz355JOiY6mRbQm3OuhWCwGgTZs2ovUvWKi/rZ7H/t///V/RBQoUiGs/swIjNTEHTU3M4Xn6cddddwEAli5dGvJ1XSFVD1gyw5VXXim6ePHiWXpWKrF+/XrRb775JgCgZMmS0jZx4kTRpUqVivq5FSpUED1w4MCg16dPny766aefDnq9Tp06ot94442ovzcSjNTEHDQ1MYfny+T79u0DANx0003S5nbjAcAtt9wiesyYMQCAmjVrxrUPbiegvo3K9QsITIGiwHfL5C+++KLonj17AghM5fSMxqBBg0Tr9YDMsHDhQtHt2rUTfeTIEQBA3rx5pc0V3weAWrVqxfI1XCYn9qGpiTk8n/1w97t0795d2txPJBC4SNCwYUMAwMsvvyxt//3f/x31dx09elS0Xnx54YUXgtry588vunTp0qJvu+22qL/PL1SpUiWoTc8E7d27V/SqVatEN2jQIEvfW7FixZDPcocPChUqJG1XXXVVlr5Lw0hNzOF5pHZ06NBBtJ7f/Prrr0W7Y0cPP/ywtP3hD+n/hL/85S+i3ZGw1atXS5vboANEXibPly+faB3JUhE94HODbH1M7uOPPxatl7szE6l3794t+q9//avozz//XLT7JS5fvry06WN5WYWRmpiDpibm8HyeOhR79uwRrXeQrVy5MsPPuWNZADB58mQAse3z1TUr3OloIHDfcBT4bp46FDpVmzZtmmi3bQEITAMdeu+1G2AD6Ze46jWGL7/8UnS1atVE66NkcYDz1MQ+NDUxh29mPzR6p5gembdo0QIA8O2334b8nJ6/DnWcKxzlypUDEFheK8aUI+XQs0Y6BZ0xY4bogwcPAgi8K16nH9u3bxft/ps9+OCD0qaXycuWLRuPbkcFIzUxh28i9a+//ip66tSpoqdMmSJ63bp1GT4jwqA3YH77iSeeEJ0dDtxejJ4jDverpldzQ6F/Ud966y0AQPPmzaVtyJAhovUvQ6JhpCbmoKmJOTxPP7Zs2QIAaNWqlbRt2rQp5HtjGfy5927YsEHa9PEjfSI9O+H+3uGOz4XC1UW5WOulbTeI1+itBskke/6XJaahqYk5PFkmnzlzpmg3Qg6XcoRCX8ugC4b/8MMPol36octk3X777bF3NnZ8t0y+detW0e7YnP7vro/Mfffdd6JDLWfrfeb6uR6ezucyObEPTU3MkbTZj/fee090165dRZ89ezbovcWKFROtDw+4zeW6EMtzzz0nWqcfjg8++EB0ktIP36H/Rr/99huAwLRM1ytcsWKF6G7dugEITEN0ujdr1izRemHLaxipiTmSFqkPHz4sOlR0rlu3rujXX39ddKhDoyTrhPu76kG4O4712GOPhXyvvg2NkZqQBEJTE3N4vkzu0APCSCmHvqxSn14Ohd7fS9LRl6PqiqV6udvduKUHmnpu+pdffhF97tw5AMndjRcORmpiDpqamCNpvxV67llf0ulmQmbPni1tLVu2FK038BcsWBBA4IGCt99+O+T3uV1/urB3duWee+4RvWbNmoD/BQJvONN/b1cKzFUpvRg97++nXY/+6QkhccKTDU36gOvzzz8PIPTcNRB4r587IKvrf+g6E/rf4sqKuaKSScR3G5pCoVdadXFOXZc7EnpO2+3P1rVTkgQ3NBH70NTEHJ6XHXMXdk6YMEHaTp48KTpcWhIKvTHH1a/I6hUPmSAl0g+N3sv+6KOPinanyfUxuLS0NNFuHhtIbl2Pi2D6QexDUxNzeJ5+hEIXsxk1apRoN4eqTynrEXj//v2T0LuIpFz6keIw/SD2oamJOXyZfqQ4TD+SC9MPYh+ampiDpibmoKmJOWhqYg6ampiDpibmoKmJOWhqYg6ampiDpibmoKmJOWhqYg6ampiDpibmoKmJOWhqYg6ampiDpibmoKmJOWhqYg6ampiDpibm8P4qJZJUdu3aBQDYs2ePtOlC6VdeeaVod2XJsmXLpG3dunWib7zxRtHuctDy5cvHucexw0hNzEFTE3MkrezY6dOnRQ8bNky0uyVK3951/Phx0cuXLw9qHzJkiLTpe7N1NVQP8XXZsapVqwIITCP0hZ6VKlUSrd8TiUsuuQQA8Mwzz0ibvmUtgUXZWXaM2IemJuZIaPqxd+9e0S+//LLo4cOHp3cgR8a/1rp/od6rr5QbP3686Fq1asXW2fjh6/TDXfH32muvSZu+bDXUHTulSpUSXahQIdH6errDhw8Hfa5Xr16ix4wZIzrO95cz/SD2SWikHjBggGj9/9RI0VdfedGuXTvRbqA4Z84cafvhhx9ElyhRQvSbb74JIHCwkiR8HalD4S72BAIH9I7KlSuLvvTSS0XrQXzPnj0BACtWrAj5HTt27Aj5jDjASE3sQ1MTcyQ0/di2bZvo/fv3i545c6boZ599FgBQvHhxaduyZYvoggULBj1XD2amT58uum/fvqLz588PAPj++++l7U9/+lNs/4DMkXLpR2bREwGNGjUCEHhX/HXXXSd60aJFokP9N80CTD+IfWhqYo6E7tIrV65cSP3jjz+KdunPtddeK22Rfp5y584tukuXLqL1yL1r164AgH/961/SVq1ataj7TkKjU8r7779ftE47HCNHjhQd55QjQxipiTk82U+t/1/r5qkjrSxGg36G0/PmzZM2Rup0Zs2aJVqvEjZv3jzovefOnROtNywtXLhQdJ48eQAA7777rrRdf/31oi9cuCA6Z87ExlJGamIOmpqYw5P04+DBg0Ftej91ZmnSpElQm17K1fPberCZnXB/e7esDQRuTNLbElwKV7JkSWl79dVXQz63TJkyANKPgAFAjx49RDdr1kz0O++8k6m+RwsjNTEHTU3M4Un6UbNmzaC2Rx99NOLnjh49CiBw5H7s2DHRoXaI6Z9DvWPvL3/5i+gHHngg4ndbwZ0c1zMTetfjtGnTMvXcrVu3Bvzvxej57UTDSE3MQVMTcyTtNHk82LBhA4DATevxYMqUKQCAzp07x+NxKbdLT+901OncSy+9BCBwp2M43DYHvbB2xRVXiG7durVovbUhDnCXHrFPSpYdC7ekHumYmEaX2tLzsNmRu+++O2S7Oz6n55s1eg2gSpUqAJK7cSkcjNTEHDQ1MUdKDRTPnDkDAFi9erW06XoiK1euFL1582YAQO3ataWtY8eOouvXry9aV++MAyk3UNTokm9uPWH79u3S9sYbb4ju1KmT6HjssswkHCgS+9DUxBwplX5EQv80uuNco0ePljZ92jyBpHT6kZaWJnrcuHEAApfUdYrnE5h+EPuk5Dx1OPSvToRfIKLQR63cAFvTtGnTZHYnyzBSE3PQ1MQcptIPPcfq4bxpynHkyBHRH330keiKFSsCCDxBngowUhNz0NTEHKbSjy+//NLrLqQk4XbhtWjRIsk9iQ+M1MQcNDUxh6n0w927TWJj8eLFXnchrjBSE3OkfKSeO3eu6FB1Py6//PJkdidl0NF5586dHvYk/jBSE3PQ1MQcKZ9+fPXVVyHb8+XLBwCoW7duMruTMugtBaGubk5lGKmJOWhqYo6UTz+qV68est2dIr/yyiuT2Z2UQc8K6QI0rrIsANx1111J7VO8YKQm5kj5SB2uzFWca3mYo2rVqqL1fmoLMFITc9DUxBym6n74hJSu+5GCsO4HsQ9NTcxBUxNz0NTEHDQ1MQdNTcxBUxNz0NTEHDQ1MQdNTcxBUxNz0NTEHDQ1MUfKHxIYPny46Oeff170p59+CoCHBbIjjNTEHCm/n7p8+fKit23bJrpBgwYAgKVLlya7S9xPnVy4n5rYh6Ym5kj5gWI43M1SJPP8/vvvAIDZs2dL21tvvRXyva6Katu2baVt3rx5oosXLy76zjvvBAAULVpU2u6++27RJUuWDKmjhZGamIOmJuYwO/sxY8YMAECHDh2S3SUzsx9dunQBAEydOjXie52PYrmUVXtPf07/N/3zn/8MAHj55ZelrVChQvoxnP0g9qGpiTlScvZDL6gcPnxYdK5cuUS7ouskNvbu3St62bJlnvShdOnSotetWwcgcNbl8ccfz/DzjNTEHCk5UHRL4EDgjVyXXXaZ6K1btya1T4qUGyju2LFDdNeuXUUvWLAgw8/pq0ecj86cOSNtzZs3F12mTBnRW7ZsARA4T62rsFapUiWkDgMHisQ+NDUxR0oNFNeuXQsAWL9+vcc9SX10ytGiRQvRbmAGpM8d6zSjdevWotPS0oKee+7cOdEFChSIT2djhJGamIOmJuZIqfRj3LhxAAJvkNLokTsJjZsVatasmbRt3rxZtJ4Ne/HFFwEAjz32WNTPz5s3b1a7mGUYqYk5aGpiDt8vvuidd3r3ViguXLiQ6O5Eg68XX4YNGwYg8BS+Ru+Ac/e+R7EA4iVcfCH28f1AcdeuXaJD7dW9/fbbk9mdlOfUqVMZvj537lzRPo/QYWGkJuagqYk5fJ9+jBw5MsPXW7ZsmaSe2GDnzp1BbWXLlhXdqFGjZHYnITBSE3PQ1MQcvkw/Vq9eLfrjjz8WHWr2o1WrVknpkxWuuuqqoLYKFSp40JPEwUhNzOHLSO1KWAGBG2wcEyZMEK2PcJHIuL+n/rvqv7f+Nezbty8AoE+fPtKWmTJgyYaRmpiDpibm8GX6oX8CQ+nrrrsu6X2ygqsuquto6E1jmrFjxwJIv2oECKxk6tfUj5GamIOmJubwZfpBEkflypUBAL169ZK2fv36iT579mzQZ3766SfR3bp1E63XEPwEIzUxB01NzOHL9GPSpEled8E8PXr0EO1SEgAYMmSI6G+++Sboc3qX3/Hjx0V7VbgmFIzUxBy+idRr1qwRrUti6eVcd/A20gFcEhu6OulNN90UpHXE3r9/v2hdf4WRmpAEQlMTc/gm/Rg/frzoY8eOidbL5O7YkS7gTbLOwYMHResSYytXrgx679VXXy1aX2PhJxipiTloamIO36QfmzZtCtmeP39+0b17905Wd8zy448/AgA+//xzaXv11VdF6/8OsVz06ScYqYk5fBOpNbVr1xatV7hYYix6Nm7cKLpTp06if/nlFwCBq4GRuOSSS0Q/99xzcehdYmGkJuagqYk5fF+fOgXxRX3qcuXKiQ5Vaiwcepm8TZs2AICmTZtKmw8robI+NbEPTU3MwfQj/vgi/dDF6g8dOiTa7bgrVqyYtOmyYz5MLyLB9IPYh6Ym5mD6EX98kX5kI5h+EPvQ1MQcNDUxB01NzBFpl15qbqhNXfj3jgOM1MQcNDUxB01NzEFTE3PQ1MQcNDUxx/8DYcxV5iPxWUkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x2160 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3 * batch_size))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_batch[:,0].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_batch[:,1].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roughly half will be a pair of the same and half will be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3\n",
    "\n",
    "Exercise: train the DNN on this training set. For each image pair, you can simultaneously feed the first image to DNN A and the second image to DNN B. The whole network will gradually learn to tell whether two images belong to the same class or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1, y_test1 = generate_batch(X_test, y_test, batch_size=len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 784)"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1[453].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train loss: 0.6891399\n",
      "0 Test accuracy: 0.5279\n",
      "1 Train loss: 0.5959447\n",
      "2 Train loss: 0.5107754\n",
      "3 Train loss: 0.48419416\n",
      "4 Train loss: 0.47330052\n",
      "5 Train loss: 0.41459125\n",
      "5 Test accuracy: 0.8028\n",
      "6 Train loss: 0.4419923\n",
      "7 Train loss: 0.40510884\n",
      "8 Train loss: 0.33301252\n",
      "9 Train loss: 0.36144537\n",
      "10 Train loss: 0.30094334\n",
      "10 Test accuracy: 0.8597\n",
      "11 Train loss: 0.32066968\n",
      "12 Train loss: 0.24406616\n",
      "13 Train loss: 0.2238958\n",
      "14 Train loss: 0.21029705\n",
      "15 Train loss: 0.20106173\n",
      "15 Test accuracy: 0.9148\n",
      "16 Train loss: 0.22492558\n",
      "17 Train loss: 0.19936816\n",
      "18 Train loss: 0.19617783\n",
      "19 Train loss: 0.18172024\n",
      "20 Train loss: 0.15426688\n",
      "20 Test accuracy: 0.9311\n",
      "21 Train loss: 0.17573786\n",
      "22 Train loss: 0.1638955\n",
      "23 Train loss: 0.15242475\n",
      "24 Train loss: 0.17002347\n",
      "25 Train loss: 0.12907042\n",
      "25 Test accuracy: 0.9461\n",
      "26 Train loss: 0.14714874\n",
      "27 Train loss: 0.119652875\n",
      "28 Train loss: 0.09090712\n",
      "29 Train loss: 0.09782021\n",
      "30 Train loss: 0.10042464\n",
      "30 Test accuracy: 0.956\n",
      "31 Train loss: 0.10888391\n",
      "32 Train loss: 0.099303275\n",
      "33 Train loss: 0.082117654\n",
      "34 Train loss: 0.11048612\n",
      "35 Train loss: 0.0954681\n",
      "35 Test accuracy: 0.9592\n",
      "36 Train loss: 0.10614097\n",
      "37 Train loss: 0.0991565\n",
      "38 Train loss: 0.09667903\n",
      "39 Train loss: 0.06960881\n",
      "40 Train loss: 0.052998222\n",
      "40 Test accuracy: 0.964\n",
      "41 Train loss: 0.08947876\n",
      "42 Train loss: 0.089089006\n",
      "43 Train loss: 0.057632864\n",
      "44 Train loss: 0.06430052\n",
      "45 Train loss: 0.095158786\n",
      "45 Test accuracy: 0.9692\n",
      "46 Train loss: 0.068611026\n",
      "47 Train loss: 0.06260999\n",
      "48 Train loss: 0.07400187\n",
      "49 Train loss: 0.05225881\n",
      "50 Train loss: 0.039890498\n",
      "50 Test accuracy: 0.9726\n",
      "51 Train loss: 0.06379468\n",
      "52 Train loss: 0.06494789\n",
      "53 Train loss: 0.11156485\n",
      "54 Train loss: 0.07228095\n",
      "55 Train loss: 0.041863587\n",
      "55 Test accuracy: 0.9737\n",
      "56 Train loss: 0.045539755\n",
      "57 Train loss: 0.03767406\n",
      "58 Train loss: 0.03570893\n",
      "59 Train loss: 0.04930964\n",
      "60 Train loss: 0.04183048\n",
      "60 Test accuracy: 0.9768\n",
      "61 Train loss: 0.041465864\n",
      "62 Train loss: 0.042684894\n",
      "63 Train loss: 0.03594726\n",
      "64 Train loss: 0.029296948\n",
      "65 Train loss: 0.055028886\n",
      "65 Test accuracy: 0.9758\n",
      "66 Train loss: 0.032518182\n",
      "67 Train loss: 0.029371377\n",
      "68 Train loss: 0.047739502\n",
      "69 Train loss: 0.050844483\n",
      "70 Train loss: 0.04227406\n",
      "70 Test accuracy: 0.9774\n",
      "71 Train loss: 0.043197125\n",
      "72 Train loss: 0.05167547\n",
      "73 Train loss: 0.02918692\n",
      "74 Train loss: 0.018039998\n",
      "75 Train loss: 0.06060684\n",
      "75 Test accuracy: 0.9783\n",
      "76 Train loss: 0.023043556\n",
      "77 Train loss: 0.04156868\n",
      "78 Train loss: 0.021386117\n",
      "79 Train loss: 0.027063942\n",
      "80 Train loss: 0.05665865\n",
      "80 Test accuracy: 0.9777\n",
      "81 Train loss: 0.055631343\n",
      "82 Train loss: 0.022038966\n",
      "83 Train loss: 0.03601816\n",
      "84 Train loss: 0.02373494\n",
      "85 Train loss: 0.030756164\n",
      "85 Test accuracy: 0.9801\n",
      "86 Train loss: 0.025630012\n",
      "87 Train loss: 0.019631825\n",
      "88 Train loss: 0.035956778\n",
      "89 Train loss: 0.020653663\n",
      "90 Train loss: 0.030662106\n",
      "90 Test accuracy: 0.9799\n",
      "91 Train loss: 0.02376088\n",
      "92 Train loss: 0.017748699\n",
      "93 Train loss: 0.00737618\n",
      "94 Train loss: 0.02101872\n",
      "95 Train loss: 0.021655116\n",
      "95 Test accuracy: 0.9781\n",
      "96 Train loss: 0.026423777\n",
      "97 Train loss: 0.019785995\n",
      "98 Train loss: 0.02071725\n",
      "99 Train loss: 0.020280348\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)\n",
    "            loss_val, _ = sess.run([loss, training_op], feed_dict={X: X_batch, y: y_batch})\n",
    "        print(epoch, \"Train loss:\", loss_val)\n",
    "        if epoch % 5 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_digit_comparison_model.ckpt\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5139, 784)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got 97.81%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 \n",
    "\n",
    "create a new DNN by reusing and freezing the hidden layers of DNN A and adding a softmax output layer on top with 10 neurons. Train this network on split #2 and see if you can achieve high performance despite having only 500 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28*28\n",
    "n_outputs = 10\n",
    "\n",
    "#create handles\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "\n",
    "dnn_outputs = dnn(X,name='DNN_A')\n",
    "frozen_outputs = tf.stop_gradient(dnn_outputs)\n",
    "\n",
    "logits = tf.layers.dense(frozen_outputs, n_outputs, kernel_initializer=he_init)\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
    "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_digit_comparison_model.ckpt\n",
      "0 Test accuracy: 0.9734\n",
      "10 Test accuracy: 0.9753\n",
      "20 Test accuracy: 0.9748\n",
      "30 Test accuracy: 0.9744\n",
      "40 Test accuracy: 0.9741\n",
      "50 Test accuracy: 0.9748\n",
      "60 Test accuracy: 0.9748\n",
      "70 Test accuracy: 0.9746\n",
      "80 Test accuracy: 0.9742\n",
      "90 Test accuracy: 0.9745\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_digit_comparison_model.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review the last couple of ones later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
